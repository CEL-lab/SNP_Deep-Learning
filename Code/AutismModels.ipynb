{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65632d65-776d-448e-ad35-4a1c816bf9bd",
   "metadata": {},
   "source": [
    "## Data / Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44997ae1-2c21-468a-b201-98f0eb7912fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Affy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, GRU, Layer, Add, GlobalAveragePooling1D, Conv1D, ReLU\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "import scipy.stats as stats\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from accelerate import DataLoaderConfiguration\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from boruta import BorutaPy\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0afce5-7974-403a-a986-91cb6c721cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508ca9eb-8576-484d-818d-dd71b14025f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AMGM and Cosine Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd34545-1573-47d1-85a9-c48bf0483b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_amgm(X):\n",
    "    \"\"\"\n",
    "    Calculate AMGM for each feature (row) in the dataset X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): The input data array with shape (n_features, n_samples)\n",
    "    \n",
    "    Returns:\n",
    "    amgm_values (numpy array): The AMGM values for each feature (row)\n",
    "    \"\"\"\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    exp_X = np.exp(X)\n",
    "    amgm_values = (np.mean(exp_X, axis=1)) / (np.exp(np.mean(X, axis=1)))\n",
    "    \n",
    "    return amgm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723387fa-70ff-411c-8447-8c99c2e5f6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_redundant_features(X, relevant_indices, threshold=0.9):\n",
    "    relevant_features = X[relevant_indices, :]\n",
    "    cos_sim_matrix = cosine_similarity(relevant_features)\n",
    "    \n",
    "    to_keep = []\n",
    "    to_drop = set()\n",
    "    for i in range(cos_sim_matrix.shape[0]):\n",
    "        if i not in to_drop:\n",
    "            to_keep.append(relevant_indices[i])\n",
    "            for j in range(i + 1, cos_sim_matrix.shape[0]):\n",
    "                if cos_sim_matrix[i, j] > threshold:\n",
    "                    to_drop.add(relevant_indices[j])\n",
    "    return to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3df9e-7543-450d-af9c-89e207a5dbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d62ae719-5186-4421-bfe5-9ce864b4f93a",
   "metadata": {},
   "source": [
    "## Autoencoder Feature Selection with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f38ed4e-2bc4-4d91-9695-e6c445c95359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_feature_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)  # Encoder part\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)  # Decoder part\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae52fec-1349-4a3f-9212-cc875a189551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_l1_feature_selection(X, y, alpha=0.01, target_features=100):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    model = SelectFromModel(lasso, prefit=True, max_features=target_features)\n",
    "    X_reduced = model.transform(X)\n",
    "    selected_indices = model.get_support(indices=True)\n",
    "    return X_reduced, selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740f2ce-7d55-4634-863b-c78c41dc616f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0118e359-dc48-4f2f-b38c-f6af84e50f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "599bfb4f-4c50-4455-abb4-1e8956c1082d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77792956-76b3-478d-bfb5-8dfd93c7c231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d37ff430-1494-4ecd-91b3-3ed990c0d671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_32760\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5948d16-b140-4eaa-95c1-6e0ceb0a33e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac6db28d-80c6-4a57-8647-33d51f104a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225783, 567)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc6bc41d-7325-4b27-8c54-812c6d7bdd85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58c179ac-ab03-43c8-9a8c-7173c8392dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1dfc405-372e-42c2-a6c2-348db635bac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [181304  81445    990 223008   2500 164820  81208  97283  81289  56849]\n",
      "Top AMGM values: [1.00451284 1.00451805 1.00451976 1.00452387 1.00452528 1.00452727\n",
      " 1.00452986 1.00453206 1.00453611 1.00453671]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f4a98a3-58cc-4b11-8888-baeda44c64c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "831f3e3c-4899-4be4-9a0a-1d2010512224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert X.shape[1] == len(y), \"Mismatch between number of samples in X and y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3c0b6b7-c86f-447a-b707-769d749a52b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84b1c2da-9181-4090-9a88-a2282d66973c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28c533ee-d6aa-497c-8a9a-22e2332f8fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "065c79d4-a752-4bbe-a399-04b8b273a982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c31a07bd-1bb7-4574-964c-786724a5a8db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d262a9d-1128-4397-bc79-2c3361fe4217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(567,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a43f491-a6fd-4873-b99a-977b7661d92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "deb765da-c5f8-4cf0-b372-fa2cf0225d8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 50)                1300      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12826 (50.10 KB)\n",
      "Trainable params: 12826 (50.10 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a10f2a8-a88d-4428-a33d-69bad82972f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 13ms/step - loss: 0.6749 - accuracy: 0.5581 - val_loss: 0.6349 - val_accuracy: 0.6491 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7128 - accuracy: 0.5606 - val_loss: 0.6331 - val_accuracy: 0.6491 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.5960 - val_loss: 0.6398 - val_accuracy: 0.7018 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6795 - accuracy: 0.5808 - val_loss: 0.6267 - val_accuracy: 0.6491 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.5909 - val_loss: 0.6256 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.5732 - val_loss: 0.6145 - val_accuracy: 0.6842 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6111 - val_loss: 0.6125 - val_accuracy: 0.7018 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6414 - val_loss: 0.5959 - val_accuracy: 0.7018 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6313 - val_loss: 0.6020 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.6313 - val_loss: 0.5922 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6717 - val_loss: 0.5761 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6641 - val_loss: 0.6051 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6667 - val_loss: 0.5739 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6338 - val_loss: 0.5850 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6338 - val_loss: 0.5807 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6667 - val_loss: 0.5738 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6793 - val_loss: 0.5911 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6641 - val_loss: 0.5679 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6442 - accuracy: 0.6490 - val_loss: 0.5821 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6995 - val_loss: 0.5774 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6641 - val_loss: 0.5811 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6616 - val_loss: 0.5925 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6869 - val_loss: 0.5738 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.6793 - val_loss: 0.5906 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.7020 - val_loss: 0.5681 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.7020 - val_loss: 0.5751 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6717 - val_loss: 0.5842 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.6894 - val_loss: 0.5700 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.7020 - val_loss: 0.5921 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6919 - val_loss: 0.5847 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.7071 - val_loss: 0.5741 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.7045 - val_loss: 0.5797 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6042 - accuracy: 0.7020 - val_loss: 0.5832 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7020 - val_loss: 0.5740 - val_accuracy: 0.7193 - lr: 0.0011\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7146 - val_loss: 0.5964 - val_accuracy: 0.7544 - lr: 0.0011\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.7172 - val_loss: 0.5912 - val_accuracy: 0.7544 - lr: 0.0011\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.6919 - val_loss: 0.5776 - val_accuracy: 0.7018 - lr: 0.0011\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.7121 - val_loss: 0.5844 - val_accuracy: 0.7544 - lr: 0.0011\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7045 - val_loss: 0.5934 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7071 - val_loss: 0.5881 - val_accuracy: 0.6842 - lr: 0.0011\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7071 - val_loss: 0.5923 - val_accuracy: 0.7368 - lr: 0.0011\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7172 - val_loss: 0.6057 - val_accuracy: 0.7193 - lr: 0.0011\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.7247 - val_loss: 0.5974 - val_accuracy: 0.6842 - lr: 0.0011\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.7121 - val_loss: 0.5988 - val_accuracy: 0.6842 - lr: 0.0011\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7121 - val_loss: 0.6012 - val_accuracy: 0.6842 - lr: 0.0011\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7121 - val_loss: 0.6078 - val_accuracy: 0.7018 - lr: 0.0011\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7424 - val_loss: 0.6247 - val_accuracy: 0.6842 - lr: 0.0011\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7298 - val_loss: 0.6089 - val_accuracy: 0.6842 - lr: 0.0011\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5584 - accuracy: 0.7399 - val_loss: 0.6278 - val_accuracy: 0.6842 - lr: 0.0011\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7449 - val_loss: 0.6254 - val_accuracy: 0.6667 - lr: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e99945a-5f7a-4fb6-9d3f-001476f7dfe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n",
      "Accuracy: 0.6491228070175439\n",
      "F1 Score: 0.7333333333333335\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e166851-8cc2-4736-be10-e1913c3903ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "773d995f-9d3a-4991-be96-70e2814c4823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6491228070175439\n",
      "F1 Score: 0.7333333333333335\n",
      "Specificity: 0.41304347826086957\n",
      "Sensitivity: 0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84ec35-a111-416c-9a0e-7b055eba457a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aa74725-c132-44e7-b432-80436e26dacd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c02de14-dfde-4883-9cd9-6a33a2ab6c07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_5548\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3467a5ca-a800-4646-960a-3419eda96a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754216b-3ef2-48ee-b251-480223696fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f2700-8a51-414e-b3f3-b625eed74c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86836d7c-39e7-4d52-a65f-e5962a795a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d7c5d-a26b-4c5a-8287-78f23d7ec8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "458c3257-8f48-46c2-9c7b-985625f01467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5706fd75-5079-41f0-978f-a8c4e8712f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "456388d1-399b-4980-a46d-d1e76b335f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53b92681-b751-487f-ab0d-554ee878f401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eafabe10-b510-4d61-bc20-cf3ec36532d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e4d8aed1-75fa-4a07-8050-4b98527f6da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6419753086419753, F1 Score: 0.7353324641460235, Sensitivity: 0.8417910447761194, Specificity: 0.35344827586206895\n",
      "Accuracy: 0.6860670194003528, F1 Score: 0.7541436464088398, Sensitivity: 0.8149253731343283, Specificity: 0.5          \n",
      "Accuracy: 0.6049382716049383, F1 Score: 0.7206982543640897, Sensitivity: 0.8626865671641791, Specificity: 0.23275862068965517\n",
      "Accuracy: 0.5908289241622575, F1 Score: 0.7427937915742794, Sensitivity: 1.0, Specificity: 0.0                         \n",
      "Accuracy: 0.6860670194003528, F1 Score: 0.7541436464088398, Sensitivity: 0.8149253731343283, Specificity: 0.5          \n",
      "Accuracy: 0.6225749559082893, F1 Score: 0.7131367292225201, Sensitivity: 0.7940298507462686, Specificity: 0.375        \n",
      "Accuracy: 0.5661375661375662, F1 Score: 0.60828025477707, Sensitivity: 0.5701492537313433, Specificity: 0.5603448275862069\n",
      "Accuracy: 0.582010582010582, F1 Score: 0.6570188133140377, Sensitivity: 0.6776119402985075, Specificity: 0.44396551724137934\n",
      "Accuracy: 0.6525573192239859, F1 Score: 0.7418086500655308, Sensitivity: 0.844776119402985, Specificity: 0.375         \n",
      "Accuracy: 0.6225749559082893, F1 Score: 0.7396593673965937, Sensitivity: 0.9074626865671642, Specificity: 0.21120689655172414\n",
      "Accuracy: 0.6261022927689595, F1 Score: 0.7165775401069518, Sensitivity: 0.8, Specificity: 0.375                       \n",
      "Accuracy: 0.6631393298059964, F1 Score: 0.7415426251691475, Sensitivity: 0.817910447761194, Specificity: 0.4396551724137931\n",
      "Accuracy: 0.6455026455026455, F1 Score: 0.7344782034346103, Sensitivity: 0.8298507462686567, Specificity: 0.3793103448275862\n",
      "Accuracy: 0.6878306878306878, F1 Score: 0.7604871447902571, Sensitivity: 0.8388059701492537, Specificity: 0.4698275862068966\n",
      "Accuracy: 0.6455026455026455, F1 Score: 0.7478042659974906, Sensitivity: 0.8895522388059701, Specificity: 0.29310344827586204\n",
      "Accuracy: 0.6278659611992945, F1 Score: 0.7190412782956058, Sensitivity: 0.8059701492537313, Specificity: 0.3706896551724138\n",
      "Accuracy: 0.6225749559082893, F1 Score: 0.7440191387559809, Sensitivity: 0.9283582089552239, Specificity: 0.1810344827586207\n",
      "Accuracy: 0.5731922398589065, F1 Score: 0.621875, Sensitivity: 0.5940298507462687, Specificity: 0.5431034482758621     \n",
      "Accuracy: 0.5925925925925926, F1 Score: 0.6751054852320675, Sensitivity: 0.7164179104477612, Specificity: 0.41379310344827586\n",
      "Accuracy: 0.6860670194003528, F1 Score: 0.7541436464088398, Sensitivity: 0.8149253731343283, Specificity: 0.5          \n",
      "100%|| 20/20 [09:13<00:00, 27.70s/trial, best loss: -0.7604871447902571]\n",
      "Best parameters found:  {'batch_size': 112.0, 'dropout_rate': 0.6148142319059324, 'epochs': 100.0, 'learning_rate': 0.00014614352648276044, 'neurons1': 96.0, 'neurons2': 64.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a23b7f9d-c1ac-466d-8517-49a18245ce66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6878306878306878\n",
      "Best F1 Score: 0.7604871447902571\n",
      "Best Specificity: 0.4698275862068966\n",
      "Best Sensitivity: 0.8388059701492537\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eccd46ce-70e9-47e9-a7be-c17da99193fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4991\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4991\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " dense_16855 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">9,696</span> \n",
       "\n",
       " dropout_6742 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_16856 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> \n",
       "\n",
       " dropout_6743 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_16857 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">6,240</span> \n",
       "\n",
       " dense_16858 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">9,700</span> \n",
       "\n",
       " dense_16859 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_16855 (\u001b[38;5;33mDense\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                             \u001b[38;5;34m9,696\u001b[0m \n",
       "\n",
       " dropout_6742 (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_16856 (\u001b[38;5;33mDense\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             \u001b[38;5;34m6,208\u001b[0m \n",
       "\n",
       " dropout_6743 (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_16857 (\u001b[38;5;33mDense\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                             \u001b[38;5;34m6,240\u001b[0m \n",
       "\n",
       " dense_16858 (\u001b[38;5;33mDense\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                            \u001b[38;5;34m9,700\u001b[0m \n",
       "\n",
       " dense_16859 (\u001b[38;5;33mDense\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                \u001b[38;5;34m101\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,945</span> (124.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,945\u001b[0m (124.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,945</span> (124.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,945\u001b[0m (124.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "af2ec614-e581-4226-9522-d0ef41d853b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 96\n",
      "Neurons in second layer: 64\n",
      "Dropout rate: 0.6148142319059324\n",
      "Learning rate: 0.00014614352648276044\n",
      "Number of epochs: 100\n",
      "Batch size: 112\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886de18-66da-4c47-a297-ecc9221db8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "129be82f-6b39-437e-b350-ef5a07a5329a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a452e3d2-876d-4f78-aa72-a1892eaf3238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc90fa59-e210-479d-bada-1cf627d7cedf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_5548\\2897354534.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3c6c4c5a-7592-41d2-8b6a-8ece3c774b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e0a65cf0-fbca-4d1c-8f1c-27ff7a7c69c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "837f54c7-971d-427f-8771-be327e78ab1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "928e2896-ee97-4c13-b426-e6a893228e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [181304  81445    990 223008   2500 164820  81208  97283  81289  56849]\n",
      "Top AMGM values: [1.00451284 1.00451805 1.00451976 1.00452387 1.00452528 1.00452727\n",
      " 1.00452986 1.00453206 1.00453611 1.00453671]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "82ef07cb-c872-43b8-8677-3a0e91f32028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4357340c-477a-4d20-9137-790867c642a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "be817913-7b9b-4faf-82db-854260aec68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eaffbc2f-54f4-4cb7-a443-855592e5b9e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "29133b7c-f7ca-4716-9402-12c82b1fe619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 128, 32)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b9d61b2d-69bd-4344-b139-04c6be9558c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ae8a4950-80ad-4c76-ba57-355315d4e7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6909492273730685, F1 Score: 0.7628242789403069, Sensitivity: 0.8427705622844007, Specificity: 0.4708601011481684\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7540730023988846, Sensitivity: 0.8165392958951236, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6887417218543046, F1 Score: 0.7564035938599108, Sensitivity: 0.8203707135196447, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6887417218543046, F1 Score: 0.7564035938599108, Sensitivity: 0.8203707135196447, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6799116997792494, F1 Score: 0.7558187491520826, Sensitivity: 0.8428065929582025, Specificity: 0.4436423592126845\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7540730023988846, Sensitivity: 0.8165392958951236, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7551305620341152, Sensitivity: 0.8203707135196447, Specificity: 0.4912520503007108\n",
      "Iteration Results - Accuracy: 0.6909492273730683, F1 Score: 0.7566578385933936, Sensitivity: 0.8165392958951236, Specificity: 0.5082012028430837\n",
      "Iteration Results - Accuracy: 0.6887417218543046, F1 Score: 0.7574360933719048, Sensitivity: 0.8242021311441657, Specificity: 0.4912520503007108\n",
      "Iteration Results - Accuracy: 0.6821192052980133, F1 Score: 0.7558893060770407, Sensitivity: 0.8353159562540826, Specificity: 0.4585098870056497\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7540730023988846, Sensitivity: 0.8165392958951236, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7540730023988846, Sensitivity: 0.8165392958951236, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6799116997792494, F1 Score: 0.752539977520602, Sensitivity: 0.8277752509513033, Specificity: 0.4654837570621469\n",
      "Iteration Results - Accuracy: 0.6821192052980133, F1 Score: 0.7587484754667417, Sensitivity: 0.8499308398235339, Specificity: 0.4362897530526699\n",
      "Iteration Results - Accuracy: 0.6887417218543046, F1 Score: 0.7564035938599108, Sensitivity: 0.8203707135196447, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7580045701794291, Sensitivity: 0.8165392958951236, Specificity: 0.5135775469291052\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.757874887228121, Sensitivity: 0.831656737174484, Specificity: 0.47545903954802266\n",
      "Iteration Results - Accuracy: 0.6777041942604857, F1 Score: 0.7357839459864967, Sensitivity: 0.7698903357310108, Specificity: 0.5484639830508474\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7540730023988846, Sensitivity: 0.8165392958951236, Specificity: 0.4969017678148351\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7551305620341152, Sensitivity: 0.8203707135196447, Specificity: 0.4912520503007108\n",
      "100%|| 20/20 [34:00<00:00, 102.04s/trial, best loss: -0.7628242789403069]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3192430a-d62e-4405-9205-11c5439bf35e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 32, 'dropout_rate': 0.2273582314066485, 'learning_rate': 0.0020901109616035933, 'epochs': 50, 'batch_size': 32, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b03102bd-d696-4472-9cb8-35dec7c31ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.6666666666666666\n",
      "F1 Score: 0.7432432432432432\n",
      "Sensitivity: 0.8208955223880597\n",
      "Specificity: 0.44680851063829785\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a4a55-e5ac-4db7-b8e5-150257b3fbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca52200-2185-415b-a4d3-735071038ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0861add9-c14c-4181-94af-3bd573dd59f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gru with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a168d442-edad-4a9a-9581-dc56d13a40c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a4d33ac4-90ae-4397-b539-2c352b291154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6cfc2d87-ed27-4fb1-be3e-9ab859a2685b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_5548\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1443f452-b7eb-4fa9-9796-9cde97c8ac58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4f7f87ea-63d2-4a53-b208-31380799625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f81e483d-6cd4-43e6-a13c-e937ee3e9b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "374ff74c-afcc-4315-8c7a-04a3bdc62bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5265cef0-ae34-4f25-b8cb-d69ac7f906c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "65cb06c5-0c00-4e04-9e28-db275077fd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ff6981f9-8a8d-48b8-880b-f424ba5171fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "619c1bd2-d8c0-40c8-9f5c-8bba010b9fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 64, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.4),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "247393ae-704a-401d-95b6-659cf5e1f68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a249b175-5cc9-47cd-a714-3103f43d70ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6909492273730683, F1 Score: 0.758163023554497, Sensitivity: 0.824890336001447, Specificity: 0.5015873015873016\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7659594656157523, Sensitivity: 0.8483687852108904, Specificity: 0.48134920634920636\n",
      " 10%|                                        | 2/20 [15:42<2:33:03, 510.20s/trial, best loss: -0.7659594656157523]ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000001B9A3770110>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 418, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7595896491476601, Sensitivity: 0.8201686552563746, Specificity: 0.5158730158730158\n",
      "Iteration Results - Accuracy: 0.6909492273730685, F1 Score: 0.7634356838258087, Sensitivity: 0.8483687852108904, Specificity: 0.4694444444444444\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7655901271425831, Sensitivity: 0.8524840115483391, Specificity: 0.4694444444444444\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7683449717431916, Sensitivity: 0.8596557871411673, Specificity: 0.46388888888888885\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.760348725055251, Sensitivity: 0.8236774271861992, Specificity: 0.5099206349206349\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7647310206133735, Sensitivity: 0.8483687852108904, Specificity: 0.47420634920634924\n",
      "Iteration Results - Accuracy: 0.6975717439293598, F1 Score: 0.7696447598599233, Sensitivity: 0.8596557871411673, Specificity: 0.4686507936507937\n",
      "Iteration Results - Accuracy: 0.6799116997792494, F1 Score: 0.7529609504949795, Sensitivity: 0.8313014254534723, Specificity: 0.46309523809523806\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7595896491476601, Sensitivity: 0.8201686552563746, Specificity: 0.5158730158730158\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7655113859015108, Sensitivity: 0.8520317888738941, Specificity: 0.4694444444444444\n",
      "Iteration Results - Accuracy: 0.6887417218543046, F1 Score: 0.7654026566057546, Sensitivity: 0.8631645590709919, Specificity: 0.44007936507936507\n",
      "Iteration Results - Accuracy: 0.673289183222958, F1 Score: 0.7573747309271598, Sensitivity: 0.8669817944671746, Specificity: 0.3972222222222222\n",
      "Iteration Results - Accuracy: 0.6909492273730685, F1 Score: 0.7605223019376498, Sensitivity: 0.8355708835240998, Specificity: 0.48293650793650794\n",
      "Iteration Results - Accuracy: 0.6975717439293598, F1 Score: 0.7696447598599233, Sensitivity: 0.8596557871411673, Specificity: 0.4686507936507937\n",
      "Iteration Results - Accuracy: 0.6997792494481235, F1 Score: 0.7670670039355573, Sensitivity: 0.8413512413512413, Specificity: 0.5015873015873016\n",
      "Iteration Results - Accuracy: 0.6975717439293598, F1 Score: 0.7696744375396625, Sensitivity: 0.8596557871411673, Specificity: 0.4694444444444444\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7626623753427987, Sensitivity: 0.8331207886763442, Specificity: 0.5015873015873016\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.75926180698691, Sensitivity: 0.8244381133270022, Specificity: 0.5055555555555555\n",
      "100%|| 20/20 [2:44:08<00:00, 492.42s/trial, best loss: -0.7696744375396625]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bda36308-47d7-4d06-82ff-0447d70d7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 32, 'dropout_rate': 0.35324918507868847, 'epochs': 30, 'learning_rate': 0.0001111270432741828, 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ff996c96-8e43-4ae2-9dc8-9925e866301a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "24efc4cb-db7b-4bc0-9afd-53baa2d407e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "11aa2678-d0b4-4965-a93c-c75ec3d55ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c321e56cd0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b262a864-333a-498d-a803-6c07a706383d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.631578947368421\n",
      "F1 Score: 0.7307692307692307\n",
      "Sensitivity: 0.8382352941176471\n",
      "Specificity: 0.32608695652173914\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06800a32-61b6-4931-b62c-afec61a67b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35709740-9a50-4a59-9272-b34246ccc657",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "def1e9a2-8761-460f-883e-771d8c6516ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_5548\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dbe6bce7-24c0-4db1-953d-23824adae339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1f3344f1-222b-4c44-8430-ef9fee643f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "631a9008-d07b-48a8-948c-170de6953e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "87d1564b-1f38-46e3-a862-44041c441417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2dbcff1a-7ac1-4eda-9374-b925e1ea0b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "01f61506-4099-4e76-93c0-60780f280251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "11ff93d5-c5d3-4786-84d4-5e6c5569caed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "17008984-d518-46d5-97d8-fcb1e3f6afc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f46d2807-4b66-418c-afdb-282b73e3abe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c3299d43-0c72-4641-ad33-355b8549ed6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e3bab0a1-b517-4566-bb2c-6252b7cd3c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a2cd14cc-f183-4b20-ab4a-2399097481d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6710816777041942, F1 Score: 0.7583674703021863, Sensitivity: 0.8801576591050275, Specificity: 0.3547619047619048\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6644591611479029, F1 Score: 0.7502573047037657, Sensitivity: 0.8553968015956319, Specificity: 0.40317460317460313\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6909492273730685, F1 Score: 0.7470042159239291, Sensitivity: 0.7776006968989425, Specificity: 0.5738095238095239\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7064017660044151, F1 Score: 0.7456086546359767, Sensitivity: 0.75005557578657, Specificity: 0.6238095238095238\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7019867549668874, F1 Score: 0.7618150564313604, Sensitivity: 0.8122361935227432, Specificity: 0.5428571428571428\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6799116997792494, F1 Score: 0.7662812946344356, Sensitivity: 0.886940999221701, Specificity: 0.39999999999999997\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7019867549668873, F1 Score: 0.7607123066540106, Sensitivity: 0.8076687445108498, Specificity: 0.5444444444444444\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6909492273730685, F1 Score: 0.7525286793351517, Sensitivity: 0.8005212461352812, Specificity: 0.5107142857142857\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7086092715231788, F1 Score: 0.768485705881529, Sensitivity: 0.823190454769402, Specificity: 0.5507936507936507\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6799116997792495, F1 Score: 0.7415013347338878, Sensitivity: 0.789360866553849, Specificity: 0.5257936507936508\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7086092715231788, F1 Score: 0.7692485823482017, Sensitivity: 0.8270319673828445, Specificity: 0.5345238095238095\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6909492273730683, F1 Score: 0.7549222135406368, Sensitivity: 0.811615934422952, Specificity: 0.5246031746031745\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7086092715231788, F1 Score: 0.7742330524953241, Sensitivity: 0.8543485970386554, Specificity: 0.4992063492063492\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5298013245033113, F1 Score: 0.5546646957378665, Sensitivity: 0.5716999050332384, Specificity: 0.41984126984126985\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6181015452538632, F1 Score: 0.5996585486131268, Sensitivity: 0.6728644974259009, Specificity: 0.47222222222222227\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6843267108167771, F1 Score: 0.7570046131408059, Sensitivity: 0.8381856826301272, Specificity: 0.4587301587301587\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7130242825607064, F1 Score: 0.7722115924542156, Sensitivity: 0.8302322758463109, Specificity: 0.5408730158730158\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7582063459225731, Sensitivity: 0.8180165513498846, Specificity: 0.5226190476190476\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6754966887417219, F1 Score: 0.7276250937533484, Sensitivity: 0.744990681832787, Specificity: 0.5630952380952381\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7578139605005276, Sensitivity: 0.8192642099074847, Specificity: 0.5075396825396826\n",
      "100%|| 20/20 [05:50<00:00, 17.52s/trial, best loss: -0.7742330524953241]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7dbea11c-9b97-43ce-b71b-731aac9c68dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 64, 'dropout_rate': 0.3265716784635214, 'epochs': 40, 'filters': 64, 'kernel_size': 2, 'learning_rate': 0.0016533772254117716}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "00b76205-e42b-458f-969d-4fec2f5c3402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5a83ffc6-7282-4582-a0bc-361d96cd47d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ba45e03550>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "158eee37-39a5-4f0e-b559-7fc6b92c6251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7cf7627a-eebd-44e7-be80-5ea2d33469b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.631578947368421\n",
      "F1 Score: 0.6818181818181818\n",
      "Sensitivity: 0.6617647058823529\n",
      "Specificity: 0.5869565217391305\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39cf9d7-4a6b-4c5e-a7b9-eafc0c5ce6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b855c1d-c2e7-4811-b4fa-10d1fad117d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c5767425-3b73-4d3c-a376-983fa8dc59ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_5548\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ceeda14f-e630-4552-a8cb-f5470f7efc46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "584856df-9cb4-4e96-a134-fdc5b9196531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5df5a468-2405-4641-b921-aeb6ff175650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7349e338-43d0-41e4-a1e5-3a82959365e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d8707631-47dc-4eeb-9d2b-7afdbefa2fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5b474f99-2c5d-4d94-ad95-0f4f4264ed84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bf6c7358-7048-45db-bb4c-cef1d7f7323b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d3ec1ff3-9398-4979-b6c3-ba4bc7670a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1ff35e08-bc77-4ba5-b088-7f1866136dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d7a406ba-c7c4-47d9-870a-618fe99ecf37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7d1a6e61-643c-4360-b824-71a396a9f2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d8a171c3-13f7-435a-8eba-28cc8eabb4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9bccb3e2-5e53-4911-b75a-428efa1233b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.2554784021852648, 'epochs': 40, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.008343218461711608, 'num_blocks': 10}\n",
      "Iteration - Loss: 5.613563060760498, Filters: 32, Blocks: 10, Kernel Size: 5, Dropout: 0.2554784021852648, LR: 0.008343218461711608, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.45846293468049965, 'epochs': 30, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.0004150790051000427, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6343879103660583, Filters: 96, Blocks: 6, Kernel Size: 5, Dropout: 0.45846293468049965, LR: 0.0004150790051000427, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.43757619387353786, 'epochs': 20, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.00014456351369973832, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.6912713050842285, Filters: 96, Blocks: 10, Kernel Size: 5, Dropout: 0.43757619387353786, LR: 0.00014456351369973832, Batch Size: 32, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.46505543821988665, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0063597097406487306, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.4510120749473572, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.46505543821988665, LR: 0.0063597097406487306, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.28768362734708536, 'epochs': 30, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.00010414422606379093, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6324942111968994, Filters: 32, Blocks: 6, Kernel Size: 3, Dropout: 0.28768362734708536, LR: 0.00010414422606379093, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3823795616822593, 'epochs': 40, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.0007954851297224134, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.617125928401947, Filters: 64, Blocks: 4, Kernel Size: 5, Dropout: 0.3823795616822593, LR: 0.0007954851297224134, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4350404008352966, 'epochs': 40, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0005319779113896459, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6636248826980591, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.4350404008352966, LR: 0.0005319779113896459, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3429975072082295, 'epochs': 30, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.0007220669940589252, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.672305166721344, Filters: 32, Blocks: 8, Kernel Size: 3, Dropout: 0.3429975072082295, LR: 0.0007220669940589252, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.405161340514928, 'epochs': 40, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.0007907672127385723, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.5795562863349915, Filters: 32, Blocks: 6, Kernel Size: 3, Dropout: 0.405161340514928, LR: 0.0007907672127385723, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3559417773626036, 'epochs': 30, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.007914926450220633, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.6360895037651062, Filters: 32, Blocks: 8, Kernel Size: 3, Dropout: 0.3559417773626036, LR: 0.007914926450220633, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4622984796353326, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.006901092387269823, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5473455190658569, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.4622984796353326, LR: 0.006901092387269823, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.2749988390145186, 'epochs': 40, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.000158539517479681, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.6480152010917664, Filters: 128, Blocks: 8, Kernel Size: 5, Dropout: 0.2749988390145186, LR: 0.000158539517479681, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.2028683601658662, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0001738716256547513, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.647789478302002, Filters: 96, Blocks: 4, Kernel Size: 4, Dropout: 0.2028683601658662, LR: 0.0001738716256547513, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.25279108191493427, 'epochs': 20, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.0014816100689812807, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.5527442097663879, Filters: 32, Blocks: 6, Kernel Size: 4, Dropout: 0.25279108191493427, LR: 0.0014816100689812807, Batch Size: 16, Epochs: 20\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.3720817679143601, 'epochs': 20, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0031353045836371544, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5658811330795288, Filters: 32, Blocks: 10, Kernel Size: 5, Dropout: 0.3720817679143601, LR: 0.0031353045836371544, Batch Size: 64, Epochs: 20\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4630299586900843, 'epochs': 40, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.00686288154460616, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.6347986459732056, Filters: 64, Blocks: 8, Kernel Size: 3, Dropout: 0.4630299586900843, LR: 0.00686288154460616, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.4681084370495493, 'epochs': 40, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.000407493712447913, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.686305046081543, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.4681084370495493, LR: 0.000407493712447913, Batch Size: 16, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.4741562935731984, 'epochs': 40, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.0008314186219136385, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.6266006231307983, Filters: 128, Blocks: 8, Kernel Size: 5, Dropout: 0.4741562935731984, LR: 0.0008314186219136385, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.4852496802221602, 'epochs': 40, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.00028588560341356786, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.6408728361129761, Filters: 64, Blocks: 8, Kernel Size: 3, Dropout: 0.4852496802221602, LR: 0.00028588560341356786, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3479665728959113, 'epochs': 40, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.004584328154143426, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.5507746338844299, Filters: 32, Blocks: 6, Kernel Size: 4, Dropout: 0.3479665728959113, LR: 0.004584328154143426, Batch Size: 16, Epochs: 40\n",
      "100%|| 20/20 [11:48<00:00, 35.42s/trial, best loss: 0.4510120749473572]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6dc4b770-704d-4e9c-99e2-fb48c12b113a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 16, 'dropout_rate': 0.46505543821988665, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0063597097406487306, 'num_blocks': 6}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c0f5e3a6-1bae-476f-b332-de9ab758a699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cd519193-bac8-40ca-9603-aa32c31df96d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.6073 - loss: 1.1508 - val_accuracy: 0.6304 - val_loss: 67.9615\n",
      "Epoch 2/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.6199 - loss: 0.7936 - val_accuracy: 0.6522 - val_loss: 0.6406\n",
      "Epoch 3/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.5918 - loss: 0.8870 - val_accuracy: 0.6304 - val_loss: 0.9727\n",
      "Epoch 4/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.6580 - loss: 0.6551 - val_accuracy: 0.5652 - val_loss: 1.0798\n",
      "Epoch 5/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 284ms/step - accuracy: 0.6905 - loss: 0.6527 - val_accuracy: 0.3696 - val_loss: 1.0649\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a9161b77-eb74-4be3-9bf0-cc956935e4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6ccef37b-4eb4-4524-acc5-13414eb9e27f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.5964912280701754\n",
      "F1 Score: 0.7160493827160493\n",
      "Sensitivity: 0.8529411764705882\n",
      "Specificity: 0.21739130434782608\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a553b-70be-4354-b470-2aa51655fabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc17082a-a9ab-4f98-8bca-0bde3a0cd683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b71bb323-1551-44d8-ba26-2bc5558c4fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_5548\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "43da0097-8e64-442c-8fa7-d0638f2f2070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c0d83907-dc98-4d34-9b80-fd8568850a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9fc777c7-d3f3-4643-b3cd-8109cc88285c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4e86eac9-a4b4-4b32-b920-5bec971f1d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "37f1da77-1567-4254-b912-4dc631e8c143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7d690e31-a049-468f-893b-7b0747279ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "de3cb1a5-403d-44a8-9b09-64256f7ad7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a745521f-1e39-4844-870c-295884948bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0999c7b7-f40e-4c24-980d-e511a91ffa93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0203c8a7-2158-4780-85c2-40460b946ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f57e4577-380f-4f72-9a4d-c85cb6c8c2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b38fe046-7a85-4b62-aa1b-0db9fcc9b14b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.5187875628471375, Params: {'batch_size': 16, 'dropout_rate': 0.28050824233459554, 'epochs': 70, 'learning_rate': 0.0005462451227884165, 'num_layers': 6, 'units': 160}\n",
      "Iteration - Loss: 0.5185142755508423, Params: {'batch_size': 64, 'dropout_rate': 0.1765393185080557, 'epochs': 60, 'learning_rate': 0.0006576944812491112, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.5312281250953674, Params: {'batch_size': 80, 'dropout_rate': 0.22316120047432159, 'epochs': 150, 'learning_rate': 7.740840564807408e-05, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.48945751786231995, Params: {'batch_size': 80, 'dropout_rate': 0.12190184387760548, 'epochs': 80, 'learning_rate': 1.4030871665251051e-05, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.5439595580101013, Params: {'batch_size': 48, 'dropout_rate': 0.3679344541119146, 'epochs': 90, 'learning_rate': 0.002480791127927536, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 0.5856583714485168, Params: {'batch_size': 80, 'dropout_rate': 0.3704180619094902, 'epochs': 80, 'learning_rate': 0.0007494768365672272, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.5706557631492615, Params: {'batch_size': 112, 'dropout_rate': 0.3256959124391454, 'epochs': 140, 'learning_rate': 1.4221018397848256e-05, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.5181475877761841, Params: {'batch_size': 64, 'dropout_rate': 0.4465441768895001, 'epochs': 140, 'learning_rate': 0.00010486070205902938, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.5060854554176331, Params: {'batch_size': 32, 'dropout_rate': 0.3970968609831197, 'epochs': 120, 'learning_rate': 2.032849422348292e-05, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.5265557765960693, Params: {'batch_size': 112, 'dropout_rate': 0.2802208435547198, 'epochs': 70, 'learning_rate': 0.00014865252155156055, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.5151180624961853, Params: {'batch_size': 32, 'dropout_rate': 0.4580806849601804, 'epochs': 120, 'learning_rate': 0.002671268025721378, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.5515946745872498, Params: {'batch_size': 128, 'dropout_rate': 0.17427553616869845, 'epochs': 50, 'learning_rate': 0.003398980338271314, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.5539363622665405, Params: {'batch_size': 112, 'dropout_rate': 0.3128717457116373, 'epochs': 110, 'learning_rate': 3.753437155540918e-05, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 0.5236898064613342, Params: {'batch_size': 80, 'dropout_rate': 0.34326620943723835, 'epochs': 100, 'learning_rate': 0.0017168593278732566, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.5186910033226013, Params: {'batch_size': 80, 'dropout_rate': 0.13892082957459337, 'epochs': 80, 'learning_rate': 0.0009175909945793579, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.5121530294418335, Params: {'batch_size': 64, 'dropout_rate': 0.33017363556802637, 'epochs': 140, 'learning_rate': 0.0029266049571265635, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.511441707611084, Params: {'batch_size': 64, 'dropout_rate': 0.3131608202936449, 'epochs': 70, 'learning_rate': 0.0005682194428276015, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.5390238761901855, Params: {'batch_size': 96, 'dropout_rate': 0.4891650616470572, 'epochs': 70, 'learning_rate': 0.0012293012558340002, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.5382823348045349, Params: {'batch_size': 64, 'dropout_rate': 0.19363890506632508, 'epochs': 110, 'learning_rate': 1.436381403351789e-05, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.546765923500061, Params: {'batch_size': 32, 'dropout_rate': 0.231040619188718, 'epochs': 110, 'learning_rate': 0.004512391975329588, 'num_layers': 3, 'units': 64}\n",
      "Iteration - Loss: 0.5463611483573914, Params: {'batch_size': 16, 'dropout_rate': 0.4182148333997652, 'epochs': 120, 'learning_rate': 3.5685777475467295e-05, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 0.537996232509613, Params: {'batch_size': 48, 'dropout_rate': 0.10848744782160624, 'epochs': 90, 'learning_rate': 2.7943601365619353e-05, 'num_layers': 3, 'units': 256}\n",
      "Iteration - Loss: 0.6036519408226013, Params: {'batch_size': 96, 'dropout_rate': 0.3968825854445445, 'epochs': 130, 'learning_rate': 1.2598066659019196e-05, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.5347678065299988, Params: {'batch_size': 48, 'dropout_rate': 0.48856502548639436, 'epochs': 100, 'learning_rate': 0.00029327662512315916, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.5536463260650635, Params: {'batch_size': 32, 'dropout_rate': 0.10057030395420907, 'epochs': 90, 'learning_rate': 0.007655157124095145, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.5194398760795593, Params: {'batch_size': 96, 'dropout_rate': 0.24446178146705808, 'epochs': 50, 'learning_rate': 6.341060544463395e-05, 'num_layers': 2, 'units': 160}\n",
      "Iteration - Loss: 0.541903018951416, Params: {'batch_size': 48, 'dropout_rate': 0.41203471125874, 'epochs': 120, 'learning_rate': 2.2183856917486643e-05, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.5371975898742676, Params: {'batch_size': 96, 'dropout_rate': 0.44729214771878684, 'epochs': 130, 'learning_rate': 0.00024758467514121097, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.5801692008972168, Params: {'batch_size': 16, 'dropout_rate': 0.2678092453570786, 'epochs': 80, 'learning_rate': 1.0448408325692745e-05, 'num_layers': 6, 'units': 160}\n",
      "Iteration - Loss: 0.5640482902526855, Params: {'batch_size': 32, 'dropout_rate': 0.13840366701729237, 'epochs': 60, 'learning_rate': 5.5391201656840856e-05, 'num_layers': 2, 'units': 96}\n",
      "100%|| 30/30 [10:32<00:00, 21.08s/trial, best loss: 0.48945751786231995]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1bc904a2-611d-4884-b063-68346a4b52cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 80, 'dropout_rate': 0.12190184387760548, 'epochs': 80, 'learning_rate': 1.4030871665251051e-05, 'num_layers': 3, 'units': 160}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "426e57d2-75ce-4e34-9a18-5d83566f64bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4275 - loss: 0.7481 - val_accuracy: 0.4348 - val_loss: 0.7205\n",
      "Epoch 2/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4134 - loss: 0.7509 - val_accuracy: 0.4130 - val_loss: 0.7142\n",
      "Epoch 3/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4950 - loss: 0.7258 - val_accuracy: 0.4565 - val_loss: 0.7083\n",
      "Epoch 4/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4539 - loss: 0.7378 - val_accuracy: 0.5000 - val_loss: 0.7022\n",
      "Epoch 5/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4623 - loss: 0.7273 - val_accuracy: 0.5652 - val_loss: 0.6969\n",
      "Epoch 6/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4825 - loss: 0.7208 - val_accuracy: 0.5652 - val_loss: 0.6918\n",
      "Epoch 7/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5324 - loss: 0.7081 - val_accuracy: 0.5652 - val_loss: 0.6871\n",
      "Epoch 8/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4969 - loss: 0.7189 - val_accuracy: 0.5870 - val_loss: 0.6821\n",
      "Epoch 9/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5238 - loss: 0.7157 - val_accuracy: 0.6087 - val_loss: 0.6774\n",
      "Epoch 10/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5652 - loss: 0.6922 - val_accuracy: 0.6304 - val_loss: 0.6728\n",
      "Epoch 11/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5398 - loss: 0.7042 - val_accuracy: 0.6522 - val_loss: 0.6684\n",
      "Epoch 12/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5354 - loss: 0.6958 - val_accuracy: 0.6522 - val_loss: 0.6647\n",
      "Epoch 13/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5816 - loss: 0.6873 - val_accuracy: 0.6739 - val_loss: 0.6610\n",
      "Epoch 14/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5653 - loss: 0.6899 - val_accuracy: 0.7174 - val_loss: 0.6579\n",
      "Epoch 15/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5694 - loss: 0.6932 - val_accuracy: 0.7391 - val_loss: 0.6547\n",
      "Epoch 16/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5691 - loss: 0.6815 - val_accuracy: 0.7609 - val_loss: 0.6517\n",
      "Epoch 17/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5997 - loss: 0.6766 - val_accuracy: 0.8043 - val_loss: 0.6483\n",
      "Epoch 18/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6236 - loss: 0.6713 - val_accuracy: 0.7826 - val_loss: 0.6449\n",
      "Epoch 19/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6430 - loss: 0.6602 - val_accuracy: 0.7826 - val_loss: 0.6417\n",
      "Epoch 20/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6016 - loss: 0.6804 - val_accuracy: 0.7826 - val_loss: 0.6387\n",
      "Epoch 21/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6117 - loss: 0.6670 - val_accuracy: 0.7826 - val_loss: 0.6354\n",
      "Epoch 22/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5843 - loss: 0.6836 - val_accuracy: 0.8043 - val_loss: 0.6322\n",
      "Epoch 23/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6284 - loss: 0.6654 - val_accuracy: 0.7826 - val_loss: 0.6292\n",
      "Epoch 24/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6283 - loss: 0.6611 - val_accuracy: 0.7826 - val_loss: 0.6264\n",
      "Epoch 25/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6465 - loss: 0.6699 - val_accuracy: 0.7826 - val_loss: 0.6236\n",
      "Epoch 26/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6183 - loss: 0.6642 - val_accuracy: 0.7826 - val_loss: 0.6212\n",
      "Epoch 27/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6376 - loss: 0.6663 - val_accuracy: 0.7609 - val_loss: 0.6184\n",
      "Epoch 28/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6213 - loss: 0.6605 - val_accuracy: 0.7826 - val_loss: 0.6154\n",
      "Epoch 29/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6620 - loss: 0.6612 - val_accuracy: 0.7826 - val_loss: 0.6124\n",
      "Epoch 30/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6654 - loss: 0.6519 - val_accuracy: 0.7826 - val_loss: 0.6099\n",
      "Epoch 31/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6738 - loss: 0.6648 - val_accuracy: 0.7826 - val_loss: 0.6080\n",
      "Epoch 32/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6640 - loss: 0.6469 - val_accuracy: 0.7826 - val_loss: 0.6058\n",
      "Epoch 33/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6891 - loss: 0.6468 - val_accuracy: 0.7826 - val_loss: 0.6037\n",
      "Epoch 34/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6396 - loss: 0.6532 - val_accuracy: 0.7826 - val_loss: 0.6019\n",
      "Epoch 35/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6605 - loss: 0.6382 - val_accuracy: 0.7826 - val_loss: 0.6001\n",
      "Epoch 36/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6469 - loss: 0.6529 - val_accuracy: 0.7826 - val_loss: 0.5985\n",
      "Epoch 37/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6622 - loss: 0.6523 - val_accuracy: 0.7826 - val_loss: 0.5966\n",
      "Epoch 38/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6638 - loss: 0.6424 - val_accuracy: 0.7826 - val_loss: 0.5947\n",
      "Epoch 39/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6546 - loss: 0.6493 - val_accuracy: 0.7826 - val_loss: 0.5927\n",
      "Epoch 40/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6944 - loss: 0.6440 - val_accuracy: 0.7826 - val_loss: 0.5908\n",
      "Epoch 41/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6550 - loss: 0.6501 - val_accuracy: 0.7826 - val_loss: 0.5890\n",
      "Epoch 42/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6937 - loss: 0.6388 - val_accuracy: 0.7826 - val_loss: 0.5869\n",
      "Epoch 43/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6855 - loss: 0.6265 - val_accuracy: 0.7826 - val_loss: 0.5848\n",
      "Epoch 44/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7283 - loss: 0.6170 - val_accuracy: 0.7826 - val_loss: 0.5830\n",
      "Epoch 45/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6876 - loss: 0.6235 - val_accuracy: 0.7826 - val_loss: 0.5812\n",
      "Epoch 46/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6810 - loss: 0.6231 - val_accuracy: 0.7826 - val_loss: 0.5797\n",
      "Epoch 47/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6904 - loss: 0.6286 - val_accuracy: 0.7826 - val_loss: 0.5780\n",
      "Epoch 48/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6896 - loss: 0.6237 - val_accuracy: 0.7826 - val_loss: 0.5763\n",
      "Epoch 49/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6860 - loss: 0.6326 - val_accuracy: 0.7826 - val_loss: 0.5747\n",
      "Epoch 50/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6317 - loss: 0.6481 - val_accuracy: 0.7826 - val_loss: 0.5736\n",
      "Epoch 51/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6905 - loss: 0.6190 - val_accuracy: 0.7826 - val_loss: 0.5721\n",
      "Epoch 52/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6957 - loss: 0.6305 - val_accuracy: 0.7826 - val_loss: 0.5703\n",
      "Epoch 53/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6681 - loss: 0.6271 - val_accuracy: 0.7826 - val_loss: 0.5690\n",
      "Epoch 54/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6917 - loss: 0.6219 - val_accuracy: 0.7826 - val_loss: 0.5681\n",
      "Epoch 55/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6860 - loss: 0.6245 - val_accuracy: 0.7826 - val_loss: 0.5674\n",
      "Epoch 56/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6964 - loss: 0.6114 - val_accuracy: 0.7826 - val_loss: 0.5668\n",
      "Epoch 57/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6952 - loss: 0.6215 - val_accuracy: 0.7826 - val_loss: 0.5660\n",
      "Epoch 58/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6918 - loss: 0.6309 - val_accuracy: 0.7826 - val_loss: 0.5650\n",
      "Epoch 59/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7058 - loss: 0.6051 - val_accuracy: 0.7826 - val_loss: 0.5639\n",
      "Epoch 60/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6764 - loss: 0.6208 - val_accuracy: 0.7826 - val_loss: 0.5630\n",
      "Epoch 61/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6934 - loss: 0.6162 - val_accuracy: 0.7826 - val_loss: 0.5622\n",
      "Epoch 62/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6969 - loss: 0.6174 - val_accuracy: 0.7826 - val_loss: 0.5613\n",
      "Epoch 63/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6791 - loss: 0.6157 - val_accuracy: 0.7826 - val_loss: 0.5607\n",
      "Epoch 64/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7034 - loss: 0.6118 - val_accuracy: 0.7826 - val_loss: 0.5599\n",
      "Epoch 65/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6888 - loss: 0.6132 - val_accuracy: 0.7826 - val_loss: 0.5587\n",
      "Epoch 66/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7168 - loss: 0.5940 - val_accuracy: 0.7826 - val_loss: 0.5576\n",
      "Epoch 67/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6754 - loss: 0.6263 - val_accuracy: 0.7826 - val_loss: 0.5567\n",
      "Epoch 68/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6913 - loss: 0.6101 - val_accuracy: 0.7826 - val_loss: 0.5560\n",
      "Epoch 69/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6930 - loss: 0.6114 - val_accuracy: 0.7826 - val_loss: 0.5549\n",
      "Epoch 70/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6699 - loss: 0.6181 - val_accuracy: 0.7826 - val_loss: 0.5540\n",
      "Epoch 71/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6767 - loss: 0.6153 - val_accuracy: 0.7826 - val_loss: 0.5526\n",
      "Epoch 72/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6829 - loss: 0.6095 - val_accuracy: 0.7826 - val_loss: 0.5517\n",
      "Epoch 73/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6942 - loss: 0.6286 - val_accuracy: 0.7826 - val_loss: 0.5512\n",
      "Epoch 74/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7115 - loss: 0.6006 - val_accuracy: 0.7826 - val_loss: 0.5504\n",
      "Epoch 75/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6878 - loss: 0.6180 - val_accuracy: 0.7826 - val_loss: 0.5497\n",
      "Epoch 76/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6939 - loss: 0.6179 - val_accuracy: 0.7826 - val_loss: 0.5487\n",
      "Epoch 77/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6997 - loss: 0.6039 - val_accuracy: 0.7826 - val_loss: 0.5476\n",
      "Epoch 78/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6962 - loss: 0.6040 - val_accuracy: 0.7826 - val_loss: 0.5467\n",
      "Epoch 79/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7026 - loss: 0.6183 - val_accuracy: 0.7826 - val_loss: 0.5462\n",
      "Epoch 80/80\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6749 - loss: 0.6060 - val_accuracy: 0.7826 - val_loss: 0.5452\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "400a7b49-3ff6-4cec-886e-c2c09125de05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.631578947368421\n",
      "F1 Score: 0.7236842105263158\n",
      "Sensitivity: 0.8088235294117647\n",
      "Specificity: 0.3695652173913043\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26708a0-4794-4cc9-a182-6db511d82455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb4513-f0ef-4caa-a077-d51522ef3267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f33343f-94f6-4435-ad52-dd075a466351",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b62c4b-b4f2-46e9-8b81-e589ca979e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_1428\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4be0220-3287-4ef0-92d8-74d1b0a41d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values\n",
    "features_df = features_df.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bfffbc1-ebf5-4f05-a4bd-a7a1b7562c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(features_df.values)\n",
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10d413d8-0555-48b0-b09c-340d9ed36e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(features_df.values, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ad0dbba-634a-4865-a266-e38c68190afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = features_df.iloc[selected_indices, :].T\n",
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1561eb-4555-4634-ad79-38a454ea9985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb0cef25-2f0f-44b2-989b-1f14d6bd2550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df23f9d1-7f7d-476d-aa61-de5b270ae629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f685971-27a5-4065-b39c-540f9be95577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 13:15:05,959] A new study created in memory with name: no-name-f658c1d2-fad1-4c3c-b2c3-e964e60ea6ad\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a34b0f2c-5476-4ca3-8874-6a95f57bec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 09:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.672502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.679910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.667740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 13:24:56,663] Trial 0 finished with value: 0.6677395105361938 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 1.6829711833684297e-05, 'max_length': 238}. Best is trial 0 with value: 0.6677395105361938.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 06:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.677743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669800</td>\n",
       "      <td>0.705634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.675662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 13:32:12,140] Trial 1 finished with value: 0.6756619811058044 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 2.9065545374840432e-05, 'max_length': 173}. Best is trial 0 with value: 0.6677395105361938.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 05:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.672848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672200</td>\n",
       "      <td>0.688792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 13:38:10,936] Trial 2 finished with value: 0.6887920498847961 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 1.5860725722731893e-05, 'max_length': 202}. Best is trial 0 with value: 0.6677395105361938.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 09:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.683500</td>\n",
       "      <td>0.673506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.669618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.680385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 13:48:47,696] Trial 3 finished with value: 0.680384635925293 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 3.419802991177643e-05, 'max_length': 227}. Best is trial 0 with value: 0.6677395105361938.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 09:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.684100</td>\n",
       "      <td>0.676915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.672363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.670186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 13:59:53,849] Trial 4 finished with value: 0.6701861619949341 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.7363901182178265e-05, 'max_length': 232}. Best is trial 0 with value: 0.6677395105361938.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b793bbc-c683-4546-b573-607d5ed1a03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 1.6829711833684297e-05, 'max_length': 238}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98b5cc64-f229-429b-bf55-6614507395c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a811763c-80c7-4fb3-b2b5-046051d52114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95279efe-df03-45f3-a56c-a39f5092563a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e04c20c3-1d13-4188-a412-d2342ec73c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "352f237a-96b0-42fd-be55-b52ce14b1ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cda21d5-d8bc-4fdf-8b51-8792dd40a474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 49:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.701800</td>\n",
       "      <td>0.672019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.667910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>0.668611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=87, training_loss=0.6809920168471062, metrics={'train_runtime': 2996.3643, 'train_samples_per_second': 0.454, 'train_steps_per_second': 0.029, 'total_flos': 357567924234240.0, 'train_loss': 0.6809920168471062, 'epoch': 3.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95fc1d09-f96c-4f9c-8d54-d32ea5fb3719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5964912280701754\n",
      "F1 Score: 0.7472527472527473\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2047b4-cd3f-4cc5-9ddc-c405065b0319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d2f84-31d0-492a-be25-b4c124d080f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "858c7327-0837-4a19-8a53-8e22b7b63622",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e55e96e-dd70-41cd-86c1-da8c918d0754",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_16172\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4933bac9-74da-40bf-99f0-f9777cc32a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4780b33-7adc-4014-8f03-651a730b45e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc88b8c4-fb27-4052-9c27-dda8c76cb68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 25000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4b6bc0-2ed8-4666-a9b9-7cb11acda880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:2500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5b8ab2-f470-470b-9398-4e906a99fb25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5bda1c-4371-43bb-b402-df0da5acfa29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_selected)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b66a911-fa39-4217-b228-ce00329b1a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe333f67-a2f8-4a52-9106-b520a92d0f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77edcbc-4281-447b-b77c-ad7f0675b0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 08:41:28,955] A new study created in memory with name: no-name-1a5e3eb6-6b13-4691-8bb4-bef90ebbe5b3\n",
      "[I 2024-06-13 08:41:33,975] Trial 0 finished with value: 0.0015418485272675753 and parameters: {'num_units': 208, 'learning_rate': 2.6880391952782476e-05, 'dropout_rate': 0.14453370803496787, 'activity_regularizer': 1.0911381569660001e-07, 'batch_size': 60}. Best is trial 0 with value: 0.0015418485272675753.\n",
      "[I 2024-06-13 08:41:38,222] Trial 1 finished with value: 0.0003254197654314339 and parameters: {'num_units': 78, 'learning_rate': 0.0002760389535657363, 'dropout_rate': 0.008229570688697318, 'activity_regularizer': 3.357830757088946e-07, 'batch_size': 29}. Best is trial 1 with value: 0.0003254197654314339.\n",
      "[I 2024-06-13 08:41:42,926] Trial 2 finished with value: 0.0003185069072060287 and parameters: {'num_units': 103, 'learning_rate': 5.104575537820124e-05, 'dropout_rate': 0.17612624894541537, 'activity_regularizer': 3.2645465097138066e-07, 'batch_size': 25}. Best is trial 2 with value: 0.0003185069072060287.\n",
      "[I 2024-06-13 08:41:47,609] Trial 3 finished with value: 0.0006342597771435976 and parameters: {'num_units': 109, 'learning_rate': 8.011815508897596e-05, 'dropout_rate': 0.07367393654784433, 'activity_regularizer': 2.274521300779043e-07, 'batch_size': 56}. Best is trial 2 with value: 0.0003185069072060287.\n",
      "[I 2024-06-13 08:41:53,023] Trial 4 finished with value: 0.0003154397418256849 and parameters: {'num_units': 241, 'learning_rate': 5.634900981920262e-05, 'dropout_rate': 0.2820701858159629, 'activity_regularizer': 1.7609741327245813e-07, 'batch_size': 24}. Best is trial 4 with value: 0.0003154397418256849.\n",
      "[I 2024-06-13 08:41:54,300] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:41:55,901] Trial 6 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 08:41:59,086] Trial 7 pruned. Trial was pruned at epoch 23.\n",
      "[I 2024-06-13 08:42:00,221] Trial 8 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:01,404] Trial 9 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:02,707] Trial 10 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:03,896] Trial 11 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:05,491] Trial 12 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:07,014] Trial 13 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:08,259] Trial 14 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:09,929] Trial 15 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:11,079] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:12,241] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:13,612] Trial 18 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:17,435] Trial 19 pruned. Trial was pruned at epoch 22.\n",
      "[I 2024-06-13 08:42:18,622] Trial 20 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:20,005] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:21,449] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:42:27,405] Trial 23 finished with value: 0.00028137772460468113 and parameters: {'num_units': 82, 'learning_rate': 0.000994087754144195, 'dropout_rate': 0.038152385679101286, 'activity_regularizer': 1.0138313291478329e-07, 'batch_size': 27}. Best is trial 23 with value: 0.00028137772460468113.\n",
      "[I 2024-06-13 08:42:33,617] Trial 24 finished with value: 0.00022212722979020327 and parameters: {'num_units': 129, 'learning_rate': 0.0009411537941603595, 'dropout_rate': 0.061118892892645174, 'activity_regularizer': 1.2170306768961552e-07, 'batch_size': 21}. Best is trial 24 with value: 0.00022212722979020327.\n",
      "[I 2024-06-13 08:42:39,211] Trial 25 finished with value: 0.00023426250845659524 and parameters: {'num_units': 170, 'learning_rate': 0.0009043022037270854, 'dropout_rate': 0.051208949415801036, 'activity_regularizer': 1.343012485839888e-07, 'batch_size': 20}. Best is trial 24 with value: 0.00022212722979020327.\n",
      "[I 2024-06-13 08:42:44,045] Trial 26 finished with value: 0.00019003594934474677 and parameters: {'num_units': 128, 'learning_rate': 0.0009976131989789638, 'dropout_rate': 0.03272419862502867, 'activity_regularizer': 1.0559803948210198e-07, 'batch_size': 20}. Best is trial 26 with value: 0.00019003594934474677.\n",
      "[I 2024-06-13 08:42:49,085] Trial 27 finished with value: 0.0002541009453125298 and parameters: {'num_units': 132, 'learning_rate': 0.0005390896721216425, 'dropout_rate': 0.03853904607593964, 'activity_regularizer': 1.7336393081748622e-07, 'batch_size': 19}. Best is trial 26 with value: 0.00019003594934474677.\n",
      "[I 2024-06-13 08:42:54,075] Trial 28 finished with value: 0.00022361033188644797 and parameters: {'num_units': 162, 'learning_rate': 0.0009004397952093569, 'dropout_rate': 0.034035116515067396, 'activity_regularizer': 1.0553689548243674e-07, 'batch_size': 21}. Best is trial 26 with value: 0.00019003594934474677.\n",
      "[I 2024-06-13 08:42:55,077] Trial 29 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-13 08:42:56,111] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:01,059] Trial 31 finished with value: 0.0001689440687187016 and parameters: {'num_units': 172, 'learning_rate': 0.000897573470293013, 'dropout_rate': 0.05483276230765702, 'activity_regularizer': 1.3527213139935319e-07, 'batch_size': 20}. Best is trial 31 with value: 0.0001689440687187016.\n",
      "[I 2024-06-13 08:43:06,627] Trial 32 finished with value: 0.00022948648256715387 and parameters: {'num_units': 164, 'learning_rate': 0.000725944777840866, 'dropout_rate': 0.0209232116948617, 'activity_regularizer': 2.5021268355087874e-07, 'batch_size': 20}. Best is trial 31 with value: 0.0001689440687187016.\n",
      "[I 2024-06-13 08:43:07,584] Trial 33 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:09,007] Trial 34 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 08:43:09,955] Trial 35 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:10,938] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:12,105] Trial 37 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-13 08:43:12,994] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:13,837] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:16,899] Trial 40 pruned. Trial was pruned at epoch 26.\n",
      "[I 2024-06-13 08:43:21,789] Trial 41 finished with value: 0.00023953606432769448 and parameters: {'num_units': 166, 'learning_rate': 0.0007449850902056741, 'dropout_rate': 0.022630238003926134, 'activity_regularizer': 2.4071690323348536e-07, 'batch_size': 18}. Best is trial 31 with value: 0.0001689440687187016.\n",
      "[I 2024-06-13 08:43:26,554] Trial 42 finished with value: 0.00019192451145499945 and parameters: {'num_units': 161, 'learning_rate': 0.0009669850683661366, 'dropout_rate': 0.05954889271168815, 'activity_regularizer': 2.366593370840941e-07, 'batch_size': 19}. Best is trial 31 with value: 0.0001689440687187016.\n",
      "[I 2024-06-13 08:43:27,415] Trial 43 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:33,016] Trial 44 finished with value: 0.00018572231056168675 and parameters: {'num_units': 160, 'learning_rate': 0.000966938068192607, 'dropout_rate': 0.053395770388907984, 'activity_regularizer': 1.0012382630127507e-07, 'batch_size': 18}. Best is trial 31 with value: 0.0001689440687187016.\n",
      "[I 2024-06-13 08:43:34,344] Trial 45 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 08:43:35,373] Trial 46 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-13 08:43:36,271] Trial 47 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:37,235] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:43:38,335] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b751db9-acc1-4668-b060-46d192061a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 172, 'learning_rate': 0.000897573470293013, 'dropout_rate': 0.05483276230765702, 'activity_regularizer': 1.3527213139935319e-07, 'batch_size': 20}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e77600-1dc1-4db2-9185-7e7635aadf3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94a9d35f-bf57-4b6b-85f0-2f08595048ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 4.4884e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3785e-04 - val_loss: 3.0633e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3508e-04 - val_loss: 3.0055e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2121e-04 - val_loss: 2.9912e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2251e-04 - val_loss: 2.9469e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1be24a93d50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a60abaf6-a637-40af-b3dc-a38a0aa05009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6947e-04 \n",
      "Validation Loss:  0.00045960501302033663\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95a4ac0a-3d3a-48d3-8071-889b5db405e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8451fb6f-0a85-40cb-b5e0-3146de68a006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "774cc393-63cb-49e3-98ba-7dc04306d785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c42aabe-7bd3-4b02-84ce-862d366132c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40350877192982454\n",
      "F1 Score: 0.0\n",
      "Sensitivity: 0.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce284f-7c84-475e-8224-4eacfc169564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515ad5f-4a32-4f50-81b7-9f21a41f6bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad16c87f-d7a6-4059-843b-eeabb26e5b7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34b1c0c9-65e7-4cc7-b3cb-90e3ccdff177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_23480\\1299816614.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34903399-ca6f-46bf-9e31-d331eb0b79c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71d948ba-5c6f-43cd-bb76-3e6fa2ee8459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2a4f60b-79e3-4d4c-976e-e151eeb2c6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94e43e88-0eb9-489c-8de2-e6f3bb36eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e0853d7-5ff4-4dbb-bca2-81660f4f125d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [108788  46654  90362  87579    126 155109 152481  70311 158481  79797]\n",
      "Top AMGM values: [1.0023952 1.0023955 1.0023957 1.0023957 1.0023966 1.0023972 1.0023975\n",
      " 1.0023975 1.0023979 1.0023985]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c487692-7c12-41f1-a405-d39a54f910a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fd4ead1-d82d-411e-bcf8-a8b601c9c386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T\n",
    "X_selected = X_selected.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6babe9fb-dceb-4e77-91b5-977e2836ad6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b3794eb-c098-499a-a11f-ecf6b419583b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a6dae2e-8837-4b43-a5f7-260fc1f4bd2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66807178-37a7-4abb-9bf0-e6dede089519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d103fa62-bdd0-4445-bcb0-533165a3e3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1be32f5-4e0d-45a5-bc74-70dbc0431da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fece2591-c3be-405f-8c6e-4ba67863c736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ff48542-d8f9-4c26-9bce-1618b5b560cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step                                               \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step                                               \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step                                               \n",
      "\n",
      "Iteration Results - Accuracy: 0.6631944444444444, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7847222222222222, F1 Score: 0.5506436664848223, Sensitivity: 0.41937321937321936, Specificity: 0.9621779859484777\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6631944444444444, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6631944444444444, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6631944444444444, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7465277777777778, F1 Score: 0.394966394966395, Sensitivity: 0.3190883190883191, Specificity: 0.9626984126984127\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7916666666666666, F1 Score: 0.68792383933229, Sensitivity: 0.6750712250712251, Specificity: 0.8545407233931824\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step                                               \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6770833333333334, F1 Score: 0.0909090909090909, Sensitivity: 0.05555555555555555, Specificity: 0.9888888888888889\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6631944444444444, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8194444444444443, F1 Score: 0.6599752461821428, Sensitivity: 0.5359991859991861, Specificity: 0.9560109289617488\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7256944444444443, F1 Score: 0.6437950937950937, Sensitivity: 0.7498371998371999, Specificity: 0.701392141556076\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 342ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4s/step                                                  \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 325ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7569444444444445, F1 Score: 0.4396825396825397, Sensitivity: 0.40317460317460313, Specificity: 0.9116575591985429\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7083333333333334, F1 Score: 0.22549019607843138, Sensitivity: 0.21904761904761905, Specificity: 0.9453551912568307\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7569444444444445, F1 Score: 0.4869897350202912, Sensitivity: 0.5197802197802198, Specificity: 0.8950819672131147\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6840277777777777, F1 Score: 0.09756097560975609, Sensitivity: 0.05714285714285714, Specificity: 1.0\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7881944444444445, F1 Score: 0.5944453610515317, Sensitivity: 0.46033781033781035, Specificity: 0.9510668748373666\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6944444444444443, F1 Score: 0.22857142857142856, Sensitivity: 0.1505291005291005, Specificity: 0.9612021857923497\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.673611111111111, F1 Score: 0.08602150537634408, Sensitivity: 0.05128205128205129, Specificity: 0.9952380952380953\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6597222222222222, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 0.9944444444444445     \n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step                                              \n",
      "\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803ms/step                                               \n",
      "\u001b[1m2/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step                                              \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7847222222222222, F1 Score: 0.4656084656084656, Sensitivity: 0.394973544973545, Specificity: 0.9615664845173043\n",
      "100%|| 20/20 [1:21:10<00:00, 243.50s/trial, best loss: -0.68792383933229]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84cff0a9-378d-4f77-b11b-3bc1b405f74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 2.5934051689147445e-07, 'ae_batch_size': 19.0, 'ae_dropout_rate': 0.36732121173833665, 'ae_learning_rate': 0.007481713394266199, 'autoencoder_units': 448.0, 'encoding_dim': 81.0, 'lstm_batch_size': 28.0, 'lstm_dropout_rate': 0.4454754312831254, 'lstm_learning_rate': 8.503746883962169e-05, 'lstm_units': 67.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97f657e8-d660-4f02-8cc7-a039e8d4ca74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e394fd8-f767-4269-b378-53acd8b309ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "680b090c-a971-4421-8be2-ef5061ceba64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6c822a7-181e-4c7e-9a17-a09c27f0cb53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.0562 - val_loss: 1.0121\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9940 - val_loss: 1.0123\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9592 - val_loss: 1.0123\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0175 - val_loss: 1.0122\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0156 - val_loss: 1.0121\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0804 - val_loss: 1.0120\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9878 - val_loss: 1.0119\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9589 - val_loss: 1.0118\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0083 - val_loss: 1.0117\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9590 - val_loss: 1.0117\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0098 - val_loss: 1.0116\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0318 - val_loss: 1.0115\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0299 - val_loss: 1.0115\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0015 - val_loss: 1.0114\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0173 - val_loss: 1.0235\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0157 - val_loss: 1.0082\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0341 - val_loss: 1.0095\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9945 - val_loss: 1.0074\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9490 - val_loss: 1.0080\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9548 - val_loss: 1.0097\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0055 - val_loss: 1.0094\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0184 - val_loss: 1.0095\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0181 - val_loss: 1.0083\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.6198 - loss: 0.6546 - val_accuracy: 0.6806 - val_loss: 0.6149\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.6697 - loss: 0.6089 - val_accuracy: 0.6806 - val_loss: 0.5727\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6758 - loss: 0.5630 - val_accuracy: 0.6806 - val_loss: 0.5376\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6449 - loss: 0.5394 - val_accuracy: 0.6806 - val_loss: 0.5154\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6573 - loss: 0.5147 - val_accuracy: 0.6806 - val_loss: 0.4977\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.6495 - loss: 0.5059 - val_accuracy: 0.6806 - val_loss: 0.4847\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.6547 - loss: 0.4929 - val_accuracy: 0.7639 - val_loss: 0.4769\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7820 - loss: 0.4780 - val_accuracy: 0.7778 - val_loss: 0.4726\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.8045 - loss: 0.4620 - val_accuracy: 0.7778 - val_loss: 0.4682\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8050 - loss: 0.4822 - val_accuracy: 0.7778 - val_loss: 0.4640\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8048 - loss: 0.4776 - val_accuracy: 0.7778 - val_loss: 0.4602\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8211 - loss: 0.4576 - val_accuracy: 0.7917 - val_loss: 0.4551\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8166 - loss: 0.4698 - val_accuracy: 0.7778 - val_loss: 0.4505\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8142 - loss: 0.4537 - val_accuracy: 0.7917 - val_loss: 0.4465\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.8363 - loss: 0.4491 - val_accuracy: 0.8056 - val_loss: 0.4414\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.8220 - loss: 0.4349 - val_accuracy: 0.8194 - val_loss: 0.4363\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8353 - loss: 0.4481 - val_accuracy: 0.8194 - val_loss: 0.4302\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.8189 - loss: 0.4268 - val_accuracy: 0.8194 - val_loss: 0.4243\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8427 - loss: 0.4019 - val_accuracy: 0.8333 - val_loss: 0.4195\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8204 - loss: 0.4595 - val_accuracy: 0.8472 - val_loss: 0.4146\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8480 - loss: 0.4130 - val_accuracy: 0.8472 - val_loss: 0.4094\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8727 - loss: 0.3632 - val_accuracy: 0.8333 - val_loss: 0.4070\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8254 - loss: 0.3894 - val_accuracy: 0.8333 - val_loss: 0.4019\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8477 - loss: 0.3851 - val_accuracy: 0.8333 - val_loss: 0.4016\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8563 - loss: 0.4080 - val_accuracy: 0.8333 - val_loss: 0.3983\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.8204 - loss: 0.4145 - val_accuracy: 0.8333 - val_loss: 0.3964\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.8427 - loss: 0.3768 - val_accuracy: 0.8333 - val_loss: 0.3945\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8554 - loss: 0.3534 - val_accuracy: 0.8333 - val_loss: 0.3935\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.8205 - loss: 0.4048 - val_accuracy: 0.8194 - val_loss: 0.3952\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8432 - loss: 0.3774 - val_accuracy: 0.8333 - val_loss: 0.3889\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8425 - loss: 0.4025 - val_accuracy: 0.8333 - val_loss: 0.3888\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8113 - loss: 0.4041 - val_accuracy: 0.8333 - val_loss: 0.3910\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8346 - loss: 0.3747 - val_accuracy: 0.8333 - val_loss: 0.3917\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.8330 - loss: 0.3810 - val_accuracy: 0.8333 - val_loss: 0.3906\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8288 - loss: 0.3716 - val_accuracy: 0.8333 - val_loss: 0.3908\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8690 - loss: 0.3175 - val_accuracy: 0.8333 - val_loss: 0.3910\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ef274e6-6760-440f-ac90-37279bcddc28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step\n",
      "Accuracy: 0.8333333333333334\n",
      "F1 Score: 0.7391304347826086\n",
      "Sensitivity: 0.7391304347826086\n",
      "Specificity: 0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8dce91-1cd7-4441-ac7e-3987d8fbda81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afad969-977c-4c91-b300-2c6bddab7087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f576ddec-a944-481c-9cf3-7956f8f7f790",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afba509a-1b0a-4b1a-98e7-f8b94cf62286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_25512\\775459786.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84ce388d-8b03-4546-bc7e-01757ff5230b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a59ee2d8-5968-4254-9870-46763ce9992f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e83fb6c2-6e14-460e-ba9c-be8e734ee041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59da1922-ee15-4df1-8c0d-c611125d28a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [181304  81445    990 223008  97283 164820   2500  81208 174493 168855]\n",
      "Top AMGM values: [1.0045123 1.0045205 1.0045241 1.0045246 1.0045279 1.0045315 1.0045317\n",
      " 1.0045332 1.0045352 1.0045373]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eceb2523-ab34-489b-b944-c6e569a1411f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67b00d8c-6f3e-4397-a670-ecbe65edab05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "434e3031-8131-42bb-85db-c8e3a98108ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e650f8aa-ee05-4512-a66d-d50885eefbca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "677d8dc4-93ea-4ae0-8aff-627bfe269760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "226d8121-be30-4b60-b53c-ad256a9e3a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85c8d8fb-ec36-4e9a-94af-77796319f473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f4cf627-629f-4ccd-998a-fe10f614bc0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1a73ed0-7492-4b23-bcb9-67e51e65a31d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b96ba8b3-17b6-44bf-8f6e-c4799a62101b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57b1390c-3803-438e-bbae-38eabb68febc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0ca3a6e-bac6-4344-8e6e-70ec1c4855f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                               \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                               \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                               \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                               \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                              \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "100%|| 20/20 [09:28<00:00, 28.45s/trial, best loss: -0.6998290598290599]\n",
      "Best parameters:  {'ae_activity_reg': 2.186712463067073e-06, 'ae_batch_size': 25.0, 'ae_dropout_rate': 0.2053025130075442, 'ae_learning_rate': 0.00038301767776472746, 'autoencoder_units': 488.0, 'encoding_dim': 80.0, 'fnn_batch_size': 29.0, 'fnn_dropout_rate': 0.47446652294075675, 'fnn_learning_rate': 8.730245135531804e-05, 'fnn_units': 448.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5279367f-a199-4459-8faf-8d34a0d334d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebe550a3-adfe-47e3-a8e3-c0a165821a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "256352b7-29ed-416b-8746-1bbd42c70e09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Final Model - Accuracy: 0.6998290598290599\n",
      "Final Model - F1 Score: 0.7584674429856021\n",
      "Final Model - Sensitivity: 0.8126886556721639\n",
      "Final Model - Specificity: 0.5396435250116877\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2de1c0-34dc-4c99-9d46-86f8c409109b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed1d97-8bdb-4f8f-9f22-74b9e7d4384c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7ad0d20-5a72-4d53-8e4d-eef3be67381f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_16172\\2897354534.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "838b437f-93b5-4bb0-9b7f-a00debcd9ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aebcebf1-1406-44c8-bdc5-adbe5067aeac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fce2c20-cc4a-4c9a-b016-b31318f7e210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b51c31b-5b90-4377-b75d-cdc5474ce764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc8da24f-2bc2-4503-b560-d8ec63a1d58b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [181304  81445    990 223008  97283 164820   2500  81208 174493 168855]\n",
      "Top AMGM values: [1.0045123 1.0045205 1.0045241 1.0045246 1.0045279 1.0045315 1.0045317\n",
      " 1.0045332 1.0045352 1.0045373]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f24c31d1-9a3a-4922-9fdf-c81c5540ae19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e19bbe8-d203-4af6-9885-95f5611c8d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T\n",
    "X_selected = X_selected.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c306695f-0dbb-4467-aa94-000745b2f797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2001c06b-399b-4e84-8800-583db2da07f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94f66d84-a180-47fa-9851-f1b50d226fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e30b6940-e3e6-4d6b-a0b8-4c978f554d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16498adc-a344-41c9-ae6e-465e09beac08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41497a7c-c087-4afa-bc2e-fa95dda6891a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbc5a2a3-144f-4df6-bbc9-a96d2ebfb65a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a606fc9-6fd5-4dc0-8f0b-f18f4968e92b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 551ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                               \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                              \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 536ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 534ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6799116997792494, F1 Score: 0.7581018215460885, Sensitivity: 0.8563359966868739, Specificity: 0.41825396825396827\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 845ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 433ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 828ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 425ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 858ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 449ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6997792494481235, F1 Score: 0.7642333006581712, Sensitivity: 0.8283991079312716, Specificity: 0.5174603174603175\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 316ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 303ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.673289183222958, F1 Score: 0.7603792011637122, Sensitivity: 0.8833265499932166, Specificity: 0.35000000000000003\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 278ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 274ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 274ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6975717439293598, F1 Score: 0.7610052296746783, Sensitivity: 0.8201686552563746, Specificity: 0.5210317460317461\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 211ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 617ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 601ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 635ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7591240970979497, Sensitivity: 0.8238316589193783, Specificity: 0.503968253968254\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 348ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 339ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6445916114790287, F1 Score: 0.7524897026158591, Sensitivity: 0.910892616155774, Specificity: 0.28769841269841273\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 625ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 627ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7041942604856511, F1 Score: 0.767391424377745, Sensitivity: 0.8314556571866514, Specificity: 0.5222222222222223\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 705ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 295ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 762ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 342ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7610483880363988, Sensitivity: 0.8273404308492028, Specificity: 0.5063492063492063\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 897ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6975717439293598, F1 Score: 0.7602218767575222, Sensitivity: 0.81665988332655, Specificity: 0.526984126984127\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 761ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 805ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 881ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6821192052980131, F1 Score: 0.7610733182161753, Sensitivity: 0.8619516502557438, Specificity: 0.42738095238095236\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 261ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 284ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 266ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7041942604856514, F1 Score: 0.7664272559852671, Sensitivity: 0.8274946625823819, Specificity: 0.526984126984127\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 674ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                               \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                              \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6578366445916115, F1 Score: 0.6807979933502178, Sensitivity: 0.6763090061335676, Specificity: 0.6579365079365079\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 655ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5894039735099338, F1 Score: 0.7408999004495603, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 693ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7609831767533318, Sensitivity: 0.8322163433274543, Specificity: 0.49444444444444446\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5894039735099338, F1 Score: 0.7408999004495603, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 740ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 302ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 775ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 285ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 272ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6909492273730683, F1 Score: 0.7577002878110628, Sensitivity: 0.8239858906525573, Specificity: 0.4992063492063492\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 655ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6843267108167771, F1 Score: 0.7548467853263574, Sensitivity: 0.8277926535236477, Specificity: 0.4773809523809524\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step                                              \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6975717439293598, F1 Score: 0.7602218767575222, Sensitivity: 0.81665988332655, Specificity: 0.526984126984127\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 672ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 688ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step                                              \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step                                              \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 695ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6953642384105959, F1 Score: 0.7588861958638301, Sensitivity: 0.81665988332655, Specificity: 0.5222222222222223\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step                                               \n",
      "\u001b[1m2/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step                                              \n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                              \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7702290303353326, Sensitivity: 0.8741535700600028, Specificity: 0.4373015873015873\n",
      "100%|| 20/20 [1:12:38<00:00, 217.91s/trial, best loss: -0.7702290303353326]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a02b096c-840e-4457-974f-75bba5a97aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 0.0013427543514972465, 'ae_batch_size': 57.0, 'ae_dropout_rate': 0.15411182035464638, 'ae_learning_rate': 0.00045176828547761, 'autoencoder_units': 158.0, 'encoding_dim': 11.0, 'lstm_batch_size': 46.0, 'lstm_dropout_rate': 0.49758556603284043, 'lstm_learning_rate': 2.5066303356600216e-05, 'lstm_units': 301.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a639af79-94bf-4a81-a060-7ce84e64ff4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ee6838a-4439-4e5d-800f-9da183077dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "315d89b5-7a4c-4343-b0c3-04c90783c102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f69e329-42ce-4b48-af8d-006d621b00c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.5372 - val_loss: 1.2066\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3616 - val_loss: 1.1318\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2547 - val_loss: 1.1015\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3955 - val_loss: 1.0878\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2339 - val_loss: 1.0804\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2907 - val_loss: 1.0748\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3461 - val_loss: 1.0694\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2427 - val_loss: 1.0639\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2091 - val_loss: 1.0578\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1849 - val_loss: 1.0510\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1556 - val_loss: 1.0434\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2117 - val_loss: 1.0346\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2060 - val_loss: 1.0235\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2312 - val_loss: 1.0042\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1773 - val_loss: 0.9560\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1442 - val_loss: 0.9261\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1826 - val_loss: 0.9113\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0562 - val_loss: 0.9008\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0832 - val_loss: 0.8945\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0923 - val_loss: 0.8874\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1346 - val_loss: 0.8813\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1231 - val_loss: 0.8769\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0459 - val_loss: 0.8752\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0461 - val_loss: 0.8707\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0751 - val_loss: 0.8690\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0112 - val_loss: 0.8704\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9926 - val_loss: 0.8657\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0092 - val_loss: 0.8638\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0124 - val_loss: 0.8647\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9939 - val_loss: 0.8635\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9621 - val_loss: 0.8620\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0416 - val_loss: 0.8618\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0404 - val_loss: 0.8623\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9322 - val_loss: 0.8608\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9384 - val_loss: 0.8615\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9998 - val_loss: 0.8607\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0355 - val_loss: 0.8605\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0925 - val_loss: 0.8587\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0707 - val_loss: 0.8602\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9965 - val_loss: 0.8589\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0827 - val_loss: 0.8607\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9302 - val_loss: 0.8587\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0103 - val_loss: 0.8592\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 326ms/step - accuracy: 0.5188 - loss: 0.6930 - val_accuracy: 0.6491 - val_loss: 0.6922\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - accuracy: 0.6417 - loss: 0.6918 - val_accuracy: 0.6404 - val_loss: 0.6911\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 0.6547 - loss: 0.6906 - val_accuracy: 0.6491 - val_loss: 0.6900\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.6975 - loss: 0.6891 - val_accuracy: 0.6491 - val_loss: 0.6887\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 0.6984 - loss: 0.6872 - val_accuracy: 0.6491 - val_loss: 0.6870\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - accuracy: 0.7032 - loss: 0.6847 - val_accuracy: 0.6491 - val_loss: 0.6849\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - accuracy: 0.6909 - loss: 0.6832 - val_accuracy: 0.6491 - val_loss: 0.6823\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - accuracy: 0.7015 - loss: 0.6790 - val_accuracy: 0.6579 - val_loss: 0.6787\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.6966 - loss: 0.6745 - val_accuracy: 0.6491 - val_loss: 0.6740\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - accuracy: 0.6647 - loss: 0.6710 - val_accuracy: 0.6404 - val_loss: 0.6682\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - accuracy: 0.6962 - loss: 0.6581 - val_accuracy: 0.6491 - val_loss: 0.6610\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.7017 - loss: 0.6459 - val_accuracy: 0.6491 - val_loss: 0.6537\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - accuracy: 0.7031 - loss: 0.6391 - val_accuracy: 0.6404 - val_loss: 0.6480\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.7099 - loss: 0.6220 - val_accuracy: 0.6491 - val_loss: 0.6457\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.7238 - loss: 0.5998 - val_accuracy: 0.6491 - val_loss: 0.6492\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 0.7055 - loss: 0.6037 - val_accuracy: 0.6491 - val_loss: 0.6523\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - accuracy: 0.6685 - loss: 0.6348 - val_accuracy: 0.6491 - val_loss: 0.6532\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6777 - loss: 0.6298 - val_accuracy: 0.6579 - val_loss: 0.6534\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - accuracy: 0.6981 - loss: 0.6095 - val_accuracy: 0.6491 - val_loss: 0.6540\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e83025a-f9ef-4249-8c45-25e7a22cf549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step\n",
      "Accuracy: 0.6491228070175439\n",
      "F1 Score: 0.7468354430379747\n",
      "Sensitivity: 0.8676470588235294\n",
      "Specificity: 0.32608695652173914\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2b511-47b1-4f85-b1a2-c6f3b57515fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14a1d874-060e-450f-9df3-7a909997eb58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8b7d2c-4ccd-4347-a26d-105cefc88ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060f4fa6-360e-48f7-ad73-659e626f5efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10bb0861-2a3d-4603-8344-0db37b86e569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedAutismData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df73db59-554d-4cbc-8ae9-fea3c71b2759",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_28688\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3611fd-46e6-4709-9f97-804e246218da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf31aaa-c94c-4610-b317-1df4f766415c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00de112-4702-43ec-b6bf-5e7a7fa09768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c375c35-f8e3-47b9-9175-1b511d5d34d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb23fb98-bd71-4093-8382-eeecff2a2da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e528f3-98a2-42a5-a80c-389c2ef2941d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5s/step - loss: 1.2434 - val_loss: 1.1653\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 1.0880 - val_loss: 1.0184\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5s/step - loss: 0.9892 - val_loss: 1.0040\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9884 - val_loss: 1.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9881 - val_loss: 0.9976\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9880 - val_loss: 0.9961\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9880 - val_loss: 0.9950\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9876 - val_loss: 0.9943\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9878 - val_loss: 0.9937\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9876 - val_loss: 0.9933\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9876 - val_loss: 0.9930\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9875 - val_loss: 0.9927\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9876 - val_loss: 0.9925\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9877 - val_loss: 0.9924\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9878 - val_loss: 0.9922\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9877 - val_loss: 0.9921\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5s/step - loss: 0.9877 - val_loss: 0.9921\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9876 - val_loss: 0.9920\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9877 - val_loss: 0.9920\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9877 - val_loss: 0.9919\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9874 - val_loss: 0.9919\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9877 - val_loss: 0.9919\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9874 - val_loss: 0.9918\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9875 - val_loss: 0.9918\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9872 - val_loss: 0.9918\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9872 - val_loss: 0.9918\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9872 - val_loss: 0.9918\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9875 - val_loss: 0.9918\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9874 - val_loss: 0.9917\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9873 - val_loss: 0.9917\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9872 - val_loss: 0.9917\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9875 - val_loss: 0.9917\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9872 - val_loss: 0.9917\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9875 - val_loss: 0.9917\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9876 - val_loss: 0.9917\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9871 - val_loss: 0.9917\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9874 - val_loss: 0.9917\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9874 - val_loss: 0.9917\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9871 - val_loss: 0.9917\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9870 - val_loss: 0.9917\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9872 - val_loss: 0.9917\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9869 - val_loss: 0.9917\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9873 - val_loss: 0.9917\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5s/step - loss: 0.9872 - val_loss: 0.9917\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9871 - val_loss: 0.9917\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9872 - val_loss: 0.9917\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9872 - val_loss: 0.9917\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9873 - val_loss: 0.9917\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9869 - val_loss: 0.9917\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - loss: 0.9869 - val_loss: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17c3feaa950>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder, encoder = create_feature_autoencoder(input_dim, encoding_dim)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a61536b9-fa14-49f6-85b4-af475df5a65d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step\n",
      "Shape of encoded features: (567, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = encoder.predict(X_scaled)\n",
    "print(f\"Shape of encoded features: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "919b5dfa-c183-44af-9277-228bb8bb44c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after L1-based Feature Selection: (567, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.500e+00, tolerance: 1.371e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "target_features = 200  # Target number of features\n",
    "X_final, selected_indices_l1 = apply_l1_feature_selection(X_encoded, y, alpha=0.005, target_features=target_features)\n",
    "print(f\"Shape after L1-based Feature Selection: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34c8e0f-ab45-4742-92e4-c31ec49525a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(567, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d2c6c-a1ac-4246-9730-a1e9e3fda7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "223f6564-cb0d-48b5-883c-ac51607213e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4f1778-03ba-47a0-9db2-a9b1f71deaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b526e4-604d-4f4b-b86e-dbaff823d9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f07b1ce-fd5f-45ec-b14b-80e38ba38ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> \n",
       "\n",
       " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> \n",
       "\n",
       " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                           \u001b[38;5;34m20,100\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                             \u001b[38;5;34m5,050\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                            \u001b[38;5;34m5,100\u001b[0m \n",
       "\n",
       " dense_5 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                           \u001b[38;5;34m20,200\u001b[0m \n",
       "\n",
       " dense_6 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                \u001b[38;5;34m201\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546f7e8e-0f13-4405-9f11-f0c3fa846bbb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5272 - loss: 0.7315 - val_accuracy: 0.7368 - val_loss: 0.5951 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6394 - loss: 0.6526 - val_accuracy: 0.7368 - val_loss: 0.5555 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6219 - loss: 0.6561 - val_accuracy: 0.7368 - val_loss: 0.5739 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6129 - loss: 0.6512 - val_accuracy: 0.7368 - val_loss: 0.5715 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5887 - loss: 0.6884 - val_accuracy: 0.7368 - val_loss: 0.5810 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7032 - loss: 0.6176 - val_accuracy: 0.7368 - val_loss: 0.5606 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6724 - loss: 0.6496 - val_accuracy: 0.7368 - val_loss: 0.5587 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6977 - loss: 0.6119 - val_accuracy: 0.7368 - val_loss: 0.5368 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.5906 - val_accuracy: 0.7368 - val_loss: 0.5416 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6680 - loss: 0.5935 - val_accuracy: 0.7368 - val_loss: 0.5464 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.5654 - val_accuracy: 0.7193 - val_loss: 0.5354 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6930 - loss: 0.6269 - val_accuracy: 0.7368 - val_loss: 0.5116 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7126 - loss: 0.5779 - val_accuracy: 0.7368 - val_loss: 0.5152 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7097 - loss: 0.5817 - val_accuracy: 0.7544 - val_loss: 0.5254 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7002 - loss: 0.6008 - val_accuracy: 0.7544 - val_loss: 0.5200 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6543 - loss: 0.5986 - val_accuracy: 0.7719 - val_loss: 0.5176 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7205 - loss: 0.5515 - val_accuracy: 0.7544 - val_loss: 0.5355 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7164 - loss: 0.6000 - val_accuracy: 0.7368 - val_loss: 0.5090 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6644 - loss: 0.6062 - val_accuracy: 0.7719 - val_loss: 0.5099 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6665 - loss: 0.5946 - val_accuracy: 0.7544 - val_loss: 0.5074 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.5715 - val_accuracy: 0.7544 - val_loss: 0.4941 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7204 - loss: 0.5366 - val_accuracy: 0.7719 - val_loss: 0.4750 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 0.5842 - val_accuracy: 0.7544 - val_loss: 0.4902 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6828 - loss: 0.6018 - val_accuracy: 0.7719 - val_loss: 0.5017 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7294 - loss: 0.5697 - val_accuracy: 0.7544 - val_loss: 0.4853 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7177 - loss: 0.5792 - val_accuracy: 0.7544 - val_loss: 0.4928 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6953 - loss: 0.5543 - val_accuracy: 0.7544 - val_loss: 0.4852 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7204 - loss: 0.5612 - val_accuracy: 0.7544 - val_loss: 0.4865 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7164 - loss: 0.5506 - val_accuracy: 0.7544 - val_loss: 0.4616 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7215 - loss: 0.5474 - val_accuracy: 0.8070 - val_loss: 0.4722 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.5339 - val_accuracy: 0.7719 - val_loss: 0.4628 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.5009 - val_accuracy: 0.7544 - val_loss: 0.4520 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.4951 - val_accuracy: 0.7544 - val_loss: 0.4621 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7269 - loss: 0.5230 - val_accuracy: 0.7895 - val_loss: 0.4837 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7497 - loss: 0.5623 - val_accuracy: 0.7719 - val_loss: 0.4594 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7562 - loss: 0.5141 - val_accuracy: 0.8070 - val_loss: 0.4590 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7672 - loss: 0.4883 - val_accuracy: 0.7895 - val_loss: 0.4570 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7627 - loss: 0.5317 - val_accuracy: 0.7895 - val_loss: 0.4707 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.5824 - val_accuracy: 0.7895 - val_loss: 0.4455 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.5167 - val_accuracy: 0.7544 - val_loss: 0.4802 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7376 - loss: 0.5113 - val_accuracy: 0.7544 - val_loss: 0.4770 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.5199 - val_accuracy: 0.7895 - val_loss: 0.4582 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5064 - val_accuracy: 0.7895 - val_loss: 0.4289 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7545 - loss: 0.5545 - val_accuracy: 0.7895 - val_loss: 0.4582 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7343 - loss: 0.5356 - val_accuracy: 0.7895 - val_loss: 0.4622 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6945 - loss: 0.5526 - val_accuracy: 0.8070 - val_loss: 0.4709 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7100 - loss: 0.5855 - val_accuracy: 0.8246 - val_loss: 0.4481 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7890 - loss: 0.5065 - val_accuracy: 0.8246 - val_loss: 0.4206 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.5429 - val_accuracy: 0.7895 - val_loss: 0.4408 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7351 - loss: 0.5007 - val_accuracy: 0.8070 - val_loss: 0.4541 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c0c6c8-2649-42f3-8886-5da710d80ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Accuracy: 0.7280701754385965\n",
      "F1 Score: 0.7737226277372263\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98f66703-3b9a-4896-a197-ad666dc76359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bbf6e3d-0793-4159-b98e-e9f05de7d556",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7280701754385965\n",
      "F1 Score: 0.7737226277372263\n",
      "Specificity: 0.6521739130434783\n",
      "Sensitivity: 0.7794117647058824\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2dfb3-c0ef-44cd-a96c-1bf0c80ffa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc667e1-8e59-4186-85f6-3766a4ce492e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c16445d-0f2e-4a6c-a113-7f0e532bc8fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c297757a-07b0-4bb8-a7f7-49b131544047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5f7b755-2cce-41a0-bbf3-9024a820f6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93f01450-5931-4d76-b356-84b5af89bd27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddb9de41-9c1a-4e84-a8f1-242bb654b52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62915a4a-35e9-40b1-8bba-916fa5680b00",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 23 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017C458277E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 24 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017C458277E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.6102292768959435, F1 Score: 0.7456846950517837, Sensitivity: 0.9671641791044776, Specificity: 0.09482758620689655\n",
      "Accuracy: 0.6790123456790124, F1 Score: 0.7436619718309859, Sensitivity: 0.7880597014925373, Specificity: 0.521551724137931\n",
      "Accuracy: 0.7848324514991182, F1 Score: 0.8069620253164557, Sensitivity: 0.7611940298507462, Specificity: 0.8189655172413793\n",
      "Accuracy: 0.7936507936507936, F1 Score: 0.8235294117647058, Sensitivity: 0.8149253731343283, Specificity: 0.7629310344827587\n",
      "Accuracy: 0.8148148148148148, F1 Score: 0.8406676783004552, Sensitivity: 0.826865671641791, Specificity: 0.7974137931034483\n",
      "Accuracy: 0.8324514991181657, F1 Score: 0.8567119155354449, Sensitivity: 0.8477611940298507, Specificity: 0.8103448275862069\n",
      "Accuracy: 0.6067019400352733, F1 Score: 0.7415990730011588, Sensitivity: 0.9552238805970149, Specificity: 0.10344827586206896\n",
      "Accuracy: 0.8395061728395061, F1 Score: 0.8627450980392157, Sensitivity: 0.8537313432835821, Specificity: 0.8189655172413793\n",
      "Accuracy: 0.8059964726631393, F1 Score: 0.8253968253968254, Sensitivity: 0.7761194029850746, Specificity: 0.8491379310344828\n",
      "Accuracy: 0.6172839506172839, F1 Score: 0.7356881851400731, Sensitivity: 0.9014925373134328, Specificity: 0.20689655172413793\n",
      "Accuracy: 0.7795414462081128, F1 Score: 0.8006379585326954, Sensitivity: 0.7492537313432835, Specificity: 0.8232758620689655\n",
      "Accuracy: 0.689594356261023, F1 Score: 0.754874651810585, Sensitivity: 0.808955223880597, Specificity: 0.5172413793103449\n",
      "Accuracy: 0.689594356261023, F1 Score: 0.7528089887640449, Sensitivity: 0.8, Specificity: 0.5301724137931034           \n",
      "Accuracy: 0.7566137566137566, F1 Score: 0.7857142857142857, Sensitivity: 0.755223880597015, Specificity: 0.7586206896551724\n",
      "Accuracy: 0.7566137566137566, F1 Score: 0.7883435582822086, Sensitivity: 0.7671641791044777, Specificity: 0.7413793103448276\n",
      "Accuracy: 0.6419753086419753, F1 Score: 0.7521367521367521, Sensitivity: 0.9194029850746268, Specificity: 0.2413793103448276\n",
      "Accuracy: 0.6666666666666666, F1 Score: 0.748335552596538, Sensitivity: 0.8388059701492537, Specificity: 0.41810344827586204\n",
      "Accuracy: 0.5908289241622575, F1 Score: 0.7427937915742794, Sensitivity: 1.0, Specificity: 0.0                         \n",
      "Accuracy: 0.7777777777777778, F1 Score: 0.8, Sensitivity: 0.7522388059701492, Specificity: 0.8146551724137931          \n",
      "Accuracy: 0.5291005291005291, F1 Score: 0.6615969581749049, Sensitivity: 0.7791044776119403, Specificity: 0.16810344827586207\n",
      "100%|| 20/20 [11:10<00:00, 33.52s/trial, best loss: -0.8627450980392157]\n",
      "Best parameters found:  {'batch_size': 128.0, 'dropout_rate': 0.27000703951509747, 'epochs': 200.0, 'learning_rate': 0.0001210491239187142, 'neurons1': 224.0, 'neurons2': 48.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10756785-ffcb-4102-9e7b-55787db21569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8395061728395061\n",
      "Best F1 Score: 0.8627450980392157\n",
      "Best Specificity: 0.8189655172413793\n",
      "Best Sensitivity: 0.8537313432835821\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "effedb1b-628a-423f-aa57-d0071e407841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_101\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_101\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " dense_507 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">45,024</span> \n",
       "\n",
       " dropout_202 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_508 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">10,800</span> \n",
       "\n",
       " dropout_203 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_509 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">10,976</span> \n",
       "\n",
       " dense_510 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">45,000</span> \n",
       "\n",
       " dense_511 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_507 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                           \u001b[38;5;34m45,024\u001b[0m \n",
       "\n",
       " dropout_202 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_508 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                            \u001b[38;5;34m10,800\u001b[0m \n",
       "\n",
       " dropout_203 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_509 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                           \u001b[38;5;34m10,976\u001b[0m \n",
       "\n",
       " dense_510 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                           \u001b[38;5;34m45,000\u001b[0m \n",
       "\n",
       " dense_511 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                \u001b[38;5;34m201\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,001</span> (437.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,001\u001b[0m (437.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,001</span> (437.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m112,001\u001b[0m (437.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_final.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a06a0-99d9-47a8-8fe7-afc657292437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667f307-a154-4add-8ed6-169744498010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60011eaa-b166-4653-b930-facfc18e8ed3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76c7880f-58cc-4bf0-8334-81cc5cd62992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9fccce1-4758-4924-8b53-ddac42c4f097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21799b1c-dcc4-471a-b79a-d54f3ee5aefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 64)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "661cad3b-f2a4-47eb-a877-793537aea23b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49a41361-37bc-4e05-9993-77356a372841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6931567328918322, F1 Score: 0.7477108978708281, Sensitivity: 0.7685469063221199, Specificity: 0.5831767131401494\n",
      "Iteration Results - Accuracy: 0.7196467991169978, F1 Score: 0.7595704137872813, Sensitivity: 0.7530850679529149, Specificity: 0.6691156369600875\n",
      "Iteration Results - Accuracy: 0.7350993377483444, F1 Score: 0.7697578237669638, Sensitivity: 0.7496340780920402, Specificity: 0.7123371149990887\n",
      "Iteration Results - Accuracy: 0.6799116997792495, F1 Score: 0.7325588624874976, Sensitivity: 0.7419852807678557, Specificity: 0.5885530572261709\n",
      "Iteration Results - Accuracy: 0.7064017660044151, F1 Score: 0.7311080756259365, Sensitivity: 0.6791777332307629, Specificity: 0.7452900036449791\n",
      "Iteration Results - Accuracy: 0.6754966887417219, F1 Score: 0.7380611066885576, Sensitivity: 0.7727447137854293, Specificity: 0.5366804492436669\n",
      "Iteration Results - Accuracy: 0.6953642384105959, F1 Score: 0.7487360682749312, Sensitivity: 0.7681664785584735, Specificity: 0.5875022781119008\n",
      "Iteration Results - Accuracy: 0.7461368653421635, F1 Score: 0.7772301795492825, Sensitivity: 0.7528047773865877, Specificity: 0.7356507426644797\n",
      "Iteration Results - Accuracy: 0.7218543046357615, F1 Score: 0.7335595944437497, Sensitivity: 0.6583576189433372, Specificity: 0.817369464188081\n",
      "Iteration Results - Accuracy: 0.6997792494481235, F1 Score: 0.7474516953835492, Sensitivity: 0.7504309642931344, Specificity: 0.6288784855112083\n",
      "Iteration Results - Accuracy: 0.6777041942604857, F1 Score: 0.75320321734169, Sensitivity: 0.8353159562540826, Specificity: 0.44891334062329147\n",
      "Iteration Results - Accuracy: 0.6732891832229582, F1 Score: 0.7306987650833389, Sensitivity: 0.7501366358019492, Specificity: 0.5621127209768543\n",
      "Iteration Results - Accuracy: 0.7130242825607064, F1 Score: 0.7498193358077181, Sensitivity: 0.7353355157627178, Specificity: 0.6820125979588118\n",
      "Iteration Results - Accuracy: 0.7218543046357615, F1 Score: 0.7529148023028772, Sensitivity: 0.7202321124082154, Specificity: 0.7240152861308548\n",
      "Iteration Results - Accuracy: 0.7461368653421633, F1 Score: 0.7698075776340535, Sensitivity: 0.7200238831894913, Specificity: 0.7830924229998177\n",
      "Iteration Results - Accuracy: 0.6997792494481235, F1 Score: 0.742145398189567, Sensitivity: 0.7319345945005025, Specificity: 0.6539320211408785\n",
      "Iteration Results - Accuracy: 0.6997792494481235, F1 Score: 0.744031285140995, Sensitivity: 0.7387645128746488, Specificity: 0.6418551804264625\n",
      "Iteration Results - Accuracy: 0.7483443708609272, F1 Score: 0.7674310717676747, Sensitivity: 0.7079550112584156, Specificity: 0.8034217240750866\n",
      "Iteration Results - Accuracy: 0.7108167770419426, F1 Score: 0.731604688103619, Sensitivity: 0.6782947477572074, Specificity: 0.754550528521961\n",
      "Iteration Results - Accuracy: 0.7108167770419426, F1 Score: 0.7544295413147872, Sensitivity: 0.7540401147740736, Specificity: 0.6497118188445415\n",
      "100%|| 20/20 [1:49:30<00:00, 328.55s/trial, best loss: -0.7772301795492825]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0077e92-b826-4640-8702-865678d49eba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 128, 'dropout_rate': 0.4134380442350706, 'learning_rate': 0.009180535567439925, 'epochs': 50, 'batch_size': 48, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4e63199-5925-4f3d-9b2d-98afe935ef34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7368421052631579\n",
      "F1 Score: 0.7540983606557377\n",
      "Sensitivity: 0.6865671641791045\n",
      "Specificity: 0.8085106382978723\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420b729-f000-4ee7-a385-a7ed97c0e88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3d5e3d5-7be4-46f0-8ed3-0ebbd4fc4d72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GRU with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4245244e-0663-4b92-b51a-4a5b4d48fb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a253c7ab-18eb-4ad5-b8c4-23bcc354c129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed8a357-f952-429e-add5-36cae14c2faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c2ce45-17b2-4e85-8437-53c719e89df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 128, 64)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4faed90-dc14-4579-9ae0-ab314bff8b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d511dd6-3f23-45a5-8f09-08efdbadd61f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6539624183006536, Sensitivity: 0.7574548907882241, Specificity: 0.5292929292929293\n",
      "Iteration Results - Accuracy: 0.6000000000000001, F1 Score: 0.6280188114659466, Sensitivity: 0.7535612535612536, Specificity: 0.4666666666666666\n",
      "Iteration Results - Accuracy: 0.5944444444444444, F1 Score: 0.6061506776877904, Sensitivity: 0.687369420702754, Specificity: 0.5202020202020202\n",
      "Iteration Results - Accuracy: 0.6, F1 Score: 0.6220538720538721, Sensitivity: 0.7301044634377968, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6537308482273846, Sensitivity: 0.7034188034188035, Specificity: 0.6191919191919192\n",
      "Iteration Results - Accuracy: 0.6055555555555556, F1 Score: 0.625510058673011, Sensitivity: 0.7407407407407408, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.5666666666666668, F1 Score: 0.5544767443732751, Sensitivity: 0.5978157644824311, Specificity: 0.5380867498514558\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.6282689912826899, Sensitivity: 0.6980056980056979, Specificity: 0.565359477124183\n",
      "Iteration Results - Accuracy: 0.6166666666666667, F1 Score: 0.6266655370103645, Sensitivity: 0.7074074074074074, Specificity: 0.5441473559120619\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6460707502374169, Sensitivity: 0.7716049382716049, Specificity: 0.5014260249554368\n",
      "Iteration Results - Accuracy: 0.65, F1 Score: 0.6512495555973817, Sensitivity: 0.7444444444444445, Specificity: 0.569399881164587\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6387453550195711, Sensitivity: 0.6461538461538461, Specificity: 0.6747474747474748\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.5921589919350277, Sensitivity: 0.6207027540360873, Specificity: 0.6370766488413547\n",
      "Iteration Results - Accuracy: 0.6833333333333332, F1 Score: 0.6981993514251578, Sensitivity: 0.7946818613485281, Specificity: 0.5909090909090908\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6339541280993272, Sensitivity: 0.7065527065527065, Specificity: 0.5865715983363042\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6894660894660894, Sensitivity: 0.8548907882241217, Specificity: 0.4671420083184789\n",
      "Iteration Results - Accuracy: 0.6277777777777779, F1 Score: 0.6491240026734867, Sensitivity: 0.7757834757834757, Specificity: 0.49393939393939396\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.6408712038849025, Sensitivity: 0.7586894586894587, Specificity: 0.4888888888888889\n",
      "Iteration Results - Accuracy: 0.688888888888889, F1 Score: 0.6907272890323738, Sensitivity: 0.7549857549857549, Specificity: 0.6333333333333333\n",
      "Iteration Results - Accuracy: 0.6499999999999999, F1 Score: 0.6458143132481232, Sensitivity: 0.7000949667616334, Specificity: 0.6101010101010101\n",
      "100%|| 20/20 [2:21:14<00:00, 423.72s/trial, best loss: -0.6981993514251578]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a55e2384-6b60-42fe-97c5-37df4ba23a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 48, 'bidirectional': True, 'dropout_rate': 0.4134380442350706, 'epochs': 50, 'learning_rate': 0.009180535567439925, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)  \n",
    "print(\"Best Parameters:\", best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "737c65e7-aedc-4789-8d53-ab1a74333fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3bf6ccb-0c80-49de-b773-71e97f37c1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f24e9b2b-d9f2-4ec4-bea0-374e0a2a7a20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18308096a90>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd757030-be88-4f80-9fa3-6b57990304b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.6666666666666666\n",
      "F1 Score: 0.7432432432432432\n",
      "Sensitivity: 0.8208955223880597\n",
      "Specificity: 0.44680851063829785\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95bd7c-c068-4142-863b-dc0bbd8e0561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c245a3e2-036d-43de-8c9e-715f3f4fa444",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89415dd3-a809-4efb-944e-ccfd28829cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fa8d55c-ddb7-4322-afb5-67e63795e81f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29ef2763-eb8f-4ed5-a032-c1dc8456c3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20010a6c-ee2a-4a21-963c-1721d7fb8b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "caa9d1ef-70df-439a-b760-0d0c6598f62a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "792beea1-cf66-4979-9922-555581b8af55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6887417218543046, F1 Score: 0.7509219263944225, Sensitivity: 0.7989617919442481, Specificity: 0.5349206349206349\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7554213164666616, Sensitivity: 0.8020183411996277, Specificity: 0.5436507936507936\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7461368653421635, F1 Score: 0.7839829330987759, Sensitivity: 0.7861638902574576, Specificity: 0.6865079365079364\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7505518763796909, F1 Score: 0.7907840951319213, Sensitivity: 0.8085974670769992, Specificity: 0.6515873015873016\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6401766004415012, F1 Score: 0.6925034142241833, Sensitivity: 0.7196724003741548, Specificity: 0.5337301587301587\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7064017660044151, F1 Score: 0.7530251480059516, Sensitivity: 0.7618900051648589, Specificity: 0.6353174603174603\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7439293598233996, F1 Score: 0.7731246322131368, Sensitivity: 0.745891795014602, Specificity: 0.7472222222222222\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6799116997792495, F1 Score: 0.7586934548379585, Sensitivity: 0.8601113419826869, Specificity: 0.4142857142857143\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7130242825607064, F1 Score: 0.7632859813055308, Sensitivity: 0.783692850359517, Specificity: 0.6162698412698413\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7108167770419426, F1 Score: 0.7567785584179028, Sensitivity: 0.7686200306083347, Specificity: 0.6281746031746032\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7218543046357615, F1 Score: 0.7642505603206405, Sensitivity: 0.7687637898164215, Specificity: 0.6615079365079365\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6865342163355409, F1 Score: 0.7635888606983207, Sensitivity: 0.8616569914815528, Specificity: 0.4150793650793651\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6953642384105961, F1 Score: 0.7557098414143714, Sensitivity: 0.8026247956072518, Specificity: 0.5476190476190476\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6070640176600441, F1 Score: 0.7355283828902998, Sensitivity: 0.9261615577405052, Specificity: 0.17261904761904764\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7240618101545254, F1 Score: 0.763812458727713, Sensitivity: 0.7596184192675421, Specificity: 0.6714285714285714\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7262693156732892, F1 Score: 0.7738481074723235, Sensitivity: 0.7940858794659964, Specificity: 0.623015873015873\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7041942604856514, F1 Score: 0.7452107279693486, Sensitivity: 0.7370201381897288, Specificity: 0.6686507936507936\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.706401766004415, F1 Score: 0.7636992405932411, Sensitivity: 0.8090358850592768, Specificity: 0.5603174603174603\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step                                               \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                                \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                               \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7019867549668874, F1 Score: 0.7582257048912272, Sensitivity: 0.7959052426888684, Specificity: 0.5757936507936509\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7306843267108167, F1 Score: 0.7780683412142205, Sensitivity: 0.8018641094664486, Specificity: 0.6309523809523809\n",
      "100%|| 20/20 [05:51<00:00, 17.59s/trial, best loss: -0.7907840951319213]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f528b164-d15e-4bab-abc8-876656c9fb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 32, 'dropout_rate': 0.27017929251623335, 'epochs': 40, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.003915110105257093}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd910022-ddea-480c-af9e-c5216bfd2e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aebed5a6-3cc0-497a-aeb3-26f2539d11d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18309566d50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12d24ae5-9272-44ab-9b93-c4c9d48a6908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e412244b-7b45-4373-903e-b63427df5774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7631578947368421\n",
      "F1 Score: 0.7969924812030075\n",
      "Sensitivity: 0.7794117647058824\n",
      "Specificity: 0.7391304347826086\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223d412-d683-4504-937e-a3fe9addeda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b263b1e3-0ea1-4e81-b3b3-2ee093ddac78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ResNet - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29cffda9-fbcb-43bd-bb36-8b68bc420f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91ba27e1-db64-44a7-bb59-dbf4eaf5adea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e026489-fd53-4b2a-94d1-3920fa981364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cb66e65-9e19-439d-b516-a2ba26190695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "838bc087-ede5-4075-b0fb-ba4a27da2fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3cd6e6dc-6d1c-4f8d-9b88-ddbc5d9b8bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90024645-52ff-4e7a-9f00-d39da14904c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.23277877337170363, 'epochs': 30, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.005912816096082353, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.7519435286521912, Filters: 128, Blocks: 10, Kernel Size: 5, Dropout: 0.23277877337170363, LR: 0.005912816096082353, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.24289420750888183, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.00977333118221983, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.6311425566673279, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.24289420750888183, LR: 0.00977333118221983, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.32657696694726546, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.00018336250117203753, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.6288678050041199, Filters: 64, Blocks: 8, Kernel Size: 4, Dropout: 0.32657696694726546, LR: 0.00018336250117203753, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.4584776093647174, 'epochs': 30, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0026891745972453733, 'num_blocks': 10}\n",
      "Iteration - Loss: 20.18702507019043, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.4584776093647174, LR: 0.0026891745972453733, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.2974093677999303, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.008303325899025656, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.58087557554245, Filters: 96, Blocks: 10, Kernel Size: 3, Dropout: 0.2974093677999303, LR: 0.008303325899025656, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.40996274916162717, 'epochs': 20, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.0005284442813723983, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5759406685829163, Filters: 32, Blocks: 10, Kernel Size: 3, Dropout: 0.40996274916162717, LR: 0.0005284442813723983, Batch Size: 16, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3260716528519986, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.00018183594066681005, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.5008144974708557, Filters: 64, Blocks: 6, Kernel Size: 4, Dropout: 0.3260716528519986, LR: 0.00018183594066681005, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3138940552662558, 'epochs': 20, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0014197534303136642, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.5381824970245361, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.3138940552662558, LR: 0.0014197534303136642, Batch Size: 32, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.2513502744439014, 'epochs': 30, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.005136155807915682, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5466163754463196, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.2513502744439014, LR: 0.005136155807915682, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3808586804306189, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0006993187960747584, 'num_blocks': 10}\n",
      "Iteration - Loss: 2.53979229927063, Filters: 96, Blocks: 10, Kernel Size: 4, Dropout: 0.3808586804306189, LR: 0.0006993187960747584, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.21175898425859532, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0018074826983876704, 'num_blocks': 6}\n",
      "Iteration - Loss: 1.881598949432373, Filters: 96, Blocks: 6, Kernel Size: 3, Dropout: 0.21175898425859532, LR: 0.0018074826983876704, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3737004340218577, 'epochs': 30, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.00030814785639445203, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.9249272346496582, Filters: 32, Blocks: 4, Kernel Size: 5, Dropout: 0.3737004340218577, LR: 0.00030814785639445203, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.43659101558974983, 'epochs': 20, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0007138423493773261, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.4717045724391937, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.43659101558974983, LR: 0.0007138423493773261, Batch Size: 16, Epochs: 20\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.32024733247630044, 'epochs': 40, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.00295964610395927, 'num_blocks': 8}\n",
      "Iteration - Loss: 34.45967483520508, Filters: 96, Blocks: 8, Kernel Size: 5, Dropout: 0.32024733247630044, LR: 0.00295964610395927, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.21413926318002685, 'epochs': 30, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.00035288420180223256, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5937699675559998, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.21413926318002685, LR: 0.00035288420180223256, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4764456411298167, 'epochs': 40, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.00123657275672477, 'num_blocks': 8}\n",
      "Iteration - Loss: 4.012450695037842, Filters: 128, Blocks: 8, Kernel Size: 5, Dropout: 0.4764456411298167, LR: 0.00123657275672477, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.21055855365939227, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.003701235175987684, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.7938970327377319, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.21055855365939227, LR: 0.003701235175987684, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.35816515659984827, 'epochs': 40, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.002273119621371886, 'num_blocks': 4}\n",
      "Iteration - Loss: 5.775444507598877, Filters: 128, Blocks: 4, Kernel Size: 4, Dropout: 0.35816515659984827, LR: 0.002273119621371886, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.2638027044311128, 'epochs': 40, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.0014905476178916294, 'num_blocks': 8}\n",
      "Iteration - Loss: 2.714979410171509, Filters: 96, Blocks: 8, Kernel Size: 5, Dropout: 0.2638027044311128, LR: 0.0014905476178916294, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.23761677977425283, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.00529715017361438, 'num_blocks': 10}\n",
      "Iteration - Loss: 1.5226267576217651, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.23761677977425283, LR: 0.00529715017361438, Batch Size: 48, Epochs: 40\n",
      "100%|| 20/20 [16:20<00:00, 49.05s/trial, best loss: 0.4717045724391937]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3049b1d9-af7c-4cf7-898d-28c7f03314f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 16, 'dropout_rate': 0.43659101558974983, 'epochs': 20, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0007138423493773261, 'num_blocks': 6}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "168df3cf-ef83-497b-a37d-2a93f5dcdc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acec6fba-2f29-403c-9e63-d9e4c0974096",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.7066 - loss: 0.6163 - val_accuracy: 0.7826 - val_loss: 0.4449\n",
      "Epoch 2/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.6853 - loss: 0.5904 - val_accuracy: 0.6739 - val_loss: 0.5501\n",
      "Epoch 3/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.7181 - loss: 0.6043 - val_accuracy: 0.6304 - val_loss: 3.3590\n",
      "Epoch 4/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.7430 - loss: 0.4982 - val_accuracy: 0.8261 - val_loss: 0.4716\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "182094e5-e4ee-45d4-89b6-cbf509ce6f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step \n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2d4a580b-27dc-4f9e-a4dd-b96fa6b30bca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.6842105263157895\n",
      "F1 Score: 0.7631578947368421\n",
      "Sensitivity: 0.8529411764705882\n",
      "Specificity: 0.43478260869565216\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e473f86-b775-4c20-98d2-c4dc1ed70208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
