{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12a45c9-ce2d-4557-85b3-2087b59d7b79",
   "metadata": {},
   "source": [
    "## Data / Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da206e58-d4f8-4370-b70d-4883707a3663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Affy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, GRU, Layer, Add, GlobalAveragePooling1D, Conv1D, ReLU\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "import scipy.stats as stats\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from accelerate import DataLoaderConfiguration\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from boruta import BorutaPy\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "from boruta import BorutaPy\n",
    "from skrebate import ReliefF\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6360aad-5901-4ed1-bd15-357ad9c18bf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AMGM and Cosine Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6aa5e7e-fb68-4adb-bae7-44b8dc4fe76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_amgm(X):\n",
    "    \"\"\"\n",
    "    Calculate AMGM for each feature (row) in the dataset X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): The input data array with shape (n_features, n_samples)\n",
    "    \n",
    "    Returns:\n",
    "    amgm_values (numpy array): The AMGM values for each feature (row)\n",
    "    \"\"\"\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    exp_X = np.exp(X)\n",
    "    amgm_values = (np.mean(exp_X, axis=1)) / (np.exp(np.mean(X, axis=1)))\n",
    "    \n",
    "    return amgm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0148c4-73c5-46b0-9148-6f5298d9b052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_redundant_features(X, relevant_indices, threshold=0.9):\n",
    "    relevant_features = X[relevant_indices, :]\n",
    "    cos_sim_matrix = cosine_similarity(relevant_features)\n",
    "    \n",
    "    to_keep = []\n",
    "    to_drop = set()\n",
    "    for i in range(cos_sim_matrix.shape[0]):\n",
    "        if i not in to_drop:\n",
    "            to_keep.append(relevant_indices[i])\n",
    "            for j in range(i + 1, cos_sim_matrix.shape[0]):\n",
    "                if cos_sim_matrix[i, j] > threshold:\n",
    "                    to_drop.add(relevant_indices[j])\n",
    "    return to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6abdb-2769-4a0a-9d1b-a54d0c95c377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "141167e1-fef2-4eb2-be9d-d5791ca5db14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Autoencoder Feature Selection with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b809e0f-975b-4209-b5b5-e93312ed64e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_feature_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)  # Encoder part\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)  # Decoder part\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3390d2-5b9e-48b5-9fff-da9ac0270b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_l1_feature_selection(X, y, alpha=0.01, target_features=100):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    model = SelectFromModel(lasso, prefit=True, max_features=target_features)\n",
    "    X_reduced = model.transform(X)\n",
    "    selected_indices = model.get_support(indices=True)\n",
    "    return X_reduced, selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237c56f-b40e-4fa6-8998-698b3496270d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initial Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce3ed9a-be53-4251-bf56-2687c2a66d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c6fbf8-0b41-4017-8e36-33eedfa0d11f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17419532-e1e9-4844-9e04-a51fc559e354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893f91d8-6d49-4f89-928d-4552771e81c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea511ea6-d5a3-412b-bc39-9f34239df71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef18d1e-edbe-44fe-b854-937332900c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "245db645-5770-45b3-bb08-bb111df555ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d089424c-190d-40bf-bb12-80d69f4bcd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 206406 232276 250927 321802 270758 200059 197015 126599 374361]\n",
      "Top AMGM values: [1.01338819 1.01339466 1.01339466 1.01339577 1.013396   1.01339625\n",
      " 1.01339625 1.01340604 1.01340653 1.01340799]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5bea093-e2e4-4c00-a391-191cfcfab5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef25354f-4d57-46a7-b9f2-af4194e6e163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "163b88f0-0c40-458f-890f-bc5f52818bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c7197c-7daa-4c1e-a969-bb60aada811c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02da388-b972-4fc5-9c52-b3f5b0dccf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d96341-c432-40ec-9040-59ff0f041c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2766c39e-f075-4997-8c6d-2978b2f7a770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6495cd26-fe85-4289-90fd-528e19da870b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m1,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m5,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,826</span> (50.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,826\u001b[0m (50.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,826</span> (50.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,826\u001b[0m (50.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bac03230-c128-4fc0-824d-1ab467fa2329",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9755 - loss: 0.0889 - val_accuracy: 1.0000 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9172 - loss: 0.1651 - val_accuracy: 1.0000 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9897 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9509 - loss: 0.0709 - val_accuracy: 1.0000 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9716 - loss: 0.0589 - val_accuracy: 1.0000 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9794 - loss: 0.0718 - val_accuracy: 1.0000 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9637 - loss: 0.0867 - val_accuracy: 1.0000 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9755 - loss: 0.0713 - val_accuracy: 1.0000 - val_loss: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9819 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 1.0000 - val_loss: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9716 - loss: 0.0681 - val_accuracy: 1.0000 - val_loss: 0.0038 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9406 - loss: 0.1279 - val_accuracy: 1.0000 - val_loss: 0.0038 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9833 - loss: 0.0338 - val_accuracy: 1.0000 - val_loss: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9936 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 0.0038 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0037 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9637 - loss: 0.0690 - val_accuracy: 1.0000 - val_loss: 0.0036 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9897 - loss: 0.0678 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0280 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9819 - loss: 0.0488 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9897 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0667 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0033 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9755 - loss: 0.0548 - val_accuracy: 1.0000 - val_loss: 0.0032 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0029 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0027 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0023 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9534 - loss: 0.0525 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9936 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0444 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0020 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0559 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0015 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0010 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 8.6714e-04 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 7.7237e-04 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 6.8762e-04 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9509 - loss: 0.1557 - val_accuracy: 1.0000 - val_loss: 6.9896e-04 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9819 - loss: 0.0445 - val_accuracy: 1.0000 - val_loss: 7.7414e-04 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 8.2856e-04 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0384 - val_accuracy: 1.0000 - val_loss: 8.6535e-04 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 8.7464e-04 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 8.6791e-04 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8da8045-ec53-4b40-ab39-626062bb3c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11bfd350-a3c7-4b9b-8399-c808e2a56a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16de2677-6743-4500-a48a-90a9a916ac02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Specificity: 0.8\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dfac1-b407-4aa4-9229-7e9482a4f06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f48a161-03be-47ff-b5db-7a285dad7a81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbf0a292-9c5b-47af-a690-4ae39a2a4e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff51dbd-8ce9-4c84-8fad-ee9991bb1d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f403c24-70a1-40c1-afff-da85991f6ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd7d8401-009e-44e2-9745-d1689858b101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc00fe7e-ec89-454f-8f80-e5bd5955b164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 206406 232276 250927 321802 270758 200059 197015 126599 374361]\n",
      "Top AMGM values: [1.01338819 1.01339466 1.01339466 1.01339577 1.013396   1.01339625\n",
      " 1.01339625 1.01340604 1.01340653 1.01340799]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ada8958-6c7c-4c22-9ec5-75ce678ad68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f037aca6-8a28-4299-9abe-c7e0a1d32f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36f7d6ea-d889-47a8-a3fe-f43dd026ac5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9df3b518-707d-45a2-a706-fd219ca7bcfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09365ca0-ff3c-4673-b65e-faf6e0bacd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29a2835c-e3d0-4862-9bfb-a5ee2c39fe1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "567ef149-0fc5-4175-9517-1e62921adad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52d09869-b0f4-444b-88f8-5c0147845870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000255BEC19A80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000255B7586020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9469026548672567, F1 Score: 0.9558823529411765, Sensitivity: 0.9848484848484849, Specificity: 0.8936170212765957\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.8230088495575221, F1 Score: 0.8648648648648649, Sensitivity: 0.9696969696969697, Specificity: 0.6170212765957447\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9770992366412213, Sensitivity: 0.9696969696969697, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9770992366412213, Sensitivity: 0.9696969696969697, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.584070796460177, F1 Score: 0.7374301675977654, Sensitivity: 1.0, Specificity: 0.0                          \n",
      "Accuracy: 0.7876106194690266, F1 Score: 0.8441558441558441, Sensitivity: 0.9848484848484849, Specificity: 0.5106382978723404\n",
      "100%|███████████████████████████████████████████████| 20/20 [05:13<00:00, 15.67s/trial, best loss: -0.9848484848484849]\n",
      "Best parameters found:  {'batch_size': 96.0, 'dropout_rate': 0.41702030432762127, 'epochs': 100.0, 'learning_rate': 0.00022142276787805485, 'neurons1': 224.0, 'neurons2': 16.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc020e49-565f-42d4-97df-b11ed396c57a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9823008849557522\n",
      "Best F1 Score: 0.9848484848484849\n",
      "Best Specificity: 0.9787234042553191\n",
      "Best Sensitivity: 0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "003e60bb-bad1-44fd-a53f-38ec7c881c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_101\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_101\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_505 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,624</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_202 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_506 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_203 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_507 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_508 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_509 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_505 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │          \u001b[38;5;34m22,624\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_202 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_506 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_203 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_507 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │           \u001b[38;5;34m3,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_508 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m22,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_509 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,633</span> (205.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,633\u001b[0m (205.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,633</span> (205.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,633\u001b[0m (205.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c64866ee-6644-4d02-a3df-8c05cd284cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 224\n",
      "Neurons in second layer: 16\n",
      "Dropout rate: 0.41702030432762127\n",
      "Learning rate: 0.00022142276787805485\n",
      "Number of epochs: 100\n",
      "Batch size: 96\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a31047-89d7-4727-b879-2b5620c9663b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9edf826e-5645-40e6-b73a-6cd530bb4c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee1b4161-a682-4fc1-9d4b-725c50ab5226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7abb09ee-bfec-4b14-8cda-663acf8692f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\2250372466.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66308e8c-9655-48fc-8242-296d87442b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edb45a47-4d52-428a-849d-24dd95fc57dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7bba53e-2a04-42d8-8f27-911070fc3caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d291fc8-a7e6-4fb8-8c4f-282eda482880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 206406 232276 250927 321802 270758 200059 197015 126599 374361]\n",
      "Top AMGM values: [1.01338819 1.01339466 1.01339466 1.01339577 1.013396   1.01339625\n",
      " 1.01339625 1.01340604 1.01340653 1.01340799]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5811b927-f5ca-48de-acd1-002262bc700d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5591ce28-aee4-4b20-92e4-9bcdc943ecbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36c7b2eb-3baa-4482-a565-5549959197f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28bc6182-b7b1-4265-95ef-776119606d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88836856-b58c-4c0b-8541-4bb300226224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 128, 32)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55d069ba-c3b2-4af1-8229-1f800837b51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7a316be-4071-46c2-9506-fe20fbae23e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9833333333333334, Sensitivity: 0.9833333333333334, Specificity: 0.9666666666666667\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.8248677248677249, Sensitivity: 0.8370098039215685, Specificity: 0.706959706959707\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.959349593495935, Sensitivity: 0.9666666666666667, Specificity: 0.9\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.959349593495935, Sensitivity: 0.9666666666666667, Specificity: 0.9\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9422799422799423, Sensitivity: 0.9666666666666667, Specificity: 0.8428571428571429\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9138813610358326, Sensitivity: 0.8791666666666668, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.9559139784946237, Sensitivity: 0.9458333333333333, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9622202848009299, Sensitivity: 0.9291666666666667, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.888888888888889, F1 Score: 0.8989898989898991, Sensitivity: 0.8666666666666667, Specificity: 0.942857142857143\n",
      "Iteration Results - Accuracy: 0.811111111111111, F1 Score: 0.8293638728421336, Sensitivity: 0.8178921568627451, Specificity: 0.7428571428571429\n",
      "Iteration Results - Accuracy: 0.9666666666666668, F1 Score: 0.9732323232323233, Sensitivity: 0.9637254901960784, Specificity: 0.9666666666666667\n",
      "Iteration Results - Accuracy: 0.9333333333333335, F1 Score: 0.9465122690929143, Sensitivity: 0.9291666666666667, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9636062861869314, Sensitivity: 0.9458333333333333, Specificity: 0.9666666666666667\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9325289089994971, Sensitivity: 0.9053921568627451, Specificity: 0.9410256410256411\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.959349593495935, Sensitivity: 0.9666666666666667, Specificity: 0.9\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9184668989547039, Sensitivity: 0.9, Specificity: 0.9076923076923077\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9345957799905168, Sensitivity: 0.9458333333333333, Specificity: 0.8992673992673993\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9343434343434344, Sensitivity: 0.9053921568627451, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.8777777777777779, F1 Score: 0.9052429052429053, Sensitivity: 0.9470588235294118, Specificity: 0.765934065934066\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9339177978883861, Sensitivity: 0.9274509803921568, Specificity: 0.919047619047619\n",
      "100%|███████████████████████████████████████████████| 20/20 [20:31<00:00, 61.56s/trial, best loss: -0.9833333333333334]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "befc9ed2-28d3-498f-be25-37d6055132c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 64, 'dropout_rate': 0.4611060983665523, 'learning_rate': 0.0019509237966000132, 'epochs': 30, 'batch_size': 16, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79732975-4f60-421d-b850-5c6721051b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecf61b-4ad0-484a-b914-bae72a8184dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee1fd4-568e-489a-981f-2a00be36f3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78644dd2-cedc-4523-bb1f-ff39235860c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86ac28d-7e6b-45d3-b6d7-e278a48e15a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gru with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a168d442-edad-4a9a-9581-dc56d13a40c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a4d33ac4-90ae-4397-b539-2c352b291154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cfc2d87-ed27-4fb1-be3e-9ab859a2685b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1443f452-b7eb-4fa9-9796-9cde97c8ac58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f7f87ea-63d2-4a53-b208-31380799625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f81e483d-6cd4-43e6-a13c-e937ee3e9b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "374ff74c-afcc-4315-8c7a-04a3bdc62bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5265cef0-ae34-4f25-b8cb-d69ac7f906c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65cb06c5-0c00-4e04-9e28-db275077fd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff6981f9-8a8d-48b8-880b-f424ba5171fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "619c1bd2-d8c0-40c8-9f5c-8bba010b9fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 64, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.4),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "247393ae-704a-401d-95b6-659cf5e1f68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a249b175-5cc9-47cd-a714-3103f43d70ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.9333333333333332, F1 Score: 0.9370587596394048, Sensitivity: 0.897348484848485, Specificity: 0.9583333333333334\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9777777777777779, Sensitivity: 0.9848484848484849, Specificity: 0.9166666666666666\n",
      "Iteration Results - Accuracy: 0.8666666666666667, F1 Score: 0.8889027812508683, Sensitivity: 0.9195707070707071, Specificity: 0.8222222222222223\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9807538091419407, Sensitivity: 0.9626262626262626, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.5777777777777777, F1 Score: 0.710516536603493, Sensitivity: 0.8939393939393939, Specificity: 0.25\n",
      "Iteration Results - Accuracy: 0.7666666666666666, F1 Score: 0.7844651374063139, Sensitivity: 0.7468434343434343, Specificity: 0.8202380952380953\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9814953738434609, Sensitivity: 0.9848484848484849, Specificity: 0.9777777777777779\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9814953738434609, Sensitivity: 0.9848484848484849, Specificity: 0.9777777777777779\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.7796296296296297, Sensitivity: 0.734469696969697, Specificity: 0.8234126984126985\n",
      "Iteration Results - Accuracy: 0.7888888888888889, F1 Score: 0.8142331635540465, Sensitivity: 0.7856060606060606, Specificity: 0.8234126984126985\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.6847576211894052, Sensitivity: 0.7595959595959596, Specificity: 0.35000000000000003\n",
      "Iteration Results - Accuracy: 0.7777777777777777, F1 Score: 0.7882547559966914, Sensitivity: 0.7189393939393939, Specificity: 0.8484126984126984\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.7936507936507938, Sensitivity: 0.7354797979797979, Specificity: 0.8261904761904763\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9807538091419407, Sensitivity: 0.9626262626262626, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.7888888888888889, F1 Score: 0.8119744744744745, Sensitivity: 0.7718434343434343, Specificity: 0.8456349206349206\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9684385382059801, Sensitivity: 0.9404040404040405, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9684385382059801, Sensitivity: 0.9404040404040405, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.7586324786324786, Sensitivity: 0.6758838383838383, Specificity: 0.8484126984126984\n",
      "Iteration Results - Accuracy: 0.7000000000000001, F1 Score: 0.7403616852146264, Sensitivity: 0.734469696969697, Specificity: 0.6896825396825396\n",
      "Iteration Results - Accuracy: 0.6888888888888888, F1 Score: 0.7116830065359477, Sensitivity: 0.6738636363636363, Specificity: 0.778968253968254\n",
      "100%|██████████████████████████████████████████████| 20/20 [37:00<00:00, 111.02s/trial, best loss: -0.9814953738434609]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bda36308-47d7-4d06-82ff-0447d70d7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 64, 'dropout_rate': 0.24366944217613146, 'epochs': 30, 'learning_rate': 0.005064932515917304, 'units': 32}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ff996c96-8e43-4ae2-9dc8-9925e866301a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "24efc4cb-db7b-4bc0-9afd-53baa2d407e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "11aa2678-d0b4-4965-a93c-c75ec3d55ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x258020f0c10>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b262a864-333a-498d-a803-6c07a706383d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9565217391304348\n",
      "F1 Score: 0.9629629629629629\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.9\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06800a32-61b6-4931-b62c-afec61a67b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262c8354-5ba7-4ac4-9079-3e25d09760d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aeb0ec03-8a3e-48b6-8bc7-91b41190c048",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09d2f2a6-ac7c-4975-83e6-8d5b08d0ba34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e7f41809-d793-45ba-856b-ea5bcdf5f706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "497a8be1-eb5c-42fd-91eb-780f12e9ec0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f6f1ee2f-40aa-4626-984c-8993ce4c63f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b100af3c-7374-410e-9631-c7530b0391de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8b2d7f4-a8ae-4109-8ee5-75987b511aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da8eb731-7c0d-46c0-a6a0-3a816e6c615b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c56fdc0d-e5b9-438c-891a-018552c3b356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9bdb0785-985a-4e25-ac62-6d6e31ceeae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "42368856-2c83-44fd-b2cf-508616f3b15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f2e4a19-1c24-453c-ba0f-68febb947e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b931c53c-870f-4269-ab67-85ba9af38560",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.888888888888889, F1 Score: 0.8852258852258852, Sensitivity: 0.7974747474747476, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9333333333333332, F1 Score: 0.9388915373342513, Sensitivity: 0.904419191919192, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9662835249042147, Sensitivity: 0.9626262626262626, Specificity: 0.9166666666666666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9592731516212387, Sensitivity: 0.9417929292929292, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.9478036175710595, Sensitivity: 0.9209595959595959, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9250136836343733, Sensitivity: 0.8641414141414141, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.921063921063921, Sensitivity: 0.9696969696969697, Specificity: 0.8444444444444444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8333333333333334, F1 Score: 0.8795093795093796, Sensitivity: 0.9848484848484849, Specificity: 0.6678571428571428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.903359173126615, Sensitivity: 0.8320707070707071, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9444444444444443, F1 Score: 0.9495647721454173, Sensitivity: 0.904419191919192, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9700258397932817, Sensitivity: 0.9626262626262626, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.961887530706206, Sensitivity: 0.9848484848484849, Specificity: 0.9301587301587301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9599248296922717, Sensitivity: 0.9626262626262626, Specificity: 0.953968253968254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8333333333333334, F1 Score: 0.8057546318415882, Sensitivity: 0.6891414141414142, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9174603174603174, Sensitivity: 0.8585858585858586, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9666666666666668, F1 Score: 0.9747545582047685, Sensitivity: 1.0, Specificity: 0.8944444444444445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.914470284237726, Sensitivity: 0.9431818181818182, Specificity: 0.8666666666666667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                               \n",
      "\n",
      "Iteration Results - Accuracy: 0.8666666666666667, F1 Score: 0.8486583184257603, Sensitivity: 0.7487373737373737, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.9001763668430334, Sensitivity: 0.8391414141414142, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.811111111111111, F1 Score: 0.7774745579623629, Sensitivity: 0.6517676767676769, Specificity: 1.0\n",
      "100%|███████████████████████████████████████████████| 20/20 [03:24<00:00, 10.22s/trial, best loss: -0.9747545582047685]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ef58dcd0-f7fd-43b6-9b78-b0eab3b64b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.2032790134283512, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0017143166976029654}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "87bdba1e-e582-42a5-a228-e98fb0481031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b126deca-cc4c-488b-ae65-6b61c4be159e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25654cb6010>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "42e44a22-5ccb-421a-99cd-b6e78347ca89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f1d65d2b-8c64-451d-a481-eff4c4320a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.6956521739130435\n",
      "F1 Score: 0.631578947368421\n",
      "Sensitivity: 0.46153846153846156\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76a2b0-d926-41b4-a05e-4d8ccfab550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a1f12b-0239-4076-b343-97f676fd1a57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7f3daed1-2a50-4e75-80c0-acf1b6d99a17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9ec3b627-9922-4f7e-82a3-b1b6b5d87d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5ec688b5-f8aa-4cbe-a78c-3dd3da8a20b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2c66f65b-a551-44fa-814e-a7cf73e61a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "226dd57a-04c9-43ce-9f94-497d157bed7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d1748cc9-2523-4f9c-b6b2-852acab4a4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "610d99a1-4335-4916-9f53-b6e1fa9c1356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b13248d4-e7a6-4fdf-80b1-e4ff475f71a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "91d245e3-a33a-42d3-a0b9-2628124bf7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1bc43092-f848-4878-801b-07c8039524ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6aec00ff-f4e8-4df5-a689-38361740eecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d5d3f255-095f-413e-b7e0-6e3834fb7de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1ae3ced1-58c7-4e83-a0fa-40b50a9a21d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fa075f82-09d2-4100-b03b-55da83486a5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.31037270128792305, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.00037352916999596023, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.3751348555088043, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.31037270128792305, LR: 0.00037352916999596023, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.35730373258054515, 'epochs': 50, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.00025613864490188075, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.20881536602973938, Filters: 32, Blocks: 6, Kernel Size: 4, Dropout: 0.35730373258054515, LR: 0.00025613864490188075, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3799821189098427, 'epochs': 50, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.008773189297667355, 'num_blocks': 8}\n",
      "Iteration - Loss: 173.6019744873047, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.3799821189098427, LR: 0.008773189297667355, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.32978061771607314, 'epochs': 30, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00017535061304834658, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.4135962128639221, Filters: 64, Blocks: 10, Kernel Size: 5, Dropout: 0.32978061771607314, LR: 0.00017535061304834658, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3018146826479032, 'epochs': 50, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.0006849190870361559, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.14807578921318054, Filters: 96, Blocks: 6, Kernel Size: 5, Dropout: 0.3018146826479032, LR: 0.0006849190870361559, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.26005275528471944, 'epochs': 40, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00793621792676528, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.20922358334064484, Filters: 64, Blocks: 6, Kernel Size: 5, Dropout: 0.26005275528471944, LR: 0.00793621792676528, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.20964473958217855, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.005580223068233856, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.0, Filters: 96, Blocks: 8, Kernel Size: 3, Dropout: 0.20964473958217855, LR: 0.005580223068233856, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.23990510251650116, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0021468793171350213, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.06952241063117981, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.23990510251650116, LR: 0.0021468793171350213, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.33531929274909156, 'epochs': 30, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.005363840552645706, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.8202699422836304, Filters: 96, Blocks: 8, Kernel Size: 5, Dropout: 0.33531929274909156, LR: 0.005363840552645706, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3491629633577443, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0018837885415274444, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.3912091851234436, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.3491629633577443, LR: 0.0018837885415274444, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.25975286536150644, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0051492760112513926, 'num_blocks': 10}\n",
      "Iteration - Loss: 2.3088442269170173e-09, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.25975286536150644, LR: 0.0051492760112513926, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3549820555301195, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0011753334047197308, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.09516625851392746, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.3549820555301195, LR: 0.0011753334047197308, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.2944100432295431, 'epochs': 20, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.00011540814614640556, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5951907634735107, Filters: 128, Blocks: 4, Kernel Size: 4, Dropout: 0.2944100432295431, LR: 0.00011540814614640556, Batch Size: 16, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3523217486990742, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0015527046291433505, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.05597587302327156, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.3523217486990742, LR: 0.0015527046291433505, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.2607027444016171, 'epochs': 30, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00032059061674725883, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.2842404246330261, Filters: 64, Blocks: 8, Kernel Size: 5, Dropout: 0.2607027444016171, LR: 0.00032059061674725883, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.23847996266864377, 'epochs': 40, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.009093262195134214, 'num_blocks': 8}\n",
      "Iteration - Loss: 1852.28173828125, Filters: 128, Blocks: 8, Kernel Size: 3, Dropout: 0.23847996266864377, LR: 0.009093262195134214, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3868206779272819, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.004390058122280173, 'num_blocks': 10}\n",
      "Iteration - Loss: 1.9283108711242676, Filters: 96, Blocks: 10, Kernel Size: 4, Dropout: 0.3868206779272819, LR: 0.004390058122280173, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3243128462317999, 'epochs': 40, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.00011387381037846625, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5318446755409241, Filters: 128, Blocks: 4, Kernel Size: 5, Dropout: 0.3243128462317999, LR: 0.00011387381037846625, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.2878384684396895, 'epochs': 40, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0013436056000789777, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.048924170434474945, Filters: 32, Blocks: 10, Kernel Size: 5, Dropout: 0.2878384684396895, LR: 0.0013436056000789777, Batch Size: 16, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.36962845772495423, 'epochs': 40, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.005617149457962782, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.6437492370605469, Filters: 32, Blocks: 8, Kernel Size: 4, Dropout: 0.36962845772495423, LR: 0.005617149457962782, Batch Size: 48, Epochs: 40\n",
      "100%|███████████████████████████████████████████████████████████████| 20/20 [03:08<00:00,  9.43s/trial, best loss: 0.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b3a0271d-f34c-4867-a6b2-b87d39214b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 32, 'dropout_rate': 0.20964473958217855, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.005580223068233856, 'num_blocks': 8}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b67cbb88-0c96-41cc-b373-cd473b1e086e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bca11037-e959-41d4-bfa8-9d40dcb7c3e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step - accuracy: 0.7115 - loss: 0.5586 - val_accuracy: 0.7778 - val_loss: 3.3159\n",
      "Epoch 2/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.9837 - loss: 0.0503 - val_accuracy: 0.7778 - val_loss: 6.9253\n",
      "Epoch 3/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.9698 - loss: 0.1053 - val_accuracy: 0.7778 - val_loss: 44.6874\n",
      "Epoch 4/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step - accuracy: 0.9759 - loss: 0.1069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 0.9659 - loss: 0.0571 - val_accuracy: 1.0000 - val_loss: 1.4000e-13\n",
      "Epoch 6/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step - accuracy: 0.9620 - loss: 0.0836 - val_accuracy: 0.8889 - val_loss: 8.9551\n",
      "Epoch 7/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402ms/step - accuracy: 0.9620 - loss: 0.1030 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7c372b93-0001-4950-a698-1757dd518b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9af1c749-bd04-488a-b83e-e6e128f904b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.8\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec522e-60da-4aa2-baab-95cf8c9ef727",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc46556-9fee-4eb7-9b1c-060458fe41b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f446b87-5fc1-4888-8b63-428acbd68f90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a4ba57bc-2747-4f78-8452-5aff003c0a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d8e258bc-ccea-487f-83a4-2f2febc944b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "991d89b0-45e3-4239-be1d-d8e2b14bd1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "731c64b0-9e0b-4c9b-9d13-3009ba4d360c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d3736a7d-5667-4136-bc14-8ec9e1ff90cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "528f60b1-8cd6-4eb2-86fb-e51e043a3ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3692bc03-d6cc-4586-a4f2-fac483e90e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dd419ffe-5cdc-460f-b949-38af420fb921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "56859cc2-5cae-4a77-88e4-01a283f00aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2ad9bddc-79a2-4bd5-9d0b-92faa8901e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2421e504-5f0a-4fde-87a9-21479a4e7dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "eca11bf9-8d28-4c6e-af6c-ef4946b66690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7620f668-adc5-4711-89d4-a83e758fd564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 2.2435713287194403e-09, Params: {'batch_size': 48, 'dropout_rate': 0.31854078550198983, 'epochs': 140, 'learning_rate': 0.008033133981585448, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.4306385815143585, Params: {'batch_size': 80, 'dropout_rate': 0.3351302316018883, 'epochs': 150, 'learning_rate': 2.259784027477487e-05, 'num_layers': 2, 'units': 160}\n",
      "Iteration - Loss: 0.18210694193840027, Params: {'batch_size': 80, 'dropout_rate': 0.4546830304266659, 'epochs': 130, 'learning_rate': 0.00025494829795176, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 5.316756692026747e-13, Params: {'batch_size': 64, 'dropout_rate': 0.4495378097682131, 'epochs': 140, 'learning_rate': 0.007940987500121417, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.6140477657318115, Params: {'batch_size': 128, 'dropout_rate': 0.33699937996033413, 'epochs': 130, 'learning_rate': 1.6006728305236678e-05, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.5294206738471985, Params: {'batch_size': 32, 'dropout_rate': 0.3173002526883657, 'epochs': 110, 'learning_rate': 1.964471854835027e-05, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.06214509904384613, Params: {'batch_size': 112, 'dropout_rate': 0.3415463892223247, 'epochs': 80, 'learning_rate': 0.00013215777381234508, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 1.4271910910024221e-11, Params: {'batch_size': 32, 'dropout_rate': 0.3699940915975465, 'epochs': 90, 'learning_rate': 0.0036410615358710157, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 7.761429151287302e-05, Params: {'batch_size': 64, 'dropout_rate': 0.4622531732367767, 'epochs': 110, 'learning_rate': 0.0006024211959567376, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.011232979595661163, Params: {'batch_size': 48, 'dropout_rate': 0.4089874692983334, 'epochs': 100, 'learning_rate': 0.0002699432776298115, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 7.229532457131427e-07, Params: {'batch_size': 80, 'dropout_rate': 0.23177194304277685, 'epochs': 80, 'learning_rate': 0.0027642855618070575, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 2.639785101621328e-08, Params: {'batch_size': 80, 'dropout_rate': 0.13804739059225646, 'epochs': 50, 'learning_rate': 0.009429347565030216, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 4.676232038036687e-06, Params: {'batch_size': 96, 'dropout_rate': 0.26148538361946416, 'epochs': 150, 'learning_rate': 0.0036498019693278544, 'num_layers': 3, 'units': 64}\n",
      "Iteration - Loss: 0.661198079586029, Params: {'batch_size': 80, 'dropout_rate': 0.4157195215726497, 'epochs': 60, 'learning_rate': 3.4979191277597024e-05, 'num_layers': 6, 'units': 96}\n",
      "Iteration - Loss: 2.090415649825053e-14, Params: {'batch_size': 32, 'dropout_rate': 0.4080143837124294, 'epochs': 140, 'learning_rate': 0.007874567491008405, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 7.852228736737743e-05, Params: {'batch_size': 128, 'dropout_rate': 0.2612836459779724, 'epochs': 50, 'learning_rate': 0.00044296439273789186, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.008552579209208488, Params: {'batch_size': 80, 'dropout_rate': 0.15469856241493823, 'epochs': 80, 'learning_rate': 0.0004606907469062118, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 1.7638107863149344e-08, Params: {'batch_size': 96, 'dropout_rate': 0.1323397691294857, 'epochs': 120, 'learning_rate': 0.0019711578650289095, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 1.6584651429951691e-09, Params: {'batch_size': 16, 'dropout_rate': 0.2693816744854343, 'epochs': 120, 'learning_rate': 0.0023327188450887105, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.6474664807319641, Params: {'batch_size': 64, 'dropout_rate': 0.331804032674635, 'epochs': 60, 'learning_rate': 1.8983679125761128e-05, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 6.247771671041846e-05, Params: {'batch_size': 16, 'dropout_rate': 0.49925143821644874, 'epochs': 140, 'learning_rate': 0.0011088873621339275, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 2.1092489532748004e-07, Params: {'batch_size': 32, 'dropout_rate': 0.48459974863509814, 'epochs': 140, 'learning_rate': 0.008457222833072405, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 4.918559520794642e-17, Params: {'batch_size': 48, 'dropout_rate': 0.3992527399121967, 'epochs': 130, 'learning_rate': 0.0058037326290321725, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 4.4949763378099306e-07, Params: {'batch_size': 48, 'dropout_rate': 0.38589884941126973, 'epochs': 130, 'learning_rate': 0.001199659631825993, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 2.5654627311411105e-09, Params: {'batch_size': 32, 'dropout_rate': 0.4211911109960443, 'epochs': 120, 'learning_rate': 0.004819575678884368, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 2.8151578135293676e-06, Params: {'batch_size': 16, 'dropout_rate': 0.3851411435744241, 'epochs': 150, 'learning_rate': 0.0008598512130882854, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 0.007054438348859549, Params: {'batch_size': 48, 'dropout_rate': 0.20199589315685512, 'epochs': 110, 'learning_rate': 0.0001305427468268331, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 2.999244941293e-07, Params: {'batch_size': 32, 'dropout_rate': 0.4331033754807285, 'epochs': 100, 'learning_rate': 0.005282163491191069, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.17529533803462982, Params: {'batch_size': 48, 'dropout_rate': 0.37336559584680035, 'epochs': 140, 'learning_rate': 5.252131262634247e-05, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 9.578246681485325e-05, Params: {'batch_size': 64, 'dropout_rate': 0.2935630751698647, 'epochs': 130, 'learning_rate': 0.001742885987441811, 'num_layers': 3, 'units': 256}\n",
      "100%|█████████████████████████████████████████████| 30/30 [05:18<00:00, 10.63s/trial, best loss: 4.918559520794642e-17]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "53831951-56ac-4481-b508-9d7831b68973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.3992527399121967, 'epochs': 130, 'learning_rate': 0.0058037326290321725, 'num_layers': 4, 'units': 256}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5c173725-2d74-4a04-a930-7671e216d59c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7040 - loss: 0.6260 - val_accuracy: 0.4444 - val_loss: 0.6976\n",
      "Epoch 2/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7407 - loss: 0.4696 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 3/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9684 - loss: 0.1600 - val_accuracy: 1.0000 - val_loss: 4.3490e-04\n",
      "Epoch 4/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9614 - loss: 0.1005 - val_accuracy: 1.0000 - val_loss: 2.9878e-05\n",
      "Epoch 5/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 9.9178e-04 - val_accuracy: 1.0000 - val_loss: 2.5445e-06\n",
      "Epoch 6/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9848 - loss: 0.0328 - val_accuracy: 1.0000 - val_loss: 2.7564e-09\n",
      "Epoch 7/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.1240e-06 - val_accuracy: 1.0000 - val_loss: 2.0122e-10\n",
      "Epoch 8/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.1645e-06 - val_accuracy: 1.0000 - val_loss: 4.5493e-11\n",
      "Epoch 9/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 1.0964e-05 - val_accuracy: 1.0000 - val_loss: 1.2515e-11\n",
      "Epoch 10/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 3.5679e-04 - val_accuracy: 1.0000 - val_loss: 3.1651e-12\n",
      "Epoch 11/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 7.3089e-05 - val_accuracy: 1.0000 - val_loss: 8.4600e-13\n",
      "Epoch 12/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.9490e-14\n",
      "Epoch 13/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.7440e-06 - val_accuracy: 1.0000 - val_loss: 6.4943e-16\n",
      "Epoch 14/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.6943e-09 - val_accuracy: 1.0000 - val_loss: 3.1863e-17\n",
      "Epoch 15/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 7.5420e-12 - val_accuracy: 1.0000 - val_loss: 2.3022e-18\n",
      "Epoch 16/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 8.7433e-04 - val_accuracy: 1.0000 - val_loss: 4.3055e-20\n",
      "Epoch 17/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.4515e-09 - val_accuracy: 1.0000 - val_loss: 1.3682e-21\n",
      "Epoch 18/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 4.2551e-13 - val_accuracy: 1.0000 - val_loss: 2.9113e-21\n",
      "Epoch 19/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.8201e-04 - val_accuracy: 1.0000 - val_loss: 2.7765e-21\n",
      "Epoch 20/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.1985e-11 - val_accuracy: 1.0000 - val_loss: 1.1811e-21\n",
      "Epoch 21/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9848 - loss: 0.0491 - val_accuracy: 1.0000 - val_loss: 5.4420e-24\n",
      "Epoch 22/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.6020e-12 - val_accuracy: 1.0000 - val_loss: 2.1113e-24\n",
      "Epoch 23/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 6.1018e-20 - val_accuracy: 1.0000 - val_loss: 1.0928e-23\n",
      "Epoch 24/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.3092e-20 - val_accuracy: 1.0000 - val_loss: 4.0444e-23\n",
      "Epoch 25/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 9.1927e-15 - val_accuracy: 1.0000 - val_loss: 1.1725e-22\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d63b3479-84ba-4861-b92d-189d4265d709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.8\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d233f5f-422c-472d-9094-565c1278f926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "931ad84d-dea6-43f3-88d8-c83d511ae585",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85965eff-1f3c-404e-a596-2916cca931d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_17656\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "675ff267-9781-40e8-a808-d0ccbb878c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values\n",
    "features_df = features_df.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "209c0de9-cf67-4ba1-aa27-22c04ce020e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(features_df.values)\n",
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fd50908-e409-4978-a8dd-b842072b5321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(features_df.values, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a95e3606-032b-443f-8fa9-fa4b2a9ec942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = features_df.iloc[selected_indices, :].T\n",
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3c945b8-afaa-4b7a-8b25-a6aba29983b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b733ffd2-d138-4d74-9bfb-9a9517e73187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d28dd37-f9a9-472e-a923-f747b743fe2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baf421f2-a734-4a5c-ac55-aa0efe6a66f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:11:29,630] A new study created in memory with name: no-name-0c4959d6-1cf7-423f-8970-b8baf311517b\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72b7975-b649-41c1-9131-296dd974387b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.683229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:12:45,686] Trial 0 finished with value: 0.683229386806488 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 4.1604152755614585e-05, 'max_length': 203}. Best is trial 0 with value: 0.683229386806488.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:14:53,207] Trial 1 finished with value: 0.6854141354560852 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 3.6294375127138535e-05, 'max_length': 213}. Best is trial 0 with value: 0.683229386806488.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 01:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.678223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.669782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:16:14,449] Trial 2 finished with value: 0.6697818040847778 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 3.644869073892524e-05, 'max_length': 130}. Best is trial 2 with value: 0.6697818040847778.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:17:21,736] Trial 3 finished with value: 0.697083592414856 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 2.5556506203339093e-05, 'max_length': 171}. Best is trial 2 with value: 0.6697818040847778.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:18:36,183] Trial 4 finished with value: 0.6884921193122864 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 2.459227543029821e-05, 'max_length': 144}. Best is trial 2 with value: 0.6697818040847778.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5acce8b-ad12-485d-aba2-96d749ee1e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 3.644869073892524e-05, 'max_length': 130}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3dadbdf-6e47-4664-952c-2c3ba361ca5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fa69388-3182-4319-90d1-9b4d377cbbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "325fd976-15de-4bb2-973e-b4c9affb9f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13749e07-89d8-4cc3-b8a8-78f626499140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2d85ac0-b68e-406b-888f-aa3b38a0e57f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c2f3776-f2a9-4cf5-8cfd-b201f654bff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 08:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.823956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.770024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.682706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=0.8175236119164361, metrics={'train_runtime': 556.6451, 'train_samples_per_second': 0.485, 'train_steps_per_second': 0.032, 'total_flos': 71039984947200.0, 'train_loss': 0.8175236119164361, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04e5fa7f-58d0-49fe-a402-3abcb32baba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6086956521739131\n",
      "F1 Score: 0.6896551724137931\n",
      "Sensitivity: 0.7692307692307693\n",
      "Specificity: 0.4\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc29e4-250b-4c76-bd8c-7b3cbcd474e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f2162-cd51-4f8c-b054-d02b8f8ddc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd18c9ae-87dc-411a-b93d-75f8b4669f1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469428c6-236f-4327-ba64-79846c6d00ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_18236\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d257e681-b55d-40d0-8357-e0f65fc69153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56adf49-36d7-4801-b934-f0d109901cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92fbae9-6632-448e-b186-a9c5f52dd7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 25000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092357b6-d5a4-46d1-822e-9ab2522853e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:2500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b438c74-720e-423b-9374-a66f0e071879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81149f7-3f5b-410f-9148-8b12d4a59bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_selected)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1120e131-d169-4561-97ca-6312547f7f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4913b4da-6552-43df-84e5-ac75d14c67e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c322be65-2231-4490-bbda-ce73cd5b3adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:27:32,544] A new study created in memory with name: no-name-e7479900-127f-46df-bb1a-00758c14fa92\n",
      "[I 2024-06-13 09:27:36,742] Trial 0 finished with value: 0.018329212442040443 and parameters: {'num_units': 112, 'learning_rate': 2.324076655633723e-05, 'dropout_rate': 0.1941926107252109, 'activity_regularizer': 2.5458229765663954e-06, 'batch_size': 61}. Best is trial 0 with value: 0.018329212442040443.\n",
      "[I 2024-06-13 09:27:40,827] Trial 1 finished with value: 0.01749476045370102 and parameters: {'num_units': 112, 'learning_rate': 3.4893657692315844e-05, 'dropout_rate': 0.29000063770019213, 'activity_regularizer': 4.7881467717073226e-05, 'batch_size': 32}. Best is trial 1 with value: 0.01749476045370102.\n",
      "[I 2024-06-13 09:27:44,575] Trial 2 finished with value: 0.022458521649241447 and parameters: {'num_units': 178, 'learning_rate': 6.341780337122132e-05, 'dropout_rate': 0.16703196151862273, 'activity_regularizer': 8.594642648683724e-05, 'batch_size': 36}. Best is trial 1 with value: 0.01749476045370102.\n",
      "[I 2024-06-13 09:27:48,321] Trial 3 finished with value: 0.006957738194614649 and parameters: {'num_units': 99, 'learning_rate': 0.0005578533049573826, 'dropout_rate': 0.13121692511141606, 'activity_regularizer': 6.034837285260937e-06, 'batch_size': 35}. Best is trial 3 with value: 0.006957738194614649.\n",
      "[I 2024-06-13 09:27:52,574] Trial 4 finished with value: 0.007018968928605318 and parameters: {'num_units': 186, 'learning_rate': 8.310189348740905e-05, 'dropout_rate': 0.22329366936691333, 'activity_regularizer': 1.06916044385609e-06, 'batch_size': 32}. Best is trial 3 with value: 0.006957738194614649.\n",
      "[I 2024-06-13 09:27:56,638] Trial 5 finished with value: 0.005919769871979952 and parameters: {'num_units': 171, 'learning_rate': 0.00040092004215526325, 'dropout_rate': 0.20106359875453161, 'activity_regularizer': 2.016681963257368e-06, 'batch_size': 40}. Best is trial 5 with value: 0.005919769871979952.\n",
      "[I 2024-06-13 09:28:00,866] Trial 6 finished with value: 0.0062631587497889996 and parameters: {'num_units': 250, 'learning_rate': 0.00041049175416618645, 'dropout_rate': 0.09556991506104003, 'activity_regularizer': 6.822090909389302e-06, 'batch_size': 25}. Best is trial 5 with value: 0.005919769871979952.\n",
      "[I 2024-06-13 09:28:01,711] Trial 7 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:02,678] Trial 8 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 09:28:03,565] Trial 9 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 57 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001B3BF5F7F60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:07,864] Trial 10 finished with value: 0.005469358526170254 and parameters: {'num_units': 226, 'learning_rate': 0.00021787719556293979, 'dropout_rate': 0.002877132869698512, 'activity_regularizer': 1.575959129952679e-07, 'batch_size': 17}. Best is trial 10 with value: 0.005469358526170254.\n",
      "[I 2024-06-13 09:28:12,252] Trial 11 finished with value: 0.002589585492387414 and parameters: {'num_units': 226, 'learning_rate': 0.0009717647835152961, 'dropout_rate': 0.017675088986647075, 'activity_regularizer': 1.0906208316333914e-07, 'batch_size': 18}. Best is trial 11 with value: 0.002589585492387414.\n",
      "[I 2024-06-13 09:28:16,568] Trial 12 finished with value: 0.002261972986161709 and parameters: {'num_units': 235, 'learning_rate': 0.0009966320967166595, 'dropout_rate': 0.003933775770542816, 'activity_regularizer': 1.0165428366352855e-07, 'batch_size': 16}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:20,885] Trial 13 finished with value: 0.0026993195060640574 and parameters: {'num_units': 221, 'learning_rate': 0.0009516421154177125, 'dropout_rate': 0.012384546678630759, 'activity_regularizer': 1.261017263335906e-07, 'batch_size': 18}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:24,630] Trial 14 finished with value: 0.0029267575591802597 and parameters: {'num_units': 254, 'learning_rate': 0.0009626721187079127, 'dropout_rate': 0.05725145581895992, 'activity_regularizer': 4.54827571593979e-07, 'batch_size': 23}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:25,809] Trial 15 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:30,265] Trial 16 finished with value: 0.003466432448476553 and parameters: {'num_units': 204, 'learning_rate': 0.0005602631155999077, 'dropout_rate': 0.049513862713834025, 'activity_regularizer': 7.611002857485981e-07, 'batch_size': 16}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:31,181] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:32,450] Trial 18 pruned. Trial was pruned at epoch 6.\n",
      "[I 2024-06-13 09:28:33,267] Trial 19 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 110 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001B3BC0162A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:34,402] Trial 20 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-13 09:28:35,267] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:39,740] Trial 22 finished with value: 0.004069867543876171 and parameters: {'num_units': 216, 'learning_rate': 0.0006352553411516211, 'dropout_rate': 0.02143856376482454, 'activity_regularizer': 2.133555270213689e-07, 'batch_size': 19}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:40,594] Trial 23 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:45,082] Trial 24 finished with value: 0.003570794127881527 and parameters: {'num_units': 195, 'learning_rate': 0.0009030068173266975, 'dropout_rate': 0.06317240140863548, 'activity_regularizer': 1.9287336687651815e-07, 'batch_size': 20}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:45,800] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:47,736] Trial 26 pruned. Trial was pruned at epoch 15.\n",
      "[I 2024-06-13 09:28:48,689] Trial 27 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:49,618] Trial 28 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:50,696] Trial 29 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 89 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001B3CA3ABE20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:51,611] Trial 30 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001B3CA608B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:55,977] Trial 31 finished with value: 0.002002999885007739 and parameters: {'num_units': 251, 'learning_rate': 0.0008454861971241022, 'dropout_rate': 0.04721719574807189, 'activity_regularizer': 4.287282108577875e-07, 'batch_size': 16}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:00,209] Trial 32 finished with value: 0.0027384196873754263 and parameters: {'num_units': 239, 'learning_rate': 0.0007408368987855757, 'dropout_rate': 0.037860079043161625, 'activity_regularizer': 2.732998170168504e-07, 'batch_size': 16}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:05,078] Trial 33 finished with value: 0.002385879633948207 and parameters: {'num_units': 233, 'learning_rate': 0.0007488479375379893, 'dropout_rate': 0.008611612854635624, 'activity_regularizer': 1.0297392736088668e-07, 'batch_size': 19}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:09,483] Trial 34 finished with value: 0.003759708721190691 and parameters: {'num_units': 234, 'learning_rate': 0.0005345930155641568, 'dropout_rate': 0.0399028286992375, 'activity_regularizer': 1.8350286739162144e-07, 'batch_size': 21}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:10,373] Trial 35 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:11,357] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:12,295] Trial 37 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:13,176] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:14,144] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:14,955] Trial 40 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:16,244] Trial 41 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:29:20,762] Trial 42 finished with value: 0.003451309399679303 and parameters: {'num_units': 187, 'learning_rate': 0.0007748011417460657, 'dropout_rate': 0.017967430432832124, 'activity_regularizer': 1.2938182960392938e-07, 'batch_size': 18}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:21,699] Trial 43 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:25,768] Trial 44 finished with value: 0.00266681588254869 and parameters: {'num_units': 232, 'learning_rate': 0.0009933791051073978, 'dropout_rate': 0.031021021723184185, 'activity_regularizer': 3.9497222726440353e-07, 'batch_size': 22}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:26,643] Trial 45 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:27,857] Trial 46 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:29:28,856] Trial 47 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-13 09:29:29,800] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:30,923] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e38e95-1a11-4068-baa6-5890e8bd708c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 251, 'learning_rate': 0.0008454861971241022, 'dropout_rate': 0.04721719574807189, 'activity_regularizer': 4.287282108577875e-07, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d23502f4-da0e-4e21-9232-984112075579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "236ad51a-9418-4a99-8976-482377f92a05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b3d2245490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "365521ac-069e-4f1a-9115-9d0dce43c32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026\n",
      "Validation Loss:  0.002561886329203844\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23958ad5-d695-45f1-943b-5f3afb4435b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "479b1c5c-160d-4331-9946-f5bb74cb14a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acd9e190-7e4e-4c6b-88c5-bd9666dcd9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e65ef7f1-5fe2-4f5b-8acb-21b555b07505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43478260869565216\n",
      "F1 Score: 0.0\n",
      "Sensitivity: 0.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79062be3-bbed-49c5-92ba-b59e74e66160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2c90a-1df8-4cae-9e8c-d873e0d0715b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384374b6-3e05-4cd6-a829-cc7e52af47c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "473a7acb-562d-483b-b048-ade110d42fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_18236\\2250372466.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cba6a14-c0f8-4305-bd7e-44a9d1f1e907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dafcefc-2558-47b6-bb61-ee7205082aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c152b9b-06a8-42b2-bae4-3b0f3d02f108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6245635f-3df2-4f2c-aa34-331482e483a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c72ea88e-8004-4b01-bac8-3dd9dc7fcc83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 232276 206406 321802 250927 200059 270758 197015 126599 374361]\n",
      "Top AMGM values: [1.0133886 1.0133953 1.0133953 1.0133955 1.0133955 1.0133958 1.0133958\n",
      " 1.013406  1.0134064 1.0134076]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "367dc8aa-60dc-4cfe-8231-96c7abba50ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c8872d5-d6e8-468d-91aa-a4a2805ce455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T\n",
    "X_selected = X_selected.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c0a844-56a4-4873-abce-1a535efdd4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7de03a53-3bee-48d4-8f34-1e2134e1d5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b407bb1d-811b-4234-8b1c-60d1c72f3b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa9c7f01-9cc8-40db-bbde-ac36a7ff89b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad6effb7-cba4-4a1e-bddf-217b3c7cf333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3311ef77-8fdc-47ce-a7d2-9202e8ebf90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97313402-80dc-452b-b0b2-1ef5cf1b84d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c270111-cacf-4051-8754-280381163233",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820ms/step                                              \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:49<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B39F738680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "  0%|                                                                           | 0/20 [00:53<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B39F738680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.8330985530985532, Sensitivity: 0.9431818181818182, Specificity: 0.48134920634920636\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9626262626262626, Sensitivity: 0.9626262626262626, Specificity: 0.9361111111111112\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.611111111111111, F1 Score: 0.74743961352657, Sensitivity: 1.0, Specificity: 0.08333333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.621431219873934, Sensitivity: 0.6013888888888889, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9818399044205496, Sensitivity: 1.0, Specificity: 0.9361111111111112\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5333333333333333, F1 Score: 0.6777777777777777, Sensitivity: 0.8579545454545454, Specificity: 0.16666666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6827697262479872, Sensitivity: 0.7142676767676769, Specificity: 0.4916666666666667\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9814953738434609, Sensitivity: 0.9848484848484849, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.989247311827957, Sensitivity: 1.0, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7341062801932366, Sensitivity: 0.9848484848484849, Specificity: 0.041666666666666664\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8444444444444444, F1 Score: 0.7376906318082789, Sensitivity: 0.7111111111111111, Specificity: 0.9583333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.6336917562724015, Sensitivity: 0.6236111111111111, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9487179487179488, Sensitivity: 1.0, Specificity: 0.6666666666666666\n",
      "100%|██████████████████████████████████████████████████████████████| 20/20 [27:04<00:00, 81.23s/trial, best loss: -1.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecc0d897-e0a9-4a70-8cc7-bee296181b86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 1.0195871483792565e-05, 'ae_batch_size': 57.0, 'ae_dropout_rate': 0.22040522447053654, 'ae_learning_rate': 0.0005596463584347175, 'autoencoder_units': 254.0, 'encoding_dim': 75.0, 'lstm_batch_size': 26.0, 'lstm_dropout_rate': 0.3930555875166011, 'lstm_learning_rate': 0.0002577472225551129, 'lstm_units': 448.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53c47b62-c60e-45c3-bbb2-d471164fe2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1981de2f-1c4e-4c9a-b1fc-88b90f4d1cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0ebd8d5-7bf5-468f-a0f1-40b59ef31247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d034db59-bdfb-4e3f-bf0e-66787dd300a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 1.2458 - val_loss: 1.2634\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2419 - val_loss: 1.2513\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2259 - val_loss: 1.2384\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2031 - val_loss: 1.2237\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1867 - val_loss: 1.2064\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1761 - val_loss: 1.1863\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1388 - val_loss: 1.1633\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1147 - val_loss: 1.1380\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0917 - val_loss: 1.1112\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.0678 - val_loss: 1.0847\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0335 - val_loss: 1.0605\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0128 - val_loss: 1.0400\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9881 - val_loss: 1.0241\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9757 - val_loss: 1.0125\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9610 - val_loss: 1.0047\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9594 - val_loss: 0.9993\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9535 - val_loss: 0.9954\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9465 - val_loss: 0.9923\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9517 - val_loss: 0.9897\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9471 - val_loss: 0.9875\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.9422 - val_loss: 0.9857\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9411 - val_loss: 0.9844\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9364 - val_loss: 0.9836\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9338 - val_loss: 0.9831\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9364 - val_loss: 0.9828\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.9311 - val_loss: 0.9828\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.9298 - val_loss: 0.9829\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9320 - val_loss: 0.9831\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9257 - val_loss: 0.9834\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9241 - val_loss: 0.9836\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9260 - val_loss: 0.9838\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.4643 - loss: 0.6533 - val_accuracy: 0.4348 - val_loss: 0.5640\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.3952 - loss: 0.6012 - val_accuracy: 0.4783 - val_loss: 0.5236\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5342 - loss: 0.5782 - val_accuracy: 0.7391 - val_loss: 0.4822\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7355 - loss: 0.4919 - val_accuracy: 0.9565 - val_loss: 0.3401\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9629 - loss: 0.3650 - val_accuracy: 0.9130 - val_loss: 0.2136\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9694 - loss: 0.1424 - val_accuracy: 0.9130 - val_loss: 0.3382\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9636 - loss: 0.1498 - val_accuracy: 0.9565 - val_loss: 0.3305\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9930 - loss: 0.0855 - val_accuracy: 0.9565 - val_loss: 0.3276\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9815 - loss: 0.1982 - val_accuracy: 0.9565 - val_loss: 0.3578\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9790 - loss: 0.0491 - val_accuracy: 0.9565 - val_loss: 0.4304\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d88809c9-3a2f-4fa4-8472-c8e49762b250",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841ms/step\n",
      "Accuracy: 0.9565217391304348\n",
      "F1 Score: 0.9629629629629629\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.9\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb61e1c-18c2-40b9-9dea-1c5f7a38c3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb9e367-ef47-43e0-9023-c57b6c4a7753",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96c22ef-2634-4d9c-996b-c3531a9a6da9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24364\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9904f453-10a6-48e1-bdfd-a4624f24e1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22aa7d9a-e2e8-4b15-8ae3-0ec8a36ae05d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8f4429-c1c6-45e5-a9bd-7a8361d668b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcdc331-9577-48ce-9d13-a4c1e981c82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 232276 206406 321802 250927 200059 270758 197015 126599 374361]\n",
      "Top AMGM values: [1.0133886 1.0133953 1.0133953 1.0133955 1.0133955 1.0133958 1.0133958\n",
      " 1.013406  1.0134064 1.0134076]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdde22a-d4f0-4d7d-a542-c208f10f5c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d65c95-4595-43ba-bcda-10392d89274c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c19b7a9-1a48-4ff5-b034-6f45efa44b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0402c15-2d4e-426f-9e37-863d0aabf207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4bea096-8ff8-4e29-8512-1d3ee2a3c251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e801921-22c3-4d5c-aa0d-bd9e80649d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c0f2ca3-c819-496f-bc56-e82ba7ce09d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd2ce89-51d2-4bcc-b518-c5ad0c4f5f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed45844-29ae-496d-9ea6-3f1d379d6091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3858f82f-79cc-4c8a-83ef-0bb70ef6fbfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6e00ad8-8d39-47b9-9a12-13fcb191b474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdd3ee25-35a3-4449-a657-5c8a593a1ead",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "  0%|                                                                           | 0/20 [00:05<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026779B3CEA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:07<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026779D43A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [06:01<00:00, 18.08s/trial, best loss: -0.9777777777777779]\n",
      "Best parameters:  {'ae_activity_reg': 1.8202118459323217e-07, 'ae_batch_size': 17.0, 'ae_dropout_rate': 0.2420141854175809, 'ae_learning_rate': 0.0018549636606314222, 'autoencoder_units': 500.0, 'encoding_dim': 44.0, 'fnn_batch_size': 21.0, 'fnn_dropout_rate': 0.48756629348787384, 'fnn_learning_rate': 7.200630222661965e-05, 'fnn_units': 207.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de1631cc-88ce-4cc6-9f73-d0e8a942abd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bf66812-79a6-4e5b-8e78-99d8cbe9597f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bd76054-a938-47f5-beb1-09601c112c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Final Model - Accuracy: 0.9666666666666666\n",
      "Final Model - F1 Score: 0.9697777777777776\n",
      "Final Model - Sensitivity: 0.9623931623931623\n",
      "Final Model - Specificity: 0.9777777777777779\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6b818-e209-4adf-b56c-31d6232d19c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db65195-3912-4328-969a-0afd6ed27c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd995353-f86e-4908-87f4-f000f462e080",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9751422e-939d-4320-bbfc-f0d631c6365e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65dfe44-ff41-463a-bf14-f1ae4e7ff368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739612b7-a37a-4b8f-b05f-227a7ec27af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b78d1f-d80e-42d0-8b94-9fb1c47cb990",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_21104\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f579b55-f179-4b4a-9385-2ca19244e17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4898bc7c-7c8f-4324-b63a-25f8578d496c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77235c5-cc9f-4178-8195-89c66c596356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90159326-c50b-4b63-80a3-07f8528a74b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d13ddb-4c79-4c8b-b882-ff02a28e9ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "726b84b3-59bc-4c3b-a004-42977c76345c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - loss: 1.2503 - val_loss: 1.2341\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 1.2323 - val_loss: 1.2230\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 1.0466 - val_loss: 1.1725\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9848 - val_loss: 1.1277\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9787 - val_loss: 1.0978\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9733 - val_loss: 1.0794\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9669 - val_loss: 1.0677\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9606 - val_loss: 1.0602\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9549 - val_loss: 1.0554\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9497 - val_loss: 1.0524\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9450 - val_loss: 1.0506\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9408 - val_loss: 1.0494\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9371 - val_loss: 1.0487\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9340 - val_loss: 1.0484\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9311 - val_loss: 1.0485\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9286 - val_loss: 1.0487\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9264 - val_loss: 1.0491\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9245 - val_loss: 1.0497\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9228 - val_loss: 1.0504\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9212 - val_loss: 1.0511\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9198 - val_loss: 1.0519\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9185 - val_loss: 1.0527\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9174 - val_loss: 1.0535\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9164 - val_loss: 1.0543\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9154 - val_loss: 1.0551\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9146 - val_loss: 1.0559\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9138 - val_loss: 1.0567\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9131 - val_loss: 1.0575\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9124 - val_loss: 1.0582\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9118 - val_loss: 1.0590\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9113 - val_loss: 1.0597\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9107 - val_loss: 1.0603\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9102 - val_loss: 1.0610\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9097 - val_loss: 1.0616\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9093 - val_loss: 1.0622\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9089 - val_loss: 1.0628\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9085 - val_loss: 1.0633\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9081 - val_loss: 1.0638\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9078 - val_loss: 1.0643\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9075 - val_loss: 1.0647\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9072 - val_loss: 1.0652\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9069 - val_loss: 1.0655\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9066 - val_loss: 1.0659\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9064 - val_loss: 1.0662\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9062 - val_loss: 1.0665\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 0.9060 - val_loss: 1.0668\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9058 - val_loss: 1.0671\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9056 - val_loss: 1.0674\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9054 - val_loss: 1.0677\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - loss: 0.9052 - val_loss: 1.0679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ac71bb5e50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder, encoder = create_feature_autoencoder(input_dim, encoding_dim)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32de6943-cfa7-4373-a5e3-49fd4f48ee08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step\n",
      "Shape of encoded features: (113, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = encoder.predict(X_scaled)\n",
    "print(f\"Shape of encoded features: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a2c686d-409c-4c83-9b75-66638b39b191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after L1-based Feature Selection: (113, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e-01, tolerance: 2.745e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "target_features = 200  # Target number of features\n",
    "X_final, selected_indices_l1 = apply_l1_feature_selection(X_encoded, y, alpha=0.005, target_features=target_features)\n",
    "print(f\"Shape after L1-based Feature Selection: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d62c0a40-4acb-4dd2-aa20-61058f417098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498015d-3a73-4783-946f-1c4804eb80a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96ae413-6722-4112-adbc-648a11927b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "114478e2-36a6-4bc6-8db9-6c04bc7f4241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36fbcdf4-8b98-4aad-b7eb-84843c6ae63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5268b00-c73e-4999-b9a0-fcd1afdb3a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m5,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m20,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m201\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9f95545-f267-437c-8b94-c6b1d7f47bad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.5917 - loss: 0.7034 - val_accuracy: 0.4167 - val_loss: 0.7669 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5488 - loss: 0.6988 - val_accuracy: 0.4167 - val_loss: 0.6765 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6085 - loss: 0.6553 - val_accuracy: 0.4167 - val_loss: 0.6960 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5747 - loss: 0.7077 - val_accuracy: 0.4167 - val_loss: 0.6881 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5231 - loss: 0.6819 - val_accuracy: 0.4167 - val_loss: 0.6957 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5594 - loss: 0.7324 - val_accuracy: 0.4167 - val_loss: 0.6460 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6899 - loss: 0.6443 - val_accuracy: 0.5000 - val_loss: 0.6300 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6774 - loss: 0.6491 - val_accuracy: 0.7500 - val_loss: 0.5776 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7237 - loss: 0.5780 - val_accuracy: 0.8333 - val_loss: 0.5541 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6394 - loss: 0.6241 - val_accuracy: 0.7500 - val_loss: 0.5553 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7144 - loss: 0.5504 - val_accuracy: 0.7500 - val_loss: 0.5600 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6707 - loss: 0.6622 - val_accuracy: 0.8333 - val_loss: 0.5158 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7471 - loss: 0.5080 - val_accuracy: 0.9167 - val_loss: 0.4752 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6500 - loss: 0.5925 - val_accuracy: 0.8333 - val_loss: 0.4831 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7713 - loss: 0.5435 - val_accuracy: 0.7500 - val_loss: 0.5227 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7340 - loss: 0.5127 - val_accuracy: 0.7500 - val_loss: 0.5163 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7415 - loss: 0.5383 - val_accuracy: 0.8333 - val_loss: 0.4124 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7273 - loss: 0.5643 - val_accuracy: 0.9167 - val_loss: 0.3785 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7183 - loss: 0.6028 - val_accuracy: 0.9167 - val_loss: 0.3738 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7507 - loss: 0.5458 - val_accuracy: 0.8333 - val_loss: 0.3944 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6793 - loss: 0.5870 - val_accuracy: 0.8333 - val_loss: 0.3949 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7493 - loss: 0.4608 - val_accuracy: 0.8333 - val_loss: 0.3539 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7298 - loss: 0.4775 - val_accuracy: 0.9167 - val_loss: 0.3033 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7596 - loss: 0.4370 - val_accuracy: 0.9167 - val_loss: 0.2870 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8553 - loss: 0.3574 - val_accuracy: 0.9167 - val_loss: 0.2709 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8385 - loss: 0.3605 - val_accuracy: 0.9167 - val_loss: 0.2705 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8606 - loss: 0.3667 - val_accuracy: 0.9167 - val_loss: 0.2562 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8439 - loss: 0.3855 - val_accuracy: 1.0000 - val_loss: 0.2237 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7479 - loss: 0.4641 - val_accuracy: 1.0000 - val_loss: 0.2055 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8204 - loss: 0.4615 - val_accuracy: 1.0000 - val_loss: 0.2026 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7390 - loss: 0.4320 - val_accuracy: 0.9167 - val_loss: 0.2275 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9032 - loss: 0.2761 - val_accuracy: 0.8333 - val_loss: 0.2526 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8332 - loss: 0.3978 - val_accuracy: 0.8333 - val_loss: 0.2280 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8215 - loss: 0.3606 - val_accuracy: 0.9167 - val_loss: 0.1816 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.2649 - val_accuracy: 1.0000 - val_loss: 0.1587 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9172 - loss: 0.2910 - val_accuracy: 1.0000 - val_loss: 0.1452 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8500 - loss: 0.2940 - val_accuracy: 1.0000 - val_loss: 0.1325 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9367 - loss: 0.2587 - val_accuracy: 1.0000 - val_loss: 0.1250 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8243 - loss: 0.3046 - val_accuracy: 0.9167 - val_loss: 0.1307 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8332 - loss: 0.3163 - val_accuracy: 0.9167 - val_loss: 0.1301 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9018 - loss: 0.2849 - val_accuracy: 1.0000 - val_loss: 0.1180 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9004 - loss: 0.1869 - val_accuracy: 1.0000 - val_loss: 0.1077 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8631 - loss: 0.3123 - val_accuracy: 1.0000 - val_loss: 0.1062 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9186 - loss: 0.2084 - val_accuracy: 0.9167 - val_loss: 0.1075 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8901 - loss: 0.2190 - val_accuracy: 0.9167 - val_loss: 0.1146 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9214 - loss: 0.1731 - val_accuracy: 0.9167 - val_loss: 0.1198 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9431 - loss: 0.2664 - val_accuracy: 1.0000 - val_loss: 0.0948 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8965 - loss: 0.2445 - val_accuracy: 1.0000 - val_loss: 0.0846 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8862 - loss: 0.2060 - val_accuracy: 1.0000 - val_loss: 0.0827 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9147 - loss: 0.2057 - val_accuracy: 1.0000 - val_loss: 0.0931 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d0800c4-99b7-4439-a9f8-795fc589b7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98d01933-b58c-498d-91e8-6a54823cfa5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "098fbf38-8f46-4103-ad63-d7769c972577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Specificity: 0.8\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2183782-e3ec-4daf-ad43-73dceb67c4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d69bd-2c74-4085-903e-a048c2eea45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68d99a9-058c-4fa2-9057-0d0edbaa056f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4c8acb-e6a8-43d5-beaa-b878fe2c9bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08a28a4e-477b-4abe-8270-14f6487c9452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe234c4a-c882-47e5-857c-027175714b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c06200b-a7e3-49db-b659-afab5ea3e6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a39aa1c5-a9d5-4952-87d0-763a2c38b9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002AC81BD6D40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002AC73735940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.4778761061946903, F1 Score: 0.562962962962963, Sensitivity: 0.5757575757575758, Specificity: 0.3404255319148936\n",
      "Accuracy: 0.9380530973451328, F1 Score: 0.9473684210526315, Sensitivity: 0.9545454545454546, Specificity: 0.9148936170212766\n",
      "Accuracy: 0.9380530973451328, F1 Score: 0.9473684210526315, Sensitivity: 0.9545454545454546, Specificity: 0.9148936170212766\n",
      "Accuracy: 0.9026548672566371, F1 Score: 0.9197080291970803, Sensitivity: 0.9545454545454546, Specificity: 0.8297872340425532\n",
      "Accuracy: 0.911504424778761, F1 Score: 0.927536231884058, Sensitivity: 0.9696969696969697, Specificity: 0.8297872340425532\n",
      "Accuracy: 0.6548672566371682, F1 Score: 0.7719298245614035, Sensitivity: 1.0, Specificity: 0.1702127659574468          \n",
      "Accuracy: 0.8672566371681416, F1 Score: 0.8872180451127819, Sensitivity: 0.8939393939393939, Specificity: 0.8297872340425532\n",
      "Accuracy: 0.5398230088495575, F1 Score: 0.675, Sensitivity: 0.8181818181818182, Specificity: 0.14893617021276595       \n",
      "Accuracy: 0.6637168141592921, F1 Score: 0.7323943661971831, Sensitivity: 0.7878787878787878, Specificity: 0.48936170212765956\n",
      "Accuracy: 0.9292035398230089, F1 Score: 0.9402985074626866, Sensitivity: 0.9545454545454546, Specificity: 0.8936170212765957\n",
      "Accuracy: 0.7079646017699115, F1 Score: 0.8, Sensitivity: 1.0, Specificity: 0.2978723404255319                         \n",
      "Accuracy: 0.8938053097345132, F1 Score: 0.9130434782608695, Sensitivity: 0.9545454545454546, Specificity: 0.8085106382978723\n",
      "Accuracy: 0.9203539823008849, F1 Score: 0.9333333333333333, Sensitivity: 0.9545454545454546, Specificity: 0.8723404255319149\n",
      "Accuracy: 0.9026548672566371, F1 Score: 0.920863309352518, Sensitivity: 0.9696969696969697, Specificity: 0.8085106382978723\n",
      "Accuracy: 0.9026548672566371, F1 Score: 0.9197080291970803, Sensitivity: 0.9545454545454546, Specificity: 0.8297872340425532\n",
      "Accuracy: 0.911504424778761, F1 Score: 0.9253731343283582, Sensitivity: 0.9393939393939394, Specificity: 0.8723404255319149\n",
      "Accuracy: 0.8938053097345132, F1 Score: 0.9130434782608695, Sensitivity: 0.9545454545454546, Specificity: 0.8085106382978723\n",
      "Accuracy: 0.9292035398230089, F1 Score: 0.9411764705882353, Sensitivity: 0.9696969696969697, Specificity: 0.8723404255319149\n",
      "Accuracy: 0.9292035398230089, F1 Score: 0.9411764705882353, Sensitivity: 0.9696969696969697, Specificity: 0.8723404255319149\n",
      "Accuracy: 0.8761061946902655, F1 Score: 0.8970588235294118, Sensitivity: 0.9242424242424242, Specificity: 0.8085106382978723\n",
      "100%|███████████████████████████████████████████████| 20/20 [09:40<00:00, 29.03s/trial, best loss: -0.9473684210526315]\n",
      "Best parameters found:  {'batch_size': 112.0, 'dropout_rate': 0.606223678186999, 'epochs': 100.0, 'learning_rate': 0.0031900756082588956, 'neurons1': 256.0, 'neurons2': 64.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ed47d67-7d4b-4165-b343-a0e43b1d3880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9380530973451328\n",
      "Best F1 Score: 0.9473684210526315\n",
      "Best Specificity: 0.9148936170212766\n",
      "Best Sensitivity: 0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "317e3b24-cbdd-4c55-b79c-822f88734aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_101\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_101\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_507 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_202 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_508 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_203 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_509 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_510 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_511 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_507 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m51,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_202 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_508 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_203 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_509 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m16,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_510 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m51,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_511 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m201\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,145</span> (531.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m136,145\u001b[0m (531.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,145</span> (531.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m136,145\u001b[0m (531.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_final.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b13c4101-9d63-4f92-8259-00e5639ed8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 256\n",
      "Neurons in second layer: 64\n",
      "Dropout rate: 0.606223678186999\n",
      "Learning rate: 0.0031900756082588956\n",
      "Number of epochs: 100\n",
      "Batch size: 112\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56a1b4-393f-42c8-9fae-c3760589a57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca38d758-8b35-4d60-b34c-08c51b64d6fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6e0f258-a4a8-48a0-b7d5-b77a02bef7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc81d1f0-b4c9-49b1-8253-b49049e92624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4281abd4-fdd6-4d48-a57a-03f79c6081e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 64)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08f48861-d9cf-4400-adb0-af4291f34cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4bb0dabd-6272-40be-9205-9fb91c510e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.7444444444444445, F1 Score: 0.7900584795321638, Sensitivity: 0.8191176470588234, Specificity: 0.6450549450549451\n",
      "Iteration Results - Accuracy: 0.8111111111111112, F1 Score: 0.8491140296018345, Sensitivity: 0.9245098039215686, Specificity: 0.6641025641025641\n",
      "Iteration Results - Accuracy: 0.8555555555555556, F1 Score: 0.8830968701843881, Sensitivity: 0.9274509803921568, Specificity: 0.7534798534798535\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.6929220468675275, Sensitivity: 0.770343137254902, Specificity: 0.4311355311355311\n",
      "Iteration Results - Accuracy: 0.7666666666666666, F1 Score: 0.807282913165266, Sensitivity: 0.845343137254902, Specificity: 0.6450549450549451\n",
      "Iteration Results - Accuracy: 0.6888888888888888, F1 Score: 0.7216591591591591, Sensitivity: 0.7115196078431373, Specificity: 0.6879120879120878\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.7087087087087087, Sensitivity: 0.7590686274509805, Specificity: 0.4824175824175824\n",
      "Iteration Results - Accuracy: 0.6999999999999998, F1 Score: 0.7590909090909091, Sensitivity: 0.8102941176470589, Specificity: 0.5593406593406592\n",
      "Iteration Results - Accuracy: 0.8111111111111112, F1 Score: 0.8491568491568492, Sensitivity: 0.9166666666666666, Specificity: 0.686080586080586\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.8409258440218191, Sensitivity: 0.907843137254902, Specificity: 0.6468864468864469\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.839920313604524, Sensitivity: 0.8941176470588236, Specificity: 0.6897435897435896\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.8190045248868779, Sensitivity: 0.8715686274509804, Specificity: 0.6641025641025641\n",
      "Iteration Results - Accuracy: 0.7444444444444445, F1 Score: 0.7818732193732193, Sensitivity: 0.7928921568627452, Specificity: 0.6706959706959706\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.8361305361305361, Sensitivity: 0.888235294117647, Specificity: 0.6897435897435896\n",
      "Iteration Results - Accuracy: 0.7222222222222223, F1 Score: 0.7910404861624375, Sensitivity: 0.9036764705882353, Specificity: 0.467032967032967\n",
      "Iteration Results - Accuracy: 0.7888888888888891, F1 Score: 0.8167929292929292, Sensitivity: 0.8090686274509804, Specificity: 0.7534798534798535\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.8388888888888889, Sensitivity: 0.8899509803921569, Specificity: 0.6783882783882783\n",
      "Iteration Results - Accuracy: 0.8222222222222223, F1 Score: 0.8587489928953344, Sensitivity: 0.9274509803921568, Specificity: 0.6783882783882783\n",
      "Iteration Results - Accuracy: 0.8555555555555556, F1 Score: 0.8738636363636364, Sensitivity: 0.8674019607843136, Specificity: 0.8344322344322345\n",
      "Iteration Results - Accuracy: 0.7888888888888889, F1 Score: 0.8307041795413888, Sensitivity: 0.9049019607843137, Specificity: 0.6230769230769231\n",
      "100%|███████████████████████████████████████████████| 20/20 [30:45<00:00, 92.28s/trial, best loss: -0.8830968701843881]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3a6aa7a-bf3c-48c6-862e-593f61bb6320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 256, 'dropout_rate': 0.3387077337996911, 'learning_rate': 0.002281598253565537, 'epochs': 30, 'batch_size': 32, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f82fa55-d7a6-4c0a-bb23-a31bfa93a1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7391304347826086\n",
      "F1 Score: 0.7857142857142857\n",
      "Sensitivity: 0.8461538461538461\n",
      "Specificity: 0.6\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bac44-5189-4b34-9928-61c5a8a1d983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f0f9594-c68b-4782-86f9-44d9e5e9e711",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GRU with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b8baf37-7eef-4264-a74f-dfafa1ee6823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6e47809-6ee9-43d7-a3ce-0b0559ba6bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0f08203-cbc0-4019-89be-5ddf53760212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfe14ad5-c286-4c58-bb67-dd049622f568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 128, 64)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df17e7f3-6bef-40f5-a0cc-250632809af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a2384ae-4905-4740-bc0e-bd39841c65ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.7666666666666666, F1 Score: 0.7909961685823755, Sensitivity: 0.7992424242424242, Specificity: 0.7535714285714286\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.5962544362544362, Sensitivity: 0.5654040404040405, Specificity: 0.686904761904762\n",
      "Iteration Results - Accuracy: 0.7222222222222223, F1 Score: 0.754029304029304, Sensitivity: 0.7784090909090908, Specificity: 0.686904761904762\n",
      "Iteration Results - Accuracy: 0.5444444444444444, F1 Score: 0.6697925547030406, Sensitivity: 0.8333333333333334, Specificity: 0.2916666666666667\n",
      "Iteration Results - Accuracy: 0.5222222222222223, F1 Score: 0.6558441558441558, Sensitivity: 0.7983585858585859, Specificity: 0.2126984126984127\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.6883405144274709, Sensitivity: 0.8636363636363636, Specificity: 0.25\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.7598545914335387, Sensitivity: 0.774621212121212, Specificity: 0.7091269841269842\n",
      "Iteration Results - Accuracy: 0.7888888888888889, F1 Score: 0.8247633125681905, Sensitivity: 0.8617424242424242, Specificity: 0.7103174603174603\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.7654101469890944, Sensitivity: 0.7954545454545454, Specificity: 0.6853174603174604\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.7597754548974062, Sensitivity: 0.8087121212121212, Specificity: 0.6424603174603175\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6809523809523809, Sensitivity: 0.7026515151515151, Specificity: 0.6202380952380953\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6855495925263367, Sensitivity: 0.7215909090909092, Specificity: 0.598015873015873\n",
      "Iteration Results - Accuracy: 0.6555555555555556, F1 Score: 0.6869793621013134, Sensitivity: 0.7064393939393939, Specificity: 0.6246031746031746\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.747049247049247, Sensitivity: 0.7410353535353535, Specificity: 0.7313492063492063\n",
      "Iteration Results - Accuracy: 0.7000000000000001, F1 Score: 0.747872340425532, Sensitivity: 0.8390151515151515, Specificity: 0.4920634920634921\n",
      "Iteration Results - Accuracy: 0.5444444444444444, F1 Score: 0.6534632034632034, Sensitivity: 0.7680555555555556, Specificity: 0.34047619047619043\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.8264408793820559, Sensitivity: 0.850378787878788, Specificity: 0.7146825396825397\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.7285714285714286, Sensitivity: 0.7026515151515151, Specificity: 0.7757936507936508\n",
      "Iteration Results - Accuracy: 0.7666666666666666, F1 Score: 0.8021759825921393, Sensitivity: 0.850378787878788, Specificity: 0.6674603174603174\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.828761677598887, Sensitivity: 0.9337121212121212, Specificity: 0.5976190476190476\n",
      "100%|█████████████████████████████████████████████| 20/20 [2:03:28<00:00, 370.41s/trial, best loss: -0.828761677598887]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f9d7104-d47e-4aaa-be92-08120fe814c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 64, 'dropout_rate': 0.32829912940927286, 'epochs': 30, 'learning_rate': 0.006730294137741577, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)  \n",
    "print(\"Best Parameters:\", best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d914612b-3fa2-418e-bd4a-8cc14e877ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0d5fcb6-b4fe-4362-b02c-f7f918f07222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c8c9e1c-b5e7-4af8-ae11-d79141b94c61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b60d27c950>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c1a9e73-ec16-48c2-85fe-960dce4233cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7391304347826086\n",
      "F1 Score: 0.8\n",
      "Sensitivity: 0.9230769230769231\n",
      "Specificity: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c19e10-cd6c-4ddd-af51-b852dac64c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ff9f99-3409-48c5-861b-75518abe648b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e10b2f4-5a8c-47ca-a13f-10e3e42b65a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8d3f143-0eda-4a33-ba26-8d10004fef9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e3993ab-eb12-457b-b8e2-9751af0ff1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6229c27b-4206-45b0-8a35-a7a7ae79bd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f553f999-e6aa-4c50-8b51-7e140bbed3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6006d8b-6641-4f97-945e-f203e6c03206",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.762057709883797, Sensitivity: 0.6536616161616161, Specificity: 0.953968253968254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222223, F1 Score: 0.7877445551864156, Sensitivity: 0.903030303030303, Specificity: 0.5380952380952381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9254032258064516, Sensitivity: 0.9347222222222222, Specificity: 0.9095238095238095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8111111111111112, F1 Score: 0.8275771388499299, Sensitivity: 0.8486111111111111, Specificity: 0.7357142857142858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.7701423839635222, Sensitivity: 0.69760101010101, Specificity: 0.8841269841269841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777777, F1 Score: 0.791812865497076, Sensitivity: 0.736868686868687, Specificity: 0.8634920634920634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8333333333333334, F1 Score: 0.7933675414801016, Sensitivity: 0.7569444444444443, Specificity: 0.8527777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.611111111111111, F1 Score: 0.6070707070707071, Sensitivity: 0.5819444444444445, Specificity: 0.7317460317460318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.7481077275127618, Sensitivity: 0.8125, Specificity: 0.48888888888888893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6642951251646904, Sensitivity: 0.7277777777777779, Specificity: 0.5833333333333334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8444444444444446, F1 Score: 0.8612403100775193, Sensitivity: 0.8656565656565657, Specificity: 0.8007936507936507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8111111111111112, F1 Score: 0.8188225986262453, Sensitivity: 0.7931818181818183, Specificity: 0.7861111111111111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.8402830748368505, Sensitivity: 0.9555555555555556, Specificity: 0.596031746031746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8333333333333334, F1 Score: 0.8499149659863946, Sensitivity: 0.8680555555555555, Specificity: 0.7011904761904763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.7874130297280203, Sensitivity: 0.8987373737373737, Specificity: 0.36190476190476195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.8104454685099847, Sensitivity: 0.8338383838383838, Specificity: 0.7119047619047619\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222223, F1 Score: 0.7722222222222223, Sensitivity: 0.8353535353535353, Specificity: 0.6123015873015872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8777777777777778, F1 Score: 0.8909414340448824, Sensitivity: 0.8722222222222222, Specificity: 0.8095238095238096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6444444444444445, F1 Score: 0.6123456790123457, Sensitivity: 0.5299242424242424, Specificity: 0.8857142857142857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7999999999999999, F1 Score: 0.8348524477556736, Sensitivity: 0.8835858585858586, Specificity: 0.6833333333333332\n",
      "100%|███████████████████████████████████████████████| 20/20 [02:58<00:00,  8.93s/trial, best loss: -0.9254032258064516]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f4ba8f0-994d-4a1d-a1c3-c93fd00f44cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2970620017123239, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.004115425796633014}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4bf0d0bd-1037-4a62-8fb7-48312e4ac77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "606b8f69-d23f-4e33-ae82-6b68b668b41c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b7089a7ad0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "392976ba-392e-4b7f-b5d3-82d3fb0cb8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4611d94d-8639-4ea4-a0b7-a9fb3c9309f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.8\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521672af-5224-428c-9e0f-f4e3004e97e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c49581-02dc-41ce-ba8a-656ebca2ab55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8378b95e-a862-4f0c-8885-5a0ed5dc16ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "456eb6b0-5984-422a-a731-db8cbed28e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e60d39d7-b359-43b4-9aad-f449b8f91634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08b59738-579c-46a8-9ce4-ea6dd07aadea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58b6ac1a-177f-4e37-ad83-38ed1d39fa54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "82539106-fd2f-4db9-a438-b8b61938e2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3d757f8-47e9-41e9-b21e-b419c4dd83b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.40783419982859614, 'epochs': 20, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0008605819942603669, 'num_blocks': 10}\n",
      "Iteration - Loss: 8.51718807220459, Filters: 128, Blocks: 10, Kernel Size: 4, Dropout: 0.40783419982859614, LR: 0.0008605819942603669, Batch Size: 16, Epochs: 20\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.2525194181594599, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.001093388448785455, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.5844725370407104, Filters: 64, Blocks: 6, Kernel Size: 4, Dropout: 0.2525194181594599, LR: 0.001093388448785455, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.27676693763934346, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.00023092191318947576, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.31991302967071533, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.27676693763934346, LR: 0.00023092191318947576, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.409123591200412, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.00029545122096075486, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.3694537281990051, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.409123591200412, LR: 0.00029545122096075486, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.2930495972324517, 'epochs': 50, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0008414162556399997, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.1415928602218628, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.2930495972324517, LR: 0.0008414162556399997, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.4960506136307669, 'epochs': 20, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.008390687738504305, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6864669322967529, Filters: 64, Blocks: 6, Kernel Size: 4, Dropout: 0.4960506136307669, LR: 0.008390687738504305, Batch Size: 64, Epochs: 20\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.37715728509009155, 'epochs': 40, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0012691706115602179, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.4582896828651428, Filters: 32, Blocks: 8, Kernel Size: 5, Dropout: 0.37715728509009155, LR: 0.0012691706115602179, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.24862919275466788, 'epochs': 20, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0004783618835134821, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5779955387115479, Filters: 128, Blocks: 10, Kernel Size: 4, Dropout: 0.24862919275466788, LR: 0.0004783618835134821, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3377980076068203, 'epochs': 20, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.004320190081130043, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.7868519425392151, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.3377980076068203, LR: 0.004320190081130043, Batch Size: 32, Epochs: 20\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3425495112950154, 'epochs': 30, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.009939485951941265, 'num_blocks': 10}\n",
      "Iteration - Loss: 100.48170471191406, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.3425495112950154, LR: 0.009939485951941265, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.39640433522539487, 'epochs': 50, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00016871719718993363, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.17352379858493805, Filters: 64, Blocks: 6, Kernel Size: 5, Dropout: 0.39640433522539487, LR: 0.00016871719718993363, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.2627437631077633, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.008640956548271822, 'num_blocks': 6}\n",
      "Iteration - Loss: 1559.181884765625, Filters: 128, Blocks: 6, Kernel Size: 4, Dropout: 0.2627437631077633, LR: 0.008640956548271822, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.35572658673455904, 'epochs': 20, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0004459684641731388, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.6681750416755676, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.35572658673455904, LR: 0.0004459684641731388, Batch Size: 64, Epochs: 20\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.46991054853531, 'epochs': 20, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.007814101762296183, 'num_blocks': 4}\n",
      "Iteration - Loss: 110.6826171875, Filters: 64, Blocks: 4, Kernel Size: 4, Dropout: 0.46991054853531, LR: 0.007814101762296183, Batch Size: 64, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.4619192444458016, 'epochs': 30, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0005323520596251782, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.3761444687843323, Filters: 96, Blocks: 4, Kernel Size: 4, Dropout: 0.4619192444458016, LR: 0.0005323520596251782, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3452161788108061, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0017346317737831577, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.8455222845077515, Filters: 128, Blocks: 4, Kernel Size: 4, Dropout: 0.3452161788108061, LR: 0.0017346317737831577, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.4985863598046998, 'epochs': 30, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.00014065814967219805, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.3318304419517517, Filters: 96, Blocks: 4, Kernel Size: 4, Dropout: 0.4985863598046998, LR: 0.00014065814967219805, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.397028135588275, 'epochs': 40, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0007005511883477396, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.4892447292804718, Filters: 128, Blocks: 4, Kernel Size: 4, Dropout: 0.397028135588275, LR: 0.0007005511883477396, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3113662125855209, 'epochs': 50, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.0007414035297734373, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.22821852564811707, Filters: 32, Blocks: 6, Kernel Size: 4, Dropout: 0.3113662125855209, LR: 0.0007414035297734373, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.428621165724604, 'epochs': 40, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.00010542049988575153, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.3095705807209015, Filters: 64, Blocks: 4, Kernel Size: 3, Dropout: 0.428621165724604, LR: 0.00010542049988575153, Batch Size: 48, Epochs: 40\n",
      "100%|███████████████████████████████████████████████| 20/20 [04:46<00:00, 14.31s/trial, best loss: 0.17352379858493805]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3d36981a-ccd5-4cb8-a213-a238283a87ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 16, 'dropout_rate': 0.39640433522539487, 'epochs': 50, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00016871719718993363, 'num_blocks': 6}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ab1e88a-ae45-4486-b42a-6359f03aa47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f17e0be9-7917-4395-b378-bfdd6b8ce187",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 459ms/step - accuracy: 0.4681 - loss: 1.1265 - val_accuracy: 0.7778 - val_loss: 0.3903\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 437ms/step - accuracy: 0.5110 - loss: 0.9367 - val_accuracy: 0.7778 - val_loss: 0.3568\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 439ms/step - accuracy: 0.6078 - loss: 0.9415 - val_accuracy: 0.7778 - val_loss: 0.3171\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 437ms/step - accuracy: 0.6464 - loss: 0.8216 - val_accuracy: 0.7778 - val_loss: 0.2759\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 444ms/step - accuracy: 0.6020 - loss: 0.9150 - val_accuracy: 0.7778 - val_loss: 0.2688\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 439ms/step - accuracy: 0.6107 - loss: 0.7255 - val_accuracy: 0.7778 - val_loss: 0.2634\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 442ms/step - accuracy: 0.6399 - loss: 0.7250 - val_accuracy: 0.7778 - val_loss: 0.2568\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 437ms/step - accuracy: 0.7210 - loss: 0.5169 - val_accuracy: 0.7778 - val_loss: 0.2444\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 446ms/step - accuracy: 0.7528 - loss: 0.7136 - val_accuracy: 0.7778 - val_loss: 0.2339\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 456ms/step - accuracy: 0.6851 - loss: 0.6208 - val_accuracy: 0.8889 - val_loss: 0.2186\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 445ms/step - accuracy: 0.8372 - loss: 0.4540 - val_accuracy: 1.0000 - val_loss: 0.2068\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 439ms/step - accuracy: 0.6746 - loss: 0.6735 - val_accuracy: 1.0000 - val_loss: 0.1912\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 437ms/step - accuracy: 0.7707 - loss: 0.5205 - val_accuracy: 1.0000 - val_loss: 0.1746\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 442ms/step - accuracy: 0.7945 - loss: 0.4046 - val_accuracy: 1.0000 - val_loss: 0.1621\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 439ms/step - accuracy: 0.8351 - loss: 0.3243 - val_accuracy: 1.0000 - val_loss: 0.1596\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 436ms/step - accuracy: 0.8204 - loss: 0.3657 - val_accuracy: 1.0000 - val_loss: 0.1452\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 436ms/step - accuracy: 0.7793 - loss: 0.5616 - val_accuracy: 1.0000 - val_loss: 0.1519\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 432ms/step - accuracy: 0.7750 - loss: 0.5217 - val_accuracy: 1.0000 - val_loss: 0.1520\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 434ms/step - accuracy: 0.8544 - loss: 0.4948 - val_accuracy: 1.0000 - val_loss: 0.1681\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66ebb88b-8313-4ad3-a1ce-8978d4e73a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8ae39735-d80b-4962-be60-4ff3053aa583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.6521739130434783\n",
      "F1 Score: 0.7647058823529411\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.2\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843d977-9ee2-4eb2-9a96-1f54d24d9d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826e435c-2b69-4696-b68c-cc7d7d6b6c38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a736e9e-6ef9-4643-ab18-f33b9cf3465d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "660f2c10-76e2-4486-b9f7-64abfcd7c6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e8f855e-34da-4500-8797-722d2f7fc62a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1288f9f3-82e3-45a6-8914-9c8e2cc95842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c162185-68dd-4bef-8860-94c7961aa246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc307c86-51c0-4650-8797-71a5d677edf5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.06097210943698883, Params: {'batch_size': 64, 'dropout_rate': 0.44909548225014395, 'epochs': 50, 'learning_rate': 0.0002824036606184278, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.3026765286922455, Params: {'batch_size': 48, 'dropout_rate': 0.15924858914057044, 'epochs': 120, 'learning_rate': 0.00031897546003225094, 'num_layers': 6, 'units': 224}\n",
      "Iteration - Loss: 0.15747027099132538, Params: {'batch_size': 112, 'dropout_rate': 0.1806659374986065, 'epochs': 70, 'learning_rate': 0.0003790010190489661, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 8.670440673828125, Params: {'batch_size': 64, 'dropout_rate': 0.1360470729743966, 'epochs': 100, 'learning_rate': 4.534134512471041e-05, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.18293070793151855, Params: {'batch_size': 112, 'dropout_rate': 0.1074464224299641, 'epochs': 110, 'learning_rate': 5.7347595002534735e-05, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 3.235668659210205, Params: {'batch_size': 128, 'dropout_rate': 0.36727936935565053, 'epochs': 60, 'learning_rate': 0.00010457426539247574, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.670491635799408, Params: {'batch_size': 64, 'dropout_rate': 0.4501093047684962, 'epochs': 90, 'learning_rate': 1.4265293876431528e-05, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.020160583779215813, Params: {'batch_size': 48, 'dropout_rate': 0.21213663347077058, 'epochs': 130, 'learning_rate': 0.004669977542487522, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.09024517238140106, Params: {'batch_size': 16, 'dropout_rate': 0.3674275232602473, 'epochs': 130, 'learning_rate': 0.0001573307004907693, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.1820007860660553, Params: {'batch_size': 32, 'dropout_rate': 0.26747643887340355, 'epochs': 70, 'learning_rate': 0.0015003661272788122, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.2704627811908722, Params: {'batch_size': 96, 'dropout_rate': 0.14926864310286536, 'epochs': 140, 'learning_rate': 8.352108592098546e-05, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 1.7328429222106934, Params: {'batch_size': 64, 'dropout_rate': 0.2539980804692086, 'epochs': 130, 'learning_rate': 0.00047903711996778476, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.023518137633800507, Params: {'batch_size': 64, 'dropout_rate': 0.41882302095449775, 'epochs': 90, 'learning_rate': 0.007114927424843095, 'num_layers': 3, 'units': 256}\n",
      "Iteration - Loss: 0.13406650722026825, Params: {'batch_size': 96, 'dropout_rate': 0.26194747231415355, 'epochs': 110, 'learning_rate': 0.0008604459565194321, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.3244234621524811, Params: {'batch_size': 128, 'dropout_rate': 0.33050088514439524, 'epochs': 120, 'learning_rate': 0.0008742744732266592, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.7401857376098633, Params: {'batch_size': 112, 'dropout_rate': 0.3695450810217492, 'epochs': 100, 'learning_rate': 1.4301374131358253e-05, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.13272173702716827, Params: {'batch_size': 16, 'dropout_rate': 0.4186101980656195, 'epochs': 120, 'learning_rate': 0.0020785229882383936, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.28020602464675903, Params: {'batch_size': 96, 'dropout_rate': 0.17355665280809318, 'epochs': 110, 'learning_rate': 0.0016119032622538565, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 0.4022812843322754, Params: {'batch_size': 16, 'dropout_rate': 0.4039450803359309, 'epochs': 100, 'learning_rate': 0.0001709204496593157, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.020716078579425812, Params: {'batch_size': 32, 'dropout_rate': 0.12905858553680039, 'epochs': 140, 'learning_rate': 0.006818231003092622, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.15255533158779144, Params: {'batch_size': 32, 'dropout_rate': 0.20734020988049442, 'epochs': 150, 'learning_rate': 0.009931092318018838, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.001659861532971263, Params: {'batch_size': 32, 'dropout_rate': 0.21180990199098468, 'epochs': 150, 'learning_rate': 0.0049519672534511045, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.24704238772392273, Params: {'batch_size': 48, 'dropout_rate': 0.20376482198354504, 'epochs': 150, 'learning_rate': 0.006120080102476216, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 0.03481346741318703, Params: {'batch_size': 48, 'dropout_rate': 0.2216124201352691, 'epochs': 140, 'learning_rate': 0.003366172644986454, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.017883582040667534, Params: {'batch_size': 32, 'dropout_rate': 0.3037576462313737, 'epochs': 150, 'learning_rate': 0.002799545863475121, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.01605832763016224, Params: {'batch_size': 32, 'dropout_rate': 0.2900868464047094, 'epochs': 150, 'learning_rate': 0.0027793676082925297, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 1.4356122016906738, Params: {'batch_size': 80, 'dropout_rate': 0.3076511032540813, 'epochs': 140, 'learning_rate': 0.0010521210618815822, 'num_layers': 3, 'units': 64}\n",
      "Iteration - Loss: 0.1882106214761734, Params: {'batch_size': 16, 'dropout_rate': 0.24072868413829482, 'epochs': 150, 'learning_rate': 0.0034641131496570034, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 0.03252202272415161, Params: {'batch_size': 80, 'dropout_rate': 0.3322462762151976, 'epochs': 50, 'learning_rate': 0.0007160780809679552, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.23281250894069672, Params: {'batch_size': 32, 'dropout_rate': 0.4791843264104141, 'epochs': 130, 'learning_rate': 0.008260595276516229, 'num_layers': 3, 'units': 64}\n",
      "100%|██████████████████████████████████████████████| 30/30 [01:05<00:00,  2.18s/trial, best loss: 0.001659861532971263]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c483a25-6821-43f0-9ba3-8752c69d072f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 32, 'dropout_rate': 0.21180990199098468, 'epochs': 150, 'learning_rate': 0.0049519672534511045, 'num_layers': 2, 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c342230-9484-4e56-b4a0-3a4889ff368e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5154 - loss: 38.4776 - val_accuracy: 0.6667 - val_loss: 7.3209\n",
      "Epoch 2/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7184 - loss: 13.8328 - val_accuracy: 0.6667 - val_loss: 8.5492\n",
      "Epoch 3/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7258 - loss: 7.3557 - val_accuracy: 1.0000 - val_loss: 0.0397\n",
      "Epoch 4/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8634 - loss: 3.9043 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
      "Epoch 5/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9200 - loss: 4.9814 - val_accuracy: 1.0000 - val_loss: 0.0284\n",
      "Epoch 6/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9138 - loss: 2.3133 - val_accuracy: 0.7778 - val_loss: 1.5875\n",
      "Epoch 7/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9138 - loss: 0.6928 - val_accuracy: 0.7778 - val_loss: 1.7582\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4e10a01-dc6b-4ec0-9e0e-eb51deedcbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7391304347826086\n",
      "F1 Score: 0.8125\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.4\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b359e5-9346-4296-83b7-b2794f055b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17158e7c-484c-4293-9f5a-da025b00a923",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d965e1a0-2f98-4120-9dba-a5e1c910f532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_final]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a123ebfa-c356-4d1e-ba0b-28a798b4c113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad87f650-ccb4-4f24-93bf-1ff5d43f1752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7364395f-4592-42f5-b1de-80a15d1f64c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-20 16:37:27,725] A new study created in memory with name: no-name-425fb207-0ffc-4bc9-a036-3e6a52494d40\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b68da91-843d-4725-b347-18a854a3f6a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>0.685052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-20 16:38:48,619] Trial 0 finished with value: 0.6850518584251404 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 1.3828227888301917e-05, 'max_length': 193}. Best is trial 0 with value: 0.6850518584251404.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.687054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-20 16:41:07,800] Trial 1 finished with value: 0.687053918838501 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 2.280992991110837e-05, 'max_length': 217}. Best is trial 0 with value: 0.6850518584251404.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 02:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-20 16:43:35,239] Trial 2 finished with value: 0.676939070224762 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 3.7420100029349256e-05, 'max_length': 225}. Best is trial 2 with value: 0.676939070224762.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-20 16:45:02,435] Trial 3 finished with value: 0.6805121898651123 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.3237609089112108e-05, 'max_length': 135}. Best is trial 2 with value: 0.676939070224762.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 02:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-20 16:47:47,934] Trial 4 finished with value: 0.680433988571167 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.3278683665501395e-05, 'max_length': 250}. Best is trial 2 with value: 0.676939070224762.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "234507ec-9f5e-4418-811f-be47c73cc23e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 3.7420100029349256e-05, 'max_length': 225}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f91a3a1-0006-42ff-ad0d-e645d243f39d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2ade2ec8-d225-478d-bb0b-a516fb82c549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c66520e-c93a-45f9-a71b-4c08aa950a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "994b1820-4107-40a9-a1d3-cedab7315494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c154560e-d661-4a30-ab0d-86aa90ed84dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e9d50dc1-bf8a-49e9-8b52-d77cef2784c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 09:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.854594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.844284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.826121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9, training_loss=0.8573275672064887, metrics={'train_runtime': 672.2863, 'train_samples_per_second': 0.402, 'train_steps_per_second': 0.013, 'total_flos': 71039984947200.0, 'train_loss': 0.8573275672064887, 'epoch': 3.0})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "07f6e532-0cc7-42e7-80af-9adacaeea279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43478260869565216\n",
      "F1 Score: 0.0\n",
      "Sensitivity: 0.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2932c1d-0520-45ce-acb8-36587353527e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0859ce5-0315-4a7a-b806-3a1f2132d424",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2f943099-35fe-4ebb-8be3-0b350868993b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val= train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bee69523-7f4a-4ca5-83cb-8b5ba35ab6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a550a9d3-5d12-4dc3-8e4f-497a176607b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3fd44534-7d64-48f3-afa0-1c1d0051155c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 08:38:52,049] A new study created in memory with name: no-name-e421c5eb-2dcd-4f69-8fbf-15c0498aaa0e\n",
      "[I 2024-06-21 08:38:59,086] Trial 0 finished with value: 6961.95654296875 and parameters: {'num_units': 151, 'learning_rate': 0.00024985143550969205, 'dropout_rate': 0.11900540980428878, 'activity_regularizer': 9.460282672318887e-07, 'batch_size': 49}. Best is trial 0 with value: 6961.95654296875.\n",
      "[I 2024-06-21 08:39:06,189] Trial 1 finished with value: 6990.1025390625 and parameters: {'num_units': 168, 'learning_rate': 2.6711027505229857e-05, 'dropout_rate': 0.2291720706298218, 'activity_regularizer': 1.228874104665107e-07, 'batch_size': 63}. Best is trial 0 with value: 6961.95654296875.\n",
      "[I 2024-06-21 08:39:15,289] Trial 2 finished with value: 6993.58154296875 and parameters: {'num_units': 231, 'learning_rate': 2.535703519764922e-05, 'dropout_rate': 0.1320029633837692, 'activity_regularizer': 6.421448465317909e-05, 'batch_size': 34}. Best is trial 0 with value: 6961.95654296875.\n",
      "[I 2024-06-21 08:39:22,839] Trial 3 finished with value: 6988.44384765625 and parameters: {'num_units': 178, 'learning_rate': 4.115916415445501e-05, 'dropout_rate': 0.028512557570965633, 'activity_regularizer': 3.019489761072378e-05, 'batch_size': 48}. Best is trial 0 with value: 6961.95654296875.\n",
      "[I 2024-06-21 08:39:30,004] Trial 4 finished with value: 6962.3251953125 and parameters: {'num_units': 246, 'learning_rate': 0.00025250386554678464, 'dropout_rate': 0.17760220041787433, 'activity_regularizer': 2.8547049678111833e-05, 'batch_size': 45}. Best is trial 0 with value: 6961.95654296875.\n",
      "[I 2024-06-21 08:39:30,302] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:39:38,460] Trial 6 finished with value: 6963.03759765625 and parameters: {'num_units': 184, 'learning_rate': 0.0002410236674289118, 'dropout_rate': 0.09008158657357215, 'activity_regularizer': 2.935671623864853e-05, 'batch_size': 40}. Best is trial 0 with value: 6961.95654296875.\n",
      "[I 2024-06-21 08:39:38,749] Trial 7 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:39:44,962] Trial 8 finished with value: 6972.97900390625 and parameters: {'num_units': 153, 'learning_rate': 0.00011663687063057793, 'dropout_rate': 0.05314407529477265, 'activity_regularizer': 1.075042185097528e-06, 'batch_size': 53}. Best is trial 0 with value: 6961.95654296875.\n",
      "[I 2024-06-21 08:39:46,332] Trial 9 pruned. Trial was pruned at epoch 4.\n",
      "[I 2024-06-21 08:39:55,267] Trial 10 finished with value: 6954.05517578125 and parameters: {'num_units': 70, 'learning_rate': 0.000904145255957448, 'dropout_rate': 0.2982597456083135, 'activity_regularizer': 7.035704904510312e-07, 'batch_size': 27}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:40:04,163] Trial 11 finished with value: 6955.048828125 and parameters: {'num_units': 68, 'learning_rate': 0.0007857541800826039, 'dropout_rate': 0.2981011360829659, 'activity_regularizer': 8.949692963006951e-07, 'batch_size': 27}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:40:13,066] Trial 12 finished with value: 6954.56640625 and parameters: {'num_units': 69, 'learning_rate': 0.0008371174977566728, 'dropout_rate': 0.2926995542635533, 'activity_regularizer': 5.508176281943437e-07, 'batch_size': 25}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:40:23,797] Trial 13 finished with value: 6954.21484375 and parameters: {'num_units': 66, 'learning_rate': 0.000979511389842066, 'dropout_rate': 0.29488800101038787, 'activity_regularizer': 3.4701148084709727e-07, 'batch_size': 22}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:40:36,018] Trial 14 finished with value: 6955.86865234375 and parameters: {'num_units': 104, 'learning_rate': 0.0004611752926803086, 'dropout_rate': 0.26756708320019423, 'activity_regularizer': 3.083892031447868e-07, 'batch_size': 16}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:40:45,022] Trial 15 finished with value: 6954.89599609375 and parameters: {'num_units': 102, 'learning_rate': 0.0005848009334711763, 'dropout_rate': 0.19780115030896417, 'activity_regularizer': 3.321971784825594e-06, 'batch_size': 24}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:40:45,353] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:40:45,671] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:40:54,909] Trial 18 finished with value: 6954.56103515625 and parameters: {'num_units': 85, 'learning_rate': 0.0009672402118092362, 'dropout_rate': 0.2972412112048141, 'activity_regularizer': 1.5951883332454715e-06, 'batch_size': 20}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:40:55,284] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:40:55,620] Trial 20 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:06,164] Trial 21 finished with value: 6955.63525390625 and parameters: {'num_units': 83, 'learning_rate': 0.0009578453014433444, 'dropout_rate': 0.2954130220604949, 'activity_regularizer': 1.7089328511744226e-06, 'batch_size': 21}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:41:06,552] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:06,884] Trial 23 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:15,778] Trial 24 finished with value: 6954.904296875 and parameters: {'num_units': 90, 'learning_rate': 0.000972646821955073, 'dropout_rate': 0.2687516212905715, 'activity_regularizer': 1.9657371826111075e-07, 'batch_size': 29}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:41:16,163] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:17,747] Trial 26 pruned. Trial was pruned at epoch 7.\n",
      "[I 2024-06-21 08:41:18,223] Trial 27 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-21 08:41:18,599] Trial 28 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:18,979] Trial 29 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:19,284] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:19,613] Trial 31 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:28,583] Trial 32 finished with value: 6954.16455078125 and parameters: {'num_units': 97, 'learning_rate': 0.0008344751915885917, 'dropout_rate': 0.2737628781139021, 'activity_regularizer': 1.8348148854330395e-07, 'batch_size': 25}. Best is trial 10 with value: 6954.05517578125.\n",
      "[I 2024-06-21 08:41:28,837] Trial 33 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:29,351] Trial 34 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-21 08:41:29,666] Trial 35 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:29,999] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:41:30,992] Trial 37 pruned. Trial was pruned at epoch 3.\n",
      "[I 2024-06-21 08:41:34,834] Trial 38 pruned. Trial was pruned at epoch 16.\n",
      "[I 2024-06-21 08:41:35,295] Trial 39 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-21 08:41:42,090] Trial 40 finished with value: 6953.85009765625 and parameters: {'num_units': 203, 'learning_rate': 0.0007151636076373778, 'dropout_rate': 0.24323398478191693, 'activity_regularizer': 2.301817872490256e-07, 'batch_size': 42}. Best is trial 40 with value: 6953.85009765625.\n",
      "[I 2024-06-21 08:41:49,734] Trial 41 finished with value: 6953.9130859375 and parameters: {'num_units': 207, 'learning_rate': 0.0007293945387957755, 'dropout_rate': 0.24133357258993635, 'activity_regularizer': 2.4341563103245494e-07, 'batch_size': 41}. Best is trial 40 with value: 6953.85009765625.\n",
      "[I 2024-06-21 08:41:57,335] Trial 42 finished with value: 6954.37890625 and parameters: {'num_units': 204, 'learning_rate': 0.0007944684873184961, 'dropout_rate': 0.2465359878773666, 'activity_regularizer': 2.1823422253877977e-07, 'batch_size': 43}. Best is trial 40 with value: 6953.85009765625.\n",
      "[I 2024-06-21 08:42:03,867] Trial 43 pruned. Trial was pruned at epoch 42.\n",
      "[I 2024-06-21 08:42:04,163] Trial 44 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:42:04,585] Trial 45 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-21 08:42:09,070] Trial 46 pruned. Trial was pruned at epoch 28.\n",
      "[I 2024-06-21 08:42:09,378] Trial 47 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 08:42:15,448] Trial 48 finished with value: 6953.892578125 and parameters: {'num_units': 210, 'learning_rate': 0.0008203829957428027, 'dropout_rate': 0.2389999362186816, 'activity_regularizer': 4.841437449708464e-07, 'batch_size': 43}. Best is trial 40 with value: 6953.85009765625.\n",
      "[I 2024-06-21 08:42:15,729] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c09b0a93-aa85-424d-a487-b5fc43848a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 203, 'learning_rate': 0.0007151636076373778, 'dropout_rate': 0.24323398478191693, 'activity_regularizer': 2.301817872490256e-07, 'batch_size': 42}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b0c1501-82c9-4d1d-ad93-de5099fa416f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c9170f41-4161-49eb-863f-ec7a66a7a038",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 7221.7104 - val_loss: 6994.6992\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6977.7334 - val_loss: 6991.0381\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6863.0225 - val_loss: 6987.5317\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6938.2495 - val_loss: 6983.7783\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7043.1699 - val_loss: 6980.8042\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6679.7363 - val_loss: 6977.9346\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 6826.0645 - val_loss: 6975.2739\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6926.0459 - val_loss: 6972.6128\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6893.2783 - val_loss: 6970.2827\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6821.7231 - val_loss: 6968.3989\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7117.9463 - val_loss: 6966.9814\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6837.9805 - val_loss: 6965.6904\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 6894.1270 - val_loss: 6964.2583\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6775.4995 - val_loss: 6962.8936\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6902.8999 - val_loss: 6962.0747\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7016.4590 - val_loss: 6961.3623\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6808.0449 - val_loss: 6960.4023\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7038.1494 - val_loss: 6959.6870\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7217.1572 - val_loss: 6958.9468\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7044.1553 - val_loss: 6958.3901\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7048.9688 - val_loss: 6957.7217\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 6788.7896 - val_loss: 6957.4272\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6906.8330 - val_loss: 6957.2119\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7090.8740 - val_loss: 6957.0332\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6995.3604 - val_loss: 6956.7998\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7057.8721 - val_loss: 6956.6748\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6941.4082 - val_loss: 6956.5610\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6903.1445 - val_loss: 6956.4775\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 6745.1572 - val_loss: 6956.4062\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6971.8657 - val_loss: 6956.2280\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 6882.2979 - val_loss: 6956.1021\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7035.1626 - val_loss: 6955.9219\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 7080.2651 - val_loss: 6955.8262\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7014.2231 - val_loss: 6955.8208\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6774.3530 - val_loss: 6955.8213\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6833.4858 - val_loss: 6955.8213\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6864.2920 - val_loss: 6955.7847\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 6938.2368 - val_loss: 6955.7842\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7060.0425 - val_loss: 6955.7783\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6996.8301 - val_loss: 6955.7305\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 6955.2197 - val_loss: 6955.6167\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6871.3691 - val_loss: 6955.6157\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 6872.0093 - val_loss: 6955.6157\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 6894.3281 - val_loss: 6955.6128\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 6933.5825 - val_loss: 6955.6099\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6735.5210 - val_loss: 6955.6060\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6934.8921 - val_loss: 6955.5967\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6820.3857 - val_loss: 6955.5874\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6893.3223 - val_loss: 6955.5835\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6986.7017 - val_loss: 6955.5845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bc3822f690>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e35d12a4-51f6-4953-9a25-0075d148e190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6955.5835\n",
      "Validation Loss:  6955.58349609375\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1335ff21-8c23-4848-a9e4-4a88b7cbb50e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "098e4a24-8a70-4eb9-92ca-69cdeb7dab30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de482208-fe4e-4df6-8757-dea8c9104f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2089927b-66b9-4f11-9c4f-ee8b46f17166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34782608695652173\n",
      "F1 Score: 0.0\n",
      "Sensitivity: 0.0\n",
      "Specificity: 0.8\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d7b43-b4bc-4169-b33f-f36a946dc32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2dc2521-e6bc-4278-92c7-29bc3f4afa36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2d95ecd8-d609-4dae-8aeb-55f847b02777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final = X_final.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9c2fe97f-1d0b-496f-953f-bcb1e5c8b15e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bb9ce46a-b3fc-4677-b342-43964842e6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18649c0b-3ac2-49ec-870f-f3e763812933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cacb02eb-f7b3-4858-bf75-ba1c8155f6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a6600bab-8b65-4595-b370-625a2801190d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "95eb41c1-9d51-42ff-af37-1c70f89f0121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "24813fd0-b728-4bd7-88ad-f986814d079f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.5213675213675214, Sensitivity: 0.625, Specificity: 0.4523809523809524\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.7158164832583438, Sensitivity: 0.7799242424242424, Specificity: 0.4297619047619048\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.6888641149510715, Sensitivity: 0.8575757575757575, Specificity: 0.15\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.688888888888889, F1 Score: 0.6271493212669683, Sensitivity: 0.6694444444444444, Specificity: 0.5476190476190476\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6, F1 Score: 0.7412080672950238, Sensitivity: 1.0, Specificity: 0.022222222222222223   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.8242294053464265, Sensitivity: 0.9185606060606061, Specificity: 0.47341269841269845\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.8005728607232366, Sensitivity: 0.9791666666666666, Specificity: 0.35833333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4555555555555555, F1 Score: 0.5096618357487922, Sensitivity: 0.6969696969696969, Specificity: 0.3333333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6903846153846155, Sensitivity: 0.7430555555555555, Specificity: 0.39206349206349206\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5333333333333333, F1 Score: 0.6892764857881137, Sensitivity: 0.8977272727272728, Specificity: 0.023809523809523808\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.7379937482239272, Sensitivity: 0.8768939393939394, Specificity: 0.2976190476190476\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5333333333333333, F1 Score: 0.6866644197281203, Sensitivity: 0.8939393939393939, Specificity: 0.08333333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.7000000000000001, F1 Score: 0.7407464607464607, Sensitivity: 0.8084595959595959, Specificity: 0.45436507936507936\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.7234591495461061, Sensitivity: 0.9111111111111111, Specificity: 0.13333333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4777777777777777, F1 Score: 0.5874396135265699, Sensitivity: 0.7575757575757575, Specificity: 0.25\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "100%|████████████████████████████████████████████| 20/20 [1:30:54<00:00, 272.73s/trial, best loss: -0.8242294053464265]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ace3fce-b9cb-4fb0-a793-df592e33095d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 9.613038253006618e-07, 'ae_batch_size': 37.0, 'ae_dropout_rate': 0.30932740634422884, 'ae_learning_rate': 0.007175305754252685, 'autoencoder_units': 301.0, 'encoding_dim': 81.0, 'lstm_batch_size': 52.0, 'lstm_dropout_rate': 0.28935372762778827, 'lstm_learning_rate': 0.0006151304812403228, 'lstm_units': 374.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "90f44325-0861-49ce-ab15-098c66cca4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d9487d0b-2e87-462a-95d4-f9d6760d0ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "877d79e7-64df-46d9-abc6-8c6b9d23351e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "92e6193e-20bb-445a-acab-7fb4e54f4512",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 6746.9121 - val_loss: 6959.1250\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 7034.5898 - val_loss: 6958.4727\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 6874.7856 - val_loss: 6958.1670\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 7308.9990 - val_loss: 6958.0952\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 6675.7134 - val_loss: 6958.1221\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 6943.9912 - val_loss: 6958.3071\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 6908.7612 - val_loss: 6958.3003\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 6726.7764 - val_loss: 6958.2812\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 6815.9609 - val_loss: 6958.7964\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6s/step - accuracy: 0.5256 - loss: 0.9116 - val_accuracy: 0.6087 - val_loss: 0.6743\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7s/step - accuracy: 0.5849 - loss: 0.7149 - val_accuracy: 0.5652 - val_loss: 0.9160\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9s/step - accuracy: 0.5913 - loss: 0.8141 - val_accuracy: 0.5652 - val_loss: 0.6510\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.5330 - loss: 0.6796 - val_accuracy: 0.5217 - val_loss: 0.6721\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.5276 - loss: 0.6970 - val_accuracy: 0.6087 - val_loss: 0.6363\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.5667 - loss: 0.6741 - val_accuracy: 0.6522 - val_loss: 0.6248\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6199 - loss: 0.6466 - val_accuracy: 0.6522 - val_loss: 0.6444\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6550 - loss: 0.6376 - val_accuracy: 0.6522 - val_loss: 0.6269\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6688 - loss: 0.6227 - val_accuracy: 0.6522 - val_loss: 0.5890\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7s/step - accuracy: 0.7123 - loss: 0.5984 - val_accuracy: 0.6522 - val_loss: 0.5698\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6624 - loss: 0.5946 - val_accuracy: 0.6087 - val_loss: 0.5632\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.7942 - loss: 0.5446 - val_accuracy: 0.6522 - val_loss: 0.5538\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6772 - loss: 0.5578 - val_accuracy: 0.6522 - val_loss: 0.5550\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.7231 - loss: 0.5283 - val_accuracy: 0.6522 - val_loss: 0.5692\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6s/step - accuracy: 0.6974 - loss: 0.5304 - val_accuracy: 0.6522 - val_loss: 0.5552\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.7038 - loss: 0.5224 - val_accuracy: 0.6522 - val_loss: 0.5370\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6954 - loss: 0.5161 - val_accuracy: 0.6522 - val_loss: 0.5287\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7s/step - accuracy: 0.7113 - loss: 0.5193 - val_accuracy: 0.6522 - val_loss: 0.5245\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.7038 - loss: 0.5070 - val_accuracy: 0.6522 - val_loss: 0.5237\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6900 - loss: 0.5100 - val_accuracy: 0.6522 - val_loss: 0.5356\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.7093 - loss: 0.5251 - val_accuracy: 0.6522 - val_loss: 0.5368\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6516 - loss: 0.5418 - val_accuracy: 0.6522 - val_loss: 0.5151\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.7231 - loss: 0.5554 - val_accuracy: 0.6522 - val_loss: 0.5126\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6688 - loss: 0.6194 - val_accuracy: 0.6522 - val_loss: 0.5115\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6964 - loss: 0.5626 - val_accuracy: 0.6522 - val_loss: 0.5202\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6348 - loss: 0.5601 - val_accuracy: 0.6522 - val_loss: 0.5448\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6688 - loss: 0.5549 - val_accuracy: 0.6522 - val_loss: 0.5352\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.7261 - loss: 0.5206 - val_accuracy: 0.6522 - val_loss: 0.5159\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6s/step - accuracy: 0.6984 - loss: 0.5359 - val_accuracy: 0.6522 - val_loss: 0.5130\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3ab139b2-fdb5-4257-abe1-7c8869818998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Accuracy: 0.6521739130434783\n",
      "F1 Score: 0.7647058823529411\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.2\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d2c84-db03-462e-ac58-4482f7d141ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "353e38e3-cd40-42d9-8601-e8496f1fbb00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "27be2213-c65d-4f3a-8a4c-8212ef2ea118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "322dad12-b0f8-4b69-8738-aa16eb1487e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "76da5dc1-8d83-47d9-a80b-066223f1a4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4a6039cf-3e9b-420c-b4fa-c94ac31638f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7514e1e9-dbba-4eca-9c23-914a77423923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "24df7775-a739-47d6-b6ac-c4385aeafed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "33562242-b82a-40b2-beff-3ef2b7de3d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6082f4f4-7039-4f28-8414-5200d2309db9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [25:12<00:00, 75.62s/trial, best loss: -0.7666666666666667]\n",
      "Best parameters:  {'ae_activity_reg': 2.3197255622685547e-07, 'ae_batch_size': 62.0, 'ae_dropout_rate': 0.2860032321959243, 'ae_learning_rate': 0.00043315861820639927, 'autoencoder_units': 309.0, 'encoding_dim': 93.0, 'fnn_batch_size': 22.0, 'fnn_dropout_rate': 0.16407132082353554, 'fnn_learning_rate': 0.0024960820557592134, 'fnn_units': 383.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "70fbf648-eeb0-40fa-a2b8-ae012f5ac51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ed19dc97-d105-459e-9400-95b461b867b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "33f5d3b0-1c56-400c-a430-aaba2bde0cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Final Model - Accuracy: 0.8111111111111111\n",
      "Final Model - F1 Score: 0.7956568580609501\n",
      "Final Model - Sensitivity: 0.7339549339549339\n",
      "Final Model - Specificity: 0.9092063492063491\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49591a1a-a4e2-4b29-b5f5-b76a1bde6184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd0cedee-bd9c-42c4-bf0e-c2622c1ac473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization - 1500 SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35b9059-2596-4949-949a-1b8295f59499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_41408\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4fa12b-5b42-40cb-a37b-5ccfd43ce1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bd17af-ae3a-4ac5-ade1-2fb9741ac9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abd4884-2997-4966-b9a9-fca43a3d7203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdac91e-0c5a-4395-b198-f081c07e07d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44817a34-932c-47a9-bb8f-43f83dc8410c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10f49e3-2d34-467b-ac27-26b5d08d1887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9a8d12-43a7-4c02-b4dc-f59ba4359042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae1dbe8-f829-4233-98d2-2fdf36e50934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "055bfc97-c6c3-475d-83a3-ba1ebb2263b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accda98d-bb1c-4840-8fe5-ef67516c64f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91acf649-25f7-42d9-9b25-af18e93e031f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8225dc93-21ce-4ecd-98ae-b888ce6a37e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 2.1721004372921016e-07, Params: {'batch_size': 96, 'dropout_rate': 0.12276120326636941, 'epochs': 100, 'learning_rate': 0.005206598238757878, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 7.343531893688748e-10, Params: {'batch_size': 80, 'dropout_rate': 0.3461060274399002, 'epochs': 90, 'learning_rate': 0.0035472207387708668, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.02443823032081127, Params: {'batch_size': 112, 'dropout_rate': 0.44266832423416225, 'epochs': 140, 'learning_rate': 0.0003352100372693119, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.11037226766347885, Params: {'batch_size': 128, 'dropout_rate': 0.2621787879384934, 'epochs': 70, 'learning_rate': 7.823948164780953e-05, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.00029435160104185343, Params: {'batch_size': 80, 'dropout_rate': 0.3646644871775264, 'epochs': 120, 'learning_rate': 0.002755567048454139, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.06082063913345337, Params: {'batch_size': 80, 'dropout_rate': 0.21994852218350036, 'epochs': 100, 'learning_rate': 0.0007470820820747454, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.012253821827471256, Params: {'batch_size': 32, 'dropout_rate': 0.1631301813517828, 'epochs': 130, 'learning_rate': 0.0001822241374510375, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.04087381064891815, Params: {'batch_size': 48, 'dropout_rate': 0.1064540821691375, 'epochs': 70, 'learning_rate': 0.00017842068125673374, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 3.8745417824669634e-17, Params: {'batch_size': 32, 'dropout_rate': 0.4070431777223472, 'epochs': 120, 'learning_rate': 0.007317068667553475, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 1.3432281775749288e-06, Params: {'batch_size': 80, 'dropout_rate': 0.1442880245816531, 'epochs': 80, 'learning_rate': 0.0010571663019861342, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.4702865779399872, Params: {'batch_size': 48, 'dropout_rate': 0.2883094608610582, 'epochs': 80, 'learning_rate': 2.0382266105553197e-05, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.003093383042141795, Params: {'batch_size': 32, 'dropout_rate': 0.3063375840875867, 'epochs': 80, 'learning_rate': 0.0005891448297958135, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 0.011944808065891266, Params: {'batch_size': 32, 'dropout_rate': 0.2754897987329451, 'epochs': 90, 'learning_rate': 0.00030143101234416763, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.005514631513506174, Params: {'batch_size': 112, 'dropout_rate': 0.42526891801251987, 'epochs': 70, 'learning_rate': 0.0007368295710514536, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 1.3474724447348763e-08, Params: {'batch_size': 96, 'dropout_rate': 0.10709804779022024, 'epochs': 70, 'learning_rate': 0.0019258293614328017, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 0.0031456071883440018, Params: {'batch_size': 32, 'dropout_rate': 0.375563927163466, 'epochs': 110, 'learning_rate': 0.00060772175446862, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.00012575801520142704, Params: {'batch_size': 112, 'dropout_rate': 0.31162918509667725, 'epochs': 60, 'learning_rate': 0.0017328321103265599, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.0036974665708839893, Params: {'batch_size': 80, 'dropout_rate': 0.19862268462476007, 'epochs': 80, 'learning_rate': 0.001129177146626667, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 0.041431672871112823, Params: {'batch_size': 112, 'dropout_rate': 0.29638574289676445, 'epochs': 100, 'learning_rate': 0.00015932700673300574, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 0.5514987707138062, Params: {'batch_size': 128, 'dropout_rate': 0.361578366794968, 'epochs': 140, 'learning_rate': 6.350960250449664e-05, 'num_layers': 6, 'units': 96}\n",
      "Iteration - Loss: 7.78068202315213e-15, Params: {'batch_size': 64, 'dropout_rate': 0.49794383962055305, 'epochs': 120, 'learning_rate': 0.008607213821153654, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 1.3155314254176677e-29, Params: {'batch_size': 48, 'dropout_rate': 0.497315424898908, 'epochs': 120, 'learning_rate': 0.007537877441551526, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 8.400352413673318e-08, Params: {'batch_size': 16, 'dropout_rate': 0.49533463765555125, 'epochs': 150, 'learning_rate': 0.009175123506194139, 'num_layers': 6, 'units': 160}\n",
      "Iteration - Loss: 2.475316063232924e-10, Params: {'batch_size': 48, 'dropout_rate': 0.45298572167880113, 'epochs': 120, 'learning_rate': 0.005789700432651467, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 16, 'dropout_rate': 0.3964017257273706, 'epochs': 130, 'learning_rate': 0.009030063440254357, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 1.870798471920263e-15, Params: {'batch_size': 16, 'dropout_rate': 0.47200597024463065, 'epochs': 150, 'learning_rate': 0.004376558118740183, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.673792839050293, Params: {'batch_size': 64, 'dropout_rate': 0.4882300552913431, 'epochs': 130, 'learning_rate': 1.8175013644287866e-05, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 3.38652739628742e-06, Params: {'batch_size': 16, 'dropout_rate': 0.40578152387844346, 'epochs': 140, 'learning_rate': 0.00239070955061133, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 1.3903686687209704e-13, Params: {'batch_size': 48, 'dropout_rate': 0.40097529515158764, 'epochs': 110, 'learning_rate': 0.009924242231949354, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 2.4219312322515716e-17, Params: {'batch_size': 64, 'dropout_rate': 0.33382362469349663, 'epochs': 130, 'learning_rate': 0.004435666981683886, 'num_layers': 6, 'units': 160}\n",
      "100%|███████████████████████████████████████████████████████████████| 30/30 [03:26<00:00,  6.89s/trial, best loss: 0.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f994a1-7504-4448-a1e7-9c769fb76c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 16, 'dropout_rate': 0.3964017257273706, 'epochs': 130, 'learning_rate': 0.009030063440254357, 'num_layers': 6, 'units': 192}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b3d2d5d-e04c-4227-842a-4be316a8ca3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_selected, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_selected):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "          num_layers=best_params['num_layers'],\n",
    "          units=best_params['units'],\n",
    "          dropout_rate=best_params['dropout_rate'],\n",
    "          learning_rate=best_params['learning_rate'])\n",
    "        \n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dbf8d75-3c2d-436f-932e-4250433fcd62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000219415B80E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.9777777777777779\n",
      "F1 Score: 0.9833333333333332\n",
      "Sensitivity: 0.9692307692307693\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_train, y_train, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a930f3e-84b5-437e-bdd7-74b6bb12a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e783e5-3d50-4818-89b5-b2874fe15ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10acca05-52c9-4627-8d31-8cb37936bf77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - 1500 SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69e1e98a-2163-434e-baf4-4a76b2415a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_29844\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75fd1c15-ddc9-4ee9-a94c-e5a0c0b68253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4dab77b-47d0-406b-8b37-3b5a16c4e3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69e965b8-8008-4acd-9a14-bfd079c05895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e0bb691-81b3-4632-8a57-662c0e01f980",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [575822 114143  71716 499736 767356 750187 514835 412607 468562 385721]\n",
      "Top AMGM values: [1.00529797 1.0052982  1.00529837 1.00529853 1.00529853 1.00529858\n",
      " 1.00529869 1.00529874 1.00529877 1.00529877]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e38fbf01-8bea-48f6-acf1-9a70c82720a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de27f2d-1b1c-44ff-81d4-313ebf21742f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c80db634-29e8-455f-93b4-8c797822ec39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f65ead6-7a2a-4ac4-975c-b519cd76def5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "811aeab0-4580-4e0f-98ce-720ee6ce0772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecfb65fe-290e-4e88-b209-e445855a15c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee191120-97ee-4eb9-a193-c5cd5a296755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602621ab-cf77-4b16-8d08-d0e40102d06c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002195430E160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9026548672566371, F1 Score: 0.9219858156028369, Sensitivity: 0.9848484848484849, Specificity: 0.7872340425531915\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9767441860465116, Sensitivity: 0.9545454545454546, Specificity: 1.0          \n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.911504424778761, F1 Score: 0.927536231884058, Sensitivity: 0.9696969696969697, Specificity: 0.8297872340425532\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9911504424778761, F1 Score: 0.9923664122137404, Sensitivity: 0.9848484848484849, Specificity: 1.0          \n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9770992366412213, Sensitivity: 0.9696969696969697, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9770992366412213, Sensitivity: 0.9696969696969697, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "100%|███████████████████████████████████████████████| 20/20 [11:44<00:00, 35.21s/trial, best loss: -0.9923664122137404]\n",
      "Best parameters found:  {'batch_size': 96.0, 'dropout_rate': 0.4115256590485654, 'epochs': 50.0, 'learning_rate': 0.05908411677273943, 'neurons1': 96.0, 'neurons2': 48.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9010f2c-4a57-44fb-aea8-946c881b0638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_135\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_135\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_698 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">144,096</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_363 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_699 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_364 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_700 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_701 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">145,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_702 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,501</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_698 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │         \u001b[38;5;34m144,096\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_363 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_699 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │           \u001b[38;5;34m4,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_364 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_700 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │           \u001b[38;5;34m4,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_701 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)                │         \u001b[38;5;34m145,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_702 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,501\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">300,457</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m300,457\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">300,457</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m300,457\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "899c9eeb-acab-458e-82b2-f168f9b20b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_selected, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_selected):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_deep_autoencoder(\n",
    "            input_dim=X_selected.shape[1],\n",
    "            neurons1=best_params['neurons1'],\n",
    "            neurons2=best_params['neurons2'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d81517a-90c4-4bc2-82aa-8b88bcdc4024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.9913043478260869\n",
      "F1 Score: 0.9913043478260869\n",
      "Sensitivity: 0.9833333333333332\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_selected, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716675cc-bad6-4b0d-b1b4-46d13b6b8422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b09f11df-9ca4-496b-bb87-a8c4bfca53e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization - 1500 SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5746b07-f9ad-44a1-a47b-db2305850d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_15196\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8db315-02cb-4c2c-b8a6-8b88257768c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4ed142-6509-4c72-bc5c-488ec69effc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c053f8b6-4b24-4d24-9679-5ba011b3a1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033b7b4e-a314-491a-aced-0af941202060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55eb35c4-69d6-4be0-bbb1-3ee477eb6e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bcd21c7-3256-42aa-8e52-7fbb404673a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c092ecc2-d1f3-4613-a3cc-51200f6d15a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f7f9ce-72d5-488e-9393-c355c9f28267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e05bba-f568-4b37-91c3-4216a29d2b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9219f98-c1c0-458f-865b-54521ae30726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68fe351a-3b34-4f0f-a850-6f7b91a365fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cdc2078-6154-4c22-a24f-8a3a7b4b9539",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step                                                \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:09<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022185602B60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                               \n",
      "  0%|                                                                           | 0/20 [00:15<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022185602B60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9944444444444445, F1 Score: 0.9939393939393939, Sensitivity: 0.9882352941176471, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9944444444444445, F1 Score: 0.9939393939393939, Sensitivity: 0.9882352941176471, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9666666666666668, F1 Score: 0.9590476190476191, Sensitivity: 0.9262745098039215, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9944444444444445, F1 Score: 0.9939393939393939, Sensitivity: 0.9882352941176471, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9944444444444445, F1 Score: 0.9925925925925926, Sensitivity: 0.9857142857142858, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9777777777777779, Sensitivity: 0.96, Specificity: 1.0    \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                               \n",
      "\n",
      "Iteration Results - Accuracy: 0.9388888888888889, F1 Score: 0.9385398981324279, Sensitivity: 0.9647058823529411, Specificity: 0.9238095238095237\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9944444444444445, F1 Score: 0.9939393939393939, Sensitivity: 0.9882352941176471, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9944444444444445, F1 Score: 0.9939393939393939, Sensitivity: 0.9882352941176471, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step                                               \n",
      "\n",
      "Iteration Results - Accuracy: 0.8944444444444445, F1 Score: 0.9283018867924528, Sensitivity: 1.0, Specificity: 0.8     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 167ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9944444444444445, F1 Score: 0.9925925925925926, Sensitivity: 0.9857142857142858, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9695483870967742, Sensitivity: 0.9571428571428571, Specificity: 0.9904761904761905\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step                                               \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9870428422152561, Sensitivity: 0.9749019607843138, Specificity: 1.0\n",
      "100%|██████████████████████████████████████████████████████████████| 20/20 [14:25<00:00, 43.27s/trial, best loss: -1.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "737abfd1-72ed-4867-9e16-db28d7d4d58d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.47037495765498, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0037618499301705936}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a165c143-53af-49b8-bbeb-35ea37078669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c13ed009-9208-4d98-b6e0-9482cb1b99e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_selected, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_selected):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_cnn_model(\n",
    "            input_shape=(X_train.shape[1], 1),\n",
    "            filters=int(best_params['filters']),\n",
    "            kernel_size=int(best_params['kernel_size']),\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d81f7361-a1c1-49d2-ac98-eb369ce991f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.8355555555555556\n",
      "F1 Score: 0.844393741851369\n",
      "Sensitivity: 0.9058823529411765\n",
      "Specificity: 0.7294372294372294\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_selected, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64018c84-0c1c-475d-b67f-decffdce89b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2973deeb-e783-4017-a8b1-dc7d0a89c343",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb5c26f1-d429-41e5-8eed-b3b683631d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_35804\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33060cd3-f563-4a7b-8591-6e6d3b701dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72393adc-fd78-4750-823d-10a0e918ccfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbc4f120-35a3-4b4b-92ad-34df79564ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b22247f-1fcf-4910-b237-7b3ed110d8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a6e71ee-9e74-4e8a-be4c-ddd9479799e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40f47fb5-c0c0-4803-8929-bba561816dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34fd2c5d-eba7-4d4a-8337-c71e8d672abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59c54e88-5792-435d-8fdf-c5f24be59d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63a3c1d5-0291-4777-8983-790adfd2738f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1e54213-a4b7-4b4e-90e4-b0a1eae6eb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cdc1f11-102e-4376-b618-61fd8ba30588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef324085-7c78-413f-8c23-df5324594bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a121381d-1666-4320-98e8-03f4f8bce23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9ebb8b0-60a6-495f-a551-4d5eb8b43558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f80134ac-42bc-4a56-a62c-3e8015d4700d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                               \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [07:35<00:00, 22.79s/trial, best loss: -0.9888888888888889]\n",
      "Best parameters:  {'ae_activity_reg': 8.069224068688878e-07, 'ae_batch_size': 60.0, 'ae_dropout_rate': 0.3301202921198368, 'ae_learning_rate': 0.0011510191782298654, 'autoencoder_units': 342.0, 'encoding_dim': 75.0, 'fnn_batch_size': 21.0, 'fnn_dropout_rate': 0.18052058159957218, 'fnn_learning_rate': 0.0014027677168425045, 'fnn_units': 344.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ff18723-a764-466c-ac61-13d0c2cd4255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55957615-f29d-4663-bcfb-d3e0a5359a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8aeddae8-9b10-4915-9762-86420f74c2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Final Model - Accuracy: 0.9833333333333334\n",
      "Final Model - F1 Score: 0.981439393939394\n",
      "Final Model - Sensitivity: 0.9882352941176471\n",
      "Final Model - Specificity: 0.980952380952381\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad0373-1ec8-461a-85f6-f480bb49e90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc20f3-6820-4005-ac74-d3980b62f235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29dcb6cb-2845-4cdb-8db7-4ba6c871e968",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder - ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc45d4f-5dff-44f1-a6b3-7291a6251643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24820\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f4055c6-117c-4e12-96e8-a9c28aa47777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.T.astype(np.float32)\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.int32)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066ef975-721b-417b-8ca7-067ee5418282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_features_relieff(X, y, num_features):\n",
    "    relief = ReliefF(n_neighbors=100, n_features_to_select=num_features, discrete_threshold=10)\n",
    "    relief.fit(X, y)\n",
    "    return relief.top_features_[:num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956b48e0-d168-4254-8105-81243506110d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relieff_indices = select_features_relieff(X_scaled, y, 1000)\n",
    "X_final = X_scaled[:, relieff_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ee257e-9608-4055-b114-bd9a7a6ecce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d622e9b2-80e0-466b-a759-3847f85d2249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be3d4b0-2335-4977-8136-59314ccb18a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "666ba9ab-75c7-40ed-8955-4aee45c99496",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FE2CB5D760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "  5%|██▍                                             | 1/20 [00:34<11:03, 34.94s/trial, best loss: -0.9774436090225563]WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001FE2FEB98A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.8849557522123894, F1 Score: 0.9090909090909091, Sensitivity: 0.9848484848484849, Specificity: 0.7446808510638298\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "100%|███████████████████████████████████████████████| 20/20 [09:22<00:00, 28.13s/trial, best loss: -0.9848484848484849]\n",
      "Best parameters found:  {'batch_size': 80.0, 'dropout_rate': 0.5545425184902806, 'epochs': 200.0, 'learning_rate': 0.07936396963935553, 'neurons1': 224.0, 'neurons2': 96.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541ea296-6de5-4fdf-bfdb-0241577cc45d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_100\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_100\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_500 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">224,224</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_200 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_501 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">21,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">21,728</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_503 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">225,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_504 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_500 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │         \u001b[38;5;34m224,224\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_200 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_501 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │          \u001b[38;5;34m21,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_201 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_502 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │          \u001b[38;5;34m21,728\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_503 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │         \u001b[38;5;34m225,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_504 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,001\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">493,553</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m493,553\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">493,553</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m493,553\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_final.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf983f4-6b2a-402e-b43a-93d13fca69d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_deep_autoencoder(\n",
    "            input_dim=X_final.shape[1],\n",
    "            neurons1=best_params['neurons1'],\n",
    "            neurons2=best_params['neurons2'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc784eb-f42c-44e8-af19-af97f797c646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.9826086956521738\n",
      "F1 Score: 0.9838969404186795\n",
      "Sensitivity: 0.9833333333333332\n",
      "Specificity: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_final, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc82f4-54ac-4917-917e-11aa799b20b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab97f502-2676-4ea2-8f2a-dcd164d711e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Relieff FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a389f03-5333-4cb4-b7c5-00ec5722eff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "164db804-1e57-4cda-9304-37b60ff608b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ba091c-aca0-40e5-8792-e53b670475e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fc77d4-e42a-43b3-980a-d97e1a97e5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 8, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 32, 256, 32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59edb613-993e-4b16-abaf-868c44b3c32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4fa2493-9c32-4fd2-8143-06b8ce81022d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 8.0850426456891e-05, Params: {'batch_size': 128, 'dropout_rate': 0.4229076024603866, 'epochs': 90, 'learning_rate': 0.0006266788825929285, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.69063401222229, Params: {'batch_size': 32, 'dropout_rate': 0.5280656760382225, 'epochs': 70, 'learning_rate': 5.005013840683832e-05, 'num_layers': 7, 'units': 160}\n",
      "Iteration - Loss: 0.0008068750612437725, Params: {'batch_size': 192, 'dropout_rate': 0.5203438200272664, 'epochs': 90, 'learning_rate': 0.0007562902089326593, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.0007114290492609143, Params: {'batch_size': 32, 'dropout_rate': 0.33335315066008897, 'epochs': 80, 'learning_rate': 0.000548490801326354, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.002953078830614686, Params: {'batch_size': 160, 'dropout_rate': 0.402560062225243, 'epochs': 60, 'learning_rate': 0.00044559338935534076, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 0.630496621131897, Params: {'batch_size': 256, 'dropout_rate': 0.3213418943118908, 'epochs': 110, 'learning_rate': 5.4999707141574293e-05, 'num_layers': 7, 'units': 128}\n",
      "Iteration - Loss: 0.6677016615867615, Params: {'batch_size': 192, 'dropout_rate': 0.6790790050141949, 'epochs': 60, 'learning_rate': 0.00012127832069688097, 'num_layers': 8, 'units': 224}\n",
      "Iteration - Loss: 0.39720964431762695, Params: {'batch_size': 192, 'dropout_rate': 0.39602907691786926, 'epochs': 100, 'learning_rate': 2.7634359701467535e-05, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 7.351741078309715e-05, Params: {'batch_size': 128, 'dropout_rate': 0.3408849545992085, 'epochs': 60, 'learning_rate': 0.0010881090929682044, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.677985429763794, Params: {'batch_size': 96, 'dropout_rate': 0.6704724825517837, 'epochs': 70, 'learning_rate': 6.426072947333608e-05, 'num_layers': 7, 'units': 224}\n",
      "Iteration - Loss: 0.6498950719833374, Params: {'batch_size': 160, 'dropout_rate': 0.5515563729178157, 'epochs': 130, 'learning_rate': 0.0003020323149939763, 'num_layers': 7, 'units': 192}\n",
      "Iteration - Loss: 0.0020588962361216545, Params: {'batch_size': 128, 'dropout_rate': 0.3424642912878745, 'epochs': 100, 'learning_rate': 0.0004071840674257955, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.6820900440216064, Params: {'batch_size': 64, 'dropout_rate': 0.5731624192271123, 'epochs': 150, 'learning_rate': 1.6249318693838927e-05, 'num_layers': 8, 'units': 128}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 160, 'dropout_rate': 0.30378751184342745, 'epochs': 70, 'learning_rate': 0.0027684256941077636, 'num_layers': 6, 'units': 224}\n",
      "Iteration - Loss: 3.478044133080338e-13, Params: {'batch_size': 224, 'dropout_rate': 0.4131351999551287, 'epochs': 70, 'learning_rate': 0.0016231495671868575, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.4056488275527954, Params: {'batch_size': 224, 'dropout_rate': 0.2038044337068922, 'epochs': 120, 'learning_rate': 3.4929502638641806e-05, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 0.3148689568042755, Params: {'batch_size': 128, 'dropout_rate': 0.30881466874037267, 'epochs': 100, 'learning_rate': 5.454476124262414e-05, 'num_layers': 7, 'units': 224}\n",
      "Iteration - Loss: 0.6317986845970154, Params: {'batch_size': 64, 'dropout_rate': 0.4262419920519691, 'epochs': 100, 'learning_rate': 0.002436049003188287, 'num_layers': 7, 'units': 160}\n",
      "Iteration - Loss: 0.004620232619345188, Params: {'batch_size': 128, 'dropout_rate': 0.6645628135425604, 'epochs': 120, 'learning_rate': 0.00075691382884554, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 5.49086180399172e-05, Params: {'batch_size': 32, 'dropout_rate': 0.5458665508714683, 'epochs': 140, 'learning_rate': 0.001480469387709158, 'num_layers': 3, 'units': 256}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 224, 'dropout_rate': 0.10775751076482443, 'epochs': 50, 'learning_rate': 0.0046116187108715375, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 256, 'dropout_rate': 0.10989080930948253, 'epochs': 50, 'learning_rate': 0.009147601924333972, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 9.424658492207527e-05, Params: {'batch_size': 256, 'dropout_rate': 0.10449479302430895, 'epochs': 50, 'learning_rate': 0.008457850761631715, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 224, 'dropout_rate': 0.1945438528504962, 'epochs': 80, 'learning_rate': 0.004170683767724017, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 256, 'dropout_rate': 0.18817862938459923, 'epochs': 80, 'learning_rate': 0.00888351540255459, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 256, 'dropout_rate': 0.17269246391066043, 'epochs': 50, 'learning_rate': 0.0070168546336686795, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 224, 'dropout_rate': 0.1969359973652605, 'epochs': 80, 'learning_rate': 0.00464465447520939, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 1.3898128615918251e-38, Params: {'batch_size': 96, 'dropout_rate': 0.25715454120322684, 'epochs': 90, 'learning_rate': 0.002645296583135951, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.002840049099177122, Params: {'batch_size': 160, 'dropout_rate': 0.25453251281618805, 'epochs': 60, 'learning_rate': 0.00020201100317404665, 'num_layers': 6, 'units': 224}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 192, 'dropout_rate': 0.14417724074909188, 'epochs': 110, 'learning_rate': 0.0057830410500119426, 'num_layers': 4, 'units': 160}\n",
      "100%|███████████████████████████████████████████████████████████████| 30/30 [02:50<00:00,  5.70s/trial, best loss: 0.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deff37d7-b79e-4189-8f39-d0418674b28b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 160, 'dropout_rate': 0.30378751184342745, 'epochs': 70, 'learning_rate': 0.0027684256941077636, 'num_layers': 6, 'units': 224}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5188bd74-193b-4bef-99dd-3691387887c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "          num_layers=best_params['num_layers'],\n",
    "          units=best_params['units'],\n",
    "          dropout_rate=best_params['dropout_rate'],\n",
    "          learning_rate=best_params['learning_rate'])\n",
    "        \n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2101e62d-5c72-4e1d-8967-9d064f35751f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.9888888888888889\n",
      "F1 Score: 0.992\n",
      "Sensitivity: 0.9846153846153847\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_train, y_train, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f627020-5c7f-4423-a86b-9722c04a79ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1484d2d9-6456-4993-8283-72ebc0ee4a03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CNN with ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc9a8e1-c364-463a-9ff5-1c46966b4ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e8bad8-9d76-4803-97e2-6c99c0d59705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ec42664-78ad-4b6f-9b0d-08a122be7cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c6ec92a-af58-4f50-a317-56a59e815216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4d6d1ee-dd33-4196-9d85-f4841e16612d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ed6c06a-2b92-442d-bb0f-2f238de2852d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.946271050521251, Sensitivity: 0.9001262626262626, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9576858500339371, Sensitivity: 0.9195707070707071, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9818399044205496, Sensitivity: 1.0, Specificity: 0.9361111111111112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9706527990409306, Sensitivity: 0.9626262626262626, Specificity: 0.9761904761904763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.9184323107803979, Sensitivity: 0.9640151515151515, Specificity: 0.8444444444444444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9807538091419407, Sensitivity: 0.9626262626262626, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9259259259259259, Sensitivity: 0.8787878787878788, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9089147286821705, Sensitivity: 0.8515151515151516, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9814953738434609, Sensitivity: 0.9640151515151515, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9655172413793104, Sensitivity: 0.9375, Specificity: 1.0  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.8811369509043927, Sensitivity: 0.8181818181818182, Specificity: 1.0     \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9089147286821705, Sensitivity: 0.8515151515151516, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9333333333333335, F1 Score: 0.9446290143964563, Sensitivity: 0.9848484848484849, Specificity: 0.8888888888888888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9585315869197184, Sensitivity: 0.9209595959595959, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.8938271604938272, Sensitivity: 0.8291666666666666, Specificity: 0.9583333333333334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8777777777777778, F1 Score: 0.8888888888888888, Sensitivity: 0.8333333333333334, Specificity: 1.0\n",
      "100%|██████████████████████████████████████████████████████████████| 20/20 [06:38<00:00, 19.95s/trial, best loss: -1.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cde8e536-4504-47bc-9e34-702085a71a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 32, 'dropout_rate': 0.20266794248030262, 'epochs': 50, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0011267748158477553}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b25a4b68-0efd-4f26-949b-829837465edb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m create_cnn_model(\n\u001b[0;32m      2\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m(X_selected\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m----> 3\u001b[0m     filters\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilters\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m     kernel_size\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      5\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      6\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'filters'"
     ]
    }
   ],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c39a8d94-952b-4898-907c-5383a60ddfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x200633cffd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aeba167-0c34-4085-a15a-69c1174cb953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29d3fb97-6ac6-4d45-b02a-69cc57769f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7391304347826086\n",
      "F1 Score: 0.8125\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.4\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee5ca7-29d5-4363-8f74-2f3de56646c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e87dc900-291d-4502-9f50-c1b332cc4a36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder & FNN with ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92d60092-f44b-4a0e-b8eb-dc31617ff270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20e19f8a-24c0-483e-af24-0eb74cf869ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba2d9bf0-d9c0-4857-8934-6a94dc4fa587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "945e67ff-b3a6-4c76-9072-edc7ad4cc3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40073cae-8b17-4a66-9966-9978ee97fc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50565aaf-ffe5-4f4e-b4c7-76827a8f2815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa5aa0b6-7b81-4d25-95af-7704ad5ebd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7986e81f-721c-496d-8784-3c1c0a4f24ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8f490b5-8ed1-4446-bf5c-23beb3ae6bb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [09:17<00:00, 27.89s/trial, best loss: -0.9888888888888889]\n",
      "Best parameters:  {'ae_activity_reg': 1.4210268616195605e-06, 'ae_batch_size': 31.0, 'ae_dropout_rate': 0.42890781138499945, 'ae_learning_rate': 0.00012586655521301725, 'autoencoder_units': 447.0, 'encoding_dim': 30.0, 'fnn_batch_size': 22.0, 'fnn_dropout_rate': 0.4063572003499122, 'fnn_learning_rate': 0.00032852800585104775, 'fnn_units': 71.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad9c4752-0dc8-42f4-a878-96e08e4eef10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3224c966-4139-4f6b-aa1e-a1065c6a9fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcf0565e-2a1f-4fca-beb1-cb24cf5551a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Final Model - Accuracy: 0.9444444444444444\n",
      "Final Model - F1 Score: 0.9523809523809523\n",
      "Final Model - Sensitivity: 0.923076923076923\n",
      "Final Model - Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56695fb0-e3c8-470c-882f-5275d9547a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24001dee-1f41-48bd-accd-2e042c7d9c30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10cf950f-6c88-4f68-89fa-2b236b01dc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24820\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c529d72-8355-4d8e-85e1-31f0ac0461a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.T.astype(np.float32)\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.int32)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43465a22-b374-4e58-89fb-beea1329bb5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_features_cmim(X, y, num_features):\n",
    "    mi_scores = mutual_info_classif(X, y)\n",
    "    top_indices = np.argsort(mi_scores)[-num_features:]\n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "655c246d-ce58-4c5d-9984-51fc68c926bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_features_svm_rfe(X, y, num_features):\n",
    "    svc = SVC(kernel=\"linear\", C=1)\n",
    "    rfe = RFE(estimator=svc, n_features_to_select=num_features, step=1)\n",
    "    rfe.fit(X, y)\n",
    "    return np.where(rfe.support_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb66dc88-2d06-431f-a3b2-4331c8f86a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final selected features: (113, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_features_cmim = 5000  # Number of features to keep after CMIM\n",
    "cmim_indices = select_features_cmim(X_scaled, y, num_features_cmim)\n",
    "X_cmim = X_scaled[:, cmim_indices]\n",
    "\n",
    "# Second step: Apply SVM-RFE on the reduced feature space from CMIM\n",
    "num_features_final = 1000  # Number of final features to select\n",
    "svm_rfe_indices = select_features_svm_rfe(X_cmim, y, num_features_final)\n",
    "X_final = X_cmim[:, svm_rfe_indices]\n",
    "\n",
    "print(f\"Shape of final selected features: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a05d861-42e8-4774-b999-8abd63be999d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7c98d42-9bca-4b4b-947d-1a37b75bbe75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67e0bda3-b4ec-405c-8be3-c29ed8d6f3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe8d2721-a2ae-4365-9c82-26f5a5941e1e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.8672566371681416, F1 Score: 0.8979591836734694, Sensitivity: 1.0, Specificity: 0.6808510638297872          \n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9203539823008849, F1 Score: 0.935251798561151, Sensitivity: 0.9848484848484849, Specificity: 0.8297872340425532\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "100%|███████████████████████████████████████████████| 20/20 [09:26<00:00, 28.34s/trial, best loss: -0.9848484848484849]\n",
      "Best parameters found:  {'batch_size': 48.0, 'dropout_rate': 0.5338211758649722, 'epochs': 150.0, 'learning_rate': 0.06083507515101849, 'neurons1': 96.0, 'neurons2': 48.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63144e91-295b-4ffc-af54-626cf6cd7cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_302\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_302\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1999 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">96,096</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_987 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2000 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_988 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2001 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2002 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">97,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2003 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1999 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │          \u001b[38;5;34m96,096\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_987 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2000 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │           \u001b[38;5;34m4,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_988 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2001 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │           \u001b[38;5;34m4,704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2002 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │          \u001b[38;5;34m97,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2003 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,001\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,457</span> (794.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m203,457\u001b[0m (794.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,457</span> (794.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m203,457\u001b[0m (794.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebc31290-af3f-44a0-a28d-603772df2485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_deep_autoencoder(\n",
    "            input_dim=X_final.shape[1],\n",
    "            neurons1=best_params['neurons1'],\n",
    "            neurons2=best_params['neurons2'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8023c46a-a404-48c0-ac4e-e7301a4951dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.9826086956521738\n",
      "F1 Score: 0.9838969404186795\n",
      "Sensitivity: 0.9833333333333332\n",
      "Specificity: 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_final, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962ff4f-eed8-47e2-9938-24d36ad09ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "449b24c0-4d55-494e-a208-b544d6187435",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "660fa82e-48a1-4cfe-a99f-d6cf13906069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10370d6e-8c0b-4fd4-a9ff-9223f730c35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdccc841-a6fe-44b6-bd0d-2820eccb8cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "562c7928-08e4-4749-92d4-6e9545fe95b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 8, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 32, 256, 32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93fa5a73-e2d6-4757-a156-7a4978e30cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01176065-daae-45da-8e0d-a8c4d0276676",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 1.0521740913391113, Params: {'batch_size': 160, 'dropout_rate': 0.3852916676477669, 'epochs': 120, 'learning_rate': 2.7345622662198396e-05, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.621030867099762, Params: {'batch_size': 192, 'dropout_rate': 0.48377339639821615, 'epochs': 100, 'learning_rate': 4.444841075604645e-05, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 3.863941586994188e-21, Params: {'batch_size': 256, 'dropout_rate': 0.1619060416218893, 'epochs': 80, 'learning_rate': 0.005205214265326374, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.12294194102287292, Params: {'batch_size': 64, 'dropout_rate': 0.3539364242059567, 'epochs': 80, 'learning_rate': 6.165281694801519e-05, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.6222122311592102, Params: {'batch_size': 192, 'dropout_rate': 0.4583492290562984, 'epochs': 60, 'learning_rate': 3.9650725921819016e-05, 'num_layers': 3, 'units': 64}\n",
      "Iteration - Loss: 0.16613104939460754, Params: {'batch_size': 224, 'dropout_rate': 0.21061098978807719, 'epochs': 110, 'learning_rate': 4.256014571775571e-05, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.6597477197647095, Params: {'batch_size': 128, 'dropout_rate': 0.6157194929510791, 'epochs': 130, 'learning_rate': 0.0007656822664750724, 'num_layers': 7, 'units': 160}\n",
      "Iteration - Loss: 0.698083221912384, Params: {'batch_size': 96, 'dropout_rate': 0.6664896137475291, 'epochs': 140, 'learning_rate': 0.00013581039485537858, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 0.5932242274284363, Params: {'batch_size': 96, 'dropout_rate': 0.672430092391531, 'epochs': 120, 'learning_rate': 0.0014125337062470928, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 0.7110635638237, Params: {'batch_size': 192, 'dropout_rate': 0.6441918920015913, 'epochs': 60, 'learning_rate': 5.10432827670141e-05, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 3.0795685808827384e-21, Params: {'batch_size': 96, 'dropout_rate': 0.49645754472785153, 'epochs': 60, 'learning_rate': 0.006891376236550236, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.666435956954956, Params: {'batch_size': 192, 'dropout_rate': 0.6626421700625311, 'epochs': 90, 'learning_rate': 0.0005667385732875606, 'num_layers': 6, 'units': 64}\n",
      "Iteration - Loss: 4.978421853806165e-16, Params: {'batch_size': 64, 'dropout_rate': 0.27111283669421116, 'epochs': 120, 'learning_rate': 0.0014182143173972653, 'num_layers': 8, 'units': 160}\n",
      "Iteration - Loss: 9.422271851633468e-09, Params: {'batch_size': 96, 'dropout_rate': 0.6485738870610831, 'epochs': 90, 'learning_rate': 0.00911449200824871, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.6625275611877441, Params: {'batch_size': 64, 'dropout_rate': 0.685669785495467, 'epochs': 130, 'learning_rate': 8.995276611865325e-05, 'num_layers': 7, 'units': 224}\n",
      "Iteration - Loss: 0.028492722660303116, Params: {'batch_size': 256, 'dropout_rate': 0.14874442205227772, 'epochs': 130, 'learning_rate': 4.018485464530918e-05, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 2.8151183073532593e-07, Params: {'batch_size': 128, 'dropout_rate': 0.24051404542932217, 'epochs': 60, 'learning_rate': 0.0003209004286416118, 'num_layers': 8, 'units': 224}\n",
      "Iteration - Loss: 0.6708343625068665, Params: {'batch_size': 224, 'dropout_rate': 0.22938867464197382, 'epochs': 70, 'learning_rate': 1.0772741330561272e-05, 'num_layers': 7, 'units': 224}\n",
      "Iteration - Loss: 1.1543279470060952e-06, Params: {'batch_size': 192, 'dropout_rate': 0.15847148405536388, 'epochs': 140, 'learning_rate': 0.00048031430669883725, 'num_layers': 6, 'units': 160}\n",
      "Iteration - Loss: 0.2692641317844391, Params: {'batch_size': 192, 'dropout_rate': 0.4751810269755663, 'epochs': 70, 'learning_rate': 6.169338498007375e-05, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 1.4226123489927887e-16, Params: {'batch_size': 32, 'dropout_rate': 0.553155013600376, 'epochs': 50, 'learning_rate': 0.00961064272164615, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 3.5434359890729183e-09, Params: {'batch_size': 32, 'dropout_rate': 0.3126968362069108, 'epochs': 80, 'learning_rate': 0.0033320981387085897, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 5.5088737391240095e-12, Params: {'batch_size': 128, 'dropout_rate': 0.5551160723675028, 'epochs': 50, 'learning_rate': 0.00494305204694149, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 1.96536720231677e-09, Params: {'batch_size': 256, 'dropout_rate': 0.43358633544992614, 'epochs': 80, 'learning_rate': 0.004105568115460357, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.6500877141952515, Params: {'batch_size': 160, 'dropout_rate': 0.5526558238061894, 'epochs': 70, 'learning_rate': 0.0020349702401958976, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 96, 'dropout_rate': 0.3289174154536916, 'epochs': 90, 'learning_rate': 0.007085531037987677, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 96, 'dropout_rate': 0.3051268507253517, 'epochs': 100, 'learning_rate': 0.008198332934994574, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 1.1859409559525084e-28, Params: {'batch_size': 64, 'dropout_rate': 0.3200364750045025, 'epochs': 100, 'learning_rate': 0.0022654521156702523, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.0, Params: {'batch_size': 160, 'dropout_rate': 0.3797325043138542, 'epochs': 110, 'learning_rate': 0.009801604052223207, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.6750213503837585, Params: {'batch_size': 160, 'dropout_rate': 0.39867496337030883, 'epochs': 110, 'learning_rate': 1.9616273986195436e-05, 'num_layers': 5, 'units': 192}\n",
      "100%|███████████████████████████████████████████████████████████████| 30/30 [03:04<00:00,  6.15s/trial, best loss: 0.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "def4b763-89f5-44e1-a30f-45d6b603dcb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 96, 'dropout_rate': 0.3289174154536916, 'epochs': 90, 'learning_rate': 0.007085531037987677, 'num_layers': 4, 'units': 96}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cd48e49-3f12-4a57-a130-f02100233865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "          num_layers=best_params['num_layers'],\n",
    "          units=best_params['units'],\n",
    "          dropout_rate=best_params['dropout_rate'],\n",
    "          learning_rate=best_params['learning_rate'])\n",
    "        \n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a612503-3323-4b81-a613-b35b34a083b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.9888888888888889\n",
      "F1 Score: 0.992\n",
      "Sensitivity: 0.9846153846153847\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_train, y_train, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144adae7-66d8-45f5-91e3-8a52b96085df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe55cde7-778f-4298-a729-8f645681a1e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad237d86-0628-4927-96b8-fcdea1141538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "305dd3a4-16cc-4db0-ada4-0b7a967b76e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbffe310-3a20-490f-972f-f570f9a48c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e279251-08ed-44c8-9a8b-970064f73ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ef70d4e-956a-4c96-9bf4-c018d5ac9b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae182a7f-fe65-4c9f-b603-e3cf2cd41b56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9807538091419407, Sensitivity: 0.9626262626262626, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9066666666666666, Sensitivity: 0.8541666666666666, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.989247311827957, Sensitivity: 1.0, Specificity: 0.9777777777777779\n",
      "100%|██████████████████████████████████████████████████████████████| 20/20 [08:46<00:00, 26.32s/trial, best loss: -1.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec9da072-25c7-4bab-9cab-2f6af4371a84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 32, 'dropout_rate': 0.37257321062634174, 'epochs': 40, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.0020061067297330927}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1739e3e3-28fe-4cda-818a-49b307728367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "526f77dc-a286-4784-bd2d-03f1dbc7f480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fe4e0ccc10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eff14448-9fb7-4316-a565-5aa7f93bb0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21c24c6a-b30f-4203-b454-2a14ea77f510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7391304347826086\n",
      "F1 Score: 0.8125\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.4\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14fa54-8be1-4a35-8856-99ebe97373de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c8669b8-3cbb-4016-95f8-551c8b559800",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder & FNN with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7f260fc-84e5-4a56-aae1-a481edc3c788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2390c597-6a1d-4c5b-baa1-755cb9196b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e76862c-d2b0-4be0-89e3-11b9250d3274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45c0a744-3ca9-4845-99bb-09b4a5a08265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa29a74f-eaeb-4db1-98ec-9cc609ba5856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb4beaca-3bba-4fa5-85dd-1973a158cb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3537c39a-6da9-4f0b-905e-242f8a48ee57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e9299eb8-2b2f-4b3c-841b-3755318eda80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5ab768f-6762-4228-b272-794fe5994e05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 9s/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [09:43<00:00, 29.16s/trial, best loss: -0.9888888888888889]\n",
      "Best parameters:  {'ae_activity_reg': 5.316782896619807e-06, 'ae_batch_size': 48.0, 'ae_dropout_rate': 0.2566373787070236, 'ae_learning_rate': 0.001094304602227039, 'autoencoder_units': 245.0, 'encoding_dim': 55.0, 'fnn_batch_size': 37.0, 'fnn_dropout_rate': 0.3296099974845966, 'fnn_learning_rate': 0.0015668601017060032, 'fnn_units': 395.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "257cec12-659e-42e0-b36f-93ec88aab6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4f08f08-7f87-4d4f-8298-6535e751b3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c68bec5c-cc2c-4e3c-a826-e8baaf377da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Final Model - Accuracy: 0.9888888888888889\n",
      "Final Model - F1 Score: 0.992\n",
      "Final Model - Sensitivity: 0.9846153846153847\n",
      "Final Model - Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba945c2-1184-4b2a-9f17-c99fe8947252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
