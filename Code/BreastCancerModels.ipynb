{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12a45c9-ce2d-4557-85b3-2087b59d7b79",
   "metadata": {},
   "source": [
    "## Data / Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da206e58-d4f8-4370-b70d-4883707a3663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Affy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, GRU, Layer, Add, GlobalAveragePooling1D, Conv1D, ReLU\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "import scipy.stats as stats\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from accelerate import DataLoaderConfiguration\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from boruta import BorutaPy\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6360aad-5901-4ed1-bd15-357ad9c18bf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AMGM and Cosine Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6aa5e7e-fb68-4adb-bae7-44b8dc4fe76d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_amgm(X):\n",
    "    \"\"\"\n",
    "    Calculate AMGM for each feature (row) in the dataset X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): The input data array with shape (n_features, n_samples)\n",
    "    \n",
    "    Returns:\n",
    "    amgm_values (numpy array): The AMGM values for each feature (row)\n",
    "    \"\"\"\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    exp_X = np.exp(X)\n",
    "    amgm_values = (np.mean(exp_X, axis=1)) / (np.exp(np.mean(X, axis=1)))\n",
    "    \n",
    "    return amgm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0148c4-73c5-46b0-9148-6f5298d9b052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_redundant_features(X, relevant_indices, threshold=0.9):\n",
    "    relevant_features = X[relevant_indices, :]\n",
    "    cos_sim_matrix = cosine_similarity(relevant_features)\n",
    "    \n",
    "    to_keep = []\n",
    "    to_drop = set()\n",
    "    for i in range(cos_sim_matrix.shape[0]):\n",
    "        if i not in to_drop:\n",
    "            to_keep.append(relevant_indices[i])\n",
    "            for j in range(i + 1, cos_sim_matrix.shape[0]):\n",
    "                if cos_sim_matrix[i, j] > threshold:\n",
    "                    to_drop.add(relevant_indices[j])\n",
    "    return to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6abdb-2769-4a0a-9d1b-a54d0c95c377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "141167e1-fef2-4eb2-be9d-d5791ca5db14",
   "metadata": {},
   "source": [
    "## Autoencoder Feature Selection with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b809e0f-975b-4209-b5b5-e93312ed64e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_feature_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)  # Encoder part\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)  # Decoder part\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3390d2-5b9e-48b5-9fff-da9ac0270b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_l1_feature_selection(X, y, alpha=0.01, target_features=100):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    model = SelectFromModel(lasso, prefit=True, max_features=target_features)\n",
    "    X_reduced = model.transform(X)\n",
    "    selected_indices = model.get_support(indices=True)\n",
    "    return X_reduced, selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237c56f-b40e-4fa6-8998-698b3496270d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initial Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce3ed9a-be53-4251-bf56-2687c2a66d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c6fbf8-0b41-4017-8e36-33eedfa0d11f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17419532-e1e9-4844-9e04-a51fc559e354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893f91d8-6d49-4f89-928d-4552771e81c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea511ea6-d5a3-412b-bc39-9f34239df71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef18d1e-edbe-44fe-b854-937332900c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "245db645-5770-45b3-bb08-bb111df555ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d089424c-190d-40bf-bb12-80d69f4bcd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 206406 232276 250927 321802 270758 200059 197015 126599 374361]\n",
      "Top AMGM values: [1.01338819 1.01339466 1.01339466 1.01339577 1.013396   1.01339625\n",
      " 1.01339625 1.01340604 1.01340653 1.01340799]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5bea093-e2e4-4c00-a391-191cfcfab5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef25354f-4d57-46a7-b9f2-af4194e6e163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "163b88f0-0c40-458f-890f-bc5f52818bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c7197c-7daa-4c1e-a969-bb60aada811c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02da388-b972-4fc5-9c52-b3f5b0dccf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d96341-c432-40ec-9040-59ff0f041c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2766c39e-f075-4997-8c6d-2978b2f7a770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6495cd26-fe85-4289-90fd-528e19da870b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m1,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m5,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,826</span> (50.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,826\u001b[0m (50.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,826</span> (50.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,826\u001b[0m (50.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bac03230-c128-4fc0-824d-1ab467fa2329",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9755 - loss: 0.0889 - val_accuracy: 1.0000 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9172 - loss: 0.1651 - val_accuracy: 1.0000 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9897 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9509 - loss: 0.0709 - val_accuracy: 1.0000 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9716 - loss: 0.0589 - val_accuracy: 1.0000 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9794 - loss: 0.0718 - val_accuracy: 1.0000 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9637 - loss: 0.0867 - val_accuracy: 1.0000 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9755 - loss: 0.0713 - val_accuracy: 1.0000 - val_loss: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9819 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 1.0000 - val_loss: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9716 - loss: 0.0681 - val_accuracy: 1.0000 - val_loss: 0.0038 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9406 - loss: 0.1279 - val_accuracy: 1.0000 - val_loss: 0.0038 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9833 - loss: 0.0338 - val_accuracy: 1.0000 - val_loss: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9936 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0041 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 0.0038 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0037 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9637 - loss: 0.0690 - val_accuracy: 1.0000 - val_loss: 0.0036 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9897 - loss: 0.0678 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.0280 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9819 - loss: 0.0488 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9897 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0667 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0033 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9755 - loss: 0.0548 - val_accuracy: 1.0000 - val_loss: 0.0032 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0029 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0027 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0023 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9534 - loss: 0.0525 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9936 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0444 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0020 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0559 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9897 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0015 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0010 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 8.6714e-04 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 7.7237e-04 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 6.8762e-04 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9509 - loss: 0.1557 - val_accuracy: 1.0000 - val_loss: 6.9896e-04 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9819 - loss: 0.0445 - val_accuracy: 1.0000 - val_loss: 7.7414e-04 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 8.2856e-04 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0384 - val_accuracy: 1.0000 - val_loss: 8.6535e-04 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 8.7464e-04 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 8.6791e-04 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8da8045-ec53-4b40-ab39-626062bb3c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11bfd350-a3c7-4b9b-8399-c808e2a56a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16de2677-6743-4500-a48a-90a9a916ac02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Specificity: 0.8\n",
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dfac1-b407-4aa4-9229-7e9482a4f06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f48a161-03be-47ff-b5db-7a285dad7a81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbf0a292-9c5b-47af-a690-4ae39a2a4e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff51dbd-8ce9-4c84-8fad-ee9991bb1d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f403c24-70a1-40c1-afff-da85991f6ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd7d8401-009e-44e2-9745-d1689858b101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc00fe7e-ec89-454f-8f80-e5bd5955b164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 206406 232276 250927 321802 270758 200059 197015 126599 374361]\n",
      "Top AMGM values: [1.01338819 1.01339466 1.01339466 1.01339577 1.013396   1.01339625\n",
      " 1.01339625 1.01340604 1.01340653 1.01340799]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ada8958-6c7c-4c22-9ec5-75ce678ad68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f037aca6-8a28-4299-9abe-c7e0a1d32f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36f7d6ea-d889-47a8-a3fe-f43dd026ac5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9df3b518-707d-45a2-a706-fd219ca7bcfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09365ca0-ff3c-4673-b65e-faf6e0bacd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29a2835c-e3d0-4862-9bfb-a5ee2c39fe1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "567ef149-0fc5-4175-9517-1e62921adad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52d09869-b0f4-444b-88f8-5c0147845870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000255BEC19A80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000255B7586020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9823008849557522, F1 Score: 0.9848484848484849, Sensitivity: 0.9848484848484849, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9469026548672567, F1 Score: 0.9558823529411765, Sensitivity: 0.9848484848484849, Specificity: 0.8936170212765957\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9774436090225563, Sensitivity: 0.9848484848484849, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9646017699115044, F1 Score: 0.9696969696969697, Sensitivity: 0.9696969696969697, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.8230088495575221, F1 Score: 0.8648648648648649, Sensitivity: 0.9696969696969697, Specificity: 0.6170212765957447\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9770992366412213, Sensitivity: 0.9696969696969697, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.9557522123893806, F1 Score: 0.9618320610687023, Sensitivity: 0.9545454545454546, Specificity: 0.9574468085106383\n",
      "Accuracy: 0.9734513274336283, F1 Score: 0.9770992366412213, Sensitivity: 0.9696969696969697, Specificity: 0.9787234042553191\n",
      "Accuracy: 0.584070796460177, F1 Score: 0.7374301675977654, Sensitivity: 1.0, Specificity: 0.0                          \n",
      "Accuracy: 0.7876106194690266, F1 Score: 0.8441558441558441, Sensitivity: 0.9848484848484849, Specificity: 0.5106382978723404\n",
      "100%|███████████████████████████████████████████████| 20/20 [05:13<00:00, 15.67s/trial, best loss: -0.9848484848484849]\n",
      "Best parameters found:  {'batch_size': 96.0, 'dropout_rate': 0.41702030432762127, 'epochs': 100.0, 'learning_rate': 0.00022142276787805485, 'neurons1': 224.0, 'neurons2': 16.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc020e49-565f-42d4-97df-b11ed396c57a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9823008849557522\n",
      "Best F1 Score: 0.9848484848484849\n",
      "Best Specificity: 0.9787234042553191\n",
      "Best Sensitivity: 0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "003e60bb-bad1-44fd-a53f-38ec7c881c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_101\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_101\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_505 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,624</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_202 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_506 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_203 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_507 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_508 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_509 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_505 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │          \u001b[38;5;34m22,624\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_202 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_506 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_203 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_507 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)                 │           \u001b[38;5;34m3,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_508 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m22,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_509 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,633</span> (205.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,633\u001b[0m (205.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,633</span> (205.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,633\u001b[0m (205.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c64866ee-6644-4d02-a3df-8c05cd284cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 224\n",
      "Neurons in second layer: 16\n",
      "Dropout rate: 0.41702030432762127\n",
      "Learning rate: 0.00022142276787805485\n",
      "Number of epochs: 100\n",
      "Batch size: 96\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a31047-89d7-4727-b879-2b5620c9663b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9edf826e-5645-40e6-b73a-6cd530bb4c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee1b4161-a682-4fc1-9d4b-725c50ab5226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7abb09ee-bfec-4b14-8cda-663acf8692f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\2250372466.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66308e8c-9655-48fc-8242-296d87442b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edb45a47-4d52-428a-849d-24dd95fc57dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7bba53e-2a04-42d8-8f27-911070fc3caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d291fc8-a7e6-4fb8-8c4f-282eda482880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 206406 232276 250927 321802 270758 200059 197015 126599 374361]\n",
      "Top AMGM values: [1.01338819 1.01339466 1.01339466 1.01339577 1.013396   1.01339625\n",
      " 1.01339625 1.01340604 1.01340653 1.01340799]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5811b927-f5ca-48de-acd1-002262bc700d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5591ce28-aee4-4b20-92e4-9bcdc943ecbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36c7b2eb-3baa-4482-a565-5549959197f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28bc6182-b7b1-4265-95ef-776119606d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88836856-b58c-4c0b-8541-4bb300226224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 128, 32)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55d069ba-c3b2-4af1-8229-1f800837b51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7a316be-4071-46c2-9506-fe20fbae23e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9833333333333334, Sensitivity: 0.9833333333333334, Specificity: 0.9666666666666667\n",
      "Iteration Results - Accuracy: 0.8000000000000002, F1 Score: 0.8248677248677249, Sensitivity: 0.8370098039215685, Specificity: 0.706959706959707\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.959349593495935, Sensitivity: 0.9666666666666667, Specificity: 0.9\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.959349593495935, Sensitivity: 0.9666666666666667, Specificity: 0.9\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9422799422799423, Sensitivity: 0.9666666666666667, Specificity: 0.8428571428571429\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9138813610358326, Sensitivity: 0.8791666666666668, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.9559139784946237, Sensitivity: 0.9458333333333333, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9622202848009299, Sensitivity: 0.9291666666666667, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.888888888888889, F1 Score: 0.8989898989898991, Sensitivity: 0.8666666666666667, Specificity: 0.942857142857143\n",
      "Iteration Results - Accuracy: 0.811111111111111, F1 Score: 0.8293638728421336, Sensitivity: 0.8178921568627451, Specificity: 0.7428571428571429\n",
      "Iteration Results - Accuracy: 0.9666666666666668, F1 Score: 0.9732323232323233, Sensitivity: 0.9637254901960784, Specificity: 0.9666666666666667\n",
      "Iteration Results - Accuracy: 0.9333333333333335, F1 Score: 0.9465122690929143, Sensitivity: 0.9291666666666667, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9636062861869314, Sensitivity: 0.9458333333333333, Specificity: 0.9666666666666667\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9325289089994971, Sensitivity: 0.9053921568627451, Specificity: 0.9410256410256411\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.959349593495935, Sensitivity: 0.9666666666666667, Specificity: 0.9\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9184668989547039, Sensitivity: 0.9, Specificity: 0.9076923076923077\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9345957799905168, Sensitivity: 0.9458333333333333, Specificity: 0.8992673992673993\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9343434343434344, Sensitivity: 0.9053921568627451, Specificity: 0.9333333333333332\n",
      "Iteration Results - Accuracy: 0.8777777777777779, F1 Score: 0.9052429052429053, Sensitivity: 0.9470588235294118, Specificity: 0.765934065934066\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9339177978883861, Sensitivity: 0.9274509803921568, Specificity: 0.919047619047619\n",
      "100%|███████████████████████████████████████████████| 20/20 [20:31<00:00, 61.56s/trial, best loss: -0.9833333333333334]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "befc9ed2-28d3-498f-be25-37d6055132c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 64, 'dropout_rate': 0.4611060983665523, 'learning_rate': 0.0019509237966000132, 'epochs': 30, 'batch_size': 16, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79732975-4f60-421d-b850-5c6721051b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecf61b-4ad0-484a-b914-bae72a8184dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee1fd4-568e-489a-981f-2a00be36f3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78644dd2-cedc-4523-bb1f-ff39235860c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86ac28d-7e6b-45d3-b6d7-e278a48e15a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gru with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a168d442-edad-4a9a-9581-dc56d13a40c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a4d33ac4-90ae-4397-b539-2c352b291154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cfc2d87-ed27-4fb1-be3e-9ab859a2685b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1443f452-b7eb-4fa9-9796-9cde97c8ac58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f7f87ea-63d2-4a53-b208-31380799625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f81e483d-6cd4-43e6-a13c-e937ee3e9b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "374ff74c-afcc-4315-8c7a-04a3bdc62bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5265cef0-ae34-4f25-b8cb-d69ac7f906c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65cb06c5-0c00-4e04-9e28-db275077fd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff6981f9-8a8d-48b8-880b-f424ba5171fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "619c1bd2-d8c0-40c8-9f5c-8bba010b9fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 64, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.4),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "247393ae-704a-401d-95b6-659cf5e1f68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a249b175-5cc9-47cd-a714-3103f43d70ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.9333333333333332, F1 Score: 0.9370587596394048, Sensitivity: 0.897348484848485, Specificity: 0.9583333333333334\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9777777777777779, Sensitivity: 0.9848484848484849, Specificity: 0.9166666666666666\n",
      "Iteration Results - Accuracy: 0.8666666666666667, F1 Score: 0.8889027812508683, Sensitivity: 0.9195707070707071, Specificity: 0.8222222222222223\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9807538091419407, Sensitivity: 0.9626262626262626, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.5777777777777777, F1 Score: 0.710516536603493, Sensitivity: 0.8939393939393939, Specificity: 0.25\n",
      "Iteration Results - Accuracy: 0.7666666666666666, F1 Score: 0.7844651374063139, Sensitivity: 0.7468434343434343, Specificity: 0.8202380952380953\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9814953738434609, Sensitivity: 0.9848484848484849, Specificity: 0.9777777777777779\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9814953738434609, Sensitivity: 0.9848484848484849, Specificity: 0.9777777777777779\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.7796296296296297, Sensitivity: 0.734469696969697, Specificity: 0.8234126984126985\n",
      "Iteration Results - Accuracy: 0.7888888888888889, F1 Score: 0.8142331635540465, Sensitivity: 0.7856060606060606, Specificity: 0.8234126984126985\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.6847576211894052, Sensitivity: 0.7595959595959596, Specificity: 0.35000000000000003\n",
      "Iteration Results - Accuracy: 0.7777777777777777, F1 Score: 0.7882547559966914, Sensitivity: 0.7189393939393939, Specificity: 0.8484126984126984\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.7936507936507938, Sensitivity: 0.7354797979797979, Specificity: 0.8261904761904763\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9807538091419407, Sensitivity: 0.9626262626262626, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.7888888888888889, F1 Score: 0.8119744744744745, Sensitivity: 0.7718434343434343, Specificity: 0.8456349206349206\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9684385382059801, Sensitivity: 0.9404040404040405, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9684385382059801, Sensitivity: 0.9404040404040405, Specificity: 1.0\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.7586324786324786, Sensitivity: 0.6758838383838383, Specificity: 0.8484126984126984\n",
      "Iteration Results - Accuracy: 0.7000000000000001, F1 Score: 0.7403616852146264, Sensitivity: 0.734469696969697, Specificity: 0.6896825396825396\n",
      "Iteration Results - Accuracy: 0.6888888888888888, F1 Score: 0.7116830065359477, Sensitivity: 0.6738636363636363, Specificity: 0.778968253968254\n",
      "100%|██████████████████████████████████████████████| 20/20 [37:00<00:00, 111.02s/trial, best loss: -0.9814953738434609]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bda36308-47d7-4d06-82ff-0447d70d7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 64, 'dropout_rate': 0.24366944217613146, 'epochs': 30, 'learning_rate': 0.005064932515917304, 'units': 32}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ff996c96-8e43-4ae2-9dc8-9925e866301a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "24efc4cb-db7b-4bc0-9afd-53baa2d407e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "11aa2678-d0b4-4965-a93c-c75ec3d55ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x258020f0c10>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b262a864-333a-498d-a803-6c07a706383d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9565217391304348\n",
      "F1 Score: 0.9629629629629629\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.9\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06800a32-61b6-4931-b62c-afec61a67b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262c8354-5ba7-4ac4-9079-3e25d09760d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aeb0ec03-8a3e-48b6-8bc7-91b41190c048",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09d2f2a6-ac7c-4975-83e6-8d5b08d0ba34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e7f41809-d793-45ba-856b-ea5bcdf5f706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "497a8be1-eb5c-42fd-91eb-780f12e9ec0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f6f1ee2f-40aa-4626-984c-8993ce4c63f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b100af3c-7374-410e-9631-c7530b0391de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8b2d7f4-a8ae-4109-8ee5-75987b511aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da8eb731-7c0d-46c0-a6a0-3a816e6c615b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c56fdc0d-e5b9-438c-891a-018552c3b356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9bdb0785-985a-4e25-ac62-6d6e31ceeae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "42368856-2c83-44fd-b2cf-508616f3b15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f2e4a19-1c24-453c-ba0f-68febb947e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b931c53c-870f-4269-ab67-85ba9af38560",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.888888888888889, F1 Score: 0.8852258852258852, Sensitivity: 0.7974747474747476, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9333333333333332, F1 Score: 0.9388915373342513, Sensitivity: 0.904419191919192, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9662835249042147, Sensitivity: 0.9626262626262626, Specificity: 0.9166666666666666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9592731516212387, Sensitivity: 0.9417929292929292, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9444444444444445, F1 Score: 0.9478036175710595, Sensitivity: 0.9209595959595959, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9250136836343733, Sensitivity: 0.8641414141414141, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.921063921063921, Sensitivity: 0.9696969696969697, Specificity: 0.8444444444444444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8333333333333334, F1 Score: 0.8795093795093796, Sensitivity: 0.9848484848484849, Specificity: 0.6678571428571428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.903359173126615, Sensitivity: 0.8320707070707071, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9444444444444443, F1 Score: 0.9495647721454173, Sensitivity: 0.904419191919192, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9666666666666667, F1 Score: 0.9700258397932817, Sensitivity: 0.9626262626262626, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.961887530706206, Sensitivity: 0.9848484848484849, Specificity: 0.9301587301587301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9599248296922717, Sensitivity: 0.9626262626262626, Specificity: 0.953968253968254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8333333333333334, F1 Score: 0.8057546318415882, Sensitivity: 0.6891414141414142, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9222222222222222, F1 Score: 0.9174603174603174, Sensitivity: 0.8585858585858586, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9666666666666668, F1 Score: 0.9747545582047685, Sensitivity: 1.0, Specificity: 0.8944444444444445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.914470284237726, Sensitivity: 0.9431818181818182, Specificity: 0.8666666666666667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                               \n",
      "\n",
      "Iteration Results - Accuracy: 0.8666666666666667, F1 Score: 0.8486583184257603, Sensitivity: 0.7487373737373737, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.9001763668430334, Sensitivity: 0.8391414141414142, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.811111111111111, F1 Score: 0.7774745579623629, Sensitivity: 0.6517676767676769, Specificity: 1.0\n",
      "100%|███████████████████████████████████████████████| 20/20 [03:24<00:00, 10.22s/trial, best loss: -0.9747545582047685]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ef58dcd0-f7fd-43b6-9b78-b0eab3b64b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.2032790134283512, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0017143166976029654}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "87bdba1e-e582-42a5-a228-e98fb0481031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b126deca-cc4c-488b-ae65-6b61c4be159e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25654cb6010>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "42e44a22-5ccb-421a-99cd-b6e78347ca89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f1d65d2b-8c64-451d-a481-eff4c4320a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.6956521739130435\n",
      "F1 Score: 0.631578947368421\n",
      "Sensitivity: 0.46153846153846156\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76a2b0-d926-41b4-a05e-4d8ccfab550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a1f12b-0239-4076-b343-97f676fd1a57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7f3daed1-2a50-4e75-80c0-acf1b6d99a17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9ec3b627-9922-4f7e-82a3-b1b6b5d87d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5ec688b5-f8aa-4cbe-a78c-3dd3da8a20b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2c66f65b-a551-44fa-814e-a7cf73e61a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "226dd57a-04c9-43ce-9f94-497d157bed7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d1748cc9-2523-4f9c-b6b2-852acab4a4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "610d99a1-4335-4916-9f53-b6e1fa9c1356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b13248d4-e7a6-4fdf-80b1-e4ff475f71a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "91d245e3-a33a-42d3-a0b9-2628124bf7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1bc43092-f848-4878-801b-07c8039524ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6aec00ff-f4e8-4df5-a689-38361740eecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d5d3f255-095f-413e-b7e0-6e3834fb7de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1ae3ced1-58c7-4e83-a0fa-40b50a9a21d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fa075f82-09d2-4100-b03b-55da83486a5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.31037270128792305, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.00037352916999596023, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.3751348555088043, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.31037270128792305, LR: 0.00037352916999596023, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.35730373258054515, 'epochs': 50, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.00025613864490188075, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.20881536602973938, Filters: 32, Blocks: 6, Kernel Size: 4, Dropout: 0.35730373258054515, LR: 0.00025613864490188075, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3799821189098427, 'epochs': 50, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.008773189297667355, 'num_blocks': 8}\n",
      "Iteration - Loss: 173.6019744873047, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.3799821189098427, LR: 0.008773189297667355, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.32978061771607314, 'epochs': 30, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00017535061304834658, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.4135962128639221, Filters: 64, Blocks: 10, Kernel Size: 5, Dropout: 0.32978061771607314, LR: 0.00017535061304834658, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3018146826479032, 'epochs': 50, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.0006849190870361559, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.14807578921318054, Filters: 96, Blocks: 6, Kernel Size: 5, Dropout: 0.3018146826479032, LR: 0.0006849190870361559, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.26005275528471944, 'epochs': 40, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00793621792676528, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.20922358334064484, Filters: 64, Blocks: 6, Kernel Size: 5, Dropout: 0.26005275528471944, LR: 0.00793621792676528, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.20964473958217855, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.005580223068233856, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.0, Filters: 96, Blocks: 8, Kernel Size: 3, Dropout: 0.20964473958217855, LR: 0.005580223068233856, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.23990510251650116, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0021468793171350213, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.06952241063117981, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.23990510251650116, LR: 0.0021468793171350213, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.33531929274909156, 'epochs': 30, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.005363840552645706, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.8202699422836304, Filters: 96, Blocks: 8, Kernel Size: 5, Dropout: 0.33531929274909156, LR: 0.005363840552645706, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3491629633577443, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0018837885415274444, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.3912091851234436, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.3491629633577443, LR: 0.0018837885415274444, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.25975286536150644, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0051492760112513926, 'num_blocks': 10}\n",
      "Iteration - Loss: 2.3088442269170173e-09, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.25975286536150644, LR: 0.0051492760112513926, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3549820555301195, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0011753334047197308, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.09516625851392746, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.3549820555301195, LR: 0.0011753334047197308, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.2944100432295431, 'epochs': 20, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.00011540814614640556, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5951907634735107, Filters: 128, Blocks: 4, Kernel Size: 4, Dropout: 0.2944100432295431, LR: 0.00011540814614640556, Batch Size: 16, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3523217486990742, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0015527046291433505, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.05597587302327156, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.3523217486990742, LR: 0.0015527046291433505, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.2607027444016171, 'epochs': 30, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00032059061674725883, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.2842404246330261, Filters: 64, Blocks: 8, Kernel Size: 5, Dropout: 0.2607027444016171, LR: 0.00032059061674725883, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.23847996266864377, 'epochs': 40, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.009093262195134214, 'num_blocks': 8}\n",
      "Iteration - Loss: 1852.28173828125, Filters: 128, Blocks: 8, Kernel Size: 3, Dropout: 0.23847996266864377, LR: 0.009093262195134214, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3868206779272819, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.004390058122280173, 'num_blocks': 10}\n",
      "Iteration - Loss: 1.9283108711242676, Filters: 96, Blocks: 10, Kernel Size: 4, Dropout: 0.3868206779272819, LR: 0.004390058122280173, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3243128462317999, 'epochs': 40, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.00011387381037846625, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5318446755409241, Filters: 128, Blocks: 4, Kernel Size: 5, Dropout: 0.3243128462317999, LR: 0.00011387381037846625, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.2878384684396895, 'epochs': 40, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0013436056000789777, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.048924170434474945, Filters: 32, Blocks: 10, Kernel Size: 5, Dropout: 0.2878384684396895, LR: 0.0013436056000789777, Batch Size: 16, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.36962845772495423, 'epochs': 40, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.005617149457962782, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.6437492370605469, Filters: 32, Blocks: 8, Kernel Size: 4, Dropout: 0.36962845772495423, LR: 0.005617149457962782, Batch Size: 48, Epochs: 40\n",
      "100%|███████████████████████████████████████████████████████████████| 20/20 [03:08<00:00,  9.43s/trial, best loss: 0.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b3a0271d-f34c-4867-a6b2-b87d39214b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 32, 'dropout_rate': 0.20964473958217855, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.005580223068233856, 'num_blocks': 8}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b67cbb88-0c96-41cc-b373-cd473b1e086e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bca11037-e959-41d4-bfa8-9d40dcb7c3e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step - accuracy: 0.7115 - loss: 0.5586 - val_accuracy: 0.7778 - val_loss: 3.3159\n",
      "Epoch 2/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.9837 - loss: 0.0503 - val_accuracy: 0.7778 - val_loss: 6.9253\n",
      "Epoch 3/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.9698 - loss: 0.1053 - val_accuracy: 0.7778 - val_loss: 44.6874\n",
      "Epoch 4/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401ms/step - accuracy: 0.9759 - loss: 0.1069 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 0.9659 - loss: 0.0571 - val_accuracy: 1.0000 - val_loss: 1.4000e-13\n",
      "Epoch 6/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407ms/step - accuracy: 0.9620 - loss: 0.0836 - val_accuracy: 0.8889 - val_loss: 8.9551\n",
      "Epoch 7/40\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402ms/step - accuracy: 0.9620 - loss: 0.1030 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7c372b93-0001-4950-a698-1757dd518b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9af1c749-bd04-488a-b83e-e6e128f904b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.8\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec522e-60da-4aa2-baab-95cf8c9ef727",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc46556-9fee-4eb7-9b1c-060458fe41b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f446b87-5fc1-4888-8b63-428acbd68f90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a4ba57bc-2747-4f78-8452-5aff003c0a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_7784\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d8e258bc-ccea-487f-83a4-2f2febc944b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "991d89b0-45e3-4239-be1d-d8e2b14bd1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "731c64b0-9e0b-4c9b-9d13-3009ba4d360c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d3736a7d-5667-4136-bc14-8ec9e1ff90cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "528f60b1-8cd6-4eb2-86fb-e51e043a3ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3692bc03-d6cc-4586-a4f2-fac483e90e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dd419ffe-5cdc-460f-b949-38af420fb921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "56859cc2-5cae-4a77-88e4-01a283f00aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2ad9bddc-79a2-4bd5-9d0b-92faa8901e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2421e504-5f0a-4fde-87a9-21479a4e7dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "eca11bf9-8d28-4c6e-af6c-ef4946b66690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7620f668-adc5-4711-89d4-a83e758fd564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 2.2435713287194403e-09, Params: {'batch_size': 48, 'dropout_rate': 0.31854078550198983, 'epochs': 140, 'learning_rate': 0.008033133981585448, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.4306385815143585, Params: {'batch_size': 80, 'dropout_rate': 0.3351302316018883, 'epochs': 150, 'learning_rate': 2.259784027477487e-05, 'num_layers': 2, 'units': 160}\n",
      "Iteration - Loss: 0.18210694193840027, Params: {'batch_size': 80, 'dropout_rate': 0.4546830304266659, 'epochs': 130, 'learning_rate': 0.00025494829795176, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 5.316756692026747e-13, Params: {'batch_size': 64, 'dropout_rate': 0.4495378097682131, 'epochs': 140, 'learning_rate': 0.007940987500121417, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.6140477657318115, Params: {'batch_size': 128, 'dropout_rate': 0.33699937996033413, 'epochs': 130, 'learning_rate': 1.6006728305236678e-05, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.5294206738471985, Params: {'batch_size': 32, 'dropout_rate': 0.3173002526883657, 'epochs': 110, 'learning_rate': 1.964471854835027e-05, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.06214509904384613, Params: {'batch_size': 112, 'dropout_rate': 0.3415463892223247, 'epochs': 80, 'learning_rate': 0.00013215777381234508, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 1.4271910910024221e-11, Params: {'batch_size': 32, 'dropout_rate': 0.3699940915975465, 'epochs': 90, 'learning_rate': 0.0036410615358710157, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 7.761429151287302e-05, Params: {'batch_size': 64, 'dropout_rate': 0.4622531732367767, 'epochs': 110, 'learning_rate': 0.0006024211959567376, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.011232979595661163, Params: {'batch_size': 48, 'dropout_rate': 0.4089874692983334, 'epochs': 100, 'learning_rate': 0.0002699432776298115, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 7.229532457131427e-07, Params: {'batch_size': 80, 'dropout_rate': 0.23177194304277685, 'epochs': 80, 'learning_rate': 0.0027642855618070575, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 2.639785101621328e-08, Params: {'batch_size': 80, 'dropout_rate': 0.13804739059225646, 'epochs': 50, 'learning_rate': 0.009429347565030216, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 4.676232038036687e-06, Params: {'batch_size': 96, 'dropout_rate': 0.26148538361946416, 'epochs': 150, 'learning_rate': 0.0036498019693278544, 'num_layers': 3, 'units': 64}\n",
      "Iteration - Loss: 0.661198079586029, Params: {'batch_size': 80, 'dropout_rate': 0.4157195215726497, 'epochs': 60, 'learning_rate': 3.4979191277597024e-05, 'num_layers': 6, 'units': 96}\n",
      "Iteration - Loss: 2.090415649825053e-14, Params: {'batch_size': 32, 'dropout_rate': 0.4080143837124294, 'epochs': 140, 'learning_rate': 0.007874567491008405, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 7.852228736737743e-05, Params: {'batch_size': 128, 'dropout_rate': 0.2612836459779724, 'epochs': 50, 'learning_rate': 0.00044296439273789186, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.008552579209208488, Params: {'batch_size': 80, 'dropout_rate': 0.15469856241493823, 'epochs': 80, 'learning_rate': 0.0004606907469062118, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 1.7638107863149344e-08, Params: {'batch_size': 96, 'dropout_rate': 0.1323397691294857, 'epochs': 120, 'learning_rate': 0.0019711578650289095, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 1.6584651429951691e-09, Params: {'batch_size': 16, 'dropout_rate': 0.2693816744854343, 'epochs': 120, 'learning_rate': 0.0023327188450887105, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.6474664807319641, Params: {'batch_size': 64, 'dropout_rate': 0.331804032674635, 'epochs': 60, 'learning_rate': 1.8983679125761128e-05, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 6.247771671041846e-05, Params: {'batch_size': 16, 'dropout_rate': 0.49925143821644874, 'epochs': 140, 'learning_rate': 0.0011088873621339275, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 2.1092489532748004e-07, Params: {'batch_size': 32, 'dropout_rate': 0.48459974863509814, 'epochs': 140, 'learning_rate': 0.008457222833072405, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 4.918559520794642e-17, Params: {'batch_size': 48, 'dropout_rate': 0.3992527399121967, 'epochs': 130, 'learning_rate': 0.0058037326290321725, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 4.4949763378099306e-07, Params: {'batch_size': 48, 'dropout_rate': 0.38589884941126973, 'epochs': 130, 'learning_rate': 0.001199659631825993, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 2.5654627311411105e-09, Params: {'batch_size': 32, 'dropout_rate': 0.4211911109960443, 'epochs': 120, 'learning_rate': 0.004819575678884368, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 2.8151578135293676e-06, Params: {'batch_size': 16, 'dropout_rate': 0.3851411435744241, 'epochs': 150, 'learning_rate': 0.0008598512130882854, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 0.007054438348859549, Params: {'batch_size': 48, 'dropout_rate': 0.20199589315685512, 'epochs': 110, 'learning_rate': 0.0001305427468268331, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 2.999244941293e-07, Params: {'batch_size': 32, 'dropout_rate': 0.4331033754807285, 'epochs': 100, 'learning_rate': 0.005282163491191069, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.17529533803462982, Params: {'batch_size': 48, 'dropout_rate': 0.37336559584680035, 'epochs': 140, 'learning_rate': 5.252131262634247e-05, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 9.578246681485325e-05, Params: {'batch_size': 64, 'dropout_rate': 0.2935630751698647, 'epochs': 130, 'learning_rate': 0.001742885987441811, 'num_layers': 3, 'units': 256}\n",
      "100%|█████████████████████████████████████████████| 30/30 [05:18<00:00, 10.63s/trial, best loss: 4.918559520794642e-17]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "53831951-56ac-4481-b508-9d7831b68973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.3992527399121967, 'epochs': 130, 'learning_rate': 0.0058037326290321725, 'num_layers': 4, 'units': 256}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5c173725-2d74-4a04-a930-7671e216d59c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7040 - loss: 0.6260 - val_accuracy: 0.4444 - val_loss: 0.6976\n",
      "Epoch 2/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7407 - loss: 0.4696 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 3/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9684 - loss: 0.1600 - val_accuracy: 1.0000 - val_loss: 4.3490e-04\n",
      "Epoch 4/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9614 - loss: 0.1005 - val_accuracy: 1.0000 - val_loss: 2.9878e-05\n",
      "Epoch 5/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 9.9178e-04 - val_accuracy: 1.0000 - val_loss: 2.5445e-06\n",
      "Epoch 6/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9848 - loss: 0.0328 - val_accuracy: 1.0000 - val_loss: 2.7564e-09\n",
      "Epoch 7/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.1240e-06 - val_accuracy: 1.0000 - val_loss: 2.0122e-10\n",
      "Epoch 8/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.1645e-06 - val_accuracy: 1.0000 - val_loss: 4.5493e-11\n",
      "Epoch 9/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 1.0964e-05 - val_accuracy: 1.0000 - val_loss: 1.2515e-11\n",
      "Epoch 10/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 3.5679e-04 - val_accuracy: 1.0000 - val_loss: 3.1651e-12\n",
      "Epoch 11/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 7.3089e-05 - val_accuracy: 1.0000 - val_loss: 8.4600e-13\n",
      "Epoch 12/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 1.9490e-14\n",
      "Epoch 13/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.7440e-06 - val_accuracy: 1.0000 - val_loss: 6.4943e-16\n",
      "Epoch 14/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.6943e-09 - val_accuracy: 1.0000 - val_loss: 3.1863e-17\n",
      "Epoch 15/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 7.5420e-12 - val_accuracy: 1.0000 - val_loss: 2.3022e-18\n",
      "Epoch 16/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 8.7433e-04 - val_accuracy: 1.0000 - val_loss: 4.3055e-20\n",
      "Epoch 17/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.4515e-09 - val_accuracy: 1.0000 - val_loss: 1.3682e-21\n",
      "Epoch 18/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 4.2551e-13 - val_accuracy: 1.0000 - val_loss: 2.9113e-21\n",
      "Epoch 19/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.8201e-04 - val_accuracy: 1.0000 - val_loss: 2.7765e-21\n",
      "Epoch 20/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.1985e-11 - val_accuracy: 1.0000 - val_loss: 1.1811e-21\n",
      "Epoch 21/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9848 - loss: 0.0491 - val_accuracy: 1.0000 - val_loss: 5.4420e-24\n",
      "Epoch 22/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.6020e-12 - val_accuracy: 1.0000 - val_loss: 2.1113e-24\n",
      "Epoch 23/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 6.1018e-20 - val_accuracy: 1.0000 - val_loss: 1.0928e-23\n",
      "Epoch 24/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.3092e-20 - val_accuracy: 1.0000 - val_loss: 4.0444e-23\n",
      "Epoch 25/130\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 9.1927e-15 - val_accuracy: 1.0000 - val_loss: 1.1725e-22\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d63b3479-84ba-4861-b92d-189d4265d709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9130434782608695\n",
      "F1 Score: 0.9285714285714286\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.8\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d233f5f-422c-472d-9094-565c1278f926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "931ad84d-dea6-43f3-88d8-c83d511ae585",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85965eff-1f3c-404e-a596-2916cca931d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_17656\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "675ff267-9781-40e8-a808-d0ccbb878c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values\n",
    "features_df = features_df.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "209c0de9-cf67-4ba1-aa27-22c04ce020e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(features_df.values)\n",
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fd50908-e409-4978-a8dd-b842072b5321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(features_df.values, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a95e3606-032b-443f-8fa9-fa4b2a9ec942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = features_df.iloc[selected_indices, :].T\n",
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3c945b8-afaa-4b7a-8b25-a6aba29983b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b733ffd2-d138-4d74-9bfb-9a9517e73187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d28dd37-f9a9-472e-a923-f747b743fe2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baf421f2-a734-4a5c-ac55-aa0efe6a66f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:11:29,630] A new study created in memory with name: no-name-0c4959d6-1cf7-423f-8970-b8baf311517b\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72b7975-b649-41c1-9131-296dd974387b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.683229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:12:45,686] Trial 0 finished with value: 0.683229386806488 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 4.1604152755614585e-05, 'max_length': 203}. Best is trial 0 with value: 0.683229386806488.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:14:53,207] Trial 1 finished with value: 0.6854141354560852 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 3.6294375127138535e-05, 'max_length': 213}. Best is trial 0 with value: 0.683229386806488.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 01:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.678223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685600</td>\n",
       "      <td>0.669782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:16:14,449] Trial 2 finished with value: 0.6697818040847778 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 3.644869073892524e-05, 'max_length': 130}. Best is trial 2 with value: 0.6697818040847778.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:17:21,736] Trial 3 finished with value: 0.697083592414856 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 2.5556506203339093e-05, 'max_length': 171}. Best is trial 2 with value: 0.6697818040847778.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:18:36,183] Trial 4 finished with value: 0.6884921193122864 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 2.459227543029821e-05, 'max_length': 144}. Best is trial 2 with value: 0.6697818040847778.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5acce8b-ad12-485d-aba2-96d749ee1e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 3.644869073892524e-05, 'max_length': 130}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3dadbdf-6e47-4664-952c-2c3ba361ca5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fa69388-3182-4319-90d1-9b4d377cbbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "325fd976-15de-4bb2-973e-b4c9affb9f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13749e07-89d8-4cc3-b8a8-78f626499140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2d85ac0-b68e-406b-888f-aa3b38a0e57f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c2f3776-f2a9-4cf5-8cfd-b201f654bff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 08:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.823956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.770024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.682706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=0.8175236119164361, metrics={'train_runtime': 556.6451, 'train_samples_per_second': 0.485, 'train_steps_per_second': 0.032, 'total_flos': 71039984947200.0, 'train_loss': 0.8175236119164361, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04e5fa7f-58d0-49fe-a402-3abcb32baba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6086956521739131\n",
      "F1 Score: 0.6896551724137931\n",
      "Sensitivity: 0.7692307692307693\n",
      "Specificity: 0.4\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc29e4-250b-4c76-bd8c-7b3cbcd474e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f2162-cd51-4f8c-b054-d02b8f8ddc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd18c9ae-87dc-411a-b93d-75f8b4669f1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469428c6-236f-4327-ba64-79846c6d00ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_18236\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d257e681-b55d-40d0-8357-e0f65fc69153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56adf49-36d7-4801-b934-f0d109901cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92fbae9-6632-448e-b186-a9c5f52dd7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 25000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092357b6-d5a4-46d1-822e-9ab2522853e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:2500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b438c74-720e-423b-9374-a66f0e071879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81149f7-3f5b-410f-9148-8b12d4a59bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_selected)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1120e131-d169-4561-97ca-6312547f7f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4913b4da-6552-43df-84e5-ac75d14c67e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c322be65-2231-4490-bbda-ce73cd5b3adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:27:32,544] A new study created in memory with name: no-name-e7479900-127f-46df-bb1a-00758c14fa92\n",
      "[I 2024-06-13 09:27:36,742] Trial 0 finished with value: 0.018329212442040443 and parameters: {'num_units': 112, 'learning_rate': 2.324076655633723e-05, 'dropout_rate': 0.1941926107252109, 'activity_regularizer': 2.5458229765663954e-06, 'batch_size': 61}. Best is trial 0 with value: 0.018329212442040443.\n",
      "[I 2024-06-13 09:27:40,827] Trial 1 finished with value: 0.01749476045370102 and parameters: {'num_units': 112, 'learning_rate': 3.4893657692315844e-05, 'dropout_rate': 0.29000063770019213, 'activity_regularizer': 4.7881467717073226e-05, 'batch_size': 32}. Best is trial 1 with value: 0.01749476045370102.\n",
      "[I 2024-06-13 09:27:44,575] Trial 2 finished with value: 0.022458521649241447 and parameters: {'num_units': 178, 'learning_rate': 6.341780337122132e-05, 'dropout_rate': 0.16703196151862273, 'activity_regularizer': 8.594642648683724e-05, 'batch_size': 36}. Best is trial 1 with value: 0.01749476045370102.\n",
      "[I 2024-06-13 09:27:48,321] Trial 3 finished with value: 0.006957738194614649 and parameters: {'num_units': 99, 'learning_rate': 0.0005578533049573826, 'dropout_rate': 0.13121692511141606, 'activity_regularizer': 6.034837285260937e-06, 'batch_size': 35}. Best is trial 3 with value: 0.006957738194614649.\n",
      "[I 2024-06-13 09:27:52,574] Trial 4 finished with value: 0.007018968928605318 and parameters: {'num_units': 186, 'learning_rate': 8.310189348740905e-05, 'dropout_rate': 0.22329366936691333, 'activity_regularizer': 1.06916044385609e-06, 'batch_size': 32}. Best is trial 3 with value: 0.006957738194614649.\n",
      "[I 2024-06-13 09:27:56,638] Trial 5 finished with value: 0.005919769871979952 and parameters: {'num_units': 171, 'learning_rate': 0.00040092004215526325, 'dropout_rate': 0.20106359875453161, 'activity_regularizer': 2.016681963257368e-06, 'batch_size': 40}. Best is trial 5 with value: 0.005919769871979952.\n",
      "[I 2024-06-13 09:28:00,866] Trial 6 finished with value: 0.0062631587497889996 and parameters: {'num_units': 250, 'learning_rate': 0.00041049175416618645, 'dropout_rate': 0.09556991506104003, 'activity_regularizer': 6.822090909389302e-06, 'batch_size': 25}. Best is trial 5 with value: 0.005919769871979952.\n",
      "[I 2024-06-13 09:28:01,711] Trial 7 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:02,678] Trial 8 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 09:28:03,565] Trial 9 pruned. Trial was pruned at epoch 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 57 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001B3BF5F7F60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:07,864] Trial 10 finished with value: 0.005469358526170254 and parameters: {'num_units': 226, 'learning_rate': 0.00021787719556293979, 'dropout_rate': 0.002877132869698512, 'activity_regularizer': 1.575959129952679e-07, 'batch_size': 17}. Best is trial 10 with value: 0.005469358526170254.\n",
      "[I 2024-06-13 09:28:12,252] Trial 11 finished with value: 0.002589585492387414 and parameters: {'num_units': 226, 'learning_rate': 0.0009717647835152961, 'dropout_rate': 0.017675088986647075, 'activity_regularizer': 1.0906208316333914e-07, 'batch_size': 18}. Best is trial 11 with value: 0.002589585492387414.\n",
      "[I 2024-06-13 09:28:16,568] Trial 12 finished with value: 0.002261972986161709 and parameters: {'num_units': 235, 'learning_rate': 0.0009966320967166595, 'dropout_rate': 0.003933775770542816, 'activity_regularizer': 1.0165428366352855e-07, 'batch_size': 16}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:20,885] Trial 13 finished with value: 0.0026993195060640574 and parameters: {'num_units': 221, 'learning_rate': 0.0009516421154177125, 'dropout_rate': 0.012384546678630759, 'activity_regularizer': 1.261017263335906e-07, 'batch_size': 18}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:24,630] Trial 14 finished with value: 0.0029267575591802597 and parameters: {'num_units': 254, 'learning_rate': 0.0009626721187079127, 'dropout_rate': 0.05725145581895992, 'activity_regularizer': 4.54827571593979e-07, 'batch_size': 23}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:25,809] Trial 15 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:30,265] Trial 16 finished with value: 0.003466432448476553 and parameters: {'num_units': 204, 'learning_rate': 0.0005602631155999077, 'dropout_rate': 0.049513862713834025, 'activity_regularizer': 7.611002857485981e-07, 'batch_size': 16}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:31,181] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:32,450] Trial 18 pruned. Trial was pruned at epoch 6.\n",
      "[I 2024-06-13 09:28:33,267] Trial 19 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 110 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001B3BC0162A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:34,402] Trial 20 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-13 09:28:35,267] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:39,740] Trial 22 finished with value: 0.004069867543876171 and parameters: {'num_units': 216, 'learning_rate': 0.0006352553411516211, 'dropout_rate': 0.02143856376482454, 'activity_regularizer': 2.133555270213689e-07, 'batch_size': 19}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:40,594] Trial 23 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:45,082] Trial 24 finished with value: 0.003570794127881527 and parameters: {'num_units': 195, 'learning_rate': 0.0009030068173266975, 'dropout_rate': 0.06317240140863548, 'activity_regularizer': 1.9287336687651815e-07, 'batch_size': 20}. Best is trial 12 with value: 0.002261972986161709.\n",
      "[I 2024-06-13 09:28:45,800] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:47,736] Trial 26 pruned. Trial was pruned at epoch 15.\n",
      "[I 2024-06-13 09:28:48,689] Trial 27 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:49,618] Trial 28 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:28:50,696] Trial 29 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 89 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001B3CA3ABE20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:51,611] Trial 30 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001B3CA608B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:28:55,977] Trial 31 finished with value: 0.002002999885007739 and parameters: {'num_units': 251, 'learning_rate': 0.0008454861971241022, 'dropout_rate': 0.04721719574807189, 'activity_regularizer': 4.287282108577875e-07, 'batch_size': 16}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:00,209] Trial 32 finished with value: 0.0027384196873754263 and parameters: {'num_units': 239, 'learning_rate': 0.0007408368987855757, 'dropout_rate': 0.037860079043161625, 'activity_regularizer': 2.732998170168504e-07, 'batch_size': 16}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:05,078] Trial 33 finished with value: 0.002385879633948207 and parameters: {'num_units': 233, 'learning_rate': 0.0007488479375379893, 'dropout_rate': 0.008611612854635624, 'activity_regularizer': 1.0297392736088668e-07, 'batch_size': 19}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:09,483] Trial 34 finished with value: 0.003759708721190691 and parameters: {'num_units': 234, 'learning_rate': 0.0005345930155641568, 'dropout_rate': 0.0399028286992375, 'activity_regularizer': 1.8350286739162144e-07, 'batch_size': 21}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:10,373] Trial 35 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:11,357] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:12,295] Trial 37 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:13,176] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:14,144] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:14,955] Trial 40 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:16,244] Trial 41 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:29:20,762] Trial 42 finished with value: 0.003451309399679303 and parameters: {'num_units': 187, 'learning_rate': 0.0007748011417460657, 'dropout_rate': 0.017967430432832124, 'activity_regularizer': 1.2938182960392938e-07, 'batch_size': 18}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:21,699] Trial 43 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:25,768] Trial 44 finished with value: 0.00266681588254869 and parameters: {'num_units': 232, 'learning_rate': 0.0009933791051073978, 'dropout_rate': 0.031021021723184185, 'activity_regularizer': 3.9497222726440353e-07, 'batch_size': 22}. Best is trial 31 with value: 0.002002999885007739.\n",
      "[I 2024-06-13 09:29:26,643] Trial 45 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:27,857] Trial 46 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:29:28,856] Trial 47 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-06-13 09:29:29,800] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:29:30,923] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e38e95-1a11-4068-baa6-5890e8bd708c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 251, 'learning_rate': 0.0008454861971241022, 'dropout_rate': 0.04721719574807189, 'activity_regularizer': 4.287282108577875e-07, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d23502f4-da0e-4e21-9232-984112075579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "236ad51a-9418-4a99-8976-482377f92a05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b3d2245490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "365521ac-069e-4f1a-9115-9d0dce43c32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026\n",
      "Validation Loss:  0.002561886329203844\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23958ad5-d695-45f1-943b-5f3afb4435b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "479b1c5c-160d-4331-9946-f5bb74cb14a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acd9e190-7e4e-4c6b-88c5-bd9666dcd9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e65ef7f1-5fe2-4f5b-8acb-21b555b07505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43478260869565216\n",
      "F1 Score: 0.0\n",
      "Sensitivity: 0.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79062be3-bbed-49c5-92ba-b59e74e66160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2c90a-1df8-4cae-9e8c-d873e0d0715b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384374b6-3e05-4cd6-a829-cc7e52af47c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "473a7acb-562d-483b-b048-ade110d42fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_18236\\2250372466.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cba6a14-c0f8-4305-bd7e-44a9d1f1e907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dafcefc-2558-47b6-bb61-ee7205082aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c152b9b-06a8-42b2-bae4-3b0f3d02f108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6245635f-3df2-4f2c-aa34-331482e483a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c72ea88e-8004-4b01-bac8-3dd9dc7fcc83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 232276 206406 321802 250927 200059 270758 197015 126599 374361]\n",
      "Top AMGM values: [1.0133886 1.0133953 1.0133953 1.0133955 1.0133955 1.0133958 1.0133958\n",
      " 1.013406  1.0134064 1.0134076]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "367dc8aa-60dc-4cfe-8231-96c7abba50ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c8872d5-d6e8-468d-91aa-a4a2805ce455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T\n",
    "X_selected = X_selected.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c0a844-56a4-4873-abce-1a535efdd4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7de03a53-3bee-48d4-8f34-1e2134e1d5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b407bb1d-811b-4234-8b1c-60d1c72f3b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa9c7f01-9cc8-40db-bbde-ac36a7ff89b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad6effb7-cba4-4a1e-bddf-217b3c7cf333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3311ef77-8fdc-47ce-a7d2-9202e8ebf90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97313402-80dc-452b-b0b2-1ef5cf1b84d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c270111-cacf-4051-8754-280381163233",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820ms/step                                              \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:49<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B39F738680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "  0%|                                                                           | 0/20 [00:53<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B39F738680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.9922480620155039, Sensitivity: 0.9848484848484849, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7361575622445188, Sensitivity: 1.0, Specificity: 0.0     \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 1.0, F1 Score: 1.0, Sensitivity: 1.0, Specificity: 1.0                                   \n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.8330985530985532, Sensitivity: 0.9431818181818182, Specificity: 0.48134920634920636\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9555555555555556, F1 Score: 0.9626262626262626, Sensitivity: 0.9626262626262626, Specificity: 0.9361111111111112\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.611111111111111, F1 Score: 0.74743961352657, Sensitivity: 1.0, Specificity: 0.08333333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.621431219873934, Sensitivity: 0.6013888888888889, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9818399044205496, Sensitivity: 1.0, Specificity: 0.9361111111111112\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5333333333333333, F1 Score: 0.6777777777777777, Sensitivity: 0.8579545454545454, Specificity: 0.16666666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6827697262479872, Sensitivity: 0.7142676767676769, Specificity: 0.4916666666666667\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9777777777777779, F1 Score: 0.9814953738434609, Sensitivity: 0.9848484848484849, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9888888888888889, F1 Score: 0.989247311827957, Sensitivity: 1.0, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5888888888888889, F1 Score: 0.7341062801932366, Sensitivity: 0.9848484848484849, Specificity: 0.041666666666666664\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8444444444444444, F1 Score: 0.7376906318082789, Sensitivity: 0.7111111111111111, Specificity: 0.9583333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.6336917562724015, Sensitivity: 0.6236111111111111, Specificity: 0.9777777777777779\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9487179487179488, Sensitivity: 1.0, Specificity: 0.6666666666666666\n",
      "100%|██████████████████████████████████████████████████████████████| 20/20 [27:04<00:00, 81.23s/trial, best loss: -1.0]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecc0d897-e0a9-4a70-8cc7-bee296181b86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 1.0195871483792565e-05, 'ae_batch_size': 57.0, 'ae_dropout_rate': 0.22040522447053654, 'ae_learning_rate': 0.0005596463584347175, 'autoencoder_units': 254.0, 'encoding_dim': 75.0, 'lstm_batch_size': 26.0, 'lstm_dropout_rate': 0.3930555875166011, 'lstm_learning_rate': 0.0002577472225551129, 'lstm_units': 448.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53c47b62-c60e-45c3-bbb2-d471164fe2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1981de2f-1c4e-4c9a-b1fc-88b90f4d1cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0ebd8d5-7bf5-468f-a0f1-40b59ef31247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d034db59-bdfb-4e3f-bf0e-66787dd300a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 1.2458 - val_loss: 1.2634\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2419 - val_loss: 1.2513\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2259 - val_loss: 1.2384\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2031 - val_loss: 1.2237\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1867 - val_loss: 1.2064\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1761 - val_loss: 1.1863\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1388 - val_loss: 1.1633\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1147 - val_loss: 1.1380\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0917 - val_loss: 1.1112\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.0678 - val_loss: 1.0847\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0335 - val_loss: 1.0605\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0128 - val_loss: 1.0400\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9881 - val_loss: 1.0241\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9757 - val_loss: 1.0125\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9610 - val_loss: 1.0047\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9594 - val_loss: 0.9993\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9535 - val_loss: 0.9954\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9465 - val_loss: 0.9923\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9517 - val_loss: 0.9897\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.9471 - val_loss: 0.9875\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.9422 - val_loss: 0.9857\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9411 - val_loss: 0.9844\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9364 - val_loss: 0.9836\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9338 - val_loss: 0.9831\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9364 - val_loss: 0.9828\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.9311 - val_loss: 0.9828\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.9298 - val_loss: 0.9829\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9320 - val_loss: 0.9831\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9257 - val_loss: 0.9834\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.9241 - val_loss: 0.9836\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9260 - val_loss: 0.9838\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.4643 - loss: 0.6533 - val_accuracy: 0.4348 - val_loss: 0.5640\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.3952 - loss: 0.6012 - val_accuracy: 0.4783 - val_loss: 0.5236\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5342 - loss: 0.5782 - val_accuracy: 0.7391 - val_loss: 0.4822\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7355 - loss: 0.4919 - val_accuracy: 0.9565 - val_loss: 0.3401\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9629 - loss: 0.3650 - val_accuracy: 0.9130 - val_loss: 0.2136\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9694 - loss: 0.1424 - val_accuracy: 0.9130 - val_loss: 0.3382\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9636 - loss: 0.1498 - val_accuracy: 0.9565 - val_loss: 0.3305\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9930 - loss: 0.0855 - val_accuracy: 0.9565 - val_loss: 0.3276\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9815 - loss: 0.1982 - val_accuracy: 0.9565 - val_loss: 0.3578\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9790 - loss: 0.0491 - val_accuracy: 0.9565 - val_loss: 0.4304\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d88809c9-3a2f-4fa4-8472-c8e49762b250",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841ms/step\n",
      "Accuracy: 0.9565217391304348\n",
      "F1 Score: 0.9629629629629629\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.9\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb61e1c-18c2-40b9-9dea-1c5f7a38c3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb9e367-ef47-43e0-9023-c57b6c4a7753",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96c22ef-2634-4d9c-996b-c3531a9a6da9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24364\\1386095298.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9904f453-10a6-48e1-bdfd-a4624f24e1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22aa7d9a-e2e8-4b15-8ae3-0ec8a36ae05d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8f4429-c1c6-45e5-a9bd-7a8361d668b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcdc331-9577-48ce-9d13-a4c1e981c82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [234413 232276 206406 321802 250927 200059 270758 197015 126599 374361]\n",
      "Top AMGM values: [1.0133886 1.0133953 1.0133953 1.0133955 1.0133955 1.0133958 1.0133958\n",
      " 1.013406  1.0134064 1.0134076]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdde22a-d4f0-4d7d-a542-c208f10f5c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d65c95-4595-43ba-bcda-10392d89274c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c19b7a9-1a48-4ff5-b034-6f45efa44b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0402c15-2d4e-426f-9e37-863d0aabf207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4bea096-8ff8-4e29-8512-1d3ee2a3c251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e801921-22c3-4d5c-aa0d-bd9e80649d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c0f2ca3-c819-496f-bc56-e82ba7ce09d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd2ce89-51d2-4bcc-b518-c5ad0c4f5f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed45844-29ae-496d-9ea6-3f1d379d6091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3858f82f-79cc-4c8a-83ef-0bb70ef6fbfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6e00ad8-8d39-47b9-9a12-13fcb191b474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdd3ee25-35a3-4449-a657-5c8a593a1ead",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "  0%|                                                                           | 0/20 [00:05<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026779B3CEA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:07<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026779D43A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [06:01<00:00, 18.08s/trial, best loss: -0.9777777777777779]\n",
      "Best parameters:  {'ae_activity_reg': 1.8202118459323217e-07, 'ae_batch_size': 17.0, 'ae_dropout_rate': 0.2420141854175809, 'ae_learning_rate': 0.0018549636606314222, 'autoencoder_units': 500.0, 'encoding_dim': 44.0, 'fnn_batch_size': 21.0, 'fnn_dropout_rate': 0.48756629348787384, 'fnn_learning_rate': 7.200630222661965e-05, 'fnn_units': 207.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de1631cc-88ce-4cc6-9f73-d0e8a942abd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bf66812-79a6-4e5b-8e78-99d8cbe9597f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bd76054-a938-47f5-beb1-09601c112c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Final Model - Accuracy: 0.9666666666666666\n",
      "Final Model - F1 Score: 0.9697777777777776\n",
      "Final Model - Sensitivity: 0.9623931623931623\n",
      "Final Model - Specificity: 0.9777777777777779\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6b818-e209-4adf-b56c-31d6232d19c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db65195-3912-4328-969a-0afd6ed27c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd995353-f86e-4908-87f4-f000f462e080",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9751422e-939d-4320-bbfc-f0d631c6365e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d65dfe44-ff41-463a-bf14-f1ae4e7ff368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739612b7-a37a-4b8f-b05f-227a7ec27af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedBreastCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b78d1f-d80e-42d0-8b94-9fb1c47cb990",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_17932\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f579b55-f179-4b4a-9385-2ca19244e17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4898bc7c-7c8f-4324-b63a-25f8578d496c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c77235c5-cc9f-4178-8195-89c66c596356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90159326-c50b-4b63-80a3-07f8528a74b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4d13ddb-4c79-4c8b-b882-ff02a28e9ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726b84b3-59bc-4c3b-a004-42977c76345c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - loss: 1.2502 - val_loss: 1.2402\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 1.2422 - val_loss: 1.2454\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 1.1462 - val_loss: 1.2418\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9945 - val_loss: 1.2343\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9888 - val_loss: 1.2253\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9859 - val_loss: 1.2174\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9830 - val_loss: 1.2110\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9795 - val_loss: 1.2052\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9759 - val_loss: 1.2000\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9730 - val_loss: 1.1960\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9701 - val_loss: 1.1931\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9675 - val_loss: 1.1907\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9652 - val_loss: 1.1889\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9631 - val_loss: 1.1876\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9612 - val_loss: 1.1871\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9595 - val_loss: 1.1871\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9580 - val_loss: 1.1876\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9567 - val_loss: 1.1883\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9555 - val_loss: 1.1893\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9544 - val_loss: 1.1904\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9535 - val_loss: 1.1918\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9526 - val_loss: 1.1933\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9518 - val_loss: 1.1948\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9512 - val_loss: 1.1964\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9505 - val_loss: 1.1980\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9500 - val_loss: 1.1995\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9495 - val_loss: 1.2011\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9490 - val_loss: 1.2026\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9487 - val_loss: 1.2041\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9483 - val_loss: 1.2056\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9479 - val_loss: 1.2070\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9477 - val_loss: 1.2083\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9474 - val_loss: 1.2096\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9471 - val_loss: 1.2108\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9469 - val_loss: 1.2119\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9467 - val_loss: 1.2130\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9465 - val_loss: 1.2140\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9464 - val_loss: 1.2150\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9462 - val_loss: 1.2159\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9460 - val_loss: 1.2168\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9459 - val_loss: 1.2176\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9458 - val_loss: 1.2183\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9457 - val_loss: 1.2190\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9456 - val_loss: 1.2197\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9454 - val_loss: 1.2203\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9454 - val_loss: 1.2209\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9453 - val_loss: 1.2215\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9452 - val_loss: 1.2220\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9451 - val_loss: 1.2225\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9450 - val_loss: 1.2230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2785db81e90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder, encoder = create_feature_autoencoder(input_dim, encoding_dim)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32de6943-cfa7-4373-a5e3-49fd4f48ee08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step\n",
      "Shape of encoded features: (225, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = encoder.predict(X_scaled)\n",
    "print(f\"Shape of encoded features: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a2c686d-409c-4c83-9b75-66638b39b191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after L1-based Feature Selection: (225, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.342e-02, tolerance: 5.504e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "target_features = 200  # Target number of features\n",
    "X_final, selected_indices_l1 = apply_l1_feature_selection(X_encoded, y, alpha=0.005, target_features=target_features)\n",
    "print(f\"Shape after L1-based Feature Selection: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d62c0a40-4acb-4dd2-aa20-61058f417098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498015d-3a73-4783-946f-1c4804eb80a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d96ae413-6722-4112-adbc-648a11927b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "114478e2-36a6-4bc6-8db9-6c04bc7f4241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "36fbcdf4-8b98-4aad-b7eb-84843c6ae63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a5268b00-c73e-4999-b9a0-fcd1afdb3a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1900 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_630 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1901 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_631 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1902 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1903 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1904 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1900 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_630 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1901 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_631 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1902 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m5,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1903 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m20,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1904 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m201\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a9f95545-f267-437c-8b94-c6b1d7f47bad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.4865 - loss: 0.7893 - val_accuracy: 0.5652 - val_loss: 0.6867 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5190 - loss: 0.7347 - val_accuracy: 0.4783 - val_loss: 0.6860 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5110 - loss: 0.6980 - val_accuracy: 0.5652 - val_loss: 0.6506 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6219 - loss: 0.6627 - val_accuracy: 0.5652 - val_loss: 0.6395 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5927 - loss: 0.6808 - val_accuracy: 0.8261 - val_loss: 0.6327 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6527 - loss: 0.6332 - val_accuracy: 0.8261 - val_loss: 0.6208 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6910 - loss: 0.6033 - val_accuracy: 0.6087 - val_loss: 0.6040 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5920 - loss: 0.6547 - val_accuracy: 0.6957 - val_loss: 0.5885 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6548 - loss: 0.6260 - val_accuracy: 0.7391 - val_loss: 0.5667 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6659 - loss: 0.5884 - val_accuracy: 0.7391 - val_loss: 0.5492 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7081 - loss: 0.5155 - val_accuracy: 0.7826 - val_loss: 0.5299 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7157 - loss: 0.5390 - val_accuracy: 0.8261 - val_loss: 0.4964 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: 0.6126 - val_accuracy: 0.8261 - val_loss: 0.4960 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7109 - loss: 0.6045 - val_accuracy: 0.7826 - val_loss: 0.4817 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7501 - loss: 0.4748 - val_accuracy: 0.7826 - val_loss: 0.4634 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7384 - loss: 0.5228 - val_accuracy: 0.7826 - val_loss: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7460 - loss: 0.5172 - val_accuracy: 0.7826 - val_loss: 0.4124 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.4136 - val_accuracy: 0.8261 - val_loss: 0.3841 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7395 - loss: 0.4784 - val_accuracy: 0.8261 - val_loss: 0.3731 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7880 - loss: 0.4375 - val_accuracy: 0.8696 - val_loss: 0.3507 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8510 - loss: 0.3858 - val_accuracy: 0.8696 - val_loss: 0.3487 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8248 - loss: 0.4460 - val_accuracy: 0.9130 - val_loss: 0.3541 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7715 - loss: 0.4219 - val_accuracy: 0.9130 - val_loss: 0.3497 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8543 - loss: 0.2947 - val_accuracy: 0.7826 - val_loss: 0.3491 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8848 - loss: 0.2724 - val_accuracy: 0.7826 - val_loss: 0.3628 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8569 - loss: 0.3758 - val_accuracy: 0.8261 - val_loss: 0.2925 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8282 - loss: 0.3174 - val_accuracy: 0.8696 - val_loss: 0.3060 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8623 - loss: 0.3671 - val_accuracy: 0.8261 - val_loss: 0.2968 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8790 - loss: 0.3040 - val_accuracy: 0.8696 - val_loss: 0.2865 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8518 - loss: 0.3022 - val_accuracy: 0.9130 - val_loss: 0.2862 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9337 - loss: 0.1840 - val_accuracy: 0.9130 - val_loss: 0.2830 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9187 - loss: 0.2275 - val_accuracy: 0.8696 - val_loss: 0.2825 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9073 - loss: 0.2693 - val_accuracy: 0.8696 - val_loss: 0.2975 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8777 - loss: 0.2478 - val_accuracy: 0.9130 - val_loss: 0.2899 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9057 - loss: 0.2332 - val_accuracy: 0.9130 - val_loss: 0.2389 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9331 - loss: 0.1807 - val_accuracy: 0.9130 - val_loss: 0.2329 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8832 - loss: 0.2510 - val_accuracy: 0.8696 - val_loss: 0.2705 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.2558 - val_accuracy: 0.8696 - val_loss: 0.2775 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2362 - val_accuracy: 0.9130 - val_loss: 0.2059 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8814 - loss: 0.2729 - val_accuracy: 0.9130 - val_loss: 0.1885 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9195 - loss: 0.1665 - val_accuracy: 0.8696 - val_loss: 0.2232 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8737 - loss: 0.2996 - val_accuracy: 0.8696 - val_loss: 0.2555 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9107 - loss: 0.1865 - val_accuracy: 0.8261 - val_loss: 0.2636 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1434 - val_accuracy: 0.8261 - val_loss: 0.2347 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8890 - loss: 0.2981 - val_accuracy: 0.8261 - val_loss: 0.2370 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.1629 - val_accuracy: 0.8261 - val_loss: 0.2335 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9389 - loss: 0.1567 - val_accuracy: 0.8261 - val_loss: 0.2895 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.2441 - val_accuracy: 0.8261 - val_loss: 0.2845 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9087 - loss: 0.1792 - val_accuracy: 0.8261 - val_loss: 0.2996 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9130 - loss: 0.2048 - val_accuracy: 0.8261 - val_loss: 0.3155 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4d0800c4-99b7-4439-a9f8-795fc589b7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "98d01933-b58c-498d-91e8-6a54823cfa5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "098fbf38-8f46-4103-ad63-d7769c972577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.8888888888888888\n",
      "Specificity: 0.9375\n",
      "Sensitivity: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2183782-e3ec-4daf-ad43-73dceb67c4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d69bd-2c74-4085-903e-a048c2eea45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68d99a9-058c-4fa2-9057-0d0edbaa056f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fc4c8acb-e6a8-43d5-beaa-b878fe2c9bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "08a28a4e-477b-4abe-8270-14f6487c9452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe234c4a-c882-47e5-857c-027175714b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4c06200b-a7e3-49db-b659-afab5ea3e6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a39aa1c5-a9d5-4952-87d0-763a2c38b9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9377777777777778, F1 Score: 0.9292929292929293, Sensitivity: 0.9583333333333334, Specificity: 0.9224806201550387\n",
      "Accuracy: 0.7644444444444445, F1 Score: 0.6293706293706294, Sensitivity: 0.46875, Specificity: 0.9844961240310077      \n",
      "Accuracy: 0.7288888888888889, F1 Score: 0.5343511450381679, Sensitivity: 0.3645833333333333, Specificity: 1.0          \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.64, F1 Score: 0.2702702702702703, Sensitivity: 0.15625, Specificity: 1.0                                   \n",
      "Accuracy: 0.9155555555555556, F1 Score: 0.8961748633879781, Sensitivity: 0.8541666666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9278350515463918, Sensitivity: 0.9375, Specificity: 0.937984496124031        \n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.93, Sensitivity: 0.96875, Specificity: 0.9147286821705426                    \n",
      "Accuracy: 0.9333333333333333, F1 Score: 0.9230769230769231, Sensitivity: 0.9375, Specificity: 0.9302325581395349       \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9484536082474226, Sensitivity: 0.9583333333333334, Specificity: 0.9534883720930233\n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.8311111111111111, F1 Score: 0.7682926829268293, Sensitivity: 0.65625, Specificity: 0.9612403100775194      \n",
      "Accuracy: 0.9466666666666667, F1 Score: 0.9381443298969072, Sensitivity: 0.9479166666666666, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.9422222222222222, F1 Score: 0.9346733668341709, Sensitivity: 0.96875, Specificity: 0.9224806201550387      \n",
      "Accuracy: 0.9288888888888889, F1 Score: 0.9191919191919192, Sensitivity: 0.9479166666666666, Specificity: 0.9147286821705426\n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.9511111111111111, F1 Score: 0.9430051813471503, Sensitivity: 0.9479166666666666, Specificity: 0.9534883720930233\n",
      "Accuracy: 0.76, F1 Score: 0.6086956521739131, Sensitivity: 0.4375, Specificity: 1.0                                    \n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9270833333333334, Sensitivity: 0.9270833333333334, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.8711111111111111, F1 Score: 0.8342857142857143, Sensitivity: 0.7604166666666666, Specificity: 0.9534883720930233\n",
      "100%|███████████████████████████████████████████████| 20/20 [07:14<00:00, 21.71s/trial, best loss: -0.9484536082474226]\n",
      "Best parameters found:  {'batch_size': 48.0, 'dropout_rate': 0.6551201949996381, 'epochs': 200.0, 'learning_rate': 0.000753710320272019, 'neurons1': 128.0, 'neurons2': 80.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2ed47d67-7d4b-4165-b343-a0e43b1d3880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9555555555555556\n",
      "Best F1 Score: 0.9484536082474226\n",
      "Best Specificity: 0.9534883720930233\n",
      "Best Sensitivity: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "317e3b24-cbdd-4c55-b79c-822f88734aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_101\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_101\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2405 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_832 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2406 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_833 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2407 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2408 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2409 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2405 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m12,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_832 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2406 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │          \u001b[38;5;34m10,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_833 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2407 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m10,368\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2408 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m12,900\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2409 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,617</span> (182.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,617\u001b[0m (182.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,617</span> (182.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,617\u001b[0m (182.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b13c4101-9d63-4f92-8259-00e5639ed8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 128\n",
      "Neurons in second layer: 80\n",
      "Dropout rate: 0.6551201949996381\n",
      "Learning rate: 0.000753710320272019\n",
      "Number of epochs: 200\n",
      "Batch size: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56a1b4-393f-42c8-9fae-c3760589a57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca38d758-8b35-4d60-b34c-08c51b64d6fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d6e0f258-a4a8-48a0-b7d5-b77a02bef7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc81d1f0-b4c9-49b1-8253-b49049e92624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4281abd4-fdd6-4d48-a57a-03f79c6081e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 64)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "08f48861-d9cf-4400-adb0-af4291f34cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4bb0dabd-6272-40be-9205-9fb91c510e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.7388888888888889, F1 Score: 0.6499582289055973, Sensitivity: 0.633140756302521, Specificity: 0.8492524916943521\n",
      "Iteration Results - Accuracy: 0.6388888888888888, F1 Score: 0.543998513563731, Sensitivity: 0.5388655462184874, Specificity: 0.7625622923588039\n",
      "Iteration Results - Accuracy: 0.6944444444444443, F1 Score: 0.6346320346320345, Sensitivity: 0.6447829131652661, Specificity: 0.7551910299003323\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.7342825361512793, Sensitivity: 0.841999299719888, Specificity: 0.725359911406423\n",
      "Iteration Results - Accuracy: 0.7333333333333334, F1 Score: 0.6806557639890972, Sensitivity: 0.7057948179271708, Specificity: 0.7798657253599114\n",
      "Iteration Results - Accuracy: 0.6777777777777777, F1 Score: 0.6371338524286244, Sensitivity: 0.6745448179271708, Specificity: 0.6814091915836102\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.3874840845429081, Sensitivity: 0.48161764705882354, Specificity: 0.6785368217054263\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.43297558922558926, Sensitivity: 0.5535714285714285, Specificity: 0.6424418604651163\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.5054798182304197, Sensitivity: 0.5026260504201681, Specificity: 0.7286475636766334\n",
      "Iteration Results - Accuracy: 0.638888888888889, F1 Score: 0.5414353461077765, Sensitivity: 0.5269607843137255, Specificity: 0.7566791251384274\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.6844401461422738, Sensitivity: 0.7462359943977591, Specificity: 0.7345999446290143\n",
      "Iteration Results - Accuracy: 0.6388888888888888, F1 Score: 0.5361811391223156, Sensitivity: 0.539390756302521, Specificity: 0.779485049833887\n",
      "Iteration Results - Accuracy: 0.6555555555555556, F1 Score: 0.5899415204678363, Sensitivity: 0.604341736694678, Specificity: 0.7271594684385382\n",
      "Iteration Results - Accuracy: 0.7000000000000001, F1 Score: 0.6456741326306544, Sensitivity: 0.6735819327731093, Specificity: 0.7634966777408638\n",
      "Iteration Results - Accuracy: 0.5666666666666668, F1 Score: 0.5519728116710875, Sensitivity: 0.6815476190476191, Specificity: 0.5605966223698782\n",
      "Iteration Results - Accuracy: 0.7388888888888889, F1 Score: 0.6762626262626262, Sensitivity: 0.6899509803921569, Specificity: 0.8206672203765226\n",
      "Iteration Results - Accuracy: 0.6833333333333332, F1 Score: 0.5944404752454288, Sensitivity: 0.5624124649859944, Specificity: 0.7900401439645627\n",
      "Iteration Results - Accuracy: 0.5777777777777778, F1 Score: 0.4823688094874536, Sensitivity: 0.5997023809523809, Specificity: 0.6630329457364341\n",
      "Iteration Results - Accuracy: 0.5944444444444444, F1 Score: 0.5561881757533932, Sensitivity: 0.6607142857142857, Specificity: 0.6368009413067552\n",
      "Iteration Results - Accuracy: 0.6055555555555556, F1 Score: 0.5267724867724868, Sensitivity: 0.5599614845938375, Specificity: 0.6961517165005536\n",
      "100%|███████████████████████████████████████████████| 20/20 [27:53<00:00, 83.66s/trial, best loss: -0.7342825361512793]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e3a6aa7a-bf3c-48c6-862e-593f61bb6320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 192, 'dropout_rate': 0.10789176927584963, 'learning_rate': 0.0005431554477143651, 'epochs': 30, 'batch_size': 64, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4f82fa55-d7a6-4c0a-bb23-a31bfa93a1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7777777777777778\n",
      "F1 Score: 0.6875\n",
      "Sensitivity: 0.5789473684210527\n",
      "Specificity: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bac44-5189-4b34-9928-61c5a8a1d983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f0f9594-c68b-4782-86f9-44d9e5e9e711",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GRU with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b8baf37-7eef-4264-a74f-dfafa1ee6823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e47809-6ee9-43d7-a3ce-0b0559ba6bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f08203-cbc0-4019-89be-5ddf53760212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfe14ad5-c286-4c58-bb67-dd049622f568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 128, 64)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df17e7f3-6bef-40f5-a0cc-250632809af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a2384ae-4905-4740-bc0e-bd39841c65ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6539624183006536, Sensitivity: 0.7574548907882241, Specificity: 0.5292929292929293\n",
      "Iteration Results - Accuracy: 0.6000000000000001, F1 Score: 0.6280188114659466, Sensitivity: 0.7535612535612536, Specificity: 0.4666666666666666\n",
      "Iteration Results - Accuracy: 0.5944444444444444, F1 Score: 0.6061506776877904, Sensitivity: 0.687369420702754, Specificity: 0.5202020202020202\n",
      "Iteration Results - Accuracy: 0.6, F1 Score: 0.6220538720538721, Sensitivity: 0.7301044634377968, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6537308482273846, Sensitivity: 0.7034188034188035, Specificity: 0.6191919191919192\n",
      "Iteration Results - Accuracy: 0.6055555555555556, F1 Score: 0.625510058673011, Sensitivity: 0.7407407407407408, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.5666666666666668, F1 Score: 0.5544767443732751, Sensitivity: 0.5978157644824311, Specificity: 0.5380867498514558\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.6282689912826899, Sensitivity: 0.6980056980056979, Specificity: 0.565359477124183\n",
      "Iteration Results - Accuracy: 0.6166666666666667, F1 Score: 0.6266655370103645, Sensitivity: 0.7074074074074074, Specificity: 0.5441473559120619\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6460707502374169, Sensitivity: 0.7716049382716049, Specificity: 0.5014260249554368\n",
      "Iteration Results - Accuracy: 0.65, F1 Score: 0.6512495555973817, Sensitivity: 0.7444444444444445, Specificity: 0.569399881164587\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6387453550195711, Sensitivity: 0.6461538461538461, Specificity: 0.6747474747474748\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.5921589919350277, Sensitivity: 0.6207027540360873, Specificity: 0.6370766488413547\n",
      "Iteration Results - Accuracy: 0.6833333333333332, F1 Score: 0.6981993514251578, Sensitivity: 0.7946818613485281, Specificity: 0.5909090909090908\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6339541280993272, Sensitivity: 0.7065527065527065, Specificity: 0.5865715983363042\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6894660894660894, Sensitivity: 0.8548907882241217, Specificity: 0.4671420083184789\n",
      "Iteration Results - Accuracy: 0.6277777777777779, F1 Score: 0.6491240026734867, Sensitivity: 0.7757834757834757, Specificity: 0.49393939393939396\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.6408712038849025, Sensitivity: 0.7586894586894587, Specificity: 0.4888888888888889\n",
      "Iteration Results - Accuracy: 0.688888888888889, F1 Score: 0.6907272890323738, Sensitivity: 0.7549857549857549, Specificity: 0.6333333333333333\n",
      "Iteration Results - Accuracy: 0.6499999999999999, F1 Score: 0.6458143132481232, Sensitivity: 0.7000949667616334, Specificity: 0.6101010101010101\n",
      "100%|████████████████████████████████████████████| 20/20 [2:21:14<00:00, 423.72s/trial, best loss: -0.6981993514251578]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f9d7104-d47e-4aaa-be92-08120fe814c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 64, 'dropout_rate': 0.3224123746707528, 'epochs': 30, 'learning_rate': 0.0001354902537099134, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)  \n",
    "print(\"Best Parameters:\", best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d914612b-3fa2-418e-bd4a-8cc14e877ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0d5fcb6-b4fe-4362-b02c-f7f918f07222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c9e1c-b5e7-4af8-ae11-d79141b94c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a9e73-ec16-48c2-85fe-960dce4233cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c19e10-cd6c-4ddd-af51-b852dac64c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
