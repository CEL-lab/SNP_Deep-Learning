{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd392ae-9326-4a6c-be5e-750d49b61d7f",
   "metadata": {},
   "source": [
    "## Data / Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f00f0ee-ac95-441c-a236-de07c0e60f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Affy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, GRU, Layer, Add, GlobalAveragePooling1D, Conv1D, ReLU\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "import scipy.stats as stats\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from accelerate import DataLoaderConfiguration\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from boruta import BorutaPy\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "from boruta import BorutaPy\n",
    "from skrebate import ReliefF\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6860d3a3-81b1-40c7-ba61-18bedfee9fc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AMGM and Cosine Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a7f397-8f20-4666-aed9-40ad33aca173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_amgm(X):\n",
    "    \"\"\"\n",
    "    Calculate AMGM for each feature (row) in the dataset X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): The input data array with shape (n_features, n_samples)\n",
    "    \n",
    "    Returns:\n",
    "    amgm_values (numpy array): The AMGM values for each feature (row)\n",
    "    \"\"\"\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    exp_X = np.exp(X)\n",
    "    amgm_values = (np.mean(exp_X, axis=1)) / (np.exp(np.mean(X, axis=1)))\n",
    "    \n",
    "    return amgm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01885de-8abe-4501-9729-751ba4d72c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_redundant_features(X, relevant_indices, threshold=0.9):\n",
    "    relevant_features = X[relevant_indices, :]\n",
    "    cos_sim_matrix = cosine_similarity(relevant_features)\n",
    "    \n",
    "    to_keep = []\n",
    "    to_drop = set()\n",
    "    for i in range(cos_sim_matrix.shape[0]):\n",
    "        if i not in to_drop:\n",
    "            to_keep.append(relevant_indices[i])\n",
    "            for j in range(i + 1, cos_sim_matrix.shape[0]):\n",
    "                if cos_sim_matrix[i, j] > threshold:\n",
    "                    to_drop.add(relevant_indices[j])\n",
    "    return to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87953735-2cf1-4355-9ae5-ed01ff49c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b0dad26-deb2-4ce3-9d56-1ede8a22ab70",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autoencoder Feature Selection with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b943080e-30d1-492d-be4e-d76475428ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_feature_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)  # Encoder part\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)  # Decoder part\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40b850a-3003-4dd5-be7d-08a29c4e7891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_l1_feature_selection(X, y, alpha=0.01, target_features=100):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    model = SelectFromModel(lasso, prefit=True, max_features=target_features)\n",
    "    X_reduced = model.transform(X)\n",
    "    selected_indices = model.get_support(indices=True)\n",
    "    return X_reduced, selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb6141-11ff-46bb-bb60-172c4d1fc0cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initial Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b5d5c24-4048-42e2-a0dd-10911a06659b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfec5c7a-3206-4962-9f2f-a177f4c6632a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a64f23d-828e-4f02-94c1-035591928b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf0a68e-a90d-435e-ab17-69c39509d0b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "380fc34e-afc2-4823-965b-b9723a48a77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90920de3-58b5-4a7c-8b26-e224de761477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8658fc6f-877a-43d7-a239-62ad404f016a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a268c417-608e-4d4f-ae52-048a865e56f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936   1827  43149 190298 237211 185366 192464 119497 195618]\n",
      "Top AMGM values: [1.00297347 1.002975   1.00297625 1.00297625 1.00297625 1.00297625\n",
      " 1.00297625 1.00297966 1.00298188 1.00298232]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd2f5770-9a6e-4131-848c-8034bb701234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2180bfb5-3bf4-4e82-a3d1-b88526441f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85a5c928-ed40-41b8-88f9-07a4e4a1c1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a22c9e7f-f4b4-4ec9-a482-c78bdbedf602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26123aab-532b-4c8b-b9fb-deaabdc8d72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b272455-9c44-4c5f-a8a6-b9c6bec540a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "359345d7-9d3a-4613-bdad-65da25c2add0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1721d85f-c521-4ef4-aae3-e5e8fd17717a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_103\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_103\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_515 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_206 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_516 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_207 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_517 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_518 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_519 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_515 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m6,464\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_206 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_516 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_207 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_517 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_518 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m6,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_519 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,257</span> (67.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,257\u001b[0m (67.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,257</span> (67.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,257\u001b[0m (67.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59608f3e-b38b-4783-9522-55cce0b15881",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5877 - loss: 0.6949 - val_accuracy: 0.6923 - val_loss: 0.6843 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4396 - loss: 0.7682 - val_accuracy: 0.3077 - val_loss: 0.8165 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5897 - loss: 0.7192 - val_accuracy: 0.3077 - val_loss: 0.7826 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5371 - loss: 0.7272 - val_accuracy: 0.5385 - val_loss: 0.6955 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4281 - loss: 0.7133 - val_accuracy: 0.6923 - val_loss: 0.6634 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4943 - loss: 0.7331 - val_accuracy: 0.6923 - val_loss: 0.6678 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5195 - loss: 0.6880 - val_accuracy: 0.3077 - val_loss: 0.7330 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5429 - loss: 0.6921 - val_accuracy: 0.3077 - val_loss: 0.7997 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6207 - loss: 0.6758 - val_accuracy: 0.3077 - val_loss: 0.8163 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5252 - loss: 0.7431 - val_accuracy: 0.3077 - val_loss: 0.7338 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5273 - loss: 0.6793 - val_accuracy: 0.6154 - val_loss: 0.6913 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5916 - loss: 0.6784 - val_accuracy: 0.6923 - val_loss: 0.6645 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5213 - loss: 0.7001 - val_accuracy: 0.6923 - val_loss: 0.6745 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5427 - loss: 0.7002 - val_accuracy: 0.5385 - val_loss: 0.6947 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5371 - loss: 0.6620 - val_accuracy: 0.4615 - val_loss: 0.7092 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5759 - loss: 0.6884 - val_accuracy: 0.3077 - val_loss: 0.7185 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5681 - loss: 0.6642 - val_accuracy: 0.4615 - val_loss: 0.7106 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5370 - loss: 0.6944 - val_accuracy: 0.4615 - val_loss: 0.7049 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6324 - loss: 0.6577 - val_accuracy: 0.4615 - val_loss: 0.6944 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6108 - loss: 0.6741 - val_accuracy: 0.6154 - val_loss: 0.6832 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6751 - loss: 0.6286 - val_accuracy: 0.4615 - val_loss: 0.6888 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5779 - loss: 0.6594 - val_accuracy: 0.4615 - val_loss: 0.7075 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6149 - loss: 0.6317 - val_accuracy: 0.3846 - val_loss: 0.7358 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5662 - loss: 0.6691 - val_accuracy: 0.3077 - val_loss: 0.7156 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6751 - loss: 0.6019 - val_accuracy: 0.4615 - val_loss: 0.6965 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5699 - loss: 0.6692 - val_accuracy: 0.5385 - val_loss: 0.6861 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7199 - loss: 0.5912 - val_accuracy: 0.6154 - val_loss: 0.6748 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6479 - loss: 0.6398 - val_accuracy: 0.6923 - val_loss: 0.6725 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6849 - loss: 0.6088 - val_accuracy: 0.5385 - val_loss: 0.6857 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6791 - loss: 0.5993 - val_accuracy: 0.4615 - val_loss: 0.7019 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6518 - loss: 0.6211 - val_accuracy: 0.5385 - val_loss: 0.6988 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7004 - loss: 0.5939 - val_accuracy: 0.6154 - val_loss: 0.6872 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7140 - loss: 0.5749 - val_accuracy: 0.6154 - val_loss: 0.6875 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7082 - loss: 0.5795 - val_accuracy: 0.6154 - val_loss: 0.6766 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7666 - loss: 0.5466 - val_accuracy: 0.6154 - val_loss: 0.6821 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6381 - loss: 0.5940 - val_accuracy: 0.6154 - val_loss: 0.6953 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7646 - loss: 0.5246 - val_accuracy: 0.6154 - val_loss: 0.7027 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6888 - loss: 0.5747 - val_accuracy: 0.6154 - val_loss: 0.7198 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7685 - loss: 0.4991 - val_accuracy: 0.6154 - val_loss: 0.7149 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6809 - loss: 0.5710 - val_accuracy: 0.6154 - val_loss: 0.7027 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7626 - loss: 0.5016 - val_accuracy: 0.6154 - val_loss: 0.6982 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7314 - loss: 0.5234 - val_accuracy: 0.6154 - val_loss: 0.7073 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8132 - loss: 0.4653 - val_accuracy: 0.5385 - val_loss: 0.7109 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7646 - loss: 0.4338 - val_accuracy: 0.6154 - val_loss: 0.7252 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7413 - loss: 0.4870 - val_accuracy: 0.6154 - val_loss: 0.7490 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8152 - loss: 0.3840 - val_accuracy: 0.6154 - val_loss: 0.7861 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 0.3986 - val_accuracy: 0.6154 - val_loss: 0.8048 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7703 - loss: 0.4269 - val_accuracy: 0.6154 - val_loss: 0.8019 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8522 - loss: 0.3897 - val_accuracy: 0.6154 - val_loss: 0.8005 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7647 - loss: 0.4604 - val_accuracy: 0.6154 - val_loss: 0.8076 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb0386f0-ff2b-4ce6-967f-22a4bb32c19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 0.68\n",
      "F1 Score: 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c12dc3fb-7e1e-4304-bd49-dc04ff30a730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f16b369-83ac-4372-80c5-ee1fedff850f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "F1 Score: 0.6363636363636364\n",
      "Specificity: 0.8333333333333334\n",
      "Sensitivity: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc8c1b-756f-4d4b-b76d-f4549fc64445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a3f5d7-97ff-4de3-b647-9dfb7c5a06b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a44670f-9311-40c7-bfff-0fc743a3c887",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da671726-dc91-4e5b-9287-3ea1f0c76390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4361ccc2-8545-47b4-b81b-073c616c7c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ade221c-0400-4b5f-8a42-9cb4d07bf219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c8e8bbd-0aa6-405d-b788-f9b8f4b0edd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936   1827  43149 190298 237211 185366 192464 119497 195618]\n",
      "Top AMGM values: [1.00297347 1.002975   1.00297625 1.00297625 1.00297625 1.00297625\n",
      " 1.00297625 1.00297966 1.00298188 1.00298232]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96c90fa4-2164-43a5-9ae8-df1b4ea335fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9f05d44-39fb-4001-8591-b751ed0da372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3eeb08fe-31b3-41f6-811a-c67d13fe2ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "182849e1-a346-4eec-b7c3-b93b8b00f5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4511f448-c3b0-4037-868d-d5aa4d8dba4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa1795e2-8645-4eae-be82-ffb71885bf12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55311067-529e-4a0e-912a-ba29a2d3d926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02e3d26b-d379-4af1-8f26-4f14dcb41dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C8852DB060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C8AA1BA660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.47580645161290325, F1 Score: 0.6198830409356725, Sensitivity: 0.8548387096774194, Specificity: 0.0967741935483871\n",
      "Accuracy: 0.6129032258064516, F1 Score: 0.6666666666666666, Sensitivity: 0.7741935483870968, Specificity: 0.45161290322580644\n",
      "Accuracy: 0.6854838709677419, F1 Score: 0.6776859504132231, Sensitivity: 0.6612903225806451, Specificity: 0.7096774193548387\n",
      "Accuracy: 0.5887096774193549, F1 Score: 0.5714285714285714, Sensitivity: 0.5483870967741935, Specificity: 0.6290322580645161\n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6229508196721312, Sensitivity: 0.6129032258064516, Specificity: 0.6451612903225806\n",
      "Accuracy: 0.6612903225806451, F1 Score: 0.6557377049180327, Sensitivity: 0.6451612903225806, Specificity: 0.6774193548387096\n",
      "Accuracy: 0.6209677419354839, F1 Score: 0.6299212598425197, Sensitivity: 0.6451612903225806, Specificity: 0.5967741935483871\n",
      "Accuracy: 0.5967741935483871, F1 Score: 0.5535714285714286, Sensitivity: 0.5, Specificity: 0.6935483870967742          \n",
      "Accuracy: 0.6532258064516129, F1 Score: 0.6666666666666666, Sensitivity: 0.6935483870967742, Specificity: 0.6129032258064516\n",
      "Accuracy: 0.6612903225806451, F1 Score: 0.6440677966101694, Sensitivity: 0.6129032258064516, Specificity: 0.7096774193548387\n",
      "Accuracy: 0.6048387096774194, F1 Score: 0.5811965811965812, Sensitivity: 0.5483870967741935, Specificity: 0.6612903225806451\n",
      "Accuracy: 0.6774193548387096, F1 Score: 0.6610169491525424, Sensitivity: 0.6290322580645161, Specificity: 0.7258064516129032\n",
      "Accuracy: 0.6370967741935484, F1 Score: 0.628099173553719, Sensitivity: 0.6129032258064516, Specificity: 0.6612903225806451\n",
      "Accuracy: 0.5645161290322581, F1 Score: 0.5970149253731343, Sensitivity: 0.6451612903225806, Specificity: 0.4838709677419355\n",
      "Accuracy: 0.6854838709677419, F1 Score: 0.6666666666666666, Sensitivity: 0.6290322580645161, Specificity: 0.7419354838709677\n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6290322580645161, Sensitivity: 0.6290322580645161, Specificity: 0.6290322580645161\n",
      "Accuracy: 0.6693548387096774, F1 Score: 0.672, Sensitivity: 0.6774193548387096, Specificity: 0.6612903225806451        \n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6617647058823529, Sensitivity: 0.7258064516129032, Specificity: 0.532258064516129\n",
      "Accuracy: 0.5645161290322581, F1 Score: 0.6086956521739131, Sensitivity: 0.6774193548387096, Specificity: 0.45161290322580644\n",
      "Accuracy: 0.49193548387096775, F1 Score: 0.6134969325153374, Sensitivity: 0.8064516129032258, Specificity: 0.1774193548387097\n",
      "100%|███████████████████████████████████████████████| 20/20 [07:05<00:00, 21.28s/trial, best loss: -0.6776859504132231]\n",
      "Best parameters found:  {'batch_size': 64.0, 'dropout_rate': 0.3886455175010518, 'epochs': 100.0, 'learning_rate': 0.00031372782335705325, 'neurons1': 192.0, 'neurons2': 32.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "132a7da7-c657-4133-aec6-f52e33245e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6854838709677419\n",
      "Best F1 Score: 0.6776859504132231\n",
      "Best Specificity: 0.7096774193548387\n",
      "Best Sensitivity: 0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e78a0fb-6256-418f-833b-1b3b4f918d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_104\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_104\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_520 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,392</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_208 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_521 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_209 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_522 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_523 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_524 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_520 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │          \u001b[38;5;34m19,392\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_208 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_521 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m6,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_209 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_522 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │           \u001b[38;5;34m6,336\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_523 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m19,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_524 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,305</span> (200.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,305\u001b[0m (200.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,305</span> (200.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,305\u001b[0m (200.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a69bd93-914f-4e00-997e-23183c40db24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 192\n",
      "Neurons in second layer: 32\n",
      "Dropout rate: 0.3886455175010518\n",
      "Learning rate: 0.00031372782335705325\n",
      "Number of epochs: 100\n",
      "Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439acd0-d449-4573-adc7-2b0c142ae75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0e13773-97d6-44a2-9fb1-0342ae6d000c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae1bec1f-b154-403e-a9c3-0b500bdc9e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "697e4b5c-d601-41f7-a2f2-8a3d6d37a4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\2580834323.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "661d99c3-10b3-4ba3-a56a-8995b2999df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d5bc8ac3-bd7a-42d9-8bf5-a41966c7b424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1a68641-177e-412f-b218-e8be27b480d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c36b1479-baba-43c4-a1de-f7f6f2292b49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936   1827  43149 190298 237211 185366 192464 119497 195618]\n",
      "Top AMGM values: [1.00297347 1.002975   1.00297625 1.00297625 1.00297625 1.00297625\n",
      " 1.00297625 1.00297966 1.00298188 1.00298232]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5b68ec2-f202-489a-b587-9b0ccf60ca8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5823643-01ca-45ca-abe7-fc89475457e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "37397bd3-1fe2-4b5e-8dba-d2981d85e104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22bc99df-1398-46cb-95f4-134777e617ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed5c5c62-79a5-43b8-a7d2-f9fba8987fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 128, 32)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69006e00-8ff7-4570-a4bc-b764756c0dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ca49a36a-52a5-4e62-99ad-b7737e181a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.8282828282828283, F1 Score: 0.8255850727387729, Sensitivity: 0.8004357298474947, Specificity: 0.862962962962963\n",
      "Iteration Results - Accuracy: 0.797979797979798, F1 Score: 0.8030303030303031, Sensitivity: 0.8189542483660132, Specificity: 0.7805555555555556\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.6641975308641975, Sensitivity: 0.5860566448801743, Specificity: 0.8435185185185184\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.7729468599033816, Sensitivity: 0.8474945533769063, Specificity: 0.6370370370370371\n",
      "Iteration Results - Accuracy: 0.7676767676767676, F1 Score: 0.7734960767218831, Sensitivity: 0.7978213507625272, Specificity: 0.736574074074074\n",
      "Iteration Results - Accuracy: 0.8282828282828283, F1 Score: 0.8326656827605595, Sensitivity: 0.8374727668845315, Specificity: 0.825925925925926\n",
      "Iteration Results - Accuracy: 0.797979797979798, F1 Score: 0.8175094599243207, Sensitivity: 0.8830065359477125, Specificity: 0.725\n",
      "Iteration Results - Accuracy: 0.8484848484848485, F1 Score: 0.8460274790919952, Sensitivity: 0.8374727668845315, Specificity: 0.8606481481481482\n",
      "Iteration Results - Accuracy: 0.7575757575757575, F1 Score: 0.7550505050505051, Sensitivity: 0.7427015250544663, Specificity: 0.7796296296296297\n",
      "Iteration Results - Accuracy: 0.8181818181818182, F1 Score: 0.8214285714285715, Sensitivity: 0.838562091503268, Specificity: 0.800462962962963\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.6479925303454716, Sensitivity: 0.5516339869281045, Specificity: 0.8486111111111111\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.6865079365079364, Sensitivity: 0.5986928104575163, Specificity: 0.8606481481481482\n",
      "Iteration Results - Accuracy: 0.8181818181818182, F1 Score: 0.8006060606060607, Sensitivity: 0.7522875816993464, Specificity: 0.8731481481481481\n",
      "Iteration Results - Accuracy: 0.7878787878787877, F1 Score: 0.7852809706257982, Sensitivity: 0.7671023965141611, Specificity: 0.8310185185185185\n",
      "Iteration Results - Accuracy: 0.6565656565656566, F1 Score: 0.6550947499223362, Sensitivity: 0.64640522875817, Specificity: 0.6893518518518519\n",
      "Iteration Results - Accuracy: 0.8383838383838383, F1 Score: 0.8383838383838386, Sensitivity: 0.8252723311546841, Specificity: 0.8666666666666667\n",
      "Iteration Results - Accuracy: 0.7676767676767676, F1 Score: 0.7587813620071685, Sensitivity: 0.7379084967320262, Specificity: 0.7967592592592593\n",
      "Iteration Results - Accuracy: 0.6767676767676768, F1 Score: 0.6199633699633699, Sensitivity: 0.5427015250544662, Specificity: 0.8226851851851852\n",
      "Iteration Results - Accuracy: 0.8282828282828283, F1 Score: 0.8273809523809524, Sensitivity: 0.8189542483660132, Specificity: 0.8421296296296297\n",
      "Iteration Results - Accuracy: 0.7575757575757575, F1 Score: 0.7395382395382395, Sensitivity: 0.707843137254902, Specificity: 0.8250000000000001\n",
      "100%|███████████████████████████████████████████████| 20/20 [21:20<00:00, 64.02s/trial, best loss: -0.8460274790919952]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b1bc955d-aea4-41eb-adc3-36a3d2c0fdae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 64, 'dropout_rate': 0.4980102429755082, 'learning_rate': 0.0002397781360725169, 'epochs': 50, 'batch_size': 48, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dae7a270-4adb-49a3-9fd7-989d6af48985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.64\n",
      "F1 Score: 0.6086956521739131\n",
      "Sensitivity: 0.5833333333333334\n",
      "Specificity: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1fdcc-a140-4929-9820-721c37cd8647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a3a5d-2b03-49e8-a3ea-a3631a821484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f7d8b46-3a5d-4150-9d43-9058296023c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gru with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a168d442-edad-4a9a-9581-dc56d13a40c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a4d33ac4-90ae-4397-b539-2c352b291154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6cfc2d87-ed27-4fb1-be3e-9ab859a2685b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1443f452-b7eb-4fa9-9796-9cde97c8ac58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f7f87ea-63d2-4a53-b208-31380799625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f81e483d-6cd4-43e6-a13c-e937ee3e9b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "374ff74c-afcc-4315-8c7a-04a3bdc62bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5265cef0-ae34-4f25-b8cb-d69ac7f906c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "65cb06c5-0c00-4e04-9e28-db275077fd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ff6981f9-8a8d-48b8-880b-f424ba5171fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "619c1bd2-d8c0-40c8-9f5c-8bba010b9fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 64, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.4),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "247393ae-704a-401d-95b6-659cf5e1f68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a249b175-5cc9-47cd-a714-3103f43d70ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6464646464646465, F1 Score: 0.6603174603174603, Sensitivity: 0.7001667063586569, Specificity: 0.6244047619047619\n",
      "Iteration Results - Accuracy: 0.6262626262626263, F1 Score: 0.6490507314036725, Sensitivity: 0.702230689846789, Specificity: 0.5869047619047619\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.6504629629629629, Sensitivity: 0.6941335238548861, Specificity: 0.5922619047619048\n",
      "Iteration Results - Accuracy: 0.7474747474747474, F1 Score: 0.7606009516316362, Sensitivity: 0.8434547908232118, Specificity: 0.6660714285714285\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6551764025448236, Sensitivity: 0.6986584107327141, Specificity: 0.686904761904762\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6827734711455643, Sensitivity: 0.7743113439707866, Specificity: 0.5738095238095239\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6652183600713013, Sensitivity: 0.6765896642057633, Specificity: 0.6785714285714285\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.6285714285714286, Sensitivity: 0.6745256807176312, Specificity: 0.5660714285714286\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.6633251433251434, Sensitivity: 0.6730173850916885, Specificity: 0.7267857142857143\n",
      "Iteration Results - Accuracy: 0.616161616161616, F1 Score: 0.6055299539170508, Sensitivity: 0.6083194411367786, Specificity: 0.669047619047619\n",
      "Iteration Results - Accuracy: 0.6161616161616162, F1 Score: 0.5966985084632143, Sensitivity: 0.5960943081686115, Specificity: 0.6630952380952381\n",
      "Iteration Results - Accuracy: 0.5757575757575757, F1 Score: 0.5813454837845081, Sensitivity: 0.6217353338096373, Specificity: 0.544047619047619\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6664809863339275, Sensitivity: 0.682622846709534, Specificity: 0.6785714285714285\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.6405228758169934, Sensitivity: 0.6650789870604111, Specificity: 0.6410714285714286\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.717948717948718, Sensitivity: 0.7536715090894658, Specificity: 0.7273809523809524\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.6347650171179583, Sensitivity: 0.6434071604350242, Specificity: 0.6702380952380952\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.6624338624338625, Sensitivity: 0.7770897832817337, Specificity: 0.5077380952380953\n",
      "Iteration Results - Accuracy: 0.5959595959595959, F1 Score: 0.6441179551644668, Sensitivity: 0.7574819401444789, Specificity: 0.493452380952381\n",
      "Iteration Results - Accuracy: 0.5858585858585857, F1 Score: 0.5608465608465608, Sensitivity: 0.5773596888147972, Specificity: 0.6482142857142857\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.5755877616747181, Sensitivity: 0.6969913471461459, Specificity: 0.35773809523809524\n",
      "100%|████████████████████████████████████████████| 20/20 [1:07:58<00:00, 203.95s/trial, best loss: -0.7606009516316362]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bda36308-47d7-4d06-82ff-0447d70d7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 48, 'dropout_rate': 0.26149192458937076, 'epochs': 20, 'learning_rate': 0.008201820631259751, 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ff996c96-8e43-4ae2-9dc8-9925e866301a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "24efc4cb-db7b-4bc0-9afd-53baa2d407e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "11aa2678-d0b4-4965-a93c-c75ec3d55ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2cab886e350>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b262a864-333a-498d-a803-6c07a706383d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.84\n",
      "F1 Score: 0.8571428571428571\n",
      "Sensitivity: 0.9230769230769231\n",
      "Specificity: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06800a32-61b6-4931-b62c-afec61a67b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456eb99-15b1-40ec-8cc3-74b567ee8156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a74844e-656a-4e3e-8626-3fb1c398cb32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4d055f46-5cce-4dea-81d6-c182e8501d79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3db8f020-3d86-4e55-961c-099fac014b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "09861ef6-1517-4024-8a29-47230d14f8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2784aaf2-a7c0-4b29-951b-60362b2dc600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "20dd59cf-7c7c-4f1f-b258-185c49cf951c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "122b9c1a-c55f-4037-9a37-283e0f5716d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c9218acd-60dd-4467-87ea-105e5427c57e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a5b3a976-5da1-415a-8e74-8713dd9208c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b7c09be-7d00-43fc-9175-a41e113b4199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9a2469a4-ec0c-4a87-b634-cfd650fcc079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "85a1e3a5-727f-4085-a271-d7c73bb378d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "258804d2-596f-4eb3-8130-f42d05087db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1650a8d7-1811-4334-8f71-d066a76d4f1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.7021072796934865, Sensitivity: 0.7724061284432802, Specificity: 0.5279761904761905\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7373737373737373, F1 Score: 0.7470559845559847, Sensitivity: 0.8001111375724378, Specificity: 0.6910714285714286\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5959595959595959, F1 Score: 0.577485380116959, Sensitivity: 0.6442803842184647, Specificity: 0.6208333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6969696969696969, F1 Score: 0.5833333333333334, Sensitivity: 0.5475113122171945, Specificity: 0.7619047619047619\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7171717171717171, F1 Score: 0.6641025641025641, Sensitivity: 0.6291180439787251, Specificity: 0.793452380952381\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6969696969696969, F1 Score: 0.6433239962651728, Sensitivity: 0.6319758672699849, Specificity: 0.6696428571428571\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7171717171717171, F1 Score: 0.6125356125356126, Sensitivity: 0.505040882749861, Specificity: 0.8910714285714286\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7272727272727274, F1 Score: 0.6443965517241379, Sensitivity: 0.5410018258315472, Specificity: 0.9011904761904762\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6161616161616161, F1 Score: 0.6973079633544751, Sensitivity: 0.9019607843137255, Specificity: 0.34761904761904755\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6565656565656567, F1 Score: 0.583024818318936, Sensitivity: 0.4861474954354212, Specificity: 0.8101190476190476\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.3565359477124183, Sensitivity: 0.22346590458045568, Specificity: 0.9833333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.6452512039298478, Sensitivity: 0.6319758672699849, Specificity: 0.6964285714285715\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5858585858585859, F1 Score: 0.34068076173339334, Sensitivity: 0.23553226958799714, Specificity: 0.9357142857142856\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.6509009009009009, Sensitivity: 0.6503929507025482, Specificity: 0.6809523809523809\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.5131987577639752, Sensitivity: 0.3524648725887116, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6565656565656567, F1 Score: 0.5326510721247564, Sensitivity: 0.4647932047312852, Specificity: 0.8375\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.5748245614035088, Sensitivity: 0.4773358736207034, Specificity: 0.8839285714285715\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6565656565656566, F1 Score: 0.5411111111111112, Sensitivity: 0.42200523934270057, Specificity: 0.9166666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.5344982078853047, Sensitivity: 0.38961657537508926, Specificity: 0.9523809523809524\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.4504761904761905, Sensitivity: 0.4717789949988092, Specificity: 0.7166666666666667\n",
      "100%|███████████████████████████████████████████████| 20/20 [03:01<00:00,  9.09s/trial, best loss: -0.7470559845559847]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6d7cd1ed-120b-4de1-92a5-77a6583b5a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.2704870963112872, 'epochs': 30, 'filters': 96, 'kernel_size': 2, 'learning_rate': 0.004843677725374834}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9073aa76-76e6-4a22-9c66-6fef6778c065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ff89d0a6-1a54-4537-b0df-0938e10f29b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ca7665bc50>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc5eeb26-d883-4009-beaf-5efbf9b14447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f323f00e-c44b-4bd7-a4bf-7cb7ed71ee45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.68\n",
      "F1 Score: 0.5555555555555556\n",
      "Sensitivity: 0.38461538461538464\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf313f-aff3-4605-a652-e66d46ea08c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3377436d-64fe-4682-b11c-01b9b1c2943d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3be676c2-3a65-4712-a96c-41a556883c95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2b29409c-fbb6-43df-884a-01e50fb2c64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6d92fd0e-f54e-459a-b0d7-3e27ac6a0d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6d10b620-86b6-4882-b8da-5867c5ce8040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b62636bd-1b32-4f4c-8b3a-27814f2ce4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d1f37621-36ef-4bd0-9ca0-93a2c694ce65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6f6ff83e-bab6-498b-8762-ae38ce29df6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "22339bb6-7cf3-4c30-9aa3-4694d7d46056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d68dfd57-071a-40bc-96a6-7d06fe73ff61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b854c088-fe82-4825-bca9-1da62f1858fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e21fc95b-ee3d-4b28-9cf6-e0a2e223ce1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6a92101a-b355-44cb-9652-ca9288df0a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c6db490b-1954-47e6-b312-2e7a1e7acb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a8be5b3e-bfe7-4446-b2ce-f11065f8438f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3975613495818561, 'epochs': 20, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.002529773575832117, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.47526001930236816, Filters: 64, Blocks: 8, Kernel Size: 3, Dropout: 0.3975613495818561, LR: 0.002529773575832117, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.41543404313065024, 'epochs': 30, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.00019116119283463248, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5327001214027405, Filters: 32, Blocks: 10, Kernel Size: 3, Dropout: 0.41543404313065024, LR: 0.00019116119283463248, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3467660067695803, 'epochs': 40, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.0012954666525448817, 'num_blocks': 10}\n",
      "Iteration - Loss: 1.283017873764038, Filters: 96, Blocks: 10, Kernel Size: 5, Dropout: 0.3467660067695803, LR: 0.0012954666525448817, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.4105247333057399, 'epochs': 40, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.009399217604704472, 'num_blocks': 4}\n",
      "Iteration - Loss: 3.8415520191192627, Filters: 64, Blocks: 4, Kernel Size: 5, Dropout: 0.4105247333057399, LR: 0.009399217604704472, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.256056903344939, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0018723258158435882, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.4070301055908203, Filters: 64, Blocks: 8, Kernel Size: 3, Dropout: 0.256056903344939, LR: 0.0018723258158435882, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.23840515270897467, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.001066828701448011, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5613354444503784, Filters: 64, Blocks: 4, Kernel Size: 4, Dropout: 0.23840515270897467, LR: 0.001066828701448011, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.23135447657125624, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.00020061151988807205, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6011539697647095, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.23135447657125624, LR: 0.00020061151988807205, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.41454792625416687, 'epochs': 20, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0003041706857813246, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.588485836982727, Filters: 96, Blocks: 10, Kernel Size: 3, Dropout: 0.41454792625416687, LR: 0.0003041706857813246, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3359765345277389, 'epochs': 30, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0001722329400123288, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.6207645535469055, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.3359765345277389, LR: 0.0001722329400123288, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4003017615556681, 'epochs': 50, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.00036438979607694363, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5924263596534729, Filters: 128, Blocks: 4, Kernel Size: 5, Dropout: 0.4003017615556681, LR: 0.00036438979607694363, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.4006895837839367, 'epochs': 50, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.002406457785164454, 'num_blocks': 10}\n",
      "Iteration - Loss: 4.259948253631592, Filters: 96, Blocks: 10, Kernel Size: 3, Dropout: 0.4006895837839367, LR: 0.002406457785164454, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3056702997036658, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.00028222373468539294, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6232805252075195, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.3056702997036658, LR: 0.00028222373468539294, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.20846325970463203, 'epochs': 20, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.004586231679406748, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.799349069595337, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.20846325970463203, LR: 0.004586231679406748, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.40591860224220927, 'epochs': 50, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.006156663101509279, 'num_blocks': 6}\n",
      "Iteration - Loss: 12.124971389770508, Filters: 64, Blocks: 6, Kernel Size: 5, Dropout: 0.40591860224220927, LR: 0.006156663101509279, Batch Size: 64, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.35676098636627845, 'epochs': 20, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.00948743840233466, 'num_blocks': 6}\n",
      "Iteration - Loss: 3.0608599185943604, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.35676098636627845, LR: 0.00948743840233466, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3911166096666332, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0021328752529582865, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5845785140991211, Filters: 64, Blocks: 8, Kernel Size: 4, Dropout: 0.3911166096666332, LR: 0.0021328752529582865, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.24036766856199393, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0005988512232548408, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5718510746955872, Filters: 96, Blocks: 10, Kernel Size: 4, Dropout: 0.24036766856199393, LR: 0.0005988512232548408, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.45887359339557016, 'epochs': 20, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0031156562685003384, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.24500493705272675, Filters: 32, Blocks: 10, Kernel Size: 5, Dropout: 0.45887359339557016, LR: 0.0031156562685003384, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.33708228934852574, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0006263782720599717, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5095992088317871, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.33708228934852574, LR: 0.0006263782720599717, Batch Size: 16, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.3033699502499596, 'epochs': 50, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0009982182953451315, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6086653470993042, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.3033699502499596, LR: 0.0009982182953451315, Batch Size: 64, Epochs: 50\n",
      "100%|███████████████████████████████████████████████| 20/20 [02:37<00:00,  7.86s/trial, best loss: 0.24500493705272675]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f24fa18f-4117-47d8-9790-2e45a3d18734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 48, 'dropout_rate': 0.45887359339557016, 'epochs': 20, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0031156562685003384, 'num_blocks': 10}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "17da7572-b153-441e-b2cc-1b8e97c1b408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "35f5b485-af87-4582-8f0d-691cf33db7da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - accuracy: 0.7599 - loss: 0.5913 - val_accuracy: 0.5000 - val_loss: 12.9370\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - accuracy: 0.7385 - loss: 0.6036 - val_accuracy: 0.5000 - val_loss: 14.1020\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - accuracy: 0.7658 - loss: 0.4888 - val_accuracy: 0.5000 - val_loss: 14.8245\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d80fa961-a18b-47b4-8503-98924cf5351d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ba21c2e5-604b-4234-886b-60b26131a51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.52\n",
      "F1 Score: 0.6842105263157895\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6fc4a-dfd3-4157-b7cb-eb486bef46e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5080ed-7f46-471e-94b5-f1d000448785",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "59093306-4685-4e3a-9d17-b757a4a720d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "62b72638-c32e-4af0-a1da-5ac1c32cd317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8b23c4b7-e073-44d9-8e66-cf8b45def847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5bf797a8-249a-419f-a6a3-97f0fa516e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "787ad11f-028d-4dbe-a36b-ee7699634a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "35fe54d9-4c29-4370-af6c-45839e30c642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1e88a4a6-a8d3-41c2-a191-74a3dc51000c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a2175fce-d5cb-4c76-a4af-973cbd5604b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a78536a7-6dc3-4a44-8ad5-a787410eb463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "941006a1-5bf7-4709-b7a5-efc26f4e8ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5db2392d-53d7-4160-91f8-ace26d4ee6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3e1cd145-11bf-498c-ba4a-fa8a5d0a454b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "06c68a22-75ae-4ada-a86f-185e6eda9196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.6557340621948242, Params: {'batch_size': 80, 'dropout_rate': 0.2759943218469899, 'epochs': 100, 'learning_rate': 5.740116088716993e-05, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.8506616353988647, Params: {'batch_size': 64, 'dropout_rate': 0.3835381824267792, 'epochs': 120, 'learning_rate': 0.00010761202010048912, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.6082776784896851, Params: {'batch_size': 32, 'dropout_rate': 0.21865977020055005, 'epochs': 70, 'learning_rate': 1.5384814765738954e-05, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.7128633856773376, Params: {'batch_size': 64, 'dropout_rate': 0.18657880609584165, 'epochs': 120, 'learning_rate': 0.006972105104347789, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.6343806385993958, Params: {'batch_size': 128, 'dropout_rate': 0.14632078019220018, 'epochs': 50, 'learning_rate': 0.0003535658424250918, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.592029333114624, Params: {'batch_size': 48, 'dropout_rate': 0.13880574154946484, 'epochs': 150, 'learning_rate': 1.3936655205482555e-05, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.5727174878120422, Params: {'batch_size': 32, 'dropout_rate': 0.368751467142198, 'epochs': 130, 'learning_rate': 0.0014170593762689169, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.6382583379745483, Params: {'batch_size': 64, 'dropout_rate': 0.1644912995363416, 'epochs': 90, 'learning_rate': 3.514328626574469e-05, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.6616369485855103, Params: {'batch_size': 48, 'dropout_rate': 0.266575696221783, 'epochs': 130, 'learning_rate': 1.3095328609438305e-05, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.6682784557342529, Params: {'batch_size': 48, 'dropout_rate': 0.13557794407778512, 'epochs': 120, 'learning_rate': 0.0001543658016836394, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.6764230728149414, Params: {'batch_size': 80, 'dropout_rate': 0.24772970543324835, 'epochs': 70, 'learning_rate': 0.0014493419639131219, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 0.6493202447891235, Params: {'batch_size': 96, 'dropout_rate': 0.41185212348216793, 'epochs': 100, 'learning_rate': 0.00011895004039257442, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 0.6409164667129517, Params: {'batch_size': 32, 'dropout_rate': 0.26341469808578777, 'epochs': 70, 'learning_rate': 0.00012172570885228749, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.6913853883743286, Params: {'batch_size': 80, 'dropout_rate': 0.3049433646081293, 'epochs': 110, 'learning_rate': 1.2591736723477136e-05, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.693686842918396, Params: {'batch_size': 80, 'dropout_rate': 0.43985684738981357, 'epochs': 90, 'learning_rate': 0.0009643493863591453, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 0.49218064546585083, Params: {'batch_size': 96, 'dropout_rate': 0.3343967525254308, 'epochs': 120, 'learning_rate': 0.00037706456010595953, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 0.49345332384109497, Params: {'batch_size': 64, 'dropout_rate': 0.1657144793140748, 'epochs': 100, 'learning_rate': 0.0011919333071824998, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.5413203239440918, Params: {'batch_size': 32, 'dropout_rate': 0.22343084881263908, 'epochs': 140, 'learning_rate': 0.000689176593005095, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.7111188173294067, Params: {'batch_size': 112, 'dropout_rate': 0.2458315734329264, 'epochs': 140, 'learning_rate': 0.00016334979813077065, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.5925184488296509, Params: {'batch_size': 32, 'dropout_rate': 0.24286443073656613, 'epochs': 80, 'learning_rate': 0.00023587248277447947, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.6621705293655396, Params: {'batch_size': 112, 'dropout_rate': 0.3378013478317411, 'epochs': 110, 'learning_rate': 0.003745788489892771, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.6854705810546875, Params: {'batch_size': 96, 'dropout_rate': 0.49565333872540607, 'epochs': 110, 'learning_rate': 0.00250356641218308, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.643005907535553, Params: {'batch_size': 96, 'dropout_rate': 0.1026764777891685, 'epochs': 90, 'learning_rate': 0.00047375255005784397, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.616463840007782, Params: {'batch_size': 112, 'dropout_rate': 0.3114362151867418, 'epochs': 130, 'learning_rate': 0.009367118004800563, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.6431114673614502, Params: {'batch_size': 128, 'dropout_rate': 0.4681248097538965, 'epochs': 80, 'learning_rate': 0.003868643962030301, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.6257606744766235, Params: {'batch_size': 96, 'dropout_rate': 0.3379706602368663, 'epochs': 110, 'learning_rate': 0.0006075952704347725, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.6636008024215698, Params: {'batch_size': 16, 'dropout_rate': 0.20498498636179022, 'epochs': 140, 'learning_rate': 0.0002851518857331077, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.6088529825210571, Params: {'batch_size': 64, 'dropout_rate': 0.3501743242184053, 'epochs': 50, 'learning_rate': 0.0017772008196554744, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.6719436049461365, Params: {'batch_size': 112, 'dropout_rate': 0.10078627166439251, 'epochs': 100, 'learning_rate': 4.536434021251887e-05, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 0.7102963328361511, Params: {'batch_size': 80, 'dropout_rate': 0.2846047660594256, 'epochs': 100, 'learning_rate': 0.0009099611366049236, 'num_layers': 4, 'units': 256}\n",
      "100%|███████████████████████████████████████████████| 30/30 [02:05<00:00,  4.17s/trial, best loss: 0.49218064546585083]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d3258374-1ca1-44e9-a146-561256dd2b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 96, 'dropout_rate': 0.3343967525254308, 'epochs': 120, 'learning_rate': 0.00037706456010595953, 'num_layers': 4, 'units': 160}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5fa7cb10-f438-448d-a698-855bf5004f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.5618 - loss: 0.6831 - val_accuracy: 0.4000 - val_loss: 0.7143\n",
      "Epoch 2/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.4719 - loss: 0.7069 - val_accuracy: 0.4000 - val_loss: 0.7126\n",
      "Epoch 3/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4944 - loss: 0.7105 - val_accuracy: 0.5000 - val_loss: 0.7125\n",
      "Epoch 4/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5955 - loss: 0.6973 - val_accuracy: 0.4000 - val_loss: 0.7112\n",
      "Epoch 5/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4494 - loss: 0.7208 - val_accuracy: 0.4000 - val_loss: 0.7100\n",
      "Epoch 6/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5843 - loss: 0.7032 - val_accuracy: 0.4000 - val_loss: 0.7091\n",
      "Epoch 7/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5393 - loss: 0.7037 - val_accuracy: 0.6000 - val_loss: 0.7094\n",
      "Epoch 8/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5955 - loss: 0.6724 - val_accuracy: 0.6000 - val_loss: 0.7097\n",
      "Epoch 9/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5056 - loss: 0.7002 - val_accuracy: 0.6000 - val_loss: 0.7100\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2e6ed749-e4d4-42cd-8b23-d855082b2e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.68\n",
      "F1 Score: 0.7142857142857143\n",
      "Sensitivity: 0.7692307692307693\n",
      "Specificity: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee3d94-1744-4b58-9b22-0262014da472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855d26f-7581-4a15-bb79-b0cc21c6e9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "053e8763-382c-410f-a5d7-4e9ca56015b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875e814c-720c-4647-a8e0-64ebedf98812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_15936\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5260ece-d62c-4fb7-9d5c-6fd6ce823cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values\n",
    "features_df = features_df.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9527f2-14bd-4d1f-bdc7-34c0656b043d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(features_df.values)\n",
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254e8c1a-cf5f-4737-b7b3-f8339a9e1605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(features_df.values, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4871bebb-5b19-4cac-b9cf-a97e9cc2d461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = features_df.iloc[selected_indices, :].T\n",
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962ef0b9-c391-414d-bc20-8ef1c646c788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c97ed17d-57f4-4bd9-91e0-0fe97034d576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80fe61f5-9bf3-4315-9e32-f94a75a5e38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d2c7fb2-5398-4630-a4e9-f9de7a64a922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 14:17:13,939] A new study created in memory with name: no-name-15a0a40b-0ddf-4246-a78e-1854f4bca071\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13cf811-77b1-4308-b6bb-d1cdd84f7181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 14:59:04,201] Trial 0 finished with value: 0.6907460689544678 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 4.660933131818913e-05, 'max_length': 188}. Best is trial 0 with value: 0.6907460689544678.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.690251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:01:04,821] Trial 1 finished with value: 0.6902512311935425 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.124303324757426e-05, 'max_length': 229}. Best is trial 1 with value: 0.6902512311935425.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.693609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>0.693480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:03:00,589] Trial 2 finished with value: 0.6934797763824463 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 2.1328378630002124e-05, 'max_length': 207}. Best is trial 1 with value: 0.6902512311935425.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:04:28,148] Trial 3 finished with value: 0.6948950886726379 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 2.182413528624614e-05, 'max_length': 226}. Best is trial 1 with value: 0.6902512311935425.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.690569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:05:32,459] Trial 4 finished with value: 0.6905686855316162 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 1.1403118672575394e-05, 'max_length': 158}. Best is trial 1 with value: 0.6902512311935425.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d782a3d-efe7-4fe4-8794-fdbd9fcc4ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.124303324757426e-05, 'max_length': 229}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "282abf66-47a3-4743-a960-da2573573212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c6422e8-7594-4512-925d-dc3a03a4f756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a9bcf7-d385-4d19-b872-9982ca900531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7803baf-a607-4616-b59d-9dafc9c0eda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a41535f0-fe59-47e9-a5e8-a14ee8d1d888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b113e824-50a5-4cb2-a051-868bf700d0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 08:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.724170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.722076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.748600</td>\n",
       "      <td>0.717885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=0.733118494351705, metrics={'train_runtime': 582.5795, 'train_samples_per_second': 0.51, 'train_steps_per_second': 0.021, 'total_flos': 78143983441920.0, 'train_loss': 0.733118494351705, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a69542a5-0097-4274-80bf-790451c04a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "F1 Score: 0.6842105263157895\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63ef0a-0f89-4e90-8743-b1b3dcceb9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8b01d-591c-4486-b665-5bc909a3e26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e443e3cb-7f4a-4f60-8636-861d56049ee4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a541a154-02a3-429b-aa63-7ffb23ead65f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24920\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444a86be-2cdf-4c9a-b332-1eb980cfca14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b63ff9-fc6f-44aa-b2d0-ce511113a10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af3288af-1250-4586-abbf-db50f9bcdc74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 25000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6084f870-0c6f-4f21-8986-92b0ae78a059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:2500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c54e8a4-56d7-447f-9a45-e8d4a81b7d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e88f850-1df2-45e5-83fe-f4f6a17daba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_selected)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd80d6b-2539-49e6-b6fd-2939c547bb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bcdfac-0c44-470a-8867-4e7c09d4ce46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2041fa8-e57b-4a62-a7cf-2b8f4ad0d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:46:48,366] A new study created in memory with name: no-name-6c4ffd20-e0f4-43c7-b4f8-97adc4d07b0e\n",
      "[I 2024-06-13 09:46:50,471] Trial 0 finished with value: 0.007652989588677883 and parameters: {'num_units': 129, 'learning_rate': 0.0002728687762563707, 'dropout_rate': 0.25208704343303295, 'activity_regularizer': 2.265561037381233e-06, 'batch_size': 48}. Best is trial 0 with value: 0.007652989588677883.\n",
      "[I 2024-06-13 09:46:54,270] Trial 1 finished with value: 0.007050937507301569 and parameters: {'num_units': 167, 'learning_rate': 0.00021881985022866298, 'dropout_rate': 0.03524417931876698, 'activity_regularizer': 1.260707654066861e-06, 'batch_size': 62}. Best is trial 1 with value: 0.007050937507301569.\n",
      "[I 2024-06-13 09:46:55,729] Trial 2 finished with value: 0.008443554863333702 and parameters: {'num_units': 248, 'learning_rate': 1.2862676099696006e-05, 'dropout_rate': 0.19443225808488382, 'activity_regularizer': 8.678771200812226e-06, 'batch_size': 45}. Best is trial 1 with value: 0.007050937507301569.\n",
      "[I 2024-06-13 09:46:57,554] Trial 3 finished with value: 0.006625966634601355 and parameters: {'num_units': 93, 'learning_rate': 0.0004897950595864854, 'dropout_rate': 0.23272481715653537, 'activity_regularizer': 3.390270767798302e-07, 'batch_size': 41}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:01,476] Trial 4 finished with value: 0.013493860140442848 and parameters: {'num_units': 152, 'learning_rate': 6.587598036018839e-05, 'dropout_rate': 8.705534246361557e-05, 'activity_regularizer': 5.516700363907684e-05, 'batch_size': 32}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:02,619] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:03,720] Trial 6 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:04,771] Trial 7 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 54 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000026740BAB7E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:06,105] Trial 8 finished with value: 0.007157334126532078 and parameters: {'num_units': 205, 'learning_rate': 4.209344824658562e-05, 'dropout_rate': 0.13612620627460187, 'activity_regularizer': 1.541274336418599e-07, 'batch_size': 52}. Best is trial 3 with value: 0.006625966634601355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 60 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000026740D6FBA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:07,159] Trial 9 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:08,307] Trial 10 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:09,688] Trial 11 finished with value: 0.007021911907941103 and parameters: {'num_units': 189, 'learning_rate': 0.00022396104460495274, 'dropout_rate': 0.19491192580860198, 'activity_regularizer': 7.169653781299245e-07, 'batch_size': 64}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:11,072] Trial 12 finished with value: 0.00692663062363863 and parameters: {'num_units': 197, 'learning_rate': 0.00044052503261075653, 'dropout_rate': 0.2113913429089339, 'activity_regularizer': 5.794665865475879e-07, 'batch_size': 64}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:12,085] Trial 13 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:13,052] Trial 14 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:14,824] Trial 15 finished with value: 0.0071802097372710705 and parameters: {'num_units': 198, 'learning_rate': 0.00034938310181971996, 'dropout_rate': 0.1784487723647888, 'activity_regularizer': 2.391733242475056e-07, 'batch_size': 17}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:15,836] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:17,267] Trial 17 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:47:18,267] Trial 18 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:19,281] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:20,584] Trial 20 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:47:21,599] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:22,641] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:23,757] Trial 23 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 09:47:25,036] Trial 24 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 09:47:26,038] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:27,378] Trial 26 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:47:31,174] Trial 27 finished with value: 0.006938186474144459 and parameters: {'num_units': 84, 'learning_rate': 0.0001492149524095405, 'dropout_rate': 0.13166778266267057, 'activity_regularizer': 2.065448915086333e-07, 'batch_size': 59}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:33,973] Trial 28 finished with value: 0.006980886682868004 and parameters: {'num_units': 84, 'learning_rate': 5.7833624643282506e-05, 'dropout_rate': 0.08816441308026494, 'activity_regularizer': 1.9644683065691156e-07, 'batch_size': 54}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:34,990] Trial 29 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:36,006] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:37,352] Trial 31 finished with value: 0.006641482003033161 and parameters: {'num_units': 84, 'learning_rate': 6.398055125305622e-05, 'dropout_rate': 0.08232461819119473, 'activity_regularizer': 1.5990276896788309e-07, 'batch_size': 54}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:38,372] Trial 32 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:39,946] Trial 33 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:40,950] Trial 34 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000002674A880680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:41,958] Trial 35 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 22 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x0000026748B36160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:42,976] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:43,988] Trial 37 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:45,259] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:46,277] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:47,839] Trial 40 finished with value: 0.006474638357758522 and parameters: {'num_units': 95, 'learning_rate': 4.5262992133035694e-05, 'dropout_rate': 0.13247553911660476, 'activity_regularizer': 1.1781594378365665e-06, 'batch_size': 45}. Best is trial 40 with value: 0.006474638357758522.\n",
      "[I 2024-06-13 09:47:51,739] Trial 41 finished with value: 0.006699718069285154 and parameters: {'num_units': 98, 'learning_rate': 4.4748257193749966e-05, 'dropout_rate': 0.12720930074735864, 'activity_regularizer': 1.1111085577492475e-06, 'batch_size': 44}. Best is trial 40 with value: 0.006474638357758522.\n",
      "[I 2024-06-13 09:47:52,750] Trial 42 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:53,797] Trial 43 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:54,818] Trial 44 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:55,837] Trial 45 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:56,990] Trial 46 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:58,017] Trial 47 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:59,061] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:48:00,105] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47d6798-1498-4e4d-a445-5a334ff7898e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 95, 'learning_rate': 4.5262992133035694e-05, 'dropout_rate': 0.13247553911660476, 'activity_regularizer': 1.1781594378365665e-06, 'batch_size': 45}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5e20dd-ad3b-478f-a920-65df18691d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e76dd3d5-d7c3-454d-bd64-e9ce5b3fef83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0026 - val_loss: 0.0087\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027 - val_loss: 0.0086\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0026 - val_loss: 0.0086\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0082\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0082\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0082\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0081\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 0.0080\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023 - val_loss: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x267527a3b10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87fc2193-573f-4efd-a72a-8dc761e3836c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0079\n",
      "Validation Loss:  0.007921494543552399\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ee7f56-9d7d-46bb-8970-a1809122d0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42330198-f5f3-4a5a-bc89-eedf349e32f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dfdc297-7e3f-4a82-9338-56ee513d2e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93a35bf1-defd-488d-a29e-35827e2933b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "F1 Score: 0.14285714285714285\n",
      "Sensitivity: 0.07692307692307693\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f971a-9537-4cc6-b65d-173ad91d3192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074561b9-2233-49ca-8860-9558c88731a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58d7b237-166d-4f1a-a63d-d3f053db9811",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3496e022-9d52-4719-8aff-f3cdeee791de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24920\\2580834323.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc66c03-7a40-42dc-82a1-328508f941a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc500b7b-0c68-498e-a687-9a25c8f3ab65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ea9108a-eb7f-4b2a-a5af-d05c15873263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b694cffc-4771-475d-b872-01bfbe389874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6f5f291-6f37-4fbe-b7f9-991124369a54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936 185366 237211  43149 190298   1827 192464 119497 195618]\n",
      "Top AMGM values: [1.0029745 1.0029751 1.0029768 1.0029768 1.0029768 1.0029769 1.0029773\n",
      " 1.0029789 1.0029818 1.0029832]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae6f6cde-4304-4b00-923d-456012aa7ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6339cb1d-45bf-4669-9422-8d6af33dff63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T\n",
    "X_selected = X_selected.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10dedecf-726e-4bff-a002-3a88d33ee4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1857a48b-3673-4198-b0e6-0116bdb99b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b086ea57-010b-4684-b764-79009baa7e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb5e1d04-cf55-4531-a808-a1c8dbde419e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24973087-5881-4ca6-bcd9-59a15ba9fd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56b1949a-790d-4317-9d27-8849505aeb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3d5cae1-3b1d-4ba0-b8c4-0d7946c9c654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "251322bf-3c43-4a64-8746-19485870aaa9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 676ms/step                                               \n",
      "  0%|                                                                           | 0/20 [00:26<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002674F8E8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step                                              \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:27<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026746470B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 625ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.6562072155411656, Sensitivity: 0.9649122807017544, Specificity: 0.0625\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.42857142857142855, Sensitivity: 0.4323251567833612, Specificity: 0.7416666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 593ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 581ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 584ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.7328090340794514, Sensitivity: 0.7724061284432802, Specificity: 0.6827380952380953\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 594ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 763ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 775ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 726ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.31414022718370543, Sensitivity: 0.28586171310629516, Specificity: 0.8125\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 595ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 549ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.34905149051490514, Sensitivity: 0.36500754147812975, Specificity: 0.8333333333333334\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 538ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 530ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 549ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.47474747474747475, F1 Score: 0.19853709508881923, Sensitivity: 0.18893387314439947, Specificity: 0.8095238095238096\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 580ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 570ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.32941176470588235, Sensitivity: 0.2986425339366516, Specificity: 0.8041666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 858ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 834ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4646464646464646, F1 Score: 0.4660661212734014, Sensitivity: 0.6181630546955624, Specificity: 0.36607142857142855\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 705ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 713ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 710ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.595959595959596, F1 Score: 0.6845421245421246, Sensitivity: 0.8974358974358975, Specificity: 0.2333333333333333\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 552ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 545ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7373737373737373, F1 Score: 0.6872082166199812, Sensitivity: 0.6151464634436771, Specificity: 0.8386904761904762\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 639ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 653ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6767676767676768, F1 Score: 0.6543435613203056, Sensitivity: 0.6854806700007939, Specificity: 0.6148809523809524\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 579ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 588ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4343434343434343, F1 Score: 0.3764399851356373, Sensitivity: 0.5490196078431372, Specificity: 0.4375\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 826ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 821ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 838ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 646ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.45454545454545453, F1 Score: 0.3365539452495974, Sensitivity: 0.45098039215686275, Specificity: 0.5833333333333334\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 617ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 583ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.1794871794871795, Sensitivity: 0.1794871794871795, Specificity: 0.9\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 608ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 603ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 611ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4343434343434343, F1 Score: 0.18840579710144925, Sensitivity: 0.3333333333333333, Specificity: 0.6666666666666666\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 548ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 544ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.646680216802168, Sensitivity: 0.6341986187187426, Specificity: 0.7648809523809524\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 587ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 601ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 591ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.041666666666666664, Sensitivity: 0.025641025641025644, Specificity: 0.9666666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 914ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 608ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.6586622073578595, Sensitivity: 1.0, Specificity: 0.0      \n",
      "100%|███████████████████████████████████████████████| 20/20 [21:15<00:00, 63.75s/trial, best loss: -0.7328090340794514]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f01252b-2854-4668-a27d-1c438d46bd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 3.6232954245926342e-06, 'ae_batch_size': 16.0, 'ae_dropout_rate': 0.30267607418856773, 'ae_learning_rate': 0.00016230132128846044, 'autoencoder_units': 212.0, 'encoding_dim': 19.0, 'lstm_batch_size': 55.0, 'lstm_dropout_rate': 0.40151942865068924, 'lstm_learning_rate': 0.0038207166561259197, 'lstm_units': 334.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd47bca5-a935-4b47-81b1-5e63d17acd41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfcc9151-dc6f-4369-b278-2fcf8bf76adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8b1b98b-a2a7-448b-90b5-22420d7a503d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "752d28b9-69f6-4036-b47a-d73ef41205b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.2641 - val_loss: 1.2784\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2415 - val_loss: 1.2720\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2088 - val_loss: 1.2659\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2179 - val_loss: 1.2592\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1748 - val_loss: 1.2522\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2357 - val_loss: 1.2443\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2133 - val_loss: 1.2357\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2010 - val_loss: 1.2259\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1826 - val_loss: 1.2150\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1795 - val_loss: 1.2027\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1539 - val_loss: 1.1892\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1122 - val_loss: 1.1754\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1363 - val_loss: 1.1607\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0864 - val_loss: 1.1461\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1112 - val_loss: 1.1317\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0534 - val_loss: 1.1174\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0627 - val_loss: 1.1039\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0266 - val_loss: 1.0916\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0028 - val_loss: 1.0812\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0235 - val_loss: 1.0724\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9855 - val_loss: 1.0648\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0071 - val_loss: 1.0587\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9973 - val_loss: 1.0536\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9884 - val_loss: 1.0495\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0301 - val_loss: 1.0461\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9917 - val_loss: 1.0431\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9676 - val_loss: 1.0407\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9990 - val_loss: 1.0387\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9396 - val_loss: 1.0370\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0148 - val_loss: 1.0352\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9774 - val_loss: 1.0335\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9506 - val_loss: 1.0321\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9806 - val_loss: 1.0309\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9603 - val_loss: 1.0297\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9669 - val_loss: 1.0284\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9682 - val_loss: 1.0274\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9736 - val_loss: 1.0264\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9512 - val_loss: 1.0256\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9665 - val_loss: 1.0247\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9613 - val_loss: 1.0240\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9480 - val_loss: 1.0233\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9796 - val_loss: 1.0227\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9716 - val_loss: 1.0223\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9412 - val_loss: 1.0218\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9443 - val_loss: 1.0214\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9389 - val_loss: 1.0210\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9658 - val_loss: 1.0205\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9719 - val_loss: 1.0202\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9493 - val_loss: 1.0198\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9531 - val_loss: 1.0194\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.4815 - loss: 1.0056 - val_accuracy: 0.5200 - val_loss: 0.8732\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step - accuracy: 0.5798 - loss: 0.8482 - val_accuracy: 0.4800 - val_loss: 0.6875\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - accuracy: 0.5522 - loss: 0.6514 - val_accuracy: 0.6000 - val_loss: 0.6638\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 0.6303 - loss: 0.6181 - val_accuracy: 0.8000 - val_loss: 0.6383\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 0.7589 - loss: 0.6008 - val_accuracy: 0.6800 - val_loss: 0.6105\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.7199 - loss: 0.5536 - val_accuracy: 0.7200 - val_loss: 0.5763\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7535 - loss: 0.5345 - val_accuracy: 0.7200 - val_loss: 0.5491\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - accuracy: 0.7791 - loss: 0.4770 - val_accuracy: 0.7600 - val_loss: 0.5112\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - accuracy: 0.7414 - loss: 0.5145 - val_accuracy: 0.7200 - val_loss: 0.5005\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7522 - loss: 0.4491 - val_accuracy: 0.7200 - val_loss: 0.5209\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7279 - loss: 0.5071 - val_accuracy: 0.7600 - val_loss: 0.5132\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7414 - loss: 0.4869 - val_accuracy: 0.7600 - val_loss: 0.4979\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.7273 - loss: 0.5059 - val_accuracy: 0.7600 - val_loss: 0.5139\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - accuracy: 0.7515 - loss: 0.4756 - val_accuracy: 0.7200 - val_loss: 0.5085\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - accuracy: 0.7205 - loss: 0.4725 - val_accuracy: 0.7200 - val_loss: 0.5268\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - accuracy: 0.7919 - loss: 0.4721 - val_accuracy: 0.7200 - val_loss: 0.5128\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - accuracy: 0.7535 - loss: 0.4656 - val_accuracy: 0.7200 - val_loss: 0.5033\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ce77f3d-cba3-4a1a-87d8-2024c92b9051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
      "Accuracy: 0.72\n",
      "F1 Score: 0.72\n",
      "Sensitivity: 0.6923076923076923\n",
      "Specificity: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80faa2-f4c8-470a-9930-b81f2a35d2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c9eac-2a4d-465a-bb93-182f52473a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b5448ed-04ee-40f1-ba5b-3a8478736dcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156a83b6-3bad-4a92-b595-a6e7019409d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_28552\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70085c6-a02f-4d81-8e22-3ffbc8556045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "852d2824-5617-42bc-8779-26287a31d2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a71235a-f346-4c66-8b15-73234cdb66fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065e730b-6416-48ed-9fc0-caf17d1fe3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936 185366 237211  43149 190298   1827 192464 119497 195618]\n",
      "Top AMGM values: [1.0029745 1.0029751 1.0029768 1.0029768 1.0029768 1.0029769 1.0029773\n",
      " 1.0029789 1.0029818 1.0029832]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7839531c-9945-47be-833e-80db75be7a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1534495-440f-4159-875a-98514c8949f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a1526a-f7b5-4710-80d4-b07ab600594b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa6fa48-0487-4aa3-8b43-3c9657fc04c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe28551-3cb0-4140-95da-93d129b27393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6091262-5372-40e5-a6d7-d479e2b85d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4b3d3a-635c-4763-8577-566e385a906b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61ce28ed-7121-4a6b-a1b6-5568d2928186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4149abb1-7335-4e35-b629-30ae30c88881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbb62f60-d011-45c7-875c-7ebb741f234c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c0c4a3a-d328-4aed-ab05-b53d22042000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1111580a-628c-48ce-a630-eff97a39c84a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "  0%|                                                                           | 0/20 [00:06<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000269003D91C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:08<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026900CEBD80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [07:30<00:00, 22.54s/trial, best loss: -0.6752631578947368]\n",
      "Best parameters:  {'ae_activity_reg': 1.7577538901751265e-07, 'ae_batch_size': 17.0, 'ae_dropout_rate': 0.23638913845296405, 'ae_learning_rate': 0.0008400982542766581, 'autoencoder_units': 74.0, 'encoding_dim': 20.0, 'fnn_batch_size': 37.0, 'fnn_dropout_rate': 0.4556162618056063, 'fnn_learning_rate': 0.0031621793581322255, 'fnn_units': 116.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f042186d-12cd-4060-8ae0-296f20ed2ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd55f54-fff2-4deb-9377-d908200330bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a855d829-e2ec-40f4-8e90-0bd6b987cc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Final Model - Accuracy: 0.5857894736842104\n",
      "Final Model - F1 Score: 0.5454545454545455\n",
      "Final Model - Sensitivity: 0.5354545454545454\n",
      "Final Model - Specificity: 0.65\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd815a-6093-4c57-b465-28aec27b698e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c801249-ee93-4668-8605-e9c59a68c55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "890e812d-90ad-4a97-a5c5-e7ee73c864e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da66292-4d96-496d-84cb-1f0ad7def947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a75571-898c-4fec-85d9-7cba2c54d37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d5cba03-4f8d-44ab-a105-40b74c5d1178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5f4b92e-cd9b-495e-a03e-77233896804e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_8956\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6db631f-83d3-4bdd-9ae7-8651b30f5640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cccfc3b4-9e8e-4e10-95db-b9f753d849dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ff389f4-e4a2-457c-b9ed-415d477465f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a1580d3-488e-4113-aaac-da75866b5bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3dc17b7-08c9-4730-a422-8dc5f7ecae75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aac81729-2f51-48be-92d9-5002e5cd0c7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - loss: 1.2504 - val_loss: 1.2227\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 1.2206 - val_loss: 1.1297\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 1.0438 - val_loss: 1.0251\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 0.9872 - val_loss: 1.0142\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 0.9763 - val_loss: 1.0094\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.9644 - val_loss: 0.9977\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.9512 - val_loss: 0.9854\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.9397 - val_loss: 0.9738\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 0.9299 - val_loss: 0.9637\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.9218 - val_loss: 0.9543\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.9146 - val_loss: 0.9452\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.9082 - val_loss: 0.9369\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.9028 - val_loss: 0.9298\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8983 - val_loss: 0.9240\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8947 - val_loss: 0.9190\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8916 - val_loss: 0.9147\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8889 - val_loss: 0.9111\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8867 - val_loss: 0.9080\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8847 - val_loss: 0.9055\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8831 - val_loss: 0.9035\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8816 - val_loss: 0.9019\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8804 - val_loss: 0.9003\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8793 - val_loss: 0.8991\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8784 - val_loss: 0.8981\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8776 - val_loss: 0.8974\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8769 - val_loss: 0.8967\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8763 - val_loss: 0.8960\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8757 - val_loss: 0.8953\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8752 - val_loss: 0.8949\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8747 - val_loss: 0.8944\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8744 - val_loss: 0.8940\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8740 - val_loss: 0.8936\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8736 - val_loss: 0.8933\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8733 - val_loss: 0.8930\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8730 - val_loss: 0.8927\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8727 - val_loss: 0.8924\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8725 - val_loss: 0.8921\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8723 - val_loss: 0.8919\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8720 - val_loss: 0.8917\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8718 - val_loss: 0.8915\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8717 - val_loss: 0.8913\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8715 - val_loss: 0.8911\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8713 - val_loss: 0.8909\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8712 - val_loss: 0.8907\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8710 - val_loss: 0.8905\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8709 - val_loss: 0.8904\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8708 - val_loss: 0.8903\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8707 - val_loss: 0.8902\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8706 - val_loss: 0.8901\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.8704 - val_loss: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1de2843f890>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder, encoder = create_feature_autoencoder(input_dim, encoding_dim)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65e520a2-8474-4e5b-bd71-817cba66e1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step\n",
      "Shape of encoded features: (124, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = encoder.predict(X_scaled)\n",
    "print(f\"Shape of encoded features: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81a623d6-b43d-409e-ae05-893a765a93b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after L1-based Feature Selection: (124, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+00, tolerance: 3.100e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "target_features = 200  # Target number of features\n",
    "X_final, selected_indices_l1 = apply_l1_feature_selection(X_encoded, y, alpha=0.005, target_features=target_features)\n",
    "print(f\"Shape after L1-based Feature Selection: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a636d3c2-a6ce-4148-8e5c-98d60241efb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 200)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d327dc6-f6ad-467d-8b4b-758ffdf233a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a0ce0f1-64ac-4548-8b5a-f8f9ac2ef8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e04de0e4-173c-47bc-899a-8ec385177381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cadd998-1a71-4ef5-8470-393bf25b21e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4625eb2e-2ca8-431c-b49b-dd3a6f005a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_104 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m12,864\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_105 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_106 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_107 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m13,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_108 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m201\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,257</span> (118.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,257\u001b[0m (118.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,257</span> (118.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,257\u001b[0m (118.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "493b6215-f3d7-4394-b994-fe8456a7de50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - accuracy: 0.4066 - loss: 0.7626 - val_accuracy: 0.3846 - val_loss: 0.6881 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5233 - loss: 0.6895 - val_accuracy: 0.3077 - val_loss: 0.7832 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5507 - loss: 0.7120 - val_accuracy: 0.3077 - val_loss: 0.7235 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5798 - loss: 0.6946 - val_accuracy: 0.6923 - val_loss: 0.6679 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4396 - loss: 0.7226 - val_accuracy: 0.6154 - val_loss: 0.6677 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5779 - loss: 0.6774 - val_accuracy: 0.5385 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5603 - loss: 0.6859 - val_accuracy: 0.3077 - val_loss: 0.7278 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6187 - loss: 0.6791 - val_accuracy: 0.3077 - val_loss: 0.7267 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5486 - loss: 0.7168 - val_accuracy: 0.3077 - val_loss: 0.7100 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7179 - loss: 0.6107 - val_accuracy: 0.3846 - val_loss: 0.7068 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6520 - loss: 0.6554 - val_accuracy: 0.3846 - val_loss: 0.7092 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5699 - loss: 0.6872 - val_accuracy: 0.3077 - val_loss: 0.7395 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5429 - loss: 0.6816 - val_accuracy: 0.3077 - val_loss: 0.7850 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6441 - loss: 0.6920 - val_accuracy: 0.3077 - val_loss: 0.7654 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5195 - loss: 0.6856 - val_accuracy: 0.3077 - val_loss: 0.7375 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6440 - loss: 0.6516 - val_accuracy: 0.5385 - val_loss: 0.7065 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6031 - loss: 0.6583 - val_accuracy: 0.5385 - val_loss: 0.7003 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5914 - loss: 0.6697 - val_accuracy: 0.5385 - val_loss: 0.7139 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6538 - loss: 0.6180 - val_accuracy: 0.2308 - val_loss: 0.7473 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5485 - loss: 0.6845 - val_accuracy: 0.2308 - val_loss: 0.7469 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6674 - loss: 0.6466 - val_accuracy: 0.4615 - val_loss: 0.7386 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7238 - loss: 0.6309 - val_accuracy: 0.3077 - val_loss: 0.7475 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6363 - loss: 0.6474 - val_accuracy: 0.3077 - val_loss: 0.7533 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6731 - loss: 0.6003 - val_accuracy: 0.3077 - val_loss: 0.7536 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5583 - loss: 0.7126 - val_accuracy: 0.4615 - val_loss: 0.7402 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6654 - loss: 0.6409 - val_accuracy: 0.5385 - val_loss: 0.7229 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6868 - loss: 0.6286 - val_accuracy: 0.5385 - val_loss: 0.7226 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5876 - loss: 0.6480 - val_accuracy: 0.6154 - val_loss: 0.7245 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6265 - loss: 0.6362 - val_accuracy: 0.6154 - val_loss: 0.7037 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7025 - loss: 0.5885 - val_accuracy: 0.6154 - val_loss: 0.7134 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6303 - loss: 0.6716 - val_accuracy: 0.3846 - val_loss: 0.7648 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5564 - loss: 0.7119 - val_accuracy: 0.3077 - val_loss: 0.7839 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6011 - loss: 0.6346 - val_accuracy: 0.3077 - val_loss: 0.7990 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6323 - loss: 0.6153 - val_accuracy: 0.3077 - val_loss: 0.7794 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5934 - loss: 0.6694 - val_accuracy: 0.3846 - val_loss: 0.7835 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6440 - loss: 0.6009 - val_accuracy: 0.3846 - val_loss: 0.7914 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6421 - loss: 0.6174 - val_accuracy: 0.3077 - val_loss: 0.8096 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5291 - loss: 0.6624 - val_accuracy: 0.3077 - val_loss: 0.8305 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6557 - loss: 0.5905 - val_accuracy: 0.3077 - val_loss: 0.8112 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7083 - loss: 0.6060 - val_accuracy: 0.3846 - val_loss: 0.7931 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6225 - loss: 0.6798 - val_accuracy: 0.3077 - val_loss: 0.8187 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6498 - loss: 0.6239 - val_accuracy: 0.3077 - val_loss: 0.8442 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6069 - loss: 0.6138 - val_accuracy: 0.3077 - val_loss: 0.8608 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5933 - loss: 0.6727 - val_accuracy: 0.2308 - val_loss: 0.8797 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6616 - loss: 0.6073 - val_accuracy: 0.3846 - val_loss: 0.8416 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6169 - loss: 0.6118 - val_accuracy: 0.3846 - val_loss: 0.7972 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5874 - loss: 0.6556 - val_accuracy: 0.4615 - val_loss: 0.7984 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6109 - loss: 0.6523 - val_accuracy: 0.3077 - val_loss: 0.8226 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6362 - loss: 0.6331 - val_accuracy: 0.3077 - val_loss: 0.8677 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7453 - loss: 0.6187 - val_accuracy: 0.3077 - val_loss: 0.8802 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f63df77-b18c-4d57-9191-0cd5cc4643aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "Accuracy: 0.44\n",
      "F1 Score: 0.5625\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2f05b0a-579b-4851-8505-1f3c6881d17f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e37b5f4-78ee-4291-a4a2-4dfce95291bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44\n",
      "F1 Score: 0.5625\n",
      "Specificity: 0.16666666666666666\n",
      "Sensitivity: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7887a-9362-4c12-88ed-1868dde959fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e8036-2b06-4284-a114-61b97de002c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33950000-89b2-463f-94b7-bbd8145fd3a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b16e0ef-d7d8-4392-86c6-2fa0a245ec3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60ca365c-f6ec-4f19-ae6d-3ef6c86fcf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5e6d5b3-7150-4497-ac39-b97a3e578844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "244e38b3-c5f1-4318-8629-e7f10c290aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4bcab3b0-3430-4cdd-ac39-e53d3549cf30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5, F1 Score: 0.4918032786885246, Sensitivity: 0.4838709677419355, Specificity: 0.5161290322580645          \n",
      "Accuracy: 0.45161290322580644, F1 Score: 0.45161290322580644, Sensitivity: 0.45161290322580644, Specificity: 0.45161290322580644\n",
      "Accuracy: 0.4596774193548387, F1 Score: 0.54421768707483, Sensitivity: 0.6451612903225806, Specificity: 0.27419354838709675\n",
      "Accuracy: 0.45161290322580644, F1 Score: 0.4603174603174603, Sensitivity: 0.46774193548387094, Specificity: 0.43548387096774194\n",
      "Accuracy: 0.5403225806451613, F1 Score: 0.45714285714285713, Sensitivity: 0.3870967741935484, Specificity: 0.6935483870967742\n",
      "Accuracy: 0.6048387096774194, F1 Score: 0.5585585585585585, Sensitivity: 0.5, Specificity: 0.7096774193548387          \n",
      "Accuracy: 0.5080645161290323, F1 Score: 0.5040650406504065, Sensitivity: 0.5, Specificity: 0.5161290322580645          \n",
      "Accuracy: 0.47580645161290325, F1 Score: 0.21686746987951808, Sensitivity: 0.14516129032258066, Specificity: 0.8064516129032258\n",
      "Accuracy: 0.5725806451612904, F1 Score: 0.5225225225225225, Sensitivity: 0.46774193548387094, Specificity: 0.6774193548387096\n",
      "Accuracy: 0.5483870967741935, F1 Score: 0.5483870967741935, Sensitivity: 0.5483870967741935, Specificity: 0.5483870967741935\n",
      "Accuracy: 0.5887096774193549, F1 Score: 0.5142857142857142, Sensitivity: 0.43548387096774194, Specificity: 0.7419354838709677\n",
      "Accuracy: 0.45161290322580644, F1 Score: 0.46875, Sensitivity: 0.4838709677419355, Specificity: 0.41935483870967744    \n",
      "Accuracy: 0.4435483870967742, F1 Score: 0.4566929133858268, Sensitivity: 0.46774193548387094, Specificity: 0.41935483870967744\n",
      "Accuracy: 0.41935483870967744, F1 Score: 0.4461538461538462, Sensitivity: 0.46774193548387094, Specificity: 0.3709677419354839\n",
      "Accuracy: 0.43548387096774194, F1 Score: 0.375, Sensitivity: 0.3387096774193548, Specificity: 0.532258064516129        \n",
      "Accuracy: 0.4112903225806452, F1 Score: 0.44274809160305345, Sensitivity: 0.46774193548387094, Specificity: 0.3548387096774194\n",
      "Accuracy: 0.5403225806451613, F1 Score: 0.5210084033613446, Sensitivity: 0.5, Specificity: 0.5806451612903226          \n",
      "Accuracy: 0.4596774193548387, F1 Score: 0.5109489051094891, Sensitivity: 0.5645161290322581, Specificity: 0.3548387096774194\n",
      "Accuracy: 0.5080645161290323, F1 Score: 0.5547445255474452, Sensitivity: 0.6129032258064516, Specificity: 0.4032258064516129\n",
      "Accuracy: 0.5, F1 Score: 0.3541666666666667, Sensitivity: 0.27419354838709675, Specificity: 0.7258064516129032         \n",
      "100%|███████████████████████████████████████████████| 20/20 [07:53<00:00, 23.67s/trial, best loss: -0.5585585585585585]\n",
      "Best parameters found:  {'batch_size': 80.0, 'dropout_rate': 0.5556606481192463, 'epochs': 100.0, 'learning_rate': 0.009485792460813571, 'neurons1': 32.0, 'neurons2': 48.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c83ac28e-a8c2-4c96-8dd4-ce6c6e212929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6048387096774194\n",
      "Best F1 Score: 0.5585585585585585\n",
      "Best Specificity: 0.7096774193548387\n",
      "Best Sensitivity: 0.5\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df378319-20a0-4336-9abd-ae57813864db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_121\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_121\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_609 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_242 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_610 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_243 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_611 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_612 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_613 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_609 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m6,432\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_242 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_610 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │           \u001b[38;5;34m1,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_243 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_611 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,568\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_612 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │           \u001b[38;5;34m6,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_613 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m201\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,385</span> (64.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,385\u001b[0m (64.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,385</span> (64.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,385\u001b[0m (64.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_final.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a57f6326-b82a-4d02-9702-7028b11b303c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 32\n",
      "Neurons in second layer: 48\n",
      "Dropout rate: 0.5556606481192463\n",
      "Learning rate: 0.009485792460813571\n",
      "Number of epochs: 100\n",
      "Batch size: 80\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549aedc4-1da4-4145-88b3-8c6efa91ac82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f2922ce-024f-4740-9620-de13223b5c39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "168f6e9b-c0fd-47be-9764-6d3e94c99b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b49c7443-588d-44f3-918b-e07271ac7074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5610fb5-be75-4dca-9dde-7450b66e8b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 64)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99267302-a85b-41d4-b948-0d35d84a167b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3556744-e9d2-413e-939f-c19c836ffeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.4545454545454546, F1 Score: 0.39454545454545453, Sensitivity: 0.3568627450980392, Specificity: 0.5430555555555555\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.604074702886248, Sensitivity: 0.5986928104575163, Specificity: 0.6069444444444444\n",
      "Iteration Results - Accuracy: 0.4646464646464647, F1 Score: 0.44086845466155805, Sensitivity: 0.41612200435729846, Specificity: 0.5069444444444444\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.6886107959916808, Sensitivity: 0.8063180827886711, Specificity: 0.48425925925925933\n",
      "Iteration Results - Accuracy: 0.5757575757575757, F1 Score: 0.5606375606375607, Sensitivity: 0.5869281045751634, Specificity: 0.5759259259259258\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.5238095238095238, Sensitivity: 0.5287581699346405, Specificity: 0.5513888888888889\n",
      "Iteration Results - Accuracy: 0.41414141414141414, F1 Score: 0.43164417282064343, Sensitivity: 0.4383442265795207, Specificity: 0.3925925925925926\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.5833333333333334, Sensitivity: 0.6559912854030502, Specificity: 0.39675925925925926\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.6435666435666435, Sensitivity: 0.7045751633986929, Specificity: 0.5180555555555555\n",
      "Iteration Results - Accuracy: 0.48484848484848486, F1 Score: 0.5338624338624338, Sensitivity: 0.6004357298474945, Specificity: 0.3680555555555555\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.4677791344458011, Sensitivity: 0.4313725490196078, Specificity: 0.6662037037037037\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.5107323232323232, Sensitivity: 0.5278867102396515, Specificity: 0.4837962962962963\n",
      "Iteration Results - Accuracy: 0.5959595959595959, F1 Score: 0.5837406321277289, Sensitivity: 0.5664488017429193, Specificity: 0.6351851851851852\n",
      "Iteration Results - Accuracy: 0.4646464646464647, F1 Score: 0.4719660837307897, Sensitivity: 0.48431372549019613, Specificity: 0.44675925925925924\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.624221844934918, Sensitivity: 0.6904139433551197, Specificity: 0.537962962962963\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.5609031491384432, Sensitivity: 0.583442265795207, Specificity: 0.5097222222222223\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.5662393162393163, Sensitivity: 0.6167755991285403, Specificity: 0.41759259259259257\n",
      "Iteration Results - Accuracy: 0.47474747474747475, F1 Score: 0.47385620915032683, Sensitivity: 0.47385620915032683, Specificity: 0.4689814814814815\n",
      "Iteration Results - Accuracy: 0.4646464646464647, F1 Score: 0.4468022399056882, Sensitivity: 0.4335511982570806, Specificity: 0.4847222222222222\n",
      "Iteration Results - Accuracy: 0.4545454545454546, F1 Score: 0.44377135756446107, Sensitivity: 0.434640522875817, Specificity: 0.46527777777777773\n",
      "100%|███████████████████████████████████████████████| 20/20 [28:05<00:00, 84.27s/trial, best loss: -0.6886107959916808]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bad32715-f08e-481e-b506-0db2ce934e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 192, 'dropout_rate': 0.44416329669632715, 'learning_rate': 0.00019730045390295713, 'epochs': 30, 'batch_size': 64, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "beb9feb0-db34-42a7-a2f9-50a700aedfc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.64\n",
      "F1 Score: 0.6086956521739131\n",
      "Sensitivity: 0.5833333333333334\n",
      "Specificity: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a13ffe-7106-4df6-9db4-c3de401bbb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e3cb33-e44d-43b9-b70d-c81ade5f9113",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GRU with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53f0e7a0-6ab3-45ec-9d56-a9933c17ee0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a0650d7-f2ff-4835-9d00-7eafc30a5c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3258ddae-cf08-4132-800c-b8b27d73b05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0abea934-4487-4c52-8cb5-012c40b8c995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 128, 64)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3450ac81-1bec-4140-aed1-702c3e41ef50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4a5b402-92f9-4789-8192-9995347a4c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.31384615384615383, Sensitivity: 0.27149321266968324, Specificity: 0.8375\n",
      "Iteration Results - Accuracy: 0.5858585858585859, F1 Score: 0.5609324009324009, Sensitivity: 0.5563229340319124, Specificity: 0.5904761904761905\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.3723409207280175, Sensitivity: 0.31618639358577444, Specificity: 0.8023809523809523\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.5367290367290368, Sensitivity: 0.4820195284591569, Specificity: 0.7113095238095237\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.49382716049382713, Sensitivity: 0.4653488925934746, Specificity: 0.6839285714285714\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.42512077294685985, Sensitivity: 0.41819480828768757, Specificity: 0.6815476190476191\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.47828282828282837, Sensitivity: 0.4842422799079145, Specificity: 0.4904761904761905\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.2846376811594203, Sensitivity: 0.20401682940382634, Specificity: 0.8273809523809524\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.5355334935098296, Sensitivity: 0.6563467492260062, Specificity: 0.4577380952380952\n",
      "Iteration Results - Accuracy: 0.5959595959595959, F1 Score: 0.49639766844067923, Sensitivity: 0.4058109073588949, Specificity: 0.7755952380952381\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.620050844471293, Sensitivity: 0.7299356989759467, Specificity: 0.44226190476190474\n",
      "Iteration Results - Accuracy: 0.5555555555555556, F1 Score: 0.5652540913006029, Sensitivity: 0.6017305707708185, Specificity: 0.4863095238095238\n",
      "Iteration Results - Accuracy: 0.616161616161616, F1 Score: 0.52046783625731, Sensitivity: 0.49503850123045173, Specificity: 0.6863095238095238\n",
      "Iteration Results - Accuracy: 0.48484848484848486, F1 Score: 0.4793650793650794, Sensitivity: 0.5278240850996269, Specificity: 0.5017857142857144\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.3181376865587392, Sensitivity: 0.3041200285782329, Specificity: 0.7428571428571429\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.5024966508342468, Sensitivity: 0.47408113042787964, Specificity: 0.6142857142857143\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.5972582972582973, Sensitivity: 0.5645788679844408, Specificity: 0.6964285714285715\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.4343025395656975, Sensitivity: 0.4080336588076527, Specificity: 0.6577380952380952\n",
      "Iteration Results - Accuracy: 0.6464646464646465, F1 Score: 0.6144636015325671, Sensitivity: 0.5766452329919822, Specificity: 0.7327380952380952\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.33714285714285713, Sensitivity: 0.26077637532745895, Specificity: 0.7827380952380952\n",
      "100%|█████████████████████████████████████████████| 20/20 [2:42:31<00:00, 487.56s/trial, best loss: -0.620050844471293]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a833d91-e41e-4e4b-8656-2be4a67c6bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 48, 'dropout_rate': 0.3545132814001993, 'epochs': 20, 'learning_rate': 0.003061272390130812, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)  \n",
    "print(\"Best Parameters:\", best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65278dd4-b5c4-417a-8c66-6882994903ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b47c42ee-b1f8-49e6-8310-d06af77066dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ece2fd4b-7d47-40db-bdff-33c2ec5ae1f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e92741bd10>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e30f460f-38e4-4df0-9906-27dbc326cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.48\n",
      "F1 Score: 0.5806451612903226\n",
      "Sensitivity: 0.6923076923076923\n",
      "Specificity: 0.25\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce962fdc-0063-4139-9576-1e1df44bdfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "543f3f15-9694-4738-8031-776579d06a73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3393a0d1-40b6-4ab1-a2ed-2b1e7eeb01e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37766382-6c62-4144-bcee-eafe7c94b26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a792721f-75fd-412b-9906-28d5c82eed48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "db83ee95-106e-4334-b2cb-9691d2c007b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8f2597ac-645a-433b-8f3a-2b694036da05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a0dcd66-dfe5-4b06-ae64-63bcb7534c30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.24221844934917938, Sensitivity: 0.24434389140271495, Specificity: 0.8333333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.15151515151515152, Sensitivity: 0.12820512820512822, Specificity: 0.9333333333333332\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "Iteration Results - Accuracy: 0.606060606060606, F1 Score: 0.5841269841269842, Sensitivity: 0.6185599745971263, Specificity: 0.5154761904761904\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.24848484848484845, Sensitivity: 0.2277526395173454, Specificity: 0.7708333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.1442495126705653, Sensitivity: 0.0904977375565611, Specificity: 0.9500000000000001\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.2864542864542865, Sensitivity: 0.20989124394697148, Specificity: 0.8690476190476191\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.4166666666666667, Sensitivity: 0.3526236405493372, Specificity: 0.7482142857142856\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.25925925925925924, Sensitivity: 0.19457013574660634, Specificity: 0.8833333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.20350877192982456, Sensitivity: 0.167420814479638, Specificity: 0.8833333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.4646464646464647, F1 Score: 0.2333333333333333, Sensitivity: 0.26998491704374056, Specificity: 0.7458333333333332\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.24492753623188404, Sensitivity: 0.1870286576168929, Specificity: 0.9166666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6161616161616162, F1 Score: 0.5733333333333334, Sensitivity: 0.5872826863538938, Specificity: 0.5863095238095238\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5757575757575758, F1 Score: 0.41203703703703703, Sensitivity: 0.40438199571326505, Specificity: 0.6660714285714285\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.30462324393358875, Sensitivity: 0.2692704612209256, Specificity: 0.8023809523809523\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.1388888888888889, Sensitivity: 0.09803921568627451, Specificity: 0.9583333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.48484848484848486, F1 Score: 0.2966507177033493, Sensitivity: 0.334841628959276, Specificity: 0.7291666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.1239766081871345, Sensitivity: 0.0708898944193062, Specificity: 0.9553571428571429\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.14444444444444446, Sensitivity: 0.08446455505279034, Specificity: 0.9595238095238096\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.3145424836601307, Sensitivity: 0.3846153846153846, Specificity: 0.6511904761904762\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.22890559732664995, Sensitivity: 0.167420814479638, Specificity: 0.9023809523809524\n",
      "100%|███████████████████████████████████████████████| 20/20 [02:58<00:00,  8.94s/trial, best loss: -0.5841269841269842]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "664114e7-1180-4f34-a6dd-5511f952c362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.2324228757632982, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0035436994104258565}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17491953-9769-4824-a93e-fc31aa199916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e7fc4165-2f15-4543-980a-f83e435a73b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e9418df750>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "66750755-12c3-492e-b826-0b3e89e30d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d994f7b-0ad8-446d-b515-787da017a350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.56\n",
      "F1 Score: 0.42105263157894735\n",
      "Sensitivity: 0.3076923076923077\n",
      "Specificity: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8fa7d-2ff8-4267-8c8b-ab0000c8c97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e218e0-44ea-4a5b-b4a8-b23dd5ca0996",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "98db27e6-4203-4011-99c7-d165b5a07d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5b51feee-a848-4b2c-b3d0-f06fdd3b2c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3fc8fc5f-45a9-4069-bb26-826c53d80249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fe14b414-fda4-4678-a72f-2a98afafdb23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f19484e-215c-4417-be0f-191fdfe38491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ff6e8e31-26f2-46c5-af05-cdcef56059ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "548e8170-5ce2-4523-bce5-c6a71b15d2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4693437367877114, 'epochs': 30, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0006942028292450598, 'num_blocks': 8}\n",
      "Iteration - Loss: 6.252742767333984, Filters: 64, Blocks: 8, Kernel Size: 4, Dropout: 0.4693437367877114, LR: 0.0006942028292450598, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.45291562420971415, 'epochs': 50, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.004606136894105526, 'num_blocks': 8}\n",
      "Iteration - Loss: 104.64173889160156, Filters: 96, Blocks: 8, Kernel Size: 3, Dropout: 0.45291562420971415, LR: 0.004606136894105526, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3643113724097633, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0026259204192940326, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.7366045117378235, Filters: 64, Blocks: 4, Kernel Size: 4, Dropout: 0.3643113724097633, LR: 0.0026259204192940326, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.43853533622369534, 'epochs': 40, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0009618353237234411, 'num_blocks': 6}\n",
      "Iteration - Loss: 8.837919235229492, Filters: 128, Blocks: 6, Kernel Size: 4, Dropout: 0.43853533622369534, LR: 0.0009618353237234411, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.2393498658688416, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0020746688160868014, 'num_blocks': 6}\n",
      "Iteration - Loss: 15.672770500183105, Filters: 128, Blocks: 6, Kernel Size: 4, Dropout: 0.2393498658688416, LR: 0.0020746688160868014, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.25524751746359, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0001567996496239181, 'num_blocks': 8}\n",
      "Iteration - Loss: 3.8464035987854004, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.25524751746359, LR: 0.0001567996496239181, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.39665203881746736, 'epochs': 20, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0007343311354172891, 'num_blocks': 4}\n",
      "Iteration - Loss: 1.0381840467453003, Filters: 96, Blocks: 4, Kernel Size: 4, Dropout: 0.39665203881746736, LR: 0.0007343311354172891, Batch Size: 32, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3068335368432805, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0001232147989916135, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.8120969533920288, Filters: 64, Blocks: 4, Kernel Size: 3, Dropout: 0.3068335368432805, LR: 0.0001232147989916135, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.2577867362742431, 'epochs': 50, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.0002444796577618306, 'num_blocks': 8}\n",
      "Iteration - Loss: 3.1933860778808594, Filters: 128, Blocks: 8, Kernel Size: 5, Dropout: 0.2577867362742431, LR: 0.0002444796577618306, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.22729196404089425, 'epochs': 30, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.00011905407193863802, 'num_blocks': 10}\n",
      "Iteration - Loss: 5.459480285644531, Filters: 96, Blocks: 10, Kernel Size: 4, Dropout: 0.22729196404089425, LR: 0.00011905407193863802, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.37313151577276626, 'epochs': 40, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.0007036038425428074, 'num_blocks': 10}\n",
      "Iteration - Loss: 1.1479511260986328, Filters: 32, Blocks: 10, Kernel Size: 4, Dropout: 0.37313151577276626, LR: 0.0007036038425428074, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4851665221468972, 'epochs': 40, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0035930472476146257, 'num_blocks': 6}\n",
      "Iteration - Loss: 51.53682327270508, Filters: 128, Blocks: 6, Kernel Size: 4, Dropout: 0.4851665221468972, LR: 0.0035930472476146257, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.41715759354500037, 'epochs': 20, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.00030514215084321417, 'num_blocks': 8}\n",
      "Iteration - Loss: 2.3539624214172363, Filters: 32, Blocks: 8, Kernel Size: 5, Dropout: 0.41715759354500037, LR: 0.00030514215084321417, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.23731248117203485, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.00260400695466459, 'num_blocks': 8}\n",
      "Iteration - Loss: 41.65218734741211, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.23731248117203485, LR: 0.00260400695466459, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.28081733532921904, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0003888776671291912, 'num_blocks': 6}\n",
      "Iteration - Loss: 4.323220252990723, Filters: 128, Blocks: 6, Kernel Size: 4, Dropout: 0.28081733532921904, LR: 0.0003888776671291912, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.4111653570988403, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.008500234524179905, 'num_blocks': 6}\n",
      "Iteration - Loss: 83.55736541748047, Filters: 64, Blocks: 6, Kernel Size: 4, Dropout: 0.4111653570988403, LR: 0.008500234524179905, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.38605638425709865, 'epochs': 40, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0007459358861765855, 'num_blocks': 10}\n",
      "Iteration - Loss: 19.6513729095459, Filters: 128, Blocks: 10, Kernel Size: 4, Dropout: 0.38605638425709865, LR: 0.0007459358861765855, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3078897123470462, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0005910851893911127, 'num_blocks': 10}\n",
      "Iteration - Loss: 8.275413513183594, Filters: 96, Blocks: 10, Kernel Size: 4, Dropout: 0.3078897123470462, LR: 0.0005910851893911127, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.2634675398011933, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.00618627508651537, 'num_blocks': 6}\n",
      "Iteration - Loss: 8.9541015625, Filters: 128, Blocks: 6, Kernel Size: 4, Dropout: 0.2634675398011933, LR: 0.00618627508651537, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.2195202241207907, 'epochs': 40, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.002465569088194434, 'num_blocks': 8}\n",
      "Iteration - Loss: 11.880029678344727, Filters: 64, Blocks: 8, Kernel Size: 3, Dropout: 0.2195202241207907, LR: 0.002465569088194434, Batch Size: 16, Epochs: 40\n",
      "100%|████████████████████████████████████████████████| 20/20 [06:21<00:00, 19.10s/trial, best loss: 0.7366045117378235]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9331d8a6-5a03-4e08-9576-e10647b17708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 16, 'dropout_rate': 0.3643113724097633, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0026259204192940326, 'num_blocks': 4}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "117e0697-3576-45d0-a47c-0b34cf8efaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3105d7c7-4366-4c0e-9c35-df8d385f685e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.4613 - loss: 6.8168 - val_accuracy: 0.2000 - val_loss: 1.0237\n",
      "Epoch 2/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5229 - loss: 5.0550 - val_accuracy: 0.3000 - val_loss: 0.9385\n",
      "Epoch 3/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5545 - loss: 4.6769 - val_accuracy: 0.4000 - val_loss: 0.8349\n",
      "Epoch 4/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.4380 - loss: 4.6514 - val_accuracy: 0.6000 - val_loss: 0.7122\n",
      "Epoch 5/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.4613 - loss: 5.2137 - val_accuracy: 0.5000 - val_loss: 0.6110\n",
      "Epoch 6/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5037 - loss: 3.6969 - val_accuracy: 0.7000 - val_loss: 0.6238\n",
      "Epoch 7/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4921 - loss: 3.8474 - val_accuracy: 0.6000 - val_loss: 0.6435\n",
      "Epoch 8/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.4846 - loss: 3.5064 - val_accuracy: 0.5000 - val_loss: 0.6865\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2c930715-6e6f-4682-942a-0047557e5d65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b08b1225-dce7-4704-aa90-e99681496884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.44\n",
      "F1 Score: 0.5882352941176471\n",
      "Sensitivity: 0.7692307692307693\n",
      "Specificity: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc30321-8377-4460-9cf8-2d6df37381ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23cb7569-59fc-42ed-8898-1d7c1d9631a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "072828b6-8e7d-4ec8-b95e-2dbea1c12708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "99859eb0-2b6d-4b5e-8ef4-92facb1227b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5b8771a2-ed83-46ea-a653-cb3a32cb0a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a9752ba-d868-43d2-a2ed-a41fa9a8764a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a24430e9-967d-4224-adfa-f81f0b5eb62e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "76156fb8-0768-431e-a9bb-a4aed0a5f0db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 5.005087852478027, Params: {'batch_size': 32, 'dropout_rate': 0.34446814085572264, 'epochs': 130, 'learning_rate': 3.5514231290050716e-05, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 2.04006290435791, Params: {'batch_size': 80, 'dropout_rate': 0.4177347508931756, 'epochs': 150, 'learning_rate': 0.0005912346096288274, 'num_layers': 6, 'units': 160}\n",
      "Iteration - Loss: 0.9107105135917664, Params: {'batch_size': 16, 'dropout_rate': 0.43023579265974365, 'epochs': 90, 'learning_rate': 0.0005143105125823063, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 7.516861915588379, Params: {'batch_size': 112, 'dropout_rate': 0.19816841902370932, 'epochs': 50, 'learning_rate': 0.0018686876049934496, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 2.305375099182129, Params: {'batch_size': 32, 'dropout_rate': 0.25713793671864915, 'epochs': 80, 'learning_rate': 9.184054035720839e-05, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 4.395810127258301, Params: {'batch_size': 32, 'dropout_rate': 0.4576188313102837, 'epochs': 110, 'learning_rate': 0.00021502265588057567, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 2.2183737754821777, Params: {'batch_size': 32, 'dropout_rate': 0.4926924011481715, 'epochs': 70, 'learning_rate': 5.85293555015792e-05, 'num_layers': 6, 'units': 160}\n",
      "Iteration - Loss: 15.267951965332031, Params: {'batch_size': 80, 'dropout_rate': 0.39694973611837714, 'epochs': 140, 'learning_rate': 0.003156107019823297, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 4.134657859802246, Params: {'batch_size': 128, 'dropout_rate': 0.1192625893446389, 'epochs': 120, 'learning_rate': 0.0028802283675222794, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 10.30055046081543, Params: {'batch_size': 64, 'dropout_rate': 0.4365884058751942, 'epochs': 60, 'learning_rate': 0.00019138820100003925, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.6720786094665527, Params: {'batch_size': 32, 'dropout_rate': 0.31999352663538194, 'epochs': 100, 'learning_rate': 0.008239995790383347, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 0.6063021421432495, Params: {'batch_size': 128, 'dropout_rate': 0.14382206024586217, 'epochs': 50, 'learning_rate': 0.007253263464254533, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 7.1528730392456055, Params: {'batch_size': 48, 'dropout_rate': 0.13737065604639687, 'epochs': 100, 'learning_rate': 0.002169970658453109, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 19.25946044921875, Params: {'batch_size': 48, 'dropout_rate': 0.34283356074309224, 'epochs': 70, 'learning_rate': 6.002001075435443e-05, 'num_layers': 2, 'units': 160}\n",
      "Iteration - Loss: 5.42494535446167, Params: {'batch_size': 96, 'dropout_rate': 0.24911803945038807, 'epochs': 120, 'learning_rate': 1.803397078169875e-05, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 7.3469085693359375, Params: {'batch_size': 80, 'dropout_rate': 0.3002932419555002, 'epochs': 90, 'learning_rate': 8.725945824071753e-05, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 1.9529523849487305, Params: {'batch_size': 96, 'dropout_rate': 0.1793197640211439, 'epochs': 110, 'learning_rate': 0.0001257961979103201, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 1.9539905786514282, Params: {'batch_size': 32, 'dropout_rate': 0.1103680050223693, 'epochs': 70, 'learning_rate': 6.180398099220139e-05, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 4.216381072998047, Params: {'batch_size': 48, 'dropout_rate': 0.19741190719849763, 'epochs': 130, 'learning_rate': 5.499839338941093e-05, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 2.878499746322632, Params: {'batch_size': 32, 'dropout_rate': 0.2611745767222833, 'epochs': 100, 'learning_rate': 9.124488782528778e-05, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.7167271375656128, Params: {'batch_size': 128, 'dropout_rate': 0.36943969283579603, 'epochs': 50, 'learning_rate': 0.009655079543421888, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 0.7191122770309448, Params: {'batch_size': 112, 'dropout_rate': 0.3013153123909014, 'epochs': 90, 'learning_rate': 0.00997323620013783, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 0.7405430674552917, Params: {'batch_size': 16, 'dropout_rate': 0.22189916712155383, 'epochs': 80, 'learning_rate': 0.005703421895278742, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 3.332176685333252, Params: {'batch_size': 64, 'dropout_rate': 0.15790987016278019, 'epochs': 110, 'learning_rate': 0.0010573204774524674, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 0.626512885093689, Params: {'batch_size': 112, 'dropout_rate': 0.3212158259756912, 'epochs': 60, 'learning_rate': 0.005462942390802946, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 0.6812769174575806, Params: {'batch_size': 112, 'dropout_rate': 0.2742473758519143, 'epochs': 60, 'learning_rate': 0.00532561667346633, 'num_layers': 6, 'units': 64}\n",
      "Iteration - Loss: 1.532475471496582, Params: {'batch_size': 128, 'dropout_rate': 0.3812291110805896, 'epochs': 60, 'learning_rate': 0.0012438752821796286, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 2.416074514389038, Params: {'batch_size': 96, 'dropout_rate': 0.22377922001133538, 'epochs': 50, 'learning_rate': 0.004970690606845147, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 2.625032424926758, Params: {'batch_size': 112, 'dropout_rate': 0.34150317807359754, 'epochs': 60, 'learning_rate': 0.0006354449148142546, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 1.3822139501571655, Params: {'batch_size': 128, 'dropout_rate': 0.4985297143558647, 'epochs': 50, 'learning_rate': 0.0012754434174311877, 'num_layers': 6, 'units': 192}\n",
      "100%|████████████████████████████████████████████████| 30/30 [01:10<00:00,  2.36s/trial, best loss: 0.6063021421432495]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "daff3872-1bc8-4930-8844-89b36e964573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 128, 'dropout_rate': 0.14382206024586217, 'epochs': 50, 'learning_rate': 0.007253263464254533, 'num_layers': 4, 'units': 192}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7531cdcc-493a-45c0-9eb8-74030212a435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.4270 - loss: 9.5144 - val_accuracy: 0.5000 - val_loss: 98.6418\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5056 - loss: 98.3197 - val_accuracy: 0.3000 - val_loss: 5.3495\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6180 - loss: 3.9673 - val_accuracy: 0.4000 - val_loss: 4.0644\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5730 - loss: 3.6939 - val_accuracy: 0.5000 - val_loss: 8.0773\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.5169 - loss: 8.0784 - val_accuracy: 0.4000 - val_loss: 2.2591\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6404 - loss: 2.1791 - val_accuracy: 0.5000 - val_loss: 4.3893\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5056 - loss: 4.0707 - val_accuracy: 0.5000 - val_loss: 3.1943\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5618 - loss: 2.7816 - val_accuracy: 0.4000 - val_loss: 2.0683\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6742 - loss: 1.0818 - val_accuracy: 0.4000 - val_loss: 3.0749\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6404 - loss: 1.5009 - val_accuracy: 0.4000 - val_loss: 3.1999\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.6292 - loss: 1.3385 - val_accuracy: 0.4000 - val_loss: 2.4564\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "47c23380-36e0-4213-98d2-325e5e492d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.44\n",
      "F1 Score: 0.46153846153846156\n",
      "Sensitivity: 0.46153846153846156\n",
      "Specificity: 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34488be3-8ad5-4f8a-b7fc-454597c820f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e54f6c83-7c9f-43ea-8909-e7a6a86f4acb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "57ce0cb6-0508-4cae-85c5-ee6bbc50f48e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_final]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bbc3e0de-8893-4bb4-b0aa-d44e5d79a783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d5d00f6e-144e-4355-ae09-14e1dae51497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "54c6128b-6069-4c56-b617-8264fad0067e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:07:01,937] A new study created in memory with name: no-name-ba0c0d41-8749-4ba2-8010-30f6b829ca84\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f5f56568-8b20-479d-b163-a34b14e294c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 01:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:09:25,580] Trial 0 finished with value: 0.6900699734687805 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 1.803102779321941e-05, 'max_length': 218}. Best is trial 0 with value: 0.6900699734687805.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 01:52, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:11:48,175] Trial 1 finished with value: 0.6943137645721436 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 3.718582759274501e-05, 'max_length': 228}. Best is trial 0 with value: 0.6900699734687805.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:14:18,665] Trial 2 finished with value: 0.6952176690101624 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 1.2451919923127736e-05, 'max_length': 247}. Best is trial 0 with value: 0.6900699734687805.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 01:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>0.693593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:16:13,199] Trial 3 finished with value: 0.6935932636260986 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 3.68504007584774e-05, 'max_length': 184}. Best is trial 0 with value: 0.6900699734687805.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 01:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693700</td>\n",
       "      <td>0.691095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:17:58,603] Trial 4 finished with value: 0.6910953521728516 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 2.5544876343183643e-05, 'max_length': 171}. Best is trial 0 with value: 0.6900699734687805.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "03bc031b-8d59-4239-bfbe-6f9259fb4fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 1.803102779321941e-05, 'max_length': 218}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9b831581-8c11-4901-a755-131b383708a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "41129310-49b1-48ba-a61d-14813018ea7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2ee704d3-9c80-4ee9-a25f-e33ee32200a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d4e53780-2856-4f24-8808-594424ab1c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5171edbf-a9e1-423a-bffb-2195517a4c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0169c96f-1e70-42cb-8d0c-e5d1c61adc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 08:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.715650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.711464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8, training_loss=0.7401257753372192, metrics={'train_runtime': 593.1816, 'train_samples_per_second': 0.334, 'train_steps_per_second': 0.013, 'total_flos': 52095988961280.0, 'train_loss': 0.7401257753372192, 'epoch': 2.0})"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c0e13899-b4f7-4a8e-8aaf-c66dae3f3b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "F1 Score: 0.6842105263157895\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37649ae3-3f9a-4e70-acd1-bce872508ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab06abec-3950-48f2-81e3-a672ad5a7cae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "30379290-a887-4fa1-8538-d741dc15bf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val= train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "65a55a7f-50c1-4e8a-9734-d663be9f1590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "75fa6b37-bf4a-4466-91bb-59197518a3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "79c32d2d-7e30-466e-91a6-f75c7fb5a988",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:28:18,738] A new study created in memory with name: no-name-8d4f19de-217b-4d5e-9db6-a23baf5ef1c9\n",
      "[I 2024-06-21 14:28:31,374] Trial 0 finished with value: 2775.833740234375 and parameters: {'num_units': 101, 'learning_rate': 0.00015551037714857355, 'dropout_rate': 0.006402032221802034, 'activity_regularizer': 1.3492912269250242e-06, 'batch_size': 17}. Best is trial 0 with value: 2775.833740234375.\n",
      "[I 2024-06-21 14:28:38,847] Trial 1 finished with value: 2781.132080078125 and parameters: {'num_units': 121, 'learning_rate': 0.00012135370337298755, 'dropout_rate': 0.006478062713871235, 'activity_regularizer': 3.670311950158564e-06, 'batch_size': 40}. Best is trial 0 with value: 2775.833740234375.\n",
      "[I 2024-06-21 14:28:46,279] Trial 2 finished with value: 2792.250732421875 and parameters: {'num_units': 77, 'learning_rate': 1.0469413757671409e-05, 'dropout_rate': 0.05481741289526262, 'activity_regularizer': 4.506646776276952e-07, 'batch_size': 34}. Best is trial 0 with value: 2775.833740234375.\n",
      "[I 2024-06-21 14:28:58,667] Trial 3 finished with value: 2774.83349609375 and parameters: {'num_units': 152, 'learning_rate': 0.00011219724841735306, 'dropout_rate': 0.04118846582965726, 'activity_regularizer': 2.7138098208912807e-05, 'batch_size': 19}. Best is trial 3 with value: 2774.83349609375.\n",
      "[I 2024-06-21 14:29:04,634] Trial 4 finished with value: 2788.111572265625 and parameters: {'num_units': 70, 'learning_rate': 9.732555301436804e-05, 'dropout_rate': 0.14873159162831043, 'activity_regularizer': 1.0855088139090484e-06, 'batch_size': 53}. Best is trial 3 with value: 2774.83349609375.\n",
      "[I 2024-06-21 14:29:04,955] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:05,243] Trial 6 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:05,601] Trial 7 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:05,868] Trial 8 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:16,772] Trial 9 finished with value: 2772.006591796875 and parameters: {'num_units': 132, 'learning_rate': 0.0001864423500252283, 'dropout_rate': 0.04675222846152216, 'activity_regularizer': 4.672625513821357e-07, 'batch_size': 23}. Best is trial 9 with value: 2772.006591796875.\n",
      "[I 2024-06-21 14:29:24,314] Trial 10 finished with value: 2769.961181640625 and parameters: {'num_units': 189, 'learning_rate': 0.000878661786299172, 'dropout_rate': 0.1646947680477891, 'activity_regularizer': 7.3636731773693385e-06, 'batch_size': 33}. Best is trial 10 with value: 2769.961181640625.\n",
      "[I 2024-06-21 14:29:33,426] Trial 11 finished with value: 2769.8076171875 and parameters: {'num_units': 181, 'learning_rate': 0.0007697808931697665, 'dropout_rate': 0.17817372086163763, 'activity_regularizer': 6.5797146109435965e-06, 'batch_size': 31}. Best is trial 11 with value: 2769.8076171875.\n",
      "[I 2024-06-21 14:29:40,916] Trial 12 finished with value: 2769.839111328125 and parameters: {'num_units': 191, 'learning_rate': 0.0008792363702916567, 'dropout_rate': 0.19441234718618794, 'activity_regularizer': 8.568878418816445e-06, 'batch_size': 33}. Best is trial 11 with value: 2769.8076171875.\n",
      "[I 2024-06-21 14:29:48,717] Trial 13 finished with value: 2770.10009765625 and parameters: {'num_units': 185, 'learning_rate': 0.0006884166527402073, 'dropout_rate': 0.20492067860428292, 'activity_regularizer': 1.0213108914706977e-05, 'batch_size': 40}. Best is trial 11 with value: 2769.8076171875.\n",
      "[I 2024-06-21 14:29:49,099] Trial 14 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:49,495] Trial 15 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:49,899] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:50,259] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:50,579] Trial 18 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:50,932] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:51,265] Trial 20 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:51,618] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:51,947] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:52,299] Trial 23 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:29:58,816] Trial 24 finished with value: 2770.233642578125 and parameters: {'num_units': 195, 'learning_rate': 0.0009695379625806951, 'dropout_rate': 0.17512274273116357, 'activity_regularizer': 7.5388492893957915e-06, 'batch_size': 23}. Best is trial 11 with value: 2769.8076171875.\n",
      "[I 2024-06-21 14:29:59,155] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:04,509] Trial 26 finished with value: 2769.4423828125 and parameters: {'num_units': 234, 'learning_rate': 0.0005610377798653234, 'dropout_rate': 0.2663163526688393, 'activity_regularizer': 1.944908400899824e-06, 'batch_size': 37}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:30:12,189] Trial 27 finished with value: 2769.977294921875 and parameters: {'num_units': 234, 'learning_rate': 0.0005256177810677814, 'dropout_rate': 0.2761498746789196, 'activity_regularizer': 1.7694372369161819e-06, 'batch_size': 38}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:30:12,479] Trial 28 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:12,801] Trial 29 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:13,229] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:20,891] Trial 31 finished with value: 2769.984375 and parameters: {'num_units': 190, 'learning_rate': 0.0007635272661178549, 'dropout_rate': 0.19443374060322255, 'activity_regularizer': 5.463888731640758e-06, 'batch_size': 34}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:30:21,203] Trial 32 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:30,408] Trial 33 finished with value: 2769.60791015625 and parameters: {'num_units': 224, 'learning_rate': 0.0009736790185931464, 'dropout_rate': 0.1549160833020848, 'activity_regularizer': 4.435153478669295e-06, 'batch_size': 26}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:30:33,246] Trial 34 pruned. Trial was pruned at epoch 14.\n",
      "[I 2024-06-21 14:30:33,639] Trial 35 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:33,993] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:43,237] Trial 37 finished with value: 2769.66552734375 and parameters: {'num_units': 241, 'learning_rate': 0.0009764375566346528, 'dropout_rate': 0.13594681577155435, 'activity_regularizer': 2.6887892545845334e-06, 'batch_size': 26}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:30:43,589] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:30:47,046] Trial 39 pruned. Trial was pruned at epoch 14.\n",
      "[I 2024-06-21 14:30:50,544] Trial 40 finished with value: 2769.935546875 and parameters: {'num_units': 244, 'learning_rate': 0.0009948251559257605, 'dropout_rate': 0.06495620764400464, 'activity_regularizer': 2.5354255217386102e-06, 'batch_size': 41}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:31:01,747] Trial 41 finished with value: 2769.69677734375 and parameters: {'num_units': 199, 'learning_rate': 0.0007660072951703286, 'dropout_rate': 0.16089334402260724, 'activity_regularizer': 2.946630181844865e-06, 'batch_size': 28}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:31:11,092] Trial 42 finished with value: 2769.49365234375 and parameters: {'num_units': 202, 'learning_rate': 0.0007298400821397937, 'dropout_rate': 0.15944244031538718, 'activity_regularizer': 1.529560746975548e-06, 'batch_size': 24}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:31:24,926] Trial 43 finished with value: 2769.6728515625 and parameters: {'num_units': 222, 'learning_rate': 0.0006620702879153313, 'dropout_rate': 0.15318709056331245, 'activity_regularizer': 7.306968545166151e-07, 'batch_size': 16}. Best is trial 26 with value: 2769.4423828125.\n",
      "[I 2024-06-21 14:31:25,470] Trial 44 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:31:26,745] Trial 45 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-21 14:31:27,500] Trial 46 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:31:40,138] Trial 47 finished with value: 2769.327392578125 and parameters: {'num_units': 233, 'learning_rate': 0.0007805162342592767, 'dropout_rate': 0.08211712301803875, 'activity_regularizer': 1.5881688445709152e-06, 'batch_size': 19}. Best is trial 47 with value: 2769.327392578125.\n",
      "[I 2024-06-21 14:31:40,511] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-21 14:31:48,021] Trial 49 finished with value: 2769.2099609375 and parameters: {'num_units': 248, 'learning_rate': 0.0007774712887167225, 'dropout_rate': 0.06550797542407365, 'activity_regularizer': 2.8187766158913764e-07, 'batch_size': 63}. Best is trial 49 with value: 2769.2099609375.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "17b2a30f-e9e5-402e-8c08-56d6610fa96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 248, 'learning_rate': 0.0007774712887167225, 'dropout_rate': 0.06550797542407365, 'activity_regularizer': 2.8187766158913764e-07, 'batch_size': 63}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c120e85b-4ce2-478b-a902-c34a5f4a2934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "27b47045-7f87-4f29-8a27-e11e60092f5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 2983.5527 - val_loss: 2792.4844\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2965.9224 - val_loss: 2789.0198\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 2959.2856 - val_loss: 2786.1462\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2958.2788 - val_loss: 2783.5293\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2951.6077 - val_loss: 2781.4424\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2980.5967 - val_loss: 2779.8965\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2944.8960 - val_loss: 2778.3721\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2930.7559 - val_loss: 2777.0012\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2982.8884 - val_loss: 2775.8494\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 2950.2820 - val_loss: 2774.7451\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2972.1296 - val_loss: 2773.8770\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 2969.0991 - val_loss: 2773.2632\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2956.9226 - val_loss: 2772.7297\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2930.2727 - val_loss: 2772.3367\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2951.1843 - val_loss: 2772.0447\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2961.3184 - val_loss: 2771.5320\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 2939.9658 - val_loss: 2771.2393\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2908.6704 - val_loss: 2771.0901\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2981.9263 - val_loss: 2771.0100\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 3005.8357 - val_loss: 2770.9233\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 2924.2539 - val_loss: 2770.8218\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 2943.8059 - val_loss: 2770.7373\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 2972.0752 - val_loss: 2770.6938\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2952.2004 - val_loss: 2770.6838\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2934.6245 - val_loss: 2770.6775\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2929.7480 - val_loss: 2770.6707\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 3004.8682 - val_loss: 2770.6497\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2949.6868 - val_loss: 2770.5596\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2959.0432 - val_loss: 2770.5437\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2950.5364 - val_loss: 2770.4814\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2955.2922 - val_loss: 2770.4819\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 2958.3479 - val_loss: 2770.4819\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2927.3779 - val_loss: 2770.4465\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 2928.2800 - val_loss: 2770.4060\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 2912.6152 - val_loss: 2770.3345\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 2965.6094 - val_loss: 2770.3325\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 2967.1929 - val_loss: 2770.3330\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2953.3413 - val_loss: 2770.3328\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2923.3677 - val_loss: 2770.3330\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 2960.8760 - val_loss: 2770.3330\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2920.9153 - val_loss: 2770.3330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ee7588b650>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c9b23a13-ddb8-4f77-a1ff-24c626043d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2770.3325\n",
      "Validation Loss:  2770.33251953125\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "98cf2ee0-08da-438c-8ea2-df2ce700c4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a5ef2fd8-9cb7-45e5-b75b-d181c8e35cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5860e303-e3e9-4bed-9734-57cb883430e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f2b1c8cb-f696-4514-b687-2325dff7cb62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "F1 Score: 0.13333333333333333\n",
      "Sensitivity: 0.07692307692307693\n",
      "Specificity: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aed804-6efe-421e-bb71-374eda0731f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f56378a-a3b1-4a20-bbcc-6cdc913f08c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5bf383e3-0560-4048-93f9-5125b82ba96c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final = X_final.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d3bd64e0-5044-4444-9c38-c43f1cec243d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "442bfcf2-65f8-482e-9e50-516ef9246466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "159ed5ff-4e62-45f3-a375-f7041d252992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9e3fd72b-5720-43a7-9ae9-2986d60a8098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "21343e85-4276-4ea9-92b9-bf737eb0833d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5371faae-487b-4cc3-8b8f-553a22fa9270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "07d2707f-e6c8-4f2c-9e8c-7a788139822c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 969ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 958ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 785ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6161616161616162, F1 Score: 0.5792540792540793, Sensitivity: 0.6048265460030167, Specificity: 0.5541666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 794ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 796ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 824ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.47474747474747475, F1 Score: 0.4140239605355885, Sensitivity: 0.6078431372549019, Specificity: 0.45\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 592ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 546ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5555555555555556, F1 Score: 0.47921318447634237, Sensitivity: 0.4744780503294435, Specificity: 0.6416666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 998ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 652ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 930ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 710ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.41830065359477125, Sensitivity: 0.5701357466063349, Specificity: 0.5041666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 718ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 715ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.21621621621621623, Sensitivity: 0.23529411764705885, Specificity: 0.8333333333333334\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 485ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 507ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 499ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.507957957957958, Sensitivity: 0.5010716837342225, Specificity: 0.5678571428571428\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.512037037037037, Sensitivity: 0.4808287687544654, Specificity: 0.6815476190476191\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.4665866346538616, Sensitivity: 0.6491228070175438, Specificity: 0.3541666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.48484848484848486, F1 Score: 0.1981981981981982, Sensitivity: 0.28205128205128205, Specificity: 0.7833333333333333\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 551ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 531ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 529ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5757575757575758, F1 Score: 0.46581196581196577, Sensitivity: 0.6274509803921569, Specificity: 0.3958333333333333\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5757575757575758, F1 Score: 0.460644007155635, Sensitivity: 0.6078431372549019, Specificity: 0.4166666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5353535353535354, F1 Score: 0.5540353979555431, Sensitivity: 0.627768516313408, Specificity: 0.48214285714285715\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6464646464646465, F1 Score: 0.5352380952380952, Sensitivity: 0.5963324601095499, Specificity: 0.5863095238095238\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 968ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 824ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 953ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 951ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.4147480814147481, Sensitivity: 0.4163689767404937, Specificity: 0.7666666666666666\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 621ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 614ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 600ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.43390329104614817, Sensitivity: 0.5159958720330238, Specificity: 0.5\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 907ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 875ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 921ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 632ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.6342962395593974, Sensitivity: 0.8250377073906486, Specificity: 0.24583333333333335\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5858585858585859, F1 Score: 0.41885521885521887, Sensitivity: 0.457172342621259, Specificity: 0.6160714285714285\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 980ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5757575757575758, F1 Score: 0.5222222222222221, Sensitivity: 0.4767008017782011, Specificity: 0.6910714285714286\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6464646464646465, F1 Score: 0.5099163679808841, Sensitivity: 0.4269270461220926, Specificity: 0.8369047619047619\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.23366927958193354, Sensitivity: 0.2652218782249742, Specificity: 0.6458333333333334\n",
      "100%|████████████████████████████████████████████| 20/20 [1:53:21<00:00, 340.09s/trial, best loss: -0.6342962395593974]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2372e04e-274b-41e3-8f8e-44b97e0acae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 0.00013475559186741903, 'ae_batch_size': 56.0, 'ae_dropout_rate': 0.3354383348244757, 'ae_learning_rate': 0.00017770361273348052, 'autoencoder_units': 455.0, 'encoding_dim': 42.0, 'lstm_batch_size': 62.0, 'lstm_dropout_rate': 0.3967465795507378, 'lstm_learning_rate': 6.264675780236865e-05, 'lstm_units': 433.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "09535863-14d0-4a6f-805c-81b7a66edcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "918bbec5-5bd3-491c-ac76-f92187407699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8daffbcb-44f1-4f47-95b7-af5e0a6d58a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "968272ae-ad61-4ba9-8420-fce02bf12e9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 2975.6003 - val_loss: 2794.3608\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 2948.6511 - val_loss: 2792.4138\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 3005.4961 - val_loss: 2790.4607\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2976.1321 - val_loss: 2788.7039\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2941.6160 - val_loss: 2786.9968\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2978.7083 - val_loss: 2785.3816\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2975.5791 - val_loss: 2783.8718\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2943.3582 - val_loss: 2782.3643\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 2938.5759 - val_loss: 2780.9844\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2974.9849 - val_loss: 2779.7244\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2930.7158 - val_loss: 2778.5547\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2972.2625 - val_loss: 2777.4229\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2944.5239 - val_loss: 2776.3799\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2955.6328 - val_loss: 2775.4619\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 2952.9941 - val_loss: 2774.6440\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 2984.0688 - val_loss: 2773.9333\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 2956.8403 - val_loss: 2773.3218\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2928.5173 - val_loss: 2772.7900\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2968.7476 - val_loss: 2772.2534\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2979.9194 - val_loss: 2771.7490\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2930.2393 - val_loss: 2771.3560\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2986.9980 - val_loss: 2771.0796\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 2953.0981 - val_loss: 2770.8772\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2969.1941 - val_loss: 2770.7224\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2931.0457 - val_loss: 2770.6157\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 2950.6394 - val_loss: 2770.5366\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2933.2874 - val_loss: 2770.4666\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 2943.4214 - val_loss: 2770.3865\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 2977.4299 - val_loss: 2770.2993\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 2963.2576 - val_loss: 2770.2188\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 2943.8855 - val_loss: 2770.1492\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2932.3354 - val_loss: 2770.0845\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2921.8713 - val_loss: 2770.0276\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 2970.2661 - val_loss: 2769.9854\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2993.4661 - val_loss: 2769.9585\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 2932.3855 - val_loss: 2769.9465\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 2934.4026 - val_loss: 2769.9409\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2936.4395 - val_loss: 2769.9363\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 2968.2798 - val_loss: 2769.9333\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 2951.5557 - val_loss: 2769.9277\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2957.1987 - val_loss: 2769.9209\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2989.0852 - val_loss: 2769.9153\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2934.1348 - val_loss: 2769.9060\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2920.7424 - val_loss: 2769.8953\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 2980.8076 - val_loss: 2769.8862\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2961.4624 - val_loss: 2769.8792\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 2919.8196 - val_loss: 2769.8738\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 2940.9207 - val_loss: 2769.8665\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2928.5583 - val_loss: 2769.8564\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 2920.5569 - val_loss: 2769.8513\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.4778 - loss: 0.6950 - val_accuracy: 0.4800 - val_loss: 0.6936\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.5317 - loss: 0.6901 - val_accuracy: 0.4800 - val_loss: 0.6948\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.5141 - loss: 0.6944 - val_accuracy: 0.4800 - val_loss: 0.6948\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.5505 - loss: 0.6876 - val_accuracy: 0.4800 - val_loss: 0.6953\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.5047 - loss: 0.6947 - val_accuracy: 0.4800 - val_loss: 0.6955\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.5666 - loss: 0.6912 - val_accuracy: 0.4800 - val_loss: 0.6955\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "22a8e3aa-b5eb-40e9-8246-a20237865e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788ms/step\n",
      "Accuracy: 0.48\n",
      "F1 Score: 0.3157894736842105\n",
      "Sensitivity: 0.23076923076923078\n",
      "Specificity: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d6dac-86a4-4398-804b-81d6cadb8ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d5d2d3-093b-4714-8376-069f4c1e73d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d0ee446c-457f-493f-8dd7-42cb34942502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "12f6786a-28c8-4e1f-b2c9-e71e26dc6e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e49552d7-d954-42de-95d9-60b3168a5648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e2245714-a635-45a3-8c85-0b00b922e361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2a632adc-875f-4b9a-98c7-1ad36d757b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2d93455c-2f2c-4a51-aa38-2e2994c4fc5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f38548c8-bb08-4456-9ffa-81be7d522fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fbdc0a7e-5127-4b27-9387-3da3d0eb5beb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [22:19<00:00, 66.96s/trial, best loss: -0.5447368421052632]\n",
      "Best parameters:  {'ae_activity_reg': 0.0007975004237455319, 'ae_batch_size': 52.0, 'ae_dropout_rate': 0.27641066861509944, 'ae_learning_rate': 0.0033959934475826336, 'autoencoder_units': 85.0, 'encoding_dim': 18.0, 'fnn_batch_size': 18.0, 'fnn_dropout_rate': 0.2488133229220186, 'fnn_learning_rate': 2.2538500566953105e-05, 'fnn_units': 319.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a3b34e09-5711-4939-9580-8f374ddd2651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "43e3a9ac-65b4-4cba-971c-ae04b5863771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d11b5667-cc51-4c5c-8d33-ac82324bd592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Final Model - Accuracy: 0.49631578947368415\n",
      "Final Model - F1 Score: 0.39021466710253894\n",
      "Final Model - Sensitivity: 0.38590909090909087\n",
      "Final Model - Specificity: 0.5855555555555556\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3b4fb-206d-4979-98d9-5a12f676350b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4adba225-068f-438f-8e77-3e1eba83151a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization - 1500 SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1452b551-f48d-403f-87e2-0a5db0a873a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_352\\3144519170.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData2.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37933bff-eff2-4c7a-9775-12e823e74967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3178b87-afdd-447b-b060-efabe6d029aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f0d488-5ba6-445f-a3e7-d053964a7a86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285ff234-888f-4fa7-bacb-bdab94d5b9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3f049d-d877-4d43-95bf-0072a2344b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca87b31-6d64-4b7a-b8ac-dd87f2931cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21693b49-926c-43d5-9cdf-ef9522e7f51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1fa4b16-d7bf-48f2-8bb3-3b48e5c87cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f0def18-f6a8-45b6-9f84-9474a734feb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0551b9f-f46d-44d6-807e-7d6e1951f8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 8, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 32, 256, 32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e062309-6aa9-47f6-8c90-a950de07cb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae55e43c-9c36-42df-8f9b-6ac930133804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.7222938537597656, Params: {'batch_size': 128, 'dropout_rate': 0.41885642336953854, 'epochs': 60, 'learning_rate': 0.0015155869660225432, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.8170136213302612, Params: {'batch_size': 224, 'dropout_rate': 0.2571001600527376, 'epochs': 120, 'learning_rate': 0.0016942344444306567, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.6705077886581421, Params: {'batch_size': 32, 'dropout_rate': 0.6930059162267048, 'epochs': 70, 'learning_rate': 0.00011158705006080678, 'num_layers': 8, 'units': 96}\n",
      "Iteration - Loss: 0.7457902431488037, Params: {'batch_size': 128, 'dropout_rate': 0.2325271742242711, 'epochs': 80, 'learning_rate': 0.0008425784311867526, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 0.7206456065177917, Params: {'batch_size': 32, 'dropout_rate': 0.11474491773842294, 'epochs': 130, 'learning_rate': 0.00010441474545632383, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 0.6757572889328003, Params: {'batch_size': 64, 'dropout_rate': 0.36967709294877016, 'epochs': 140, 'learning_rate': 2.774509210765599e-05, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 0.7261350750923157, Params: {'batch_size': 192, 'dropout_rate': 0.19893524783640193, 'epochs': 140, 'learning_rate': 0.0001632943595234256, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.6909908056259155, Params: {'batch_size': 160, 'dropout_rate': 0.2994000053570923, 'epochs': 120, 'learning_rate': 0.00042032390593460685, 'num_layers': 8, 'units': 224}\n",
      "Iteration - Loss: 0.7031175494194031, Params: {'batch_size': 128, 'dropout_rate': 0.440536809362016, 'epochs': 140, 'learning_rate': 0.0015832764937799676, 'num_layers': 7, 'units': 160}\n",
      "Iteration - Loss: 0.6892494559288025, Params: {'batch_size': 32, 'dropout_rate': 0.2887280635206433, 'epochs': 110, 'learning_rate': 2.0828757556861867e-05, 'num_layers': 7, 'units': 96}\n",
      "Iteration - Loss: 0.6748328804969788, Params: {'batch_size': 192, 'dropout_rate': 0.5605577945467575, 'epochs': 150, 'learning_rate': 8.076589897594885e-05, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.6867204904556274, Params: {'batch_size': 160, 'dropout_rate': 0.38719203354169807, 'epochs': 140, 'learning_rate': 2.7273168412394996e-05, 'num_layers': 7, 'units': 224}\n",
      "Iteration - Loss: 0.698196530342102, Params: {'batch_size': 224, 'dropout_rate': 0.6602492022674681, 'epochs': 70, 'learning_rate': 0.0028556313930977193, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 0.770592987537384, Params: {'batch_size': 64, 'dropout_rate': 0.2582228375488749, 'epochs': 80, 'learning_rate': 7.061439240492972e-05, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.6931797862052917, Params: {'batch_size': 192, 'dropout_rate': 0.23052067502671486, 'epochs': 120, 'learning_rate': 0.002896340063571294, 'num_layers': 8, 'units': 192}\n",
      "Iteration - Loss: 0.6726679801940918, Params: {'batch_size': 128, 'dropout_rate': 0.22530289268139014, 'epochs': 110, 'learning_rate': 0.008889162985811326, 'num_layers': 7, 'units': 96}\n",
      "Iteration - Loss: 0.7119107842445374, Params: {'batch_size': 192, 'dropout_rate': 0.23906571483217523, 'epochs': 70, 'learning_rate': 0.0016380405680518314, 'num_layers': 6, 'units': 64}\n",
      "Iteration - Loss: 0.692889392375946, Params: {'batch_size': 192, 'dropout_rate': 0.28789651025878826, 'epochs': 120, 'learning_rate': 0.0009592809962329482, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.8072059750556946, Params: {'batch_size': 32, 'dropout_rate': 0.6862696510998426, 'epochs': 130, 'learning_rate': 5.24478764544611e-05, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 0.6944898366928101, Params: {'batch_size': 192, 'dropout_rate': 0.2596030377881625, 'epochs': 100, 'learning_rate': 0.0018577216665168355, 'num_layers': 8, 'units': 128}\n",
      "Iteration - Loss: 0.6805588006973267, Params: {'batch_size': 96, 'dropout_rate': 0.12141164154471196, 'epochs': 90, 'learning_rate': 0.009540352255414518, 'num_layers': 7, 'units': 64}\n",
      "Iteration - Loss: 0.695051372051239, Params: {'batch_size': 64, 'dropout_rate': 0.5337093738148974, 'epochs': 100, 'learning_rate': 1.0994805665739184e-05, 'num_layers': 8, 'units': 128}\n",
      "Iteration - Loss: 0.6868767738342285, Params: {'batch_size': 256, 'dropout_rate': 0.6200374478413655, 'epochs': 50, 'learning_rate': 0.00978936982489305, 'num_layers': 7, 'units': 64}\n",
      "Iteration - Loss: 0.6856762170791626, Params: {'batch_size': 96, 'dropout_rate': 0.48371917098873946, 'epochs': 90, 'learning_rate': 0.00026541972195463786, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.6964405179023743, Params: {'batch_size': 96, 'dropout_rate': 0.16567747446352662, 'epochs': 50, 'learning_rate': 0.0003879380647566074, 'num_layers': 8, 'units': 64}\n",
      "Iteration - Loss: 0.676842987537384, Params: {'batch_size': 64, 'dropout_rate': 0.34816753324608923, 'epochs': 110, 'learning_rate': 0.005368597120903863, 'num_layers': 7, 'units': 96}\n",
      "Iteration - Loss: 0.6711137294769287, Params: {'batch_size': 96, 'dropout_rate': 0.16702395759555877, 'epochs': 90, 'learning_rate': 0.00015542353039905103, 'num_layers': 8, 'units': 256}\n",
      "Iteration - Loss: 0.7379635572433472, Params: {'batch_size': 96, 'dropout_rate': 0.5638733653552799, 'epochs': 70, 'learning_rate': 0.0001825470699851089, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.7016218900680542, Params: {'batch_size': 32, 'dropout_rate': 0.43938590520862775, 'epochs': 60, 'learning_rate': 0.0006143005967619033, 'num_layers': 8, 'units': 160}\n",
      "Iteration - Loss: 0.6817294359207153, Params: {'batch_size': 64, 'dropout_rate': 0.6241288394890766, 'epochs': 60, 'learning_rate': 4.589293028945025e-05, 'num_layers': 3, 'units': 256}\n",
      "100%|████████████████████████████████████████████████| 30/30 [01:43<00:00,  3.44s/trial, best loss: 0.6705077886581421]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40508eeb-c07e-4f51-a396-47a78c07f7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 32, 'dropout_rate': 0.6930059162267048, 'epochs': 70, 'learning_rate': 0.00011158705006080678, 'num_layers': 8, 'units': 96}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "154dcd6a-d9fe-421a-a48f-34ea1925871d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_selected, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_selected):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "          num_layers=best_params['num_layers'],\n",
    "          units=best_params['units'],\n",
    "          dropout_rate=best_params['dropout_rate'],\n",
    "          learning_rate=best_params['learning_rate'])\n",
    "        \n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "116781b8-3b98-443b-85f3-072a2dbbe813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B8281AEDE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.4936842105263158\n",
      "F1 Score: 0.44542124542124545\n",
      "Sensitivity: 0.5536363636363637\n",
      "Specificity: 0.44333333333333336\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_train, y_train, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78cb46-0bd6-4866-bd9f-4bda567b1ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f735bde-33b2-4ed5-9f36-39a429d86bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9820d00c-0aa5-4724-af0f-746454f7deb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - 1500 SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e663b4-23cd-40e2-afb8-c261fbf2f075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_18884\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69cf5f20-3fcb-4ecf-8ad4-2fb2f8e61f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bffda447-4cdc-454c-8c40-5f5e545b40b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06995c37-8986-4b01-9ca9-1248b6ae9adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 5000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af49d25c-68cb-484d-9446-1f98bb0c0518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [152486 108606  90004  84835  94661  18775 246766  40402 200937 148095]\n",
      "Top AMGM values: [1.00169181 1.00169181 1.00169181 1.00169181 1.00169181 1.00169181\n",
      " 1.00169181 1.00169181 1.00169181 1.00169181]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "579b5cce-636c-415d-982f-3953ed7ad300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b1a951-7da8-4c04-87d3-8adec1976d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ac8d5e-426e-4113-8c70-9fd675a0a00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f7c6900-1ce0-4967-b336-65f4b5b9266f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5fa7f4-aeca-4e7d-a9f6-5d81ec80e8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3291fd20-d88f-4dea-a83d-20876d24744d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f9ddc2f-1344-45ff-b511-aba69d9d537c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aa5593e-cb79-4c70-b766-b0269b87eb42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018BF228B9C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.5483870967741935, F1 Score: 0.5409836065573771, Sensitivity: 0.532258064516129, Specificity: 0.5645161290322581\n",
      "  5%|██▍                                             | 1/20 [00:34<10:57, 34.60s/trial, best loss: -0.5409836065573771]WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018BF2E42A20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.6935483870967742, F1 Score: 0.6666666666666666, Sensitivity: 0.6129032258064516, Specificity: 0.7741935483870968\n",
      "Accuracy: 0.6129032258064516, F1 Score: 0.6, Sensitivity: 0.5806451612903226, Specificity: 0.6451612903225806          \n",
      "Accuracy: 0.5967741935483871, F1 Score: 0.5901639344262295, Sensitivity: 0.5806451612903226, Specificity: 0.6129032258064516\n",
      "Accuracy: 0.6129032258064516, F1 Score: 0.5294117647058824, Sensitivity: 0.43548387096774194, Specificity: 0.7903225806451613\n",
      "Accuracy: 0.5967741935483871, F1 Score: 0.576271186440678, Sensitivity: 0.5483870967741935, Specificity: 0.6451612903225806\n",
      "Accuracy: 0.6129032258064516, F1 Score: 0.6, Sensitivity: 0.5806451612903226, Specificity: 0.6451612903225806          \n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6290322580645161, Sensitivity: 0.6290322580645161, Specificity: 0.6290322580645161\n",
      "Accuracy: 0.5887096774193549, F1 Score: 0.5714285714285714, Sensitivity: 0.5483870967741935, Specificity: 0.6290322580645161\n",
      "Accuracy: 0.6048387096774194, F1 Score: 0.6016260162601627, Sensitivity: 0.5967741935483871, Specificity: 0.6129032258064516\n",
      "Accuracy: 0.6612903225806451, F1 Score: 0.6440677966101694, Sensitivity: 0.6129032258064516, Specificity: 0.7096774193548387\n",
      "Accuracy: 0.6451612903225806, F1 Score: 0.6271186440677966, Sensitivity: 0.5967741935483871, Specificity: 0.6935483870967742\n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6229508196721312, Sensitivity: 0.6129032258064516, Specificity: 0.6451612903225806\n",
      "Accuracy: 0.6209677419354839, F1 Score: 0.6050420168067226, Sensitivity: 0.5806451612903226, Specificity: 0.6612903225806451\n",
      "Accuracy: 0.5, F1 Score: 0.4918032786885246, Sensitivity: 0.4838709677419355, Specificity: 0.5161290322580645          \n",
      "Accuracy: 0.5806451612903226, F1 Score: 0.5666666666666667, Sensitivity: 0.5483870967741935, Specificity: 0.6129032258064516\n",
      "Accuracy: 0.6048387096774194, F1 Score: 0.6201550387596899, Sensitivity: 0.6451612903225806, Specificity: 0.5645161290322581\n",
      "Accuracy: 0.6532258064516129, F1 Score: 0.6386554621848739, Sensitivity: 0.6129032258064516, Specificity: 0.6935483870967742\n",
      "Accuracy: 0.5483870967741935, F1 Score: 0.5483870967741935, Sensitivity: 0.5483870967741935, Specificity: 0.5483870967741935\n",
      "Accuracy: 0.6048387096774194, F1 Score: 0.5882352941176471, Sensitivity: 0.5645161290322581, Specificity: 0.6451612903225806\n",
      "100%|███████████████████████████████████████████████| 20/20 [08:23<00:00, 25.16s/trial, best loss: -0.6666666666666666]\n",
      "Best parameters found:  {'batch_size': 48.0, 'dropout_rate': 0.5765654424030486, 'epochs': 200.0, 'learning_rate': 0.04573831773303991, 'neurons1': 128.0, 'neurons2': 64.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee70bc47-0626-4828-bcd5-007c414a5454",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_100\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_100\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_500 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">192,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_200 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_501 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_503 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">193,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_504 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,501</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_500 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m192,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_200 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_501 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_201 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_502 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_503 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)                │         \u001b[38;5;34m193,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_504 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,501\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">403,705</span> (1.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m403,705\u001b[0m (1.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">403,705</span> (1.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m403,705\u001b[0m (1.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9520309e-92e1-4240-9189-6b396fc45090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_selected, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_selected):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_deep_autoencoder(\n",
    "            input_dim=X_selected.shape[1],\n",
    "            neurons1=best_params['neurons1'],\n",
    "            neurons2=best_params['neurons2'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27d1df30-2697-4ce3-881d-36f5398d15bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.542\n",
      "F1 Score: 0.37402597402597404\n",
      "Sensitivity: 0.4233766233766234\n",
      "Specificity: 0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_selected, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285bffb-8a4c-48be-ac8c-aba3942864a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d907e33c-082a-4b48-a202-c838ca2fc2a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization - 1500 SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7608cf0f-82d3-4df6-8847-44c01e52835b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_41596\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885ef956-16ee-49ee-8233-9648ab186cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c168eb29-700e-4158-8814-4a917232e2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d349110-37af-4eed-9010-b0753a4f5b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "549a6b2f-96d1-48c2-993e-7863e381499a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f5f030-3a0d-4259-8867-3939537c3c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9654ec8c-d717-43ae-b372-e55f4e4eaa26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f27066b2-59ed-4055-b16d-17993bf51953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90893680-d25c-46b0-9bbc-3ff8f7039977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a394a2c4-7919-426a-914e-b61634ad8ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47ee1faf-6269-41dc-ade6-343af31196b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c597f25-cbe8-4189-8286-03904bf16959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5087b2cc-8d06-4f2d-a1be-d945c7cda336",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6263157894736843, F1 Score: 0.526961926961927, Sensitivity: 0.4959090909090909, Specificity: 0.7555555555555555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6263157894736843, F1 Score: 0.4256164887743835, Sensitivity: 0.3040909090909091, Specificity: 0.9355555555555555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6684210526315789, F1 Score: 0.5243098688750862, Sensitivity: 0.4759090909090909, Specificity: 0.8333333333333334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6873684210526315, F1 Score: 0.5365144659262306, Sensitivity: 0.41409090909090907, Specificity: 0.9666666666666668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7157894736842105, F1 Score: 0.6263269339356295, Sensitivity: 0.5259090909090909, Specificity: 0.8977777777777778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6963157894736842, F1 Score: 0.5996924128503076, Sensitivity: 0.46590909090909094, Specificity: 0.9133333333333333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6247368421052631, F1 Score: 0.3756493506493507, Sensitivity: 0.26590909090909093, Specificity: 0.9833333333333332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6457894736842106, F1 Score: 0.5424365438483085, Sensitivity: 0.48909090909090913, Specificity: 0.85\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6352631578947368, F1 Score: 0.48238437001594897, Sensitivity: 0.3659090909090909, Specificity: 0.8911111111111112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6557894736842106, F1 Score: 0.5202020202020201, Sensitivity: 0.38590909090909087, Specificity: 0.9155555555555555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6357894736842105, F1 Score: 0.43833333333333335, Sensitivity: 0.3009090909090909, Specificity: 0.96\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6878947368421052, F1 Score: 0.5733333333333335, Sensitivity: 0.4727272727272728, Specificity: 0.9055555555555556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6457894736842105, F1 Score: 0.42942890442890447, Sensitivity: 0.28590909090909095, Specificity: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6957894736842105, F1 Score: 0.5388528138528139, Sensitivity: 0.4259090909090909, Specificity: 0.96\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6884210526315789, F1 Score: 0.5691558441558442, Sensitivity: 0.5059090909090909, Specificity: 0.8555555555555555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6468421052631579, F1 Score: 0.4413636363636364, Sensitivity: 0.3209090909090909, Specificity: 0.9555555555555555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5463157894736842, F1 Score: 0.5770055118821722, Sensitivity: 0.6799999999999999, Specificity: 0.4377777777777777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6484210526315789, F1 Score: 0.6237161531279178, Sensitivity: 0.7140909090909091, Specificity: 0.5555555555555556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7278947368421053, F1 Score: 0.6831461675579323, Sensitivity: 0.610909090909091, Specificity: 0.8333333333333334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                              \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6768421052631578, F1 Score: 0.5474242424242425, Sensitivity: 0.4259090909090909, Specificity: 0.9133333333333333\n",
      "100%|███████████████████████████████████████████████| 20/20 [10:35<00:00, 31.80s/trial, best loss: -0.6831461675579323]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "293b5457-81d7-491a-879c-19d8b63812c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 32, 'dropout_rate': 0.387046043398518, 'epochs': 50, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.000145349741302658}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ced6648d-fd2a-4026-af6a-50accbf80652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "175cd8c0-4abd-4356-b31c-c5f7e787f6b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_selected, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_selected):\n",
    "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_cnn_model(\n",
    "            input_shape=(X_train.shape[1], 1),\n",
    "            filters=int(best_params['filters']),\n",
    "            kernel_size=int(best_params['kernel_size']),\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9277515d-acc0-44c4-812f-5c66b2f69dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.5563333333333333\n",
      "F1 Score: 0.3143977591036415\n",
      "Sensitivity: 0.21648351648351646\n",
      "Specificity: 0.8987012987012987\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_selected, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e08b66-8f72-4186-b760-b32fb5075e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a5a4112-ef5d-4fee-87c6-9e7c6c46d562",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model - 1500 SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c591cb1-e19b-4cd9-b998-121778a67848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_13612\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c64efa60-b099-4e9f-bac5-cd72f9aa203d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e11fae90-ec5e-44e3-90be-0d7a2e376058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8befda0-4a7a-4bb5-bc54-488f7026b48e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "936cc95c-9c98-4a63-90d6-bb32a511ad09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06f2595e-b9bf-4cb6-bf60-7d80c4cfb0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce48d5db-8e88-438e-b269-b3fa711e29ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71e11a7a-7126-4748-82cf-eb750458405f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "257c272f-cd2e-4931-a4f2-52143b480c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d790bc5a-9915-4d9b-912c-3302f02e7782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6083c1f5-4bc4-42cd-923f-c98cf1131082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00610b2f-a82e-4801-80d7-9ab287c27b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa29928c-a058-4631-9580-c2ae5dd0c3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "475bd56e-1d24-43e4-bc2e-a49a65aa729c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3681e59e-2d05-48da-9041-1cd6f98282db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54039655-2c36-4990-a7d0-f9dbaf0d4adf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 250ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step                                               \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                               \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step                                               \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [12:36<00:00, 37.82s/trial, best loss: -0.5542105263157895]\n",
      "Best parameters:  {'ae_activity_reg': 3.575616274060793e-07, 'ae_batch_size': 18.0, 'ae_dropout_rate': 0.3195248182754782, 'ae_learning_rate': 0.00905830604441763, 'autoencoder_units': 409.0, 'encoding_dim': 33.0, 'fnn_batch_size': 57.0, 'fnn_dropout_rate': 0.4499308261847763, 'fnn_learning_rate': 0.0008560947321121307, 'fnn_units': 128.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e6d0136-bf87-4e87-8434-a9a43b714164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77ec9adb-9d4d-4f32-ad85-803b4760a1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af2edd75-a06f-4d0a-bfed-f57c5d22f62e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Final Model - Accuracy: 0.6057894736842105\n",
      "Final Model - F1 Score: 0.43487179487179484\n",
      "Final Model - Sensitivity: 0.369090909090909\n",
      "Final Model - Specificity: 0.8077777777777777\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ba2ab-6105-4ed4-abf6-267a1bd4fe84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70184fb4-5a2e-4a38-8596-b239b0194108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf331ef-a317-4c1e-80d0-b42b4b141c61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder - ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "662b1fe9-9f26-4ead-892f-c2eeaba27625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_2980\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9127ad6-f5b6-4002-824f-dd2d4240a6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.T.astype(np.float32)\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.int32)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42d2fc06-b560-4a1b-89ba-df4dfe8e20f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_features_relieff(X, y, num_features):\n",
    "    relief = ReliefF(n_neighbors=100, n_features_to_select=num_features, discrete_threshold=10)\n",
    "    relief.fit(X, y)\n",
    "    return relief.top_features_[:num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc4150c3-ed01-40bf-ab2a-a794fda52622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relieff_indices = select_features_relieff(X_scaled, y, 1000)\n",
    "X_final = X_scaled[:, relieff_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3569d7cb-bf98-47cf-8017-ac9fcf161e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21099166-ad78-45d8-88b6-95028c9b92ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "362bffa1-1522-49dd-b5bc-ceebf1fff21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b647bfa-33b0-4527-8829-20cbb10952dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012FFEE8B060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012FFEE8B060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.717741935483871, F1 Score: 0.7008547008547008, Sensitivity: 0.6612903225806451, Specificity: 0.7741935483870968\n",
      "Accuracy: 0.717741935483871, F1 Score: 0.7008547008547008, Sensitivity: 0.6612903225806451, Specificity: 0.7741935483870968\n",
      "Accuracy: 0.717741935483871, F1 Score: 0.6902654867256637, Sensitivity: 0.6290322580645161, Specificity: 0.8064516129032258\n",
      "Accuracy: 0.6612903225806451, F1 Score: 0.6666666666666666, Sensitivity: 0.6774193548387096, Specificity: 0.6451612903225806\n",
      "Accuracy: 0.7258064516129032, F1 Score: 0.734375, Sensitivity: 0.7580645161290323, Specificity: 0.6935483870967742     \n",
      "Accuracy: 0.7016129032258065, F1 Score: 0.6782608695652174, Sensitivity: 0.6290322580645161, Specificity: 0.7741935483870968\n",
      "Accuracy: 0.6693548387096774, F1 Score: 0.6095238095238096, Sensitivity: 0.5161290322580645, Specificity: 0.8225806451612904\n",
      "Accuracy: 0.7419354838709677, F1 Score: 0.7377049180327869, Sensitivity: 0.7258064516129032, Specificity: 0.7580645161290323\n",
      "Accuracy: 0.7258064516129032, F1 Score: 0.6730769230769231, Sensitivity: 0.5645161290322581, Specificity: 0.8870967741935484\n",
      "Accuracy: 0.7338709677419355, F1 Score: 0.717948717948718, Sensitivity: 0.6774193548387096, Specificity: 0.7903225806451613\n",
      "Accuracy: 0.46774193548387094, F1 Score: 0.5147058823529411, Sensitivity: 0.5645161290322581, Specificity: 0.3709677419354839\n",
      "Accuracy: 0.717741935483871, F1 Score: 0.7008547008547008, Sensitivity: 0.6612903225806451, Specificity: 0.7741935483870968\n",
      "Accuracy: 0.7016129032258065, F1 Score: 0.6837606837606838, Sensitivity: 0.6451612903225806, Specificity: 0.7580645161290323\n",
      "Accuracy: 0.6854838709677419, F1 Score: 0.6722689075630253, Sensitivity: 0.6451612903225806, Specificity: 0.7258064516129032\n",
      "Accuracy: 0.7096774193548387, F1 Score: 0.6949152542372882, Sensitivity: 0.6612903225806451, Specificity: 0.7580645161290323\n",
      "Accuracy: 0.6935483870967742, F1 Score: 0.6833333333333333, Sensitivity: 0.6612903225806451, Specificity: 0.7258064516129032\n",
      "Accuracy: 0.717741935483871, F1 Score: 0.7008547008547008, Sensitivity: 0.6612903225806451, Specificity: 0.7741935483870968\n",
      "Accuracy: 0.7258064516129032, F1 Score: 0.7068965517241379, Sensitivity: 0.6612903225806451, Specificity: 0.7903225806451613\n",
      "Accuracy: 0.6935483870967742, F1 Score: 0.6833333333333333, Sensitivity: 0.6612903225806451, Specificity: 0.7258064516129032\n",
      "Accuracy: 0.6612903225806451, F1 Score: 0.6612903225806451, Sensitivity: 0.6612903225806451, Specificity: 0.6612903225806451\n",
      "100%|███████████████████████████████████████████████| 20/20 [10:36<00:00, 31.82s/trial, best loss: -0.7377049180327869]\n",
      "Best parameters found:  {'batch_size': 64.0, 'dropout_rate': 0.22109342496076773, 'epochs': 100.0, 'learning_rate': 0.0005749027205240111, 'neurons1': 64.0, 'neurons2': 112.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b6601f2-c703-47fb-8461-64691dff229e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_100\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_100\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_500 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">64,064</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_200 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_501 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,280</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,232</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_503 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_504 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_500 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m64,064\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_200 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_501 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)                 │           \u001b[38;5;34m7,280\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_201 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_502 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m7,232\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_503 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │          \u001b[38;5;34m65,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_504 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,001\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,577</span> (564.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m144,577\u001b[0m (564.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,577</span> (564.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m144,577\u001b[0m (564.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_final.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22c66c1a-d955-4265-83de-30f97c1358a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_deep_autoencoder(\n",
    "            input_dim=X_final.shape[1],\n",
    "            neurons1=best_params['neurons1'],\n",
    "            neurons2=best_params['neurons2'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9568fd1-7df0-41c4-8968-adf93d38468b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.7263333333333333\n",
      "F1 Score: 0.7029824561403508\n",
      "Sensitivity: 0.6710689310689311\n",
      "Specificity: 0.7720346320346321\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_final, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc4e97-2d53-47b4-8479-d0b603e03b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2dcfb01-8de1-4d38-a746-78c54ca51e5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Relieff FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b50b5c65-e53e-46bc-95e2-cda206e20112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4987f69e-9a76-4186-80e5-f3e5a6fa70bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f819690-f9d8-4708-83cc-3746dc17320f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ca1c7ee-d238-416d-a0c4-e4cd1ac3ba67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 8, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 32, 256, 32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f76b8c1-fc2a-4bf7-8364-03e521b2f47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba7368d1-00f9-4f2a-b3dd-ff2bc0853cf2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.6934255361557007, Params: {'batch_size': 64, 'dropout_rate': 0.5719871692371299, 'epochs': 120, 'learning_rate': 1.3183128871331543e-05, 'num_layers': 7, 'units': 160}\n",
      "Iteration - Loss: 0.5613932013511658, Params: {'batch_size': 96, 'dropout_rate': 0.20507515481061958, 'epochs': 70, 'learning_rate': 0.007485702719711069, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.6834184527397156, Params: {'batch_size': 128, 'dropout_rate': 0.6254109639275915, 'epochs': 100, 'learning_rate': 5.4232963933179674e-05, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.6300863027572632, Params: {'batch_size': 96, 'dropout_rate': 0.5556703442696647, 'epochs': 50, 'learning_rate': 0.00027500330973683466, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.6887949109077454, Params: {'batch_size': 224, 'dropout_rate': 0.1770891345705187, 'epochs': 130, 'learning_rate': 0.0002918290943883834, 'num_layers': 7, 'units': 256}\n",
      "Iteration - Loss: 0.6640090346336365, Params: {'batch_size': 96, 'dropout_rate': 0.28900069074272705, 'epochs': 140, 'learning_rate': 2.4299764242062378e-05, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.6755940914154053, Params: {'batch_size': 192, 'dropout_rate': 0.5631684140379069, 'epochs': 70, 'learning_rate': 3.203726263453599e-05, 'num_layers': 7, 'units': 256}\n",
      "Iteration - Loss: 0.6792970299720764, Params: {'batch_size': 128, 'dropout_rate': 0.556921235350837, 'epochs': 120, 'learning_rate': 0.0009853302197535335, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 0.8024765253067017, Params: {'batch_size': 160, 'dropout_rate': 0.518976489748595, 'epochs': 60, 'learning_rate': 2.201932927136863e-05, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 0.6446336507797241, Params: {'batch_size': 256, 'dropout_rate': 0.11317973211056352, 'epochs': 60, 'learning_rate': 0.0002470713286687148, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.5867184400558472, Params: {'batch_size': 64, 'dropout_rate': 0.3210801622259968, 'epochs': 120, 'learning_rate': 2.50503823556407e-05, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.6747786402702332, Params: {'batch_size': 32, 'dropout_rate': 0.27487154920805845, 'epochs': 70, 'learning_rate': 3.184972234236159e-05, 'num_layers': 7, 'units': 192}\n",
      "Iteration - Loss: 0.6849134564399719, Params: {'batch_size': 64, 'dropout_rate': 0.22369180473628092, 'epochs': 140, 'learning_rate': 1.658520760988589e-05, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.6851998567581177, Params: {'batch_size': 160, 'dropout_rate': 0.1415980273427287, 'epochs': 100, 'learning_rate': 2.0308022823918912e-05, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 0.529328465461731, Params: {'batch_size': 224, 'dropout_rate': 0.23795274546283274, 'epochs': 70, 'learning_rate': 0.004120155532466482, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.665715217590332, Params: {'batch_size': 256, 'dropout_rate': 0.40931179028618137, 'epochs': 70, 'learning_rate': 0.0019196780960824096, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 0.5910043120384216, Params: {'batch_size': 96, 'dropout_rate': 0.16041140556709305, 'epochs': 100, 'learning_rate': 0.00038100051650685106, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.681732177734375, Params: {'batch_size': 128, 'dropout_rate': 0.4527111001144474, 'epochs': 50, 'learning_rate': 0.0015120138821680942, 'num_layers': 7, 'units': 96}\n",
      "Iteration - Loss: 0.681319534778595, Params: {'batch_size': 96, 'dropout_rate': 0.44945397808935084, 'epochs': 110, 'learning_rate': 0.009276507362076719, 'num_layers': 7, 'units': 224}\n",
      "Iteration - Loss: 0.6647480130195618, Params: {'batch_size': 128, 'dropout_rate': 0.5594117822270586, 'epochs': 70, 'learning_rate': 0.005979273723281178, 'num_layers': 7, 'units': 224}\n",
      "Iteration - Loss: 0.5927287340164185, Params: {'batch_size': 224, 'dropout_rate': 0.3317931990555102, 'epochs': 80, 'learning_rate': 0.0037177890207398872, 'num_layers': 2, 'units': 160}\n",
      "Iteration - Loss: 0.591108500957489, Params: {'batch_size': 192, 'dropout_rate': 0.22126504596575838, 'epochs': 90, 'learning_rate': 0.008859353948894621, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.7051949501037598, Params: {'batch_size': 192, 'dropout_rate': 0.21707545044428425, 'epochs': 80, 'learning_rate': 0.003991854715138343, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.5328508615493774, Params: {'batch_size': 224, 'dropout_rate': 0.367457844385242, 'epochs': 90, 'learning_rate': 0.000765194554471941, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.5458493828773499, Params: {'batch_size': 224, 'dropout_rate': 0.3714196939754261, 'epochs': 90, 'learning_rate': 0.0010143997300545802, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 0.5643569231033325, Params: {'batch_size': 256, 'dropout_rate': 0.3875378981133371, 'epochs': 90, 'learning_rate': 9.49977881806246e-05, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.509016215801239, Params: {'batch_size': 224, 'dropout_rate': 0.26919815172086065, 'epochs': 80, 'learning_rate': 0.0005985346482437288, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.5055348873138428, Params: {'batch_size': 192, 'dropout_rate': 0.267097085129297, 'epochs': 60, 'learning_rate': 0.0025288264273238066, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.5670057535171509, Params: {'batch_size': 192, 'dropout_rate': 0.28275439651692735, 'epochs': 60, 'learning_rate': 0.00013094421444011473, 'num_layers': 5, 'units': 256}\n",
      "Iteration - Loss: 0.5860803723335266, Params: {'batch_size': 160, 'dropout_rate': 0.10047327717838772, 'epochs': 80, 'learning_rate': 0.0005650860165377051, 'num_layers': 6, 'units': 224}\n",
      "100%|████████████████████████████████████████████████| 30/30 [02:06<00:00,  4.22s/trial, best loss: 0.5055348873138428]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b414e68e-d1b3-46b9-99c1-038b83832229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 192, 'dropout_rate': 0.267097085129297, 'epochs': 60, 'learning_rate': 0.0025288264273238066, 'num_layers': 5, 'units': 224}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c71c3b5a-d6b5-4fa1-8152-c6e12d903fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "          num_layers=best_params['num_layers'],\n",
    "          units=best_params['units'],\n",
    "          dropout_rate=best_params['dropout_rate'],\n",
    "          learning_rate=best_params['learning_rate'])\n",
    "        \n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5c45299-19f1-41f3-af18-17b4b3236cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.7573684210526316\n",
      "F1 Score: 0.7252168746286394\n",
      "Sensitivity: 0.6818181818181818\n",
      "Specificity: 0.8255555555555556\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_train, y_train, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3b77e-58d8-4859-93d2-4f4540f79908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad66128-336a-48e6-9810-5d431967502f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ea54090-6d98-4305-9912-fc5f4dbdb363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13218270-55ab-48b1-a0d9-0ba2855c9e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30326ba0-21f3-4445-9dfe-4d0313fcfa04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f4b1216-8e73-4be6-afdb-83fb063c5d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9f6f1ec-8448-4e2a-bcfb-180018c5dcab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0af5727-c4c0-466b-a2a1-d3e3061d2275",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.6143892339544513, Sensitivity: 0.48876716678574267, Specificity: 0.942857142857143\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8484848484848485, F1 Score: 0.8201447245564891, Sensitivity: 0.725252044137493, Specificity: 0.9553571428571429\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8282828282828283, F1 Score: 0.7850361197110424, Sensitivity: 0.744145431451933, Specificity: 0.8660714285714285\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.787878787878788, F1 Score: 0.8027768027768029, Sensitivity: 0.8730650154798761, Specificity: 0.7541666666666668\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 192ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7878787878787877, F1 Score: 0.7789173789173788, Sensitivity: 0.8174962292609352, Specificity: 0.75\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 166ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7676767676767676, F1 Score: 0.7092352092352092, Sensitivity: 0.5651345558466301, Specificity: 0.9791666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7575757575757575, F1 Score: 0.68300395256917, Sensitivity: 0.5683892990394539, Specificity: 0.9357142857142856\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8181818181818182, F1 Score: 0.775519978106185, Sensitivity: 0.6550766055410018, Specificity: 0.9791666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6767676767676768, F1 Score: 0.4908008658008658, Sensitivity: 0.33285702945145673, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8585858585858586, F1 Score: 0.830564711052516, Sensitivity: 0.8265460030165913, Specificity: 0.8452380952380952\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 184ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.585858585858586, F1 Score: 0.4843304843304843, Sensitivity: 0.6666666666666666, Specificity: 0.5\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8585858585858586, F1 Score: 0.8452191587133262, Sensitivity: 0.82106850837501, Specificity: 0.8672619047619047\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7575757575757577, F1 Score: 0.6416666666666667, Sensitivity: 0.5227435103596094, Specificity: 0.9553571428571429\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7878787878787877, F1 Score: 0.6634615384615384, Sensitivity: 0.5691831388425815, Specificity: 0.9523809523809524\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 152ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6969696969696969, F1 Score: 0.544937036398137, Sensitivity: 0.393585774390728, Specificity: 0.9761904761904763\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7575757575757577, F1 Score: 0.6872294372294373, Sensitivity: 0.6445979201397158, Specificity: 0.8476190476190476\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 158ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8585858585858586, F1 Score: 0.84050215629163, Sensitivity: 0.8170993093593714, Specificity: 0.8690476190476191\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.797979797979798, F1 Score: 0.7659200702678963, Sensitivity: 0.6807176311820274, Specificity: 0.9178571428571428\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8080808080808081, F1 Score: 0.7548850574712643, Sensitivity: 0.6294355798999761, Specificity: 0.9791666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 199ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.797979797979798, F1 Score: 0.736616097409385, Sensitivity: 0.6898467889179963, Specificity: 0.9095238095238095\n",
      "100%|███████████████████████████████████████████████| 20/20 [06:59<00:00, 20.98s/trial, best loss: -0.8452191587133262]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59e923c5-37ed-4bc1-a7c1-071e08411481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.4065886438204695, 'epochs': 40, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.00025880603660114024}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e3aba8b-25e1-47ce-8ff7-fadb4a8d5bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a22bc45d-001a-4a59-9f95-8bd918c44c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18b55c3bfd0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e2bb4b55-b170-45db-8f60-01151384b199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4fa17bc9-d002-4717-a735-3b84ef7584ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.52\n",
      "F1 Score: 0.6842105263157895\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26fb66-80fb-46eb-ad10-e66fa29c76f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92de0028-059a-4b73-a4b7-f9c81a986626",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder & FNN with ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da41815c-38c7-48a4-bd44-21e3f978374d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb139b57-0e62-4972-b851-e4d1e318494a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4cb752fc-ef50-4a61-9cad-18d3f1ba1a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1163fd48-107c-4f40-a043-d953713c3e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf2404ce-b905-4b3d-bbde-09ab45e26486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bf8d340a-0ea6-4a43-b7d4-524e4a2995b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96e4e9f2-a049-48ea-bb13-ea95df7c7768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "196d3e43-ac04-48a3-b08b-c99c000b915c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b11ed7d-d9ee-4c4c-a9a8-215be30857f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                               \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [09:44<00:00, 29.22s/trial, best loss: -0.6268421052631579]\n",
      "Best parameters:  {'ae_activity_reg': 4.214691488245977e-07, 'ae_batch_size': 36.0, 'ae_dropout_rate': 0.296496511515566, 'ae_learning_rate': 0.009026236915207608, 'autoencoder_units': 67.0, 'encoding_dim': 45.0, 'fnn_batch_size': 45.0, 'fnn_dropout_rate': 0.4343193800389916, 'fnn_learning_rate': 0.009265940953353135, 'fnn_units': 165.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78bf588d-6067-4065-924a-e818fed2858a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b14d97d-a8f7-4f35-82d9-f53c7bd80d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9adceb58-1117-4621-98d4-b81e2a4adc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Final Model - Accuracy: 0.6163157894736843\n",
      "Final Model - F1 Score: 0.6092902711323763\n",
      "Final Model - Sensitivity: 0.6222727272727273\n",
      "Final Model - Specificity: 0.6077777777777778\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f4707-6ea9-4067-b461-6706ac534d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a515fcd4-d7de-4608-a9a7-66f3ebd0957b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2f00ba00-e319-46f8-b045-b58b7dc57fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_2980\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d4ad7967-4f75-4960-8a16-0ab873a100fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.T.astype(np.float32)\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.int32)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22aa3c88-dc21-4bb5-a47b-4470114bece9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_features_cmim(X, y, num_features):\n",
    "    mi_scores = mutual_info_classif(X, y)\n",
    "    top_indices = np.argsort(mi_scores)[-num_features:]\n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce895c7a-fd50-4ba0-a71c-66f02794ead3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_features_svm_rfe(X, y, num_features):\n",
    "    svc = SVC(kernel=\"linear\", C=1)\n",
    "    rfe = RFE(estimator=svc, n_features_to_select=num_features, step=1)\n",
    "    rfe.fit(X, y)\n",
    "    return np.where(rfe.support_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f66a8a7e-6a3e-4493-a27c-f1dfc7d00fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final selected features: (124, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_features_cmim = 5000  # Number of features to keep after CMIM\n",
    "cmim_indices = select_features_cmim(X_scaled, y, num_features_cmim)\n",
    "X_cmim = X_scaled[:, cmim_indices]\n",
    "\n",
    "# Second step: Apply SVM-RFE on the reduced feature space from CMIM\n",
    "num_features_final = 1000  # Number of final features to select\n",
    "svm_rfe_indices = select_features_svm_rfe(X_cmim, y, num_features_final)\n",
    "X_final = X_cmim[:, svm_rfe_indices]\n",
    "\n",
    "print(f\"Shape of final selected features: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c560c59b-97a5-4d75-b2a5-e651c2c2452d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6920bc54-5cd4-476f-a34f-456a0b2aabed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab3b6b1a-8116-4e9d-8631-95f0ff690a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6362d8ef-cd28-40ec-9800-26b31e2d4978",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3790322580645161, F1 Score: 0.42105263157894735, Sensitivity: 0.45161290322580644, Specificity: 0.3064516129032258\n",
      "Accuracy: 0.45161290322580644, F1 Score: 0.4426229508196721, Sensitivity: 0.43548387096774194, Specificity: 0.46774193548387094\n",
      "Accuracy: 0.41935483870967744, F1 Score: 0.41935483870967744, Sensitivity: 0.41935483870967744, Specificity: 0.41935483870967744\n",
      "Accuracy: 0.3225806451612903, F1 Score: 0.16, Sensitivity: 0.12903225806451613, Specificity: 0.5161290322580645        \n",
      "Accuracy: 0.3709677419354839, F1 Score: 0.4090909090909091, Sensitivity: 0.43548387096774194, Specificity: 0.3064516129032258\n",
      "Accuracy: 0.3387096774193548, F1 Score: 0.3787878787878788, Sensitivity: 0.4032258064516129, Specificity: 0.27419354838709675\n",
      "Accuracy: 0.20967741935483872, F1 Score: 0.234375, Sensitivity: 0.24193548387096775, Specificity: 0.1774193548387097   \n",
      "Accuracy: 0.3709677419354839, F1 Score: 0.4, Sensitivity: 0.41935483870967744, Specificity: 0.3225806451612903         \n",
      "Accuracy: 0.3629032258064516, F1 Score: 0.3779527559055118, Sensitivity: 0.3870967741935484, Specificity: 0.3387096774193548\n",
      "Accuracy: 0.4435483870967742, F1 Score: 0.448, Sensitivity: 0.45161290322580644, Specificity: 0.43548387096774194      \n",
      "Accuracy: 0.3629032258064516, F1 Score: 0.34710743801652894, Sensitivity: 0.3387096774193548, Specificity: 0.3870967741935484\n",
      "Accuracy: 0.3951612903225806, F1 Score: 0.3119266055045872, Sensitivity: 0.27419354838709675, Specificity: 0.5161290322580645\n",
      "Accuracy: 0.4274193548387097, F1 Score: 0.4409448818897638, Sensitivity: 0.45161290322580644, Specificity: 0.4032258064516129\n",
      "Accuracy: 0.46774193548387094, F1 Score: 0.5925925925925926, Sensitivity: 0.7741935483870968, Specificity: 0.16129032258064516\n",
      "Accuracy: 0.3870967741935484, F1 Score: 0.3968253968253968, Sensitivity: 0.4032258064516129, Specificity: 0.3709677419354839\n",
      "Accuracy: 0.3790322580645161, F1 Score: 0.4122137404580153, Sensitivity: 0.43548387096774194, Specificity: 0.3225806451612903\n",
      "Accuracy: 0.45161290322580644, F1 Score: 0.5277777777777778, Sensitivity: 0.6129032258064516, Specificity: 0.2903225806451613\n",
      "Accuracy: 0.3064516129032258, F1 Score: 0.25862068965517243, Sensitivity: 0.24193548387096775, Specificity: 0.3709677419354839\n",
      "Accuracy: 0.4274193548387097, F1 Score: 0.40336134453781514, Sensitivity: 0.3870967741935484, Specificity: 0.46774193548387094\n",
      "Accuracy: 0.31451612903225806, F1 Score: 0.3795620437956204, Sensitivity: 0.41935483870967744, Specificity: 0.20967741935483872\n",
      "100%|███████████████████████████████████████████████| 20/20 [11:00<00:00, 33.02s/trial, best loss: -0.5925925925925926]\n",
      "Best parameters found:  {'batch_size': 32.0, 'dropout_rate': 0.6228942892014944, 'epochs': 200.0, 'learning_rate': 0.04112011759606947, 'neurons1': 96.0, 'neurons2': 32.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "010eee4d-3f41-4983-a5b6-dec12cbb587a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_122\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_122\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_610 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">96,096</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_244 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_611 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_245 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_612 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_613 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">97,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_614 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_610 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │          \u001b[38;5;34m96,096\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_244 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_611 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m3,104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_245 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_612 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_613 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │          \u001b[38;5;34m97,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_614 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,001\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,369</span> (782.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m200,369\u001b[0m (782.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,369</span> (782.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m200,369\u001b[0m (782.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c58957f-11ed-47f7-865d-87ff600d1c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_deep_autoencoder(\n",
    "            input_dim=X_final.shape[1],\n",
    "            neurons1=best_params['neurons1'],\n",
    "            neurons2=best_params['neurons2'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48078b57-370a-4aeb-bfe2-cc742ba6c970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.541\n",
      "F1 Score: 0.5659819309547077\n",
      "Sensitivity: 0.7610389610389611\n",
      "Specificity: 0.3\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_final, y, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22aa59f-2128-4412-8a52-d6233d618c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6692d65f-66f1-4fe5-8580-7fd91635dcd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9c6795f-4b85-45a9-babd-0cd649ebb069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "372132b7-6dd9-46c3-a761-433115791918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4c61c32-b1bf-4e3b-8093-ac3c39bb6653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "368e8ac2-697e-498d-bc91-72b448bfb6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 8, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 32, 256, 32))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8325f663-3bfa-4df6-8718-ec1aa1778c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "01b942a9-715b-4c8b-86b6-23a384e9e533",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.6986071467399597, Params: {'batch_size': 96, 'dropout_rate': 0.5007305817894283, 'epochs': 60, 'learning_rate': 0.0021771068005399757, 'num_layers': 3, 'units': 64}\n",
      "Iteration - Loss: 0.6664407253265381, Params: {'batch_size': 192, 'dropout_rate': 0.15601902494076827, 'epochs': 70, 'learning_rate': 3.0218426643214106e-05, 'num_layers': 6, 'units': 96}\n",
      "Iteration - Loss: 0.6897127032279968, Params: {'batch_size': 64, 'dropout_rate': 0.4266617432587797, 'epochs': 100, 'learning_rate': 0.00011213818004478609, 'num_layers': 8, 'units': 192}\n",
      "Iteration - Loss: 0.6989477872848511, Params: {'batch_size': 160, 'dropout_rate': 0.694722045245896, 'epochs': 50, 'learning_rate': 6.694011878831385e-05, 'num_layers': 8, 'units': 192}\n",
      "Iteration - Loss: 0.7337703704833984, Params: {'batch_size': 192, 'dropout_rate': 0.41366106849531914, 'epochs': 100, 'learning_rate': 5.590146154157791e-05, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.7075393795967102, Params: {'batch_size': 224, 'dropout_rate': 0.16874452926347222, 'epochs': 140, 'learning_rate': 0.003084660228137449, 'num_layers': 7, 'units': 160}\n",
      "Iteration - Loss: 0.8380630612373352, Params: {'batch_size': 160, 'dropout_rate': 0.5818389194445112, 'epochs': 60, 'learning_rate': 0.0011102227827613316, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.7016499638557434, Params: {'batch_size': 160, 'dropout_rate': 0.15242505491063482, 'epochs': 140, 'learning_rate': 4.719809749050586e-05, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.7716224193572998, Params: {'batch_size': 192, 'dropout_rate': 0.21714815504216706, 'epochs': 120, 'learning_rate': 0.0006528549118453843, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.7123616933822632, Params: {'batch_size': 96, 'dropout_rate': 0.1303275305099568, 'epochs': 90, 'learning_rate': 5.6586137450864286e-05, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.7419136762619019, Params: {'batch_size': 192, 'dropout_rate': 0.6031895804760913, 'epochs': 60, 'learning_rate': 0.00035094216838940623, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.6918440461158752, Params: {'batch_size': 128, 'dropout_rate': 0.16390035521838886, 'epochs': 70, 'learning_rate': 0.003653437528861413, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.7012377977371216, Params: {'batch_size': 128, 'dropout_rate': 0.4320087762232975, 'epochs': 50, 'learning_rate': 0.004066060688466728, 'num_layers': 7, 'units': 160}\n",
      "Iteration - Loss: 0.7016940116882324, Params: {'batch_size': 64, 'dropout_rate': 0.27460951955437934, 'epochs': 110, 'learning_rate': 0.00023247448162756843, 'num_layers': 8, 'units': 64}\n",
      "Iteration - Loss: 0.7185419797897339, Params: {'batch_size': 160, 'dropout_rate': 0.26380718665159264, 'epochs': 130, 'learning_rate': 0.00010187944948191438, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.6859189867973328, Params: {'batch_size': 192, 'dropout_rate': 0.3840897957022853, 'epochs': 70, 'learning_rate': 0.0031000900194629645, 'num_layers': 6, 'units': 64}\n",
      "Iteration - Loss: 0.6960093975067139, Params: {'batch_size': 224, 'dropout_rate': 0.11719489517758086, 'epochs': 120, 'learning_rate': 0.00900413116878612, 'num_layers': 8, 'units': 224}\n",
      "Iteration - Loss: 0.695536196231842, Params: {'batch_size': 96, 'dropout_rate': 0.3456400298191479, 'epochs': 90, 'learning_rate': 0.00032858300275110953, 'num_layers': 8, 'units': 96}\n",
      "Iteration - Loss: 0.6946302652359009, Params: {'batch_size': 160, 'dropout_rate': 0.6554881072618401, 'epochs': 120, 'learning_rate': 6.366842716531179e-05, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.743348240852356, Params: {'batch_size': 192, 'dropout_rate': 0.5517698684508557, 'epochs': 100, 'learning_rate': 0.0001253924332267193, 'num_layers': 3, 'units': 256}\n",
      "Iteration - Loss: 0.6705676913261414, Params: {'batch_size': 224, 'dropout_rate': 0.3383863786728476, 'epochs': 80, 'learning_rate': 1.2114755047653653e-05, 'num_layers': 6, 'units': 96}\n",
      "Iteration - Loss: 0.742590069770813, Params: {'batch_size': 256, 'dropout_rate': 0.3183343884993096, 'epochs': 70, 'learning_rate': 1.0770252520766764e-05, 'num_layers': 6, 'units': 96}\n",
      "Iteration - Loss: 0.7027719020843506, Params: {'batch_size': 224, 'dropout_rate': 0.21992199119394734, 'epochs': 80, 'learning_rate': 2.412148969635334e-05, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 0.6995589137077332, Params: {'batch_size': 256, 'dropout_rate': 0.4959454604801649, 'epochs': 80, 'learning_rate': 1.0147519121317332e-05, 'num_layers': 7, 'units': 128}\n",
      "Iteration - Loss: 0.7014240622520447, Params: {'batch_size': 256, 'dropout_rate': 0.30444765654918116, 'epochs': 80, 'learning_rate': 2.182031522915976e-05, 'num_layers': 6, 'units': 64}\n",
      "Iteration - Loss: 0.7338067889213562, Params: {'batch_size': 224, 'dropout_rate': 0.22233403600621837, 'epochs': 90, 'learning_rate': 1.8988227351782208e-05, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 0.6981701850891113, Params: {'batch_size': 224, 'dropout_rate': 0.3723715810117033, 'epochs': 70, 'learning_rate': 3.0144074995812733e-05, 'num_layers': 7, 'units': 128}\n",
      "Iteration - Loss: 0.7410222291946411, Params: {'batch_size': 256, 'dropout_rate': 0.10069316126001085, 'epochs': 80, 'learning_rate': 1.339816028654407e-05, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 0.7128210067749023, Params: {'batch_size': 128, 'dropout_rate': 0.47760092967887735, 'epochs': 50, 'learning_rate': 3.374592502694934e-05, 'num_layers': 6, 'units': 96}\n",
      "Iteration - Loss: 0.6971407532691956, Params: {'batch_size': 32, 'dropout_rate': 0.27162598829278184, 'epochs': 60, 'learning_rate': 1.438193358372497e-05, 'num_layers': 5, 'units': 64}\n",
      "100%|████████████████████████████████████████████████| 30/30 [01:46<00:00,  3.55s/trial, best loss: 0.6664407253265381]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "74e6b1ce-07ea-4c3f-97b1-e3a707747a08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 192, 'dropout_rate': 0.15601902494076827, 'epochs': 70, 'learning_rate': 3.0218426643214106e-05, 'num_layers': 6, 'units': 96}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "007da458-2fee-4273-b59a-562ca40c9b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X_final, y, best_params, k=5):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(X_final):\n",
    "        X_train, X_test = X_final[train_idx], X_final[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Create and compile the model\n",
    "        best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "          num_layers=best_params['num_layers'],\n",
    "          units=best_params['units'],\n",
    "          dropout_rate=best_params['dropout_rate'],\n",
    "          learning_rate=best_params['learning_rate'])\n",
    "        \n",
    "        best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), \n",
    "                           loss='binary_crossentropy', \n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        best_model.fit(X_train, y_train, \n",
    "                       epochs=best_params['epochs'], \n",
    "                       batch_size=best_params['batch_size'], \n",
    "                       verbose=0)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "        f1 = f1_score(y_test, y_test_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Store the metrics\n",
    "        accuracies.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Average the metrics over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_sensitivity = np.mean(sensitivities)\n",
    "    avg_specificity = np.mean(specificities)\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_accuracy}\")\n",
    "    print(f\"F1 Score: {avg_f1}\")\n",
    "    print(f\"Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "066ef4cf-277f-4c46-85aa-bc001743e72b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Accuracy: 0.4131578947368421\n",
      "F1 Score: 0.3269924812030075\n",
      "Sensitivity: 0.3027272727272728\n",
      "Specificity: 0.5155555555555555\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_with_kfold(X_train, y_train, best_params, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64de5a-e259-4968-a9f8-e26c0712205e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd739898-632d-4610-a2a6-41c005cb2217",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b14e7a59-ba7b-48a5-8c47-d3d107a34b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d80c4b10-1158-4bd6-9b15-b42de87491b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe2db49c-4538-4fe0-9277-02aa55d074d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21f6c891-6b6b-4fca-83fe-18b77a1e2575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed6c5981-3f1b-456f-915e-7ed0fba0e198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ee683fe6-f7e5-42ad-a75e-730c20e10602",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4444444444444444, F1 Score: 0.6019503546099291, Sensitivity: 0.8568706834960705, Specificity: 0.047619047619047616\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5454545454545455, F1 Score: 0.42024104927330735, Sensitivity: 0.4766214177978884, Specificity: 0.5\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.3238770685579196, Sensitivity: 0.36429308565531476, Specificity: 0.6470238095238096\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.47474747474747475, F1 Score: 0.4733044733044733, Sensitivity: 0.567277923315075, Specificity: 0.30297619047619045\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.39870967741935487, Sensitivity: 0.4551083591331269, Specificity: 0.5416666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 178ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.1714285714285714, Sensitivity: 0.15789473684210525, Specificity: 0.8333333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.4636363636363636, Sensitivity: 0.491069302214813, Specificity: 0.5726190476190477\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 169ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4545454545454546, F1 Score: 0.29540695710908477, Sensitivity: 0.3165039295070255, Specificity: 0.525\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 163ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.31025641025641026, Sensitivity: 0.37254901960784315, Specificity: 0.6458333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 164ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.43791975963237895, Sensitivity: 0.5127411288402001, Specificity: 0.4130952380952381\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4646464646464647, F1 Score: 0.46728395061728395, Sensitivity: 0.5483051520203223, Specificity: 0.4505952380952381\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 197ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.35927072583419334, Sensitivity: 0.3866793681035167, Specificity: 0.6458333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.41414141414141414, F1 Score: 0.1598746081504702, Sensitivity: 0.13574660633484162, Specificity: 0.7416666666666667\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6161616161616161, F1 Score: 0.6230399230399231, Sensitivity: 0.6719060093673096, Specificity: 0.5244047619047619\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 160ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.31025641025641026, Sensitivity: 0.37254901960784315, Specificity: 0.6458333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 173ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4646464646464647, F1 Score: 0.2349206349206349, Sensitivity: 0.2277526395173454, Specificity: 0.7125\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.1935897435897436, Sensitivity: 0.12352147336667461, Specificity: 0.8464285714285714\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 167ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.2509534706331045, Sensitivity: 0.25077399380804954, Specificity: 0.7440476190476191\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 205ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5252525252525252, F1 Score: 0.39333333333333337, Sensitivity: 0.4871794871794872, Specificity: 0.5833333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step                                              \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.41889919604205317, Sensitivity: 0.46892117170754943, Specificity: 0.5119047619047619\n",
      "100%|███████████████████████████████████████████████| 20/20 [04:57<00:00, 14.87s/trial, best loss: -0.6230399230399231]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ee8c4a44-6f74-42c4-82c0-81aec37ab2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 16, 'dropout_rate': 0.3038760557660284, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.004188604943294365}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6070fb92-80fc-441f-ba09-ae2b785c3ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9282d1d5-f122-4d3a-931c-0e7249d1b567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18df67d01d0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "98a47dc8-0f19-44b3-9f8b-742713f3f13d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "94b01175-cc5d-4f1c-b10b-70fd7e984549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.52\n",
      "F1 Score: 0.6842105263157895\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a16bf-e52c-4945-b58f-e3b78935f0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d767a0-a38b-45d5-a0b2-27821ffa4c34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder & FNN with Hybrid FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0da60305-6ed5-4f0b-aaac-cb844a83af2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f59145f-3ca9-41de-83ac-020fcdc18778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "10ef26e5-20ce-4568-8a45-99e26dff942f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bf4091bf-19ef-4730-a6e9-43b228a33c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3841911a-6bdb-4da5-91e1-95a9300d0a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e06c1280-3e5d-4956-a434-228205a40f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d502c22f-1ef8-45dc-bf79-7137dd17b0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1497bc51-ae2c-43ca-94c2-3aebfd352da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0441af5c-eb64-455a-b7ec-4cd85ca2ce3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [10:29<00:00, 31.45s/trial, best loss: -0.5752631578947368]\n",
      "Best parameters:  {'ae_activity_reg': 1.1158377299354902e-07, 'ae_batch_size': 21.0, 'ae_dropout_rate': 0.13485297565317222, 'ae_learning_rate': 1.0699352922012109e-05, 'autoencoder_units': 407.0, 'encoding_dim': 35.0, 'fnn_batch_size': 45.0, 'fnn_dropout_rate': 0.2839733952324477, 'fnn_learning_rate': 1.865117768568632e-05, 'fnn_units': 432.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bc67e4b7-c686-4f45-8f5a-bd12f2715868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "734ce2d7-fe73-4bc2-8824-a311441689f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "118ec075-9079-41ad-acd8-acc2590b64cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Final Model - Accuracy: 0.45473684210526316\n",
      "Final Model - F1 Score: 0.4851851851851852\n",
      "Final Model - Sensitivity: 0.6131818181818182\n",
      "Final Model - Specificity: 0.33555555555555555\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a0e34-0070-41a1-b946-26fe7530bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
