{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd392ae-9326-4a6c-be5e-750d49b61d7f",
   "metadata": {},
   "source": [
    "## Data / Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f00f0ee-ac95-441c-a236-de07c0e60f20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Affy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, GRU, Layer, Add, GlobalAveragePooling1D, Conv1D, ReLU\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "import scipy.stats as stats\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from accelerate import DataLoaderConfiguration\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from boruta import BorutaPy\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6860d3a3-81b1-40c7-ba61-18bedfee9fc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AMGM and Cosine Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a7f397-8f20-4666-aed9-40ad33aca173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_amgm(X):\n",
    "    \"\"\"\n",
    "    Calculate AMGM for each feature (row) in the dataset X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): The input data array with shape (n_features, n_samples)\n",
    "    \n",
    "    Returns:\n",
    "    amgm_values (numpy array): The AMGM values for each feature (row)\n",
    "    \"\"\"\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    exp_X = np.exp(X)\n",
    "    amgm_values = (np.mean(exp_X, axis=1)) / (np.exp(np.mean(X, axis=1)))\n",
    "    \n",
    "    return amgm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01885de-8abe-4501-9729-751ba4d72c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_redundant_features(X, relevant_indices, threshold=0.9):\n",
    "    relevant_features = X[relevant_indices, :]\n",
    "    cos_sim_matrix = cosine_similarity(relevant_features)\n",
    "    \n",
    "    to_keep = []\n",
    "    to_drop = set()\n",
    "    for i in range(cos_sim_matrix.shape[0]):\n",
    "        if i not in to_drop:\n",
    "            to_keep.append(relevant_indices[i])\n",
    "            for j in range(i + 1, cos_sim_matrix.shape[0]):\n",
    "                if cos_sim_matrix[i, j] > threshold:\n",
    "                    to_drop.add(relevant_indices[j])\n",
    "    return to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87953735-2cf1-4355-9ae5-ed01ff49c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b0dad26-deb2-4ce3-9d56-1ede8a22ab70",
   "metadata": {},
   "source": [
    "## Autoencoder Feature Selection with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b943080e-30d1-492d-be4e-d76475428ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_feature_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)  # Encoder part\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)  # Decoder part\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40b850a-3003-4dd5-be7d-08a29c4e7891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_l1_feature_selection(X, y, alpha=0.01, target_features=100):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    model = SelectFromModel(lasso, prefit=True, max_features=target_features)\n",
    "    X_reduced = model.transform(X)\n",
    "    selected_indices = model.get_support(indices=True)\n",
    "    return X_reduced, selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb6141-11ff-46bb-bb60-172c4d1fc0cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initial Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b5d5c24-4048-42e2-a0dd-10911a06659b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfec5c7a-3206-4962-9f2f-a177f4c6632a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a64f23d-828e-4f02-94c1-035591928b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf0a68e-a90d-435e-ab17-69c39509d0b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "380fc34e-afc2-4823-965b-b9723a48a77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90920de3-58b5-4a7c-8b26-e224de761477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8658fc6f-877a-43d7-a239-62ad404f016a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a268c417-608e-4d4f-ae52-048a865e56f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936   1827  43149 190298 237211 185366 192464 119497 195618]\n",
      "Top AMGM values: [1.00297347 1.002975   1.00297625 1.00297625 1.00297625 1.00297625\n",
      " 1.00297625 1.00297966 1.00298188 1.00298232]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd2f5770-9a6e-4131-848c-8034bb701234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2180bfb5-3bf4-4e82-a3d1-b88526441f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85a5c928-ed40-41b8-88f9-07a4e4a1c1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a22c9e7f-f4b4-4ec9-a482-c78bdbedf602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26123aab-532b-4c8b-b9fb-deaabdc8d72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b272455-9c44-4c5f-a8a6-b9c6bec540a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "359345d7-9d3a-4613-bdad-65da25c2add0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1721d85f-c521-4ef4-aae3-e5e8fd17717a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_103\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_103\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_515 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_206 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_516 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_207 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_517 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_518 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_519 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_515 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m6,464\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_206 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_516 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_207 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_517 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_518 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m6,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_519 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,257</span> (67.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,257\u001b[0m (67.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,257</span> (67.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,257\u001b[0m (67.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59608f3e-b38b-4783-9522-55cce0b15881",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5877 - loss: 0.6949 - val_accuracy: 0.6923 - val_loss: 0.6843 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4396 - loss: 0.7682 - val_accuracy: 0.3077 - val_loss: 0.8165 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5897 - loss: 0.7192 - val_accuracy: 0.3077 - val_loss: 0.7826 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5371 - loss: 0.7272 - val_accuracy: 0.5385 - val_loss: 0.6955 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4281 - loss: 0.7133 - val_accuracy: 0.6923 - val_loss: 0.6634 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4943 - loss: 0.7331 - val_accuracy: 0.6923 - val_loss: 0.6678 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5195 - loss: 0.6880 - val_accuracy: 0.3077 - val_loss: 0.7330 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5429 - loss: 0.6921 - val_accuracy: 0.3077 - val_loss: 0.7997 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6207 - loss: 0.6758 - val_accuracy: 0.3077 - val_loss: 0.8163 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5252 - loss: 0.7431 - val_accuracy: 0.3077 - val_loss: 0.7338 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5273 - loss: 0.6793 - val_accuracy: 0.6154 - val_loss: 0.6913 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5916 - loss: 0.6784 - val_accuracy: 0.6923 - val_loss: 0.6645 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5213 - loss: 0.7001 - val_accuracy: 0.6923 - val_loss: 0.6745 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5427 - loss: 0.7002 - val_accuracy: 0.5385 - val_loss: 0.6947 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5371 - loss: 0.6620 - val_accuracy: 0.4615 - val_loss: 0.7092 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5759 - loss: 0.6884 - val_accuracy: 0.3077 - val_loss: 0.7185 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5681 - loss: 0.6642 - val_accuracy: 0.4615 - val_loss: 0.7106 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5370 - loss: 0.6944 - val_accuracy: 0.4615 - val_loss: 0.7049 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6324 - loss: 0.6577 - val_accuracy: 0.4615 - val_loss: 0.6944 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6108 - loss: 0.6741 - val_accuracy: 0.6154 - val_loss: 0.6832 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6751 - loss: 0.6286 - val_accuracy: 0.4615 - val_loss: 0.6888 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5779 - loss: 0.6594 - val_accuracy: 0.4615 - val_loss: 0.7075 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6149 - loss: 0.6317 - val_accuracy: 0.3846 - val_loss: 0.7358 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5662 - loss: 0.6691 - val_accuracy: 0.3077 - val_loss: 0.7156 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6751 - loss: 0.6019 - val_accuracy: 0.4615 - val_loss: 0.6965 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5699 - loss: 0.6692 - val_accuracy: 0.5385 - val_loss: 0.6861 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7199 - loss: 0.5912 - val_accuracy: 0.6154 - val_loss: 0.6748 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6479 - loss: 0.6398 - val_accuracy: 0.6923 - val_loss: 0.6725 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6849 - loss: 0.6088 - val_accuracy: 0.5385 - val_loss: 0.6857 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6791 - loss: 0.5993 - val_accuracy: 0.4615 - val_loss: 0.7019 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6518 - loss: 0.6211 - val_accuracy: 0.5385 - val_loss: 0.6988 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7004 - loss: 0.5939 - val_accuracy: 0.6154 - val_loss: 0.6872 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7140 - loss: 0.5749 - val_accuracy: 0.6154 - val_loss: 0.6875 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7082 - loss: 0.5795 - val_accuracy: 0.6154 - val_loss: 0.6766 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7666 - loss: 0.5466 - val_accuracy: 0.6154 - val_loss: 0.6821 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6381 - loss: 0.5940 - val_accuracy: 0.6154 - val_loss: 0.6953 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7646 - loss: 0.5246 - val_accuracy: 0.6154 - val_loss: 0.7027 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6888 - loss: 0.5747 - val_accuracy: 0.6154 - val_loss: 0.7198 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7685 - loss: 0.4991 - val_accuracy: 0.6154 - val_loss: 0.7149 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6809 - loss: 0.5710 - val_accuracy: 0.6154 - val_loss: 0.7027 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7626 - loss: 0.5016 - val_accuracy: 0.6154 - val_loss: 0.6982 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7314 - loss: 0.5234 - val_accuracy: 0.6154 - val_loss: 0.7073 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8132 - loss: 0.4653 - val_accuracy: 0.5385 - val_loss: 0.7109 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7646 - loss: 0.4338 - val_accuracy: 0.6154 - val_loss: 0.7252 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7413 - loss: 0.4870 - val_accuracy: 0.6154 - val_loss: 0.7490 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8152 - loss: 0.3840 - val_accuracy: 0.6154 - val_loss: 0.7861 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 0.3986 - val_accuracy: 0.6154 - val_loss: 0.8048 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7703 - loss: 0.4269 - val_accuracy: 0.6154 - val_loss: 0.8019 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8522 - loss: 0.3897 - val_accuracy: 0.6154 - val_loss: 0.8005 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7647 - loss: 0.4604 - val_accuracy: 0.6154 - val_loss: 0.8076 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb0386f0-ff2b-4ce6-967f-22a4bb32c19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 0.68\n",
      "F1 Score: 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c12dc3fb-7e1e-4304-bd49-dc04ff30a730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f16b369-83ac-4372-80c5-ee1fedff850f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "F1 Score: 0.6363636363636364\n",
      "Specificity: 0.8333333333333334\n",
      "Sensitivity: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc8c1b-756f-4d4b-b76d-f4549fc64445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a3f5d7-97ff-4de3-b647-9dfb7c5a06b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a44670f-9311-40c7-bfff-0fc743a3c887",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da671726-dc91-4e5b-9287-3ea1f0c76390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4361ccc2-8545-47b4-b81b-073c616c7c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ade221c-0400-4b5f-8a42-9cb4d07bf219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c8e8bbd-0aa6-405d-b788-f9b8f4b0edd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936   1827  43149 190298 237211 185366 192464 119497 195618]\n",
      "Top AMGM values: [1.00297347 1.002975   1.00297625 1.00297625 1.00297625 1.00297625\n",
      " 1.00297625 1.00297966 1.00298188 1.00298232]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96c90fa4-2164-43a5-9ae8-df1b4ea335fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9f05d44-39fb-4001-8591-b751ed0da372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3eeb08fe-31b3-41f6-811a-c67d13fe2ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "182849e1-a346-4eec-b7c3-b93b8b00f5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4511f448-c3b0-4037-868d-d5aa4d8dba4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa1795e2-8645-4eae-be82-ffb71885bf12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55311067-529e-4a0e-912a-ba29a2d3d926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02e3d26b-d379-4af1-8f26-4f14dcb41dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C8852DB060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C8AA1BA660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.47580645161290325, F1 Score: 0.6198830409356725, Sensitivity: 0.8548387096774194, Specificity: 0.0967741935483871\n",
      "Accuracy: 0.6129032258064516, F1 Score: 0.6666666666666666, Sensitivity: 0.7741935483870968, Specificity: 0.45161290322580644\n",
      "Accuracy: 0.6854838709677419, F1 Score: 0.6776859504132231, Sensitivity: 0.6612903225806451, Specificity: 0.7096774193548387\n",
      "Accuracy: 0.5887096774193549, F1 Score: 0.5714285714285714, Sensitivity: 0.5483870967741935, Specificity: 0.6290322580645161\n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6229508196721312, Sensitivity: 0.6129032258064516, Specificity: 0.6451612903225806\n",
      "Accuracy: 0.6612903225806451, F1 Score: 0.6557377049180327, Sensitivity: 0.6451612903225806, Specificity: 0.6774193548387096\n",
      "Accuracy: 0.6209677419354839, F1 Score: 0.6299212598425197, Sensitivity: 0.6451612903225806, Specificity: 0.5967741935483871\n",
      "Accuracy: 0.5967741935483871, F1 Score: 0.5535714285714286, Sensitivity: 0.5, Specificity: 0.6935483870967742          \n",
      "Accuracy: 0.6532258064516129, F1 Score: 0.6666666666666666, Sensitivity: 0.6935483870967742, Specificity: 0.6129032258064516\n",
      "Accuracy: 0.6612903225806451, F1 Score: 0.6440677966101694, Sensitivity: 0.6129032258064516, Specificity: 0.7096774193548387\n",
      "Accuracy: 0.6048387096774194, F1 Score: 0.5811965811965812, Sensitivity: 0.5483870967741935, Specificity: 0.6612903225806451\n",
      "Accuracy: 0.6774193548387096, F1 Score: 0.6610169491525424, Sensitivity: 0.6290322580645161, Specificity: 0.7258064516129032\n",
      "Accuracy: 0.6370967741935484, F1 Score: 0.628099173553719, Sensitivity: 0.6129032258064516, Specificity: 0.6612903225806451\n",
      "Accuracy: 0.5645161290322581, F1 Score: 0.5970149253731343, Sensitivity: 0.6451612903225806, Specificity: 0.4838709677419355\n",
      "Accuracy: 0.6854838709677419, F1 Score: 0.6666666666666666, Sensitivity: 0.6290322580645161, Specificity: 0.7419354838709677\n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6290322580645161, Sensitivity: 0.6290322580645161, Specificity: 0.6290322580645161\n",
      "Accuracy: 0.6693548387096774, F1 Score: 0.672, Sensitivity: 0.6774193548387096, Specificity: 0.6612903225806451        \n",
      "Accuracy: 0.6290322580645161, F1 Score: 0.6617647058823529, Sensitivity: 0.7258064516129032, Specificity: 0.532258064516129\n",
      "Accuracy: 0.5645161290322581, F1 Score: 0.6086956521739131, Sensitivity: 0.6774193548387096, Specificity: 0.45161290322580644\n",
      "Accuracy: 0.49193548387096775, F1 Score: 0.6134969325153374, Sensitivity: 0.8064516129032258, Specificity: 0.1774193548387097\n",
      "100%|███████████████████████████████████████████████| 20/20 [07:05<00:00, 21.28s/trial, best loss: -0.6776859504132231]\n",
      "Best parameters found:  {'batch_size': 64.0, 'dropout_rate': 0.3886455175010518, 'epochs': 100.0, 'learning_rate': 0.00031372782335705325, 'neurons1': 192.0, 'neurons2': 32.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "132a7da7-c657-4133-aec6-f52e33245e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6854838709677419\n",
      "Best F1 Score: 0.6776859504132231\n",
      "Best Specificity: 0.7096774193548387\n",
      "Best Sensitivity: 0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e78a0fb-6256-418f-833b-1b3b4f918d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_104\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_104\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_520 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,392</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_208 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_521 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_209 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_522 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_523 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_524 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_520 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │          \u001b[38;5;34m19,392\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_208 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_521 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m6,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_209 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_522 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │           \u001b[38;5;34m6,336\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_523 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m19,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_524 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,305</span> (200.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,305\u001b[0m (200.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,305</span> (200.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,305\u001b[0m (200.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a69bd93-914f-4e00-997e-23183c40db24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 192\n",
      "Neurons in second layer: 32\n",
      "Dropout rate: 0.3886455175010518\n",
      "Learning rate: 0.00031372782335705325\n",
      "Number of epochs: 100\n",
      "Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439acd0-d449-4573-adc7-2b0c142ae75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0e13773-97d6-44a2-9fb1-0342ae6d000c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae1bec1f-b154-403e-a9c3-0b500bdc9e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "697e4b5c-d601-41f7-a2f2-8a3d6d37a4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\2580834323.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "661d99c3-10b3-4ba3-a56a-8995b2999df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d5bc8ac3-bd7a-42d9-8bf5-a41966c7b424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1a68641-177e-412f-b218-e8be27b480d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c36b1479-baba-43c4-a1de-f7f6f2292b49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936   1827  43149 190298 237211 185366 192464 119497 195618]\n",
      "Top AMGM values: [1.00297347 1.002975   1.00297625 1.00297625 1.00297625 1.00297625\n",
      " 1.00297625 1.00297966 1.00298188 1.00298232]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5b68ec2-f202-489a-b587-9b0ccf60ca8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5823643-01ca-45ca-abe7-fc89475457e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "37397bd3-1fe2-4b5e-8dba-d2981d85e104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22bc99df-1398-46cb-95f4-134777e617ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed5c5c62-79a5-43b8-a7d2-f9fba8987fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 128, 32)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69006e00-8ff7-4570-a4bc-b764756c0dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ca49a36a-52a5-4e62-99ad-b7737e181a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.8282828282828283, F1 Score: 0.8255850727387729, Sensitivity: 0.8004357298474947, Specificity: 0.862962962962963\n",
      "Iteration Results - Accuracy: 0.797979797979798, F1 Score: 0.8030303030303031, Sensitivity: 0.8189542483660132, Specificity: 0.7805555555555556\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.6641975308641975, Sensitivity: 0.5860566448801743, Specificity: 0.8435185185185184\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.7729468599033816, Sensitivity: 0.8474945533769063, Specificity: 0.6370370370370371\n",
      "Iteration Results - Accuracy: 0.7676767676767676, F1 Score: 0.7734960767218831, Sensitivity: 0.7978213507625272, Specificity: 0.736574074074074\n",
      "Iteration Results - Accuracy: 0.8282828282828283, F1 Score: 0.8326656827605595, Sensitivity: 0.8374727668845315, Specificity: 0.825925925925926\n",
      "Iteration Results - Accuracy: 0.797979797979798, F1 Score: 0.8175094599243207, Sensitivity: 0.8830065359477125, Specificity: 0.725\n",
      "Iteration Results - Accuracy: 0.8484848484848485, F1 Score: 0.8460274790919952, Sensitivity: 0.8374727668845315, Specificity: 0.8606481481481482\n",
      "Iteration Results - Accuracy: 0.7575757575757575, F1 Score: 0.7550505050505051, Sensitivity: 0.7427015250544663, Specificity: 0.7796296296296297\n",
      "Iteration Results - Accuracy: 0.8181818181818182, F1 Score: 0.8214285714285715, Sensitivity: 0.838562091503268, Specificity: 0.800462962962963\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.6479925303454716, Sensitivity: 0.5516339869281045, Specificity: 0.8486111111111111\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.6865079365079364, Sensitivity: 0.5986928104575163, Specificity: 0.8606481481481482\n",
      "Iteration Results - Accuracy: 0.8181818181818182, F1 Score: 0.8006060606060607, Sensitivity: 0.7522875816993464, Specificity: 0.8731481481481481\n",
      "Iteration Results - Accuracy: 0.7878787878787877, F1 Score: 0.7852809706257982, Sensitivity: 0.7671023965141611, Specificity: 0.8310185185185185\n",
      "Iteration Results - Accuracy: 0.6565656565656566, F1 Score: 0.6550947499223362, Sensitivity: 0.64640522875817, Specificity: 0.6893518518518519\n",
      "Iteration Results - Accuracy: 0.8383838383838383, F1 Score: 0.8383838383838386, Sensitivity: 0.8252723311546841, Specificity: 0.8666666666666667\n",
      "Iteration Results - Accuracy: 0.7676767676767676, F1 Score: 0.7587813620071685, Sensitivity: 0.7379084967320262, Specificity: 0.7967592592592593\n",
      "Iteration Results - Accuracy: 0.6767676767676768, F1 Score: 0.6199633699633699, Sensitivity: 0.5427015250544662, Specificity: 0.8226851851851852\n",
      "Iteration Results - Accuracy: 0.8282828282828283, F1 Score: 0.8273809523809524, Sensitivity: 0.8189542483660132, Specificity: 0.8421296296296297\n",
      "Iteration Results - Accuracy: 0.7575757575757575, F1 Score: 0.7395382395382395, Sensitivity: 0.707843137254902, Specificity: 0.8250000000000001\n",
      "100%|███████████████████████████████████████████████| 20/20 [21:20<00:00, 64.02s/trial, best loss: -0.8460274790919952]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b1bc955d-aea4-41eb-adc3-36a3d2c0fdae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 64, 'dropout_rate': 0.4980102429755082, 'learning_rate': 0.0002397781360725169, 'epochs': 50, 'batch_size': 48, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dae7a270-4adb-49a3-9fd7-989d6af48985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.64\n",
      "F1 Score: 0.6086956521739131\n",
      "Sensitivity: 0.5833333333333334\n",
      "Specificity: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1fdcc-a140-4929-9820-721c37cd8647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a3a5d-2b03-49e8-a3ea-a3631a821484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f7d8b46-3a5d-4150-9d43-9058296023c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gru with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a168d442-edad-4a9a-9581-dc56d13a40c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a4d33ac4-90ae-4397-b539-2c352b291154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6cfc2d87-ed27-4fb1-be3e-9ab859a2685b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1443f452-b7eb-4fa9-9796-9cde97c8ac58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f7f87ea-63d2-4a53-b208-31380799625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f81e483d-6cd4-43e6-a13c-e937ee3e9b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "374ff74c-afcc-4315-8c7a-04a3bdc62bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5265cef0-ae34-4f25-b8cb-d69ac7f906c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "65cb06c5-0c00-4e04-9e28-db275077fd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ff6981f9-8a8d-48b8-880b-f424ba5171fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "619c1bd2-d8c0-40c8-9f5c-8bba010b9fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 64, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.4),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "247393ae-704a-401d-95b6-659cf5e1f68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a249b175-5cc9-47cd-a714-3103f43d70ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6464646464646465, F1 Score: 0.6603174603174603, Sensitivity: 0.7001667063586569, Specificity: 0.6244047619047619\n",
      "Iteration Results - Accuracy: 0.6262626262626263, F1 Score: 0.6490507314036725, Sensitivity: 0.702230689846789, Specificity: 0.5869047619047619\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.6504629629629629, Sensitivity: 0.6941335238548861, Specificity: 0.5922619047619048\n",
      "Iteration Results - Accuracy: 0.7474747474747474, F1 Score: 0.7606009516316362, Sensitivity: 0.8434547908232118, Specificity: 0.6660714285714285\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6551764025448236, Sensitivity: 0.6986584107327141, Specificity: 0.686904761904762\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6827734711455643, Sensitivity: 0.7743113439707866, Specificity: 0.5738095238095239\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6652183600713013, Sensitivity: 0.6765896642057633, Specificity: 0.6785714285714285\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.6285714285714286, Sensitivity: 0.6745256807176312, Specificity: 0.5660714285714286\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.6633251433251434, Sensitivity: 0.6730173850916885, Specificity: 0.7267857142857143\n",
      "Iteration Results - Accuracy: 0.616161616161616, F1 Score: 0.6055299539170508, Sensitivity: 0.6083194411367786, Specificity: 0.669047619047619\n",
      "Iteration Results - Accuracy: 0.6161616161616162, F1 Score: 0.5966985084632143, Sensitivity: 0.5960943081686115, Specificity: 0.6630952380952381\n",
      "Iteration Results - Accuracy: 0.5757575757575757, F1 Score: 0.5813454837845081, Sensitivity: 0.6217353338096373, Specificity: 0.544047619047619\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.6664809863339275, Sensitivity: 0.682622846709534, Specificity: 0.6785714285714285\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.6405228758169934, Sensitivity: 0.6650789870604111, Specificity: 0.6410714285714286\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.717948717948718, Sensitivity: 0.7536715090894658, Specificity: 0.7273809523809524\n",
      "Iteration Results - Accuracy: 0.6363636363636364, F1 Score: 0.6347650171179583, Sensitivity: 0.6434071604350242, Specificity: 0.6702380952380952\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.6624338624338625, Sensitivity: 0.7770897832817337, Specificity: 0.5077380952380953\n",
      "Iteration Results - Accuracy: 0.5959595959595959, F1 Score: 0.6441179551644668, Sensitivity: 0.7574819401444789, Specificity: 0.493452380952381\n",
      "Iteration Results - Accuracy: 0.5858585858585857, F1 Score: 0.5608465608465608, Sensitivity: 0.5773596888147972, Specificity: 0.6482142857142857\n",
      "Iteration Results - Accuracy: 0.5555555555555555, F1 Score: 0.5755877616747181, Sensitivity: 0.6969913471461459, Specificity: 0.35773809523809524\n",
      "100%|████████████████████████████████████████████| 20/20 [1:07:58<00:00, 203.95s/trial, best loss: -0.7606009516316362]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bda36308-47d7-4d06-82ff-0447d70d7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 48, 'dropout_rate': 0.26149192458937076, 'epochs': 20, 'learning_rate': 0.008201820631259751, 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ff996c96-8e43-4ae2-9dc8-9925e866301a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "24efc4cb-db7b-4bc0-9afd-53baa2d407e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "11aa2678-d0b4-4965-a93c-c75ec3d55ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2cab886e350>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b262a864-333a-498d-a803-6c07a706383d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.84\n",
      "F1 Score: 0.8571428571428571\n",
      "Sensitivity: 0.9230769230769231\n",
      "Specificity: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06800a32-61b6-4931-b62c-afec61a67b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456eb99-15b1-40ec-8cc3-74b567ee8156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a74844e-656a-4e3e-8626-3fb1c398cb32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4d055f46-5cce-4dea-81d6-c182e8501d79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3db8f020-3d86-4e55-961c-099fac014b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "09861ef6-1517-4024-8a29-47230d14f8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2784aaf2-a7c0-4b29-951b-60362b2dc600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "20dd59cf-7c7c-4f1f-b258-185c49cf951c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "122b9c1a-c55f-4037-9a37-283e0f5716d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c9218acd-60dd-4467-87ea-105e5427c57e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a5b3a976-5da1-415a-8e74-8713dd9208c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b7c09be-7d00-43fc-9175-a41e113b4199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9a2469a4-ec0c-4a87-b634-cfd650fcc079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "85a1e3a5-727f-4085-a271-d7c73bb378d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "258804d2-596f-4eb3-8130-f42d05087db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1650a8d7-1811-4334-8f71-d066a76d4f1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.7021072796934865, Sensitivity: 0.7724061284432802, Specificity: 0.5279761904761905\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7373737373737373, F1 Score: 0.7470559845559847, Sensitivity: 0.8001111375724378, Specificity: 0.6910714285714286\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5959595959595959, F1 Score: 0.577485380116959, Sensitivity: 0.6442803842184647, Specificity: 0.6208333333333333\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6969696969696969, F1 Score: 0.5833333333333334, Sensitivity: 0.5475113122171945, Specificity: 0.7619047619047619\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7171717171717171, F1 Score: 0.6641025641025641, Sensitivity: 0.6291180439787251, Specificity: 0.793452380952381\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6969696969696969, F1 Score: 0.6433239962651728, Sensitivity: 0.6319758672699849, Specificity: 0.6696428571428571\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7171717171717171, F1 Score: 0.6125356125356126, Sensitivity: 0.505040882749861, Specificity: 0.8910714285714286\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7272727272727274, F1 Score: 0.6443965517241379, Sensitivity: 0.5410018258315472, Specificity: 0.9011904761904762\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6161616161616161, F1 Score: 0.6973079633544751, Sensitivity: 0.9019607843137255, Specificity: 0.34761904761904755\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6565656565656567, F1 Score: 0.583024818318936, Sensitivity: 0.4861474954354212, Specificity: 0.8101190476190476\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.3565359477124183, Sensitivity: 0.22346590458045568, Specificity: 0.9833333333333334\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.6452512039298478, Sensitivity: 0.6319758672699849, Specificity: 0.6964285714285715\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5858585858585859, F1 Score: 0.34068076173339334, Sensitivity: 0.23553226958799714, Specificity: 0.9357142857142856\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.6509009009009009, Sensitivity: 0.6503929507025482, Specificity: 0.6809523809523809\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.5131987577639752, Sensitivity: 0.3524648725887116, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6565656565656567, F1 Score: 0.5326510721247564, Sensitivity: 0.4647932047312852, Specificity: 0.8375\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7070707070707071, F1 Score: 0.5748245614035088, Sensitivity: 0.4773358736207034, Specificity: 0.8839285714285715\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6565656565656566, F1 Score: 0.5411111111111112, Sensitivity: 0.42200523934270057, Specificity: 0.9166666666666666\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6868686868686869, F1 Score: 0.5344982078853047, Sensitivity: 0.38961657537508926, Specificity: 0.9523809523809524\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.4504761904761905, Sensitivity: 0.4717789949988092, Specificity: 0.7166666666666667\n",
      "100%|███████████████████████████████████████████████| 20/20 [03:01<00:00,  9.09s/trial, best loss: -0.7470559845559847]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6d7cd1ed-120b-4de1-92a5-77a6583b5a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 48, 'dropout_rate': 0.2704870963112872, 'epochs': 30, 'filters': 96, 'kernel_size': 2, 'learning_rate': 0.004843677725374834}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9073aa76-76e6-4a22-9c66-6fef6778c065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ff89d0a6-1a54-4537-b0df-0938e10f29b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ca7665bc50>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc5eeb26-d883-4009-beaf-5efbf9b14447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f323f00e-c44b-4bd7-a4bf-7cb7ed71ee45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.68\n",
      "F1 Score: 0.5555555555555556\n",
      "Sensitivity: 0.38461538461538464\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf313f-aff3-4605-a652-e66d46ea08c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3377436d-64fe-4682-b11c-01b9b1c2943d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3be676c2-3a65-4712-a96c-41a556883c95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2b29409c-fbb6-43df-884a-01e50fb2c64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6d92fd0e-f54e-459a-b0d7-3e27ac6a0d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6d10b620-86b6-4882-b8da-5867c5ce8040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b62636bd-1b32-4f4c-8b3a-27814f2ce4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d1f37621-36ef-4bd0-9ca0-93a2c694ce65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6f6ff83e-bab6-498b-8762-ae38ce29df6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "22339bb6-7cf3-4c30-9aa3-4694d7d46056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d68dfd57-071a-40bc-96a6-7d06fe73ff61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b854c088-fe82-4825-bca9-1da62f1858fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e21fc95b-ee3d-4b28-9cf6-e0a2e223ce1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6a92101a-b355-44cb-9652-ca9288df0a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c6db490b-1954-47e6-b312-2e7a1e7acb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a8be5b3e-bfe7-4446-b2ce-f11065f8438f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3975613495818561, 'epochs': 20, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.002529773575832117, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.47526001930236816, Filters: 64, Blocks: 8, Kernel Size: 3, Dropout: 0.3975613495818561, LR: 0.002529773575832117, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.41543404313065024, 'epochs': 30, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.00019116119283463248, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5327001214027405, Filters: 32, Blocks: 10, Kernel Size: 3, Dropout: 0.41543404313065024, LR: 0.00019116119283463248, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3467660067695803, 'epochs': 40, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.0012954666525448817, 'num_blocks': 10}\n",
      "Iteration - Loss: 1.283017873764038, Filters: 96, Blocks: 10, Kernel Size: 5, Dropout: 0.3467660067695803, LR: 0.0012954666525448817, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.4105247333057399, 'epochs': 40, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.009399217604704472, 'num_blocks': 4}\n",
      "Iteration - Loss: 3.8415520191192627, Filters: 64, Blocks: 4, Kernel Size: 5, Dropout: 0.4105247333057399, LR: 0.009399217604704472, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.256056903344939, 'epochs': 30, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0018723258158435882, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.4070301055908203, Filters: 64, Blocks: 8, Kernel Size: 3, Dropout: 0.256056903344939, LR: 0.0018723258158435882, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.23840515270897467, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.001066828701448011, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5613354444503784, Filters: 64, Blocks: 4, Kernel Size: 4, Dropout: 0.23840515270897467, LR: 0.001066828701448011, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.23135447657125624, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.00020061151988807205, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6011539697647095, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.23135447657125624, LR: 0.00020061151988807205, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.41454792625416687, 'epochs': 20, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0003041706857813246, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.588485836982727, Filters: 96, Blocks: 10, Kernel Size: 3, Dropout: 0.41454792625416687, LR: 0.0003041706857813246, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3359765345277389, 'epochs': 30, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0001722329400123288, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.6207645535469055, Filters: 64, Blocks: 10, Kernel Size: 4, Dropout: 0.3359765345277389, LR: 0.0001722329400123288, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4003017615556681, 'epochs': 50, 'filters': 128, 'kernel_size': 5, 'learning_rate': 0.00036438979607694363, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5924263596534729, Filters: 128, Blocks: 4, Kernel Size: 5, Dropout: 0.4003017615556681, LR: 0.00036438979607694363, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.4006895837839367, 'epochs': 50, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.002406457785164454, 'num_blocks': 10}\n",
      "Iteration - Loss: 4.259948253631592, Filters: 96, Blocks: 10, Kernel Size: 3, Dropout: 0.4006895837839367, LR: 0.002406457785164454, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3056702997036658, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.00028222373468539294, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6232805252075195, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.3056702997036658, LR: 0.00028222373468539294, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.20846325970463203, 'epochs': 20, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.004586231679406748, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.799349069595337, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.20846325970463203, LR: 0.004586231679406748, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.40591860224220927, 'epochs': 50, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.006156663101509279, 'num_blocks': 6}\n",
      "Iteration - Loss: 12.124971389770508, Filters: 64, Blocks: 6, Kernel Size: 5, Dropout: 0.40591860224220927, LR: 0.006156663101509279, Batch Size: 64, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.35676098636627845, 'epochs': 20, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.00948743840233466, 'num_blocks': 6}\n",
      "Iteration - Loss: 3.0608599185943604, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.35676098636627845, LR: 0.00948743840233466, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3911166096666332, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0021328752529582865, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5845785140991211, Filters: 64, Blocks: 8, Kernel Size: 4, Dropout: 0.3911166096666332, LR: 0.0021328752529582865, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.24036766856199393, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0005988512232548408, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5718510746955872, Filters: 96, Blocks: 10, Kernel Size: 4, Dropout: 0.24036766856199393, LR: 0.0005988512232548408, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.45887359339557016, 'epochs': 20, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0031156562685003384, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.24500493705272675, Filters: 32, Blocks: 10, Kernel Size: 5, Dropout: 0.45887359339557016, LR: 0.0031156562685003384, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.33708228934852574, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0006263782720599717, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5095992088317871, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.33708228934852574, LR: 0.0006263782720599717, Batch Size: 16, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.3033699502499596, 'epochs': 50, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.0009982182953451315, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.6086653470993042, Filters: 64, Blocks: 6, Kernel Size: 3, Dropout: 0.3033699502499596, LR: 0.0009982182953451315, Batch Size: 64, Epochs: 50\n",
      "100%|███████████████████████████████████████████████| 20/20 [02:37<00:00,  7.86s/trial, best loss: 0.24500493705272675]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f24fa18f-4117-47d8-9790-2e45a3d18734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 48, 'dropout_rate': 0.45887359339557016, 'epochs': 20, 'filters': 32, 'kernel_size': 5, 'learning_rate': 0.0031156562685003384, 'num_blocks': 10}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "17da7572-b153-441e-b2cc-1b8e97c1b408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "35f5b485-af87-4582-8f0d-691cf33db7da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - accuracy: 0.7599 - loss: 0.5913 - val_accuracy: 0.5000 - val_loss: 12.9370\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - accuracy: 0.7385 - loss: 0.6036 - val_accuracy: 0.5000 - val_loss: 14.1020\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - accuracy: 0.7658 - loss: 0.4888 - val_accuracy: 0.5000 - val_loss: 14.8245\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d80fa961-a18b-47b4-8503-98924cf5351d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ba21c2e5-604b-4234-886b-60b26131a51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.52\n",
      "F1 Score: 0.6842105263157895\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6fc4a-dfd3-4157-b7cb-eb486bef46e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5080ed-7f46-471e-94b5-f1d000448785",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "59093306-4685-4e3a-9d17-b757a4a720d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_20200\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "62b72638-c32e-4af0-a1da-5ac1c32cd317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8b23c4b7-e073-44d9-8e66-cf8b45def847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5bf797a8-249a-419f-a6a3-97f0fa516e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "787ad11f-028d-4dbe-a36b-ee7699634a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "35fe54d9-4c29-4370-af6c-45839e30c642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1e88a4a6-a8d3-41c2-a191-74a3dc51000c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a2175fce-d5cb-4c76-a4af-973cbd5604b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a78536a7-6dc3-4a44-8ad5-a787410eb463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "941006a1-5bf7-4709-b7a5-efc26f4e8ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5db2392d-53d7-4160-91f8-ace26d4ee6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3e1cd145-11bf-498c-ba4a-fa8a5d0a454b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "06c68a22-75ae-4ada-a86f-185e6eda9196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.6557340621948242, Params: {'batch_size': 80, 'dropout_rate': 0.2759943218469899, 'epochs': 100, 'learning_rate': 5.740116088716993e-05, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.8506616353988647, Params: {'batch_size': 64, 'dropout_rate': 0.3835381824267792, 'epochs': 120, 'learning_rate': 0.00010761202010048912, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.6082776784896851, Params: {'batch_size': 32, 'dropout_rate': 0.21865977020055005, 'epochs': 70, 'learning_rate': 1.5384814765738954e-05, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.7128633856773376, Params: {'batch_size': 64, 'dropout_rate': 0.18657880609584165, 'epochs': 120, 'learning_rate': 0.006972105104347789, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.6343806385993958, Params: {'batch_size': 128, 'dropout_rate': 0.14632078019220018, 'epochs': 50, 'learning_rate': 0.0003535658424250918, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.592029333114624, Params: {'batch_size': 48, 'dropout_rate': 0.13880574154946484, 'epochs': 150, 'learning_rate': 1.3936655205482555e-05, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.5727174878120422, Params: {'batch_size': 32, 'dropout_rate': 0.368751467142198, 'epochs': 130, 'learning_rate': 0.0014170593762689169, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.6382583379745483, Params: {'batch_size': 64, 'dropout_rate': 0.1644912995363416, 'epochs': 90, 'learning_rate': 3.514328626574469e-05, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.6616369485855103, Params: {'batch_size': 48, 'dropout_rate': 0.266575696221783, 'epochs': 130, 'learning_rate': 1.3095328609438305e-05, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.6682784557342529, Params: {'batch_size': 48, 'dropout_rate': 0.13557794407778512, 'epochs': 120, 'learning_rate': 0.0001543658016836394, 'num_layers': 2, 'units': 256}\n",
      "Iteration - Loss: 0.6764230728149414, Params: {'batch_size': 80, 'dropout_rate': 0.24772970543324835, 'epochs': 70, 'learning_rate': 0.0014493419639131219, 'num_layers': 6, 'units': 192}\n",
      "Iteration - Loss: 0.6493202447891235, Params: {'batch_size': 96, 'dropout_rate': 0.41185212348216793, 'epochs': 100, 'learning_rate': 0.00011895004039257442, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 0.6409164667129517, Params: {'batch_size': 32, 'dropout_rate': 0.26341469808578777, 'epochs': 70, 'learning_rate': 0.00012172570885228749, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.6913853883743286, Params: {'batch_size': 80, 'dropout_rate': 0.3049433646081293, 'epochs': 110, 'learning_rate': 1.2591736723477136e-05, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.693686842918396, Params: {'batch_size': 80, 'dropout_rate': 0.43985684738981357, 'epochs': 90, 'learning_rate': 0.0009643493863591453, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 0.49218064546585083, Params: {'batch_size': 96, 'dropout_rate': 0.3343967525254308, 'epochs': 120, 'learning_rate': 0.00037706456010595953, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 0.49345332384109497, Params: {'batch_size': 64, 'dropout_rate': 0.1657144793140748, 'epochs': 100, 'learning_rate': 0.0011919333071824998, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 0.5413203239440918, Params: {'batch_size': 32, 'dropout_rate': 0.22343084881263908, 'epochs': 140, 'learning_rate': 0.000689176593005095, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.7111188173294067, Params: {'batch_size': 112, 'dropout_rate': 0.2458315734329264, 'epochs': 140, 'learning_rate': 0.00016334979813077065, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 0.5925184488296509, Params: {'batch_size': 32, 'dropout_rate': 0.24286443073656613, 'epochs': 80, 'learning_rate': 0.00023587248277447947, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.6621705293655396, Params: {'batch_size': 112, 'dropout_rate': 0.3378013478317411, 'epochs': 110, 'learning_rate': 0.003745788489892771, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.6854705810546875, Params: {'batch_size': 96, 'dropout_rate': 0.49565333872540607, 'epochs': 110, 'learning_rate': 0.00250356641218308, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.643005907535553, Params: {'batch_size': 96, 'dropout_rate': 0.1026764777891685, 'epochs': 90, 'learning_rate': 0.00047375255005784397, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.616463840007782, Params: {'batch_size': 112, 'dropout_rate': 0.3114362151867418, 'epochs': 130, 'learning_rate': 0.009367118004800563, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.6431114673614502, Params: {'batch_size': 128, 'dropout_rate': 0.4681248097538965, 'epochs': 80, 'learning_rate': 0.003868643962030301, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 0.6257606744766235, Params: {'batch_size': 96, 'dropout_rate': 0.3379706602368663, 'epochs': 110, 'learning_rate': 0.0006075952704347725, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.6636008024215698, Params: {'batch_size': 16, 'dropout_rate': 0.20498498636179022, 'epochs': 140, 'learning_rate': 0.0002851518857331077, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.6088529825210571, Params: {'batch_size': 64, 'dropout_rate': 0.3501743242184053, 'epochs': 50, 'learning_rate': 0.0017772008196554744, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.6719436049461365, Params: {'batch_size': 112, 'dropout_rate': 0.10078627166439251, 'epochs': 100, 'learning_rate': 4.536434021251887e-05, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 0.7102963328361511, Params: {'batch_size': 80, 'dropout_rate': 0.2846047660594256, 'epochs': 100, 'learning_rate': 0.0009099611366049236, 'num_layers': 4, 'units': 256}\n",
      "100%|███████████████████████████████████████████████| 30/30 [02:05<00:00,  4.17s/trial, best loss: 0.49218064546585083]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d3258374-1ca1-44e9-a146-561256dd2b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 96, 'dropout_rate': 0.3343967525254308, 'epochs': 120, 'learning_rate': 0.00037706456010595953, 'num_layers': 4, 'units': 160}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5fa7cb10-f438-448d-a698-855bf5004f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.5618 - loss: 0.6831 - val_accuracy: 0.4000 - val_loss: 0.7143\n",
      "Epoch 2/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.4719 - loss: 0.7069 - val_accuracy: 0.4000 - val_loss: 0.7126\n",
      "Epoch 3/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4944 - loss: 0.7105 - val_accuracy: 0.5000 - val_loss: 0.7125\n",
      "Epoch 4/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5955 - loss: 0.6973 - val_accuracy: 0.4000 - val_loss: 0.7112\n",
      "Epoch 5/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4494 - loss: 0.7208 - val_accuracy: 0.4000 - val_loss: 0.7100\n",
      "Epoch 6/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5843 - loss: 0.7032 - val_accuracy: 0.4000 - val_loss: 0.7091\n",
      "Epoch 7/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5393 - loss: 0.7037 - val_accuracy: 0.6000 - val_loss: 0.7094\n",
      "Epoch 8/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5955 - loss: 0.6724 - val_accuracy: 0.6000 - val_loss: 0.7097\n",
      "Epoch 9/120\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5056 - loss: 0.7002 - val_accuracy: 0.6000 - val_loss: 0.7100\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2e6ed749-e4d4-42cd-8b23-d855082b2e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.68\n",
      "F1 Score: 0.7142857142857143\n",
      "Sensitivity: 0.7692307692307693\n",
      "Specificity: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee3d94-1744-4b58-9b22-0262014da472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855d26f-7581-4a15-bb79-b0cc21c6e9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "053e8763-382c-410f-a5d7-4e9ca56015b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875e814c-720c-4647-a8e0-64ebedf98812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_15936\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5260ece-d62c-4fb7-9d5c-6fd6ce823cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values\n",
    "features_df = features_df.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9527f2-14bd-4d1f-bdc7-34c0656b043d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(features_df.values)\n",
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254e8c1a-cf5f-4737-b7b3-f8339a9e1605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(features_df.values, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4871bebb-5b19-4cac-b9cf-a97e9cc2d461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = features_df.iloc[selected_indices, :].T\n",
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962ef0b9-c391-414d-bc20-8ef1c646c788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c97ed17d-57f4-4bd9-91e0-0fe97034d576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80fe61f5-9bf3-4315-9e32-f94a75a5e38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d2c7fb2-5398-4630-a4e9-f9de7a64a922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 14:17:13,939] A new study created in memory with name: no-name-15a0a40b-0ddf-4246-a78e-1854f4bca071\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13cf811-77b1-4308-b6bb-d1cdd84f7181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 14:59:04,201] Trial 0 finished with value: 0.6907460689544678 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 4.660933131818913e-05, 'max_length': 188}. Best is trial 0 with value: 0.6907460689544678.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.690251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:01:04,821] Trial 1 finished with value: 0.6902512311935425 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.124303324757426e-05, 'max_length': 229}. Best is trial 1 with value: 0.6902512311935425.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.693609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>0.693480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:03:00,589] Trial 2 finished with value: 0.6934797763824463 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 2.1328378630002124e-05, 'max_length': 207}. Best is trial 1 with value: 0.6902512311935425.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 01:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:04:28,148] Trial 3 finished with value: 0.6948950886726379 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 2.182413528624614e-05, 'max_length': 226}. Best is trial 1 with value: 0.6902512311935425.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.690569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 15:05:32,459] Trial 4 finished with value: 0.6905686855316162 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 1.1403118672575394e-05, 'max_length': 158}. Best is trial 1 with value: 0.6902512311935425.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d782a3d-efe7-4fe4-8794-fdbd9fcc4ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.124303324757426e-05, 'max_length': 229}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "282abf66-47a3-4743-a960-da2573573212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c6422e8-7594-4512-925d-dc3a03a4f756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a9bcf7-d385-4d19-b872-9982ca900531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7803baf-a607-4616-b59d-9dafc9c0eda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a41535f0-fe59-47e9-a5e8-a14ee8d1d888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b113e824-50a5-4cb2-a051-868bf700d0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 08:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.724170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.722076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.748600</td>\n",
       "      <td>0.717885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=0.733118494351705, metrics={'train_runtime': 582.5795, 'train_samples_per_second': 0.51, 'train_steps_per_second': 0.021, 'total_flos': 78143983441920.0, 'train_loss': 0.733118494351705, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a69542a5-0097-4274-80bf-790451c04a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "F1 Score: 0.6842105263157895\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63ef0a-0f89-4e90-8743-b1b3dcceb9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8b01d-591c-4486-b665-5bc909a3e26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e443e3cb-7f4a-4f60-8636-861d56049ee4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a541a154-02a3-429b-aa63-7ffb23ead65f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24920\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444a86be-2cdf-4c9a-b332-1eb980cfca14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b63ff9-fc6f-44aa-b2d0-ce511113a10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af3288af-1250-4586-abbf-db50f9bcdc74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 25000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6084f870-0c6f-4f21-8986-92b0ae78a059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:2500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c54e8a4-56d7-447f-9a45-e8d4a81b7d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e88f850-1df2-45e5-83fe-f4f6a17daba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_selected)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd80d6b-2539-49e6-b6fd-2939c547bb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bcdfac-0c44-470a-8867-4e7c09d4ce46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2041fa8-e57b-4a62-a7cf-2b8f4ad0d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:46:48,366] A new study created in memory with name: no-name-6c4ffd20-e0f4-43c7-b4f8-97adc4d07b0e\n",
      "[I 2024-06-13 09:46:50,471] Trial 0 finished with value: 0.007652989588677883 and parameters: {'num_units': 129, 'learning_rate': 0.0002728687762563707, 'dropout_rate': 0.25208704343303295, 'activity_regularizer': 2.265561037381233e-06, 'batch_size': 48}. Best is trial 0 with value: 0.007652989588677883.\n",
      "[I 2024-06-13 09:46:54,270] Trial 1 finished with value: 0.007050937507301569 and parameters: {'num_units': 167, 'learning_rate': 0.00021881985022866298, 'dropout_rate': 0.03524417931876698, 'activity_regularizer': 1.260707654066861e-06, 'batch_size': 62}. Best is trial 1 with value: 0.007050937507301569.\n",
      "[I 2024-06-13 09:46:55,729] Trial 2 finished with value: 0.008443554863333702 and parameters: {'num_units': 248, 'learning_rate': 1.2862676099696006e-05, 'dropout_rate': 0.19443225808488382, 'activity_regularizer': 8.678771200812226e-06, 'batch_size': 45}. Best is trial 1 with value: 0.007050937507301569.\n",
      "[I 2024-06-13 09:46:57,554] Trial 3 finished with value: 0.006625966634601355 and parameters: {'num_units': 93, 'learning_rate': 0.0004897950595864854, 'dropout_rate': 0.23272481715653537, 'activity_regularizer': 3.390270767798302e-07, 'batch_size': 41}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:01,476] Trial 4 finished with value: 0.013493860140442848 and parameters: {'num_units': 152, 'learning_rate': 6.587598036018839e-05, 'dropout_rate': 8.705534246361557e-05, 'activity_regularizer': 5.516700363907684e-05, 'batch_size': 32}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:02,619] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:03,720] Trial 6 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:04,771] Trial 7 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 54 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000026740BAB7E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:06,105] Trial 8 finished with value: 0.007157334126532078 and parameters: {'num_units': 205, 'learning_rate': 4.209344824658562e-05, 'dropout_rate': 0.13612620627460187, 'activity_regularizer': 1.541274336418599e-07, 'batch_size': 52}. Best is trial 3 with value: 0.006625966634601355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 60 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000026740D6FBA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:07,159] Trial 9 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:08,307] Trial 10 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:09,688] Trial 11 finished with value: 0.007021911907941103 and parameters: {'num_units': 189, 'learning_rate': 0.00022396104460495274, 'dropout_rate': 0.19491192580860198, 'activity_regularizer': 7.169653781299245e-07, 'batch_size': 64}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:11,072] Trial 12 finished with value: 0.00692663062363863 and parameters: {'num_units': 197, 'learning_rate': 0.00044052503261075653, 'dropout_rate': 0.2113913429089339, 'activity_regularizer': 5.794665865475879e-07, 'batch_size': 64}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:12,085] Trial 13 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:13,052] Trial 14 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:14,824] Trial 15 finished with value: 0.0071802097372710705 and parameters: {'num_units': 198, 'learning_rate': 0.00034938310181971996, 'dropout_rate': 0.1784487723647888, 'activity_regularizer': 2.391733242475056e-07, 'batch_size': 17}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:15,836] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:17,267] Trial 17 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:47:18,267] Trial 18 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:19,281] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:20,584] Trial 20 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:47:21,599] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:22,641] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:23,757] Trial 23 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 09:47:25,036] Trial 24 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-13 09:47:26,038] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:27,378] Trial 26 pruned. Trial was pruned at epoch 5.\n",
      "[I 2024-06-13 09:47:31,174] Trial 27 finished with value: 0.006938186474144459 and parameters: {'num_units': 84, 'learning_rate': 0.0001492149524095405, 'dropout_rate': 0.13166778266267057, 'activity_regularizer': 2.065448915086333e-07, 'batch_size': 59}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:33,973] Trial 28 finished with value: 0.006980886682868004 and parameters: {'num_units': 84, 'learning_rate': 5.7833624643282506e-05, 'dropout_rate': 0.08816441308026494, 'activity_regularizer': 1.9644683065691156e-07, 'batch_size': 54}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:34,990] Trial 29 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:36,006] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:37,352] Trial 31 finished with value: 0.006641482003033161 and parameters: {'num_units': 84, 'learning_rate': 6.398055125305622e-05, 'dropout_rate': 0.08232461819119473, 'activity_regularizer': 1.5990276896788309e-07, 'batch_size': 54}. Best is trial 3 with value: 0.006625966634601355.\n",
      "[I 2024-06-13 09:47:38,372] Trial 32 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:39,946] Trial 33 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:40,950] Trial 34 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000002674A880680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:41,958] Trial 35 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 22 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x0000026748B36160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 09:47:42,976] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:43,988] Trial 37 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:45,259] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:46,277] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:47,839] Trial 40 finished with value: 0.006474638357758522 and parameters: {'num_units': 95, 'learning_rate': 4.5262992133035694e-05, 'dropout_rate': 0.13247553911660476, 'activity_regularizer': 1.1781594378365665e-06, 'batch_size': 45}. Best is trial 40 with value: 0.006474638357758522.\n",
      "[I 2024-06-13 09:47:51,739] Trial 41 finished with value: 0.006699718069285154 and parameters: {'num_units': 98, 'learning_rate': 4.4748257193749966e-05, 'dropout_rate': 0.12720930074735864, 'activity_regularizer': 1.1111085577492475e-06, 'batch_size': 44}. Best is trial 40 with value: 0.006474638357758522.\n",
      "[I 2024-06-13 09:47:52,750] Trial 42 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:53,797] Trial 43 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:54,818] Trial 44 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:55,837] Trial 45 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:56,990] Trial 46 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:58,017] Trial 47 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:47:59,061] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 09:48:00,105] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47d6798-1498-4e4d-a445-5a334ff7898e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 95, 'learning_rate': 4.5262992133035694e-05, 'dropout_rate': 0.13247553911660476, 'activity_regularizer': 1.1781594378365665e-06, 'batch_size': 45}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5e20dd-ad3b-478f-a920-65df18691d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e76dd3d5-d7c3-454d-bd64-e9ce5b3fef83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0026 - val_loss: 0.0087\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027 - val_loss: 0.0086\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0026 - val_loss: 0.0086\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0083\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0082\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0082\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0082\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0081\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 0.0080\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0080\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0023 - val_loss: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x267527a3b10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87fc2193-573f-4efd-a72a-8dc761e3836c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0079\n",
      "Validation Loss:  0.007921494543552399\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ee7f56-9d7d-46bb-8970-a1809122d0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42330198-f5f3-4a5a-bc89-eedf349e32f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dfdc297-7e3f-4a82-9338-56ee513d2e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93a35bf1-defd-488d-a29e-35827e2933b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "F1 Score: 0.14285714285714285\n",
      "Sensitivity: 0.07692307692307693\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f971a-9537-4cc6-b65d-173ad91d3192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074561b9-2233-49ca-8860-9558c88731a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58d7b237-166d-4f1a-a63d-d3f053db9811",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3496e022-9d52-4719-8aff-f3cdeee791de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_24920\\2580834323.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc66c03-7a40-42dc-82a1-328508f941a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc500b7b-0c68-498e-a687-9a25c8f3ab65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ea9108a-eb7f-4b2a-a5af-d05c15873263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b694cffc-4771-475d-b872-01bfbe389874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6f5f291-6f37-4fbe-b7f9-991124369a54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936 185366 237211  43149 190298   1827 192464 119497 195618]\n",
      "Top AMGM values: [1.0029745 1.0029751 1.0029768 1.0029768 1.0029768 1.0029769 1.0029773\n",
      " 1.0029789 1.0029818 1.0029832]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae6f6cde-4304-4b00-923d-456012aa7ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6339cb1d-45bf-4669-9422-8d6af33dff63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T\n",
    "X_selected = X_selected.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10dedecf-726e-4bff-a002-3a88d33ee4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1857a48b-3673-4198-b0e6-0116bdb99b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b086ea57-010b-4684-b764-79009baa7e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb5e1d04-cf55-4531-a808-a1c8dbde419e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24973087-5881-4ca6-bcd9-59a15ba9fd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56b1949a-790d-4317-9d27-8849505aeb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3d5cae1-3b1d-4ba0-b8c4-0d7946c9c654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "251322bf-3c43-4a64-8746-19485870aaa9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 676ms/step                                               \n",
      "  0%|                                                                           | 0/20 [00:26<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002674F8E8040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step                                              \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:27<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026746470B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 625ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.6562072155411656, Sensitivity: 0.9649122807017544, Specificity: 0.0625\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.42857142857142855, Sensitivity: 0.4323251567833612, Specificity: 0.7416666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 593ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 581ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 584ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.7328090340794514, Sensitivity: 0.7724061284432802, Specificity: 0.6827380952380953\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 594ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 763ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 775ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 726ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5656565656565656, F1 Score: 0.31414022718370543, Sensitivity: 0.28586171310629516, Specificity: 0.8125\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 595ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 549ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6060606060606061, F1 Score: 0.34905149051490514, Sensitivity: 0.36500754147812975, Specificity: 0.8333333333333334\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 538ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 530ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 549ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.47474747474747475, F1 Score: 0.19853709508881923, Sensitivity: 0.18893387314439947, Specificity: 0.8095238095238096\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 580ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 570ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5454545454545454, F1 Score: 0.32941176470588235, Sensitivity: 0.2986425339366516, Specificity: 0.8041666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 858ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 834ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4646464646464646, F1 Score: 0.4660661212734014, Sensitivity: 0.6181630546955624, Specificity: 0.36607142857142855\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 705ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 713ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 710ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.595959595959596, F1 Score: 0.6845421245421246, Sensitivity: 0.8974358974358975, Specificity: 0.2333333333333333\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 552ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 545ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 555ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7373737373737373, F1 Score: 0.6872082166199812, Sensitivity: 0.6151464634436771, Specificity: 0.8386904761904762\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 639ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 653ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6767676767676768, F1 Score: 0.6543435613203056, Sensitivity: 0.6854806700007939, Specificity: 0.6148809523809524\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 579ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 588ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4343434343434343, F1 Score: 0.3764399851356373, Sensitivity: 0.5490196078431372, Specificity: 0.4375\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 826ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 821ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 838ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5050505050505051, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 632ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 646ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.45454545454545453, F1 Score: 0.3365539452495974, Sensitivity: 0.45098039215686275, Specificity: 0.5833333333333334\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 617ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 583ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5151515151515151, F1 Score: 0.1794871794871795, Sensitivity: 0.1794871794871795, Specificity: 0.9\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 608ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 603ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 611ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.4343434343434343, F1 Score: 0.18840579710144925, Sensitivity: 0.3333333333333333, Specificity: 0.6666666666666666\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 550ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 548ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 544ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7272727272727272, F1 Score: 0.646680216802168, Sensitivity: 0.6341986187187426, Specificity: 0.7648809523809524\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 587ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 601ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 591ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.041666666666666664, Sensitivity: 0.025641025641025644, Specificity: 0.9666666666666667\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step                                              \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 914ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 608ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.494949494949495, F1 Score: 0.6586622073578595, Sensitivity: 1.0, Specificity: 0.0      \n",
      "100%|███████████████████████████████████████████████| 20/20 [21:15<00:00, 63.75s/trial, best loss: -0.7328090340794514]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f01252b-2854-4668-a27d-1c438d46bd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 3.6232954245926342e-06, 'ae_batch_size': 16.0, 'ae_dropout_rate': 0.30267607418856773, 'ae_learning_rate': 0.00016230132128846044, 'autoencoder_units': 212.0, 'encoding_dim': 19.0, 'lstm_batch_size': 55.0, 'lstm_dropout_rate': 0.40151942865068924, 'lstm_learning_rate': 0.0038207166561259197, 'lstm_units': 334.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd47bca5-a935-4b47-81b1-5e63d17acd41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfcc9151-dc6f-4369-b278-2fcf8bf76adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8b1b98b-a2a7-448b-90b5-22420d7a503d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "752d28b9-69f6-4036-b47a-d73ef41205b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.2641 - val_loss: 1.2784\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2415 - val_loss: 1.2720\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2088 - val_loss: 1.2659\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2179 - val_loss: 1.2592\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1748 - val_loss: 1.2522\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2357 - val_loss: 1.2443\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2133 - val_loss: 1.2357\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2010 - val_loss: 1.2259\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1826 - val_loss: 1.2150\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1795 - val_loss: 1.2027\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1539 - val_loss: 1.1892\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1122 - val_loss: 1.1754\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1363 - val_loss: 1.1607\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0864 - val_loss: 1.1461\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1112 - val_loss: 1.1317\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0534 - val_loss: 1.1174\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0627 - val_loss: 1.1039\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0266 - val_loss: 1.0916\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0028 - val_loss: 1.0812\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0235 - val_loss: 1.0724\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9855 - val_loss: 1.0648\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0071 - val_loss: 1.0587\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9973 - val_loss: 1.0536\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9884 - val_loss: 1.0495\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0301 - val_loss: 1.0461\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9917 - val_loss: 1.0431\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9676 - val_loss: 1.0407\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9990 - val_loss: 1.0387\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9396 - val_loss: 1.0370\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0148 - val_loss: 1.0352\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9774 - val_loss: 1.0335\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9506 - val_loss: 1.0321\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9806 - val_loss: 1.0309\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9603 - val_loss: 1.0297\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9669 - val_loss: 1.0284\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9682 - val_loss: 1.0274\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9736 - val_loss: 1.0264\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9512 - val_loss: 1.0256\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9665 - val_loss: 1.0247\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9613 - val_loss: 1.0240\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9480 - val_loss: 1.0233\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9796 - val_loss: 1.0227\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9716 - val_loss: 1.0223\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9412 - val_loss: 1.0218\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9443 - val_loss: 1.0214\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9389 - val_loss: 1.0210\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9658 - val_loss: 1.0205\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9719 - val_loss: 1.0202\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9493 - val_loss: 1.0198\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9531 - val_loss: 1.0194\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.4815 - loss: 1.0056 - val_accuracy: 0.5200 - val_loss: 0.8732\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step - accuracy: 0.5798 - loss: 0.8482 - val_accuracy: 0.4800 - val_loss: 0.6875\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - accuracy: 0.5522 - loss: 0.6514 - val_accuracy: 0.6000 - val_loss: 0.6638\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 0.6303 - loss: 0.6181 - val_accuracy: 0.8000 - val_loss: 0.6383\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 0.7589 - loss: 0.6008 - val_accuracy: 0.6800 - val_loss: 0.6105\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.7199 - loss: 0.5536 - val_accuracy: 0.7200 - val_loss: 0.5763\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7535 - loss: 0.5345 - val_accuracy: 0.7200 - val_loss: 0.5491\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - accuracy: 0.7791 - loss: 0.4770 - val_accuracy: 0.7600 - val_loss: 0.5112\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - accuracy: 0.7414 - loss: 0.5145 - val_accuracy: 0.7200 - val_loss: 0.5005\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7522 - loss: 0.4491 - val_accuracy: 0.7200 - val_loss: 0.5209\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7279 - loss: 0.5071 - val_accuracy: 0.7600 - val_loss: 0.5132\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.7414 - loss: 0.4869 - val_accuracy: 0.7600 - val_loss: 0.4979\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.7273 - loss: 0.5059 - val_accuracy: 0.7600 - val_loss: 0.5139\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - accuracy: 0.7515 - loss: 0.4756 - val_accuracy: 0.7200 - val_loss: 0.5085\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - accuracy: 0.7205 - loss: 0.4725 - val_accuracy: 0.7200 - val_loss: 0.5268\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - accuracy: 0.7919 - loss: 0.4721 - val_accuracy: 0.7200 - val_loss: 0.5128\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - accuracy: 0.7535 - loss: 0.4656 - val_accuracy: 0.7200 - val_loss: 0.5033\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ce77f3d-cba3-4a1a-87d8-2024c92b9051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
      "Accuracy: 0.72\n",
      "F1 Score: 0.72\n",
      "Sensitivity: 0.6923076923076923\n",
      "Specificity: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80faa2-f4c8-470a-9930-b81f2a35d2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c9eac-2a4d-465a-bb93-182f52473a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b5448ed-04ee-40f1-ba5b-3a8478736dcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156a83b6-3bad-4a92-b595-a6e7019409d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_28552\\877659386.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70085c6-a02f-4d81-8e22-3ffbc8556045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "852d2824-5617-42bc-8779-26287a31d2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a71235a-f346-4c66-8b15-73234cdb66fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065e730b-6416-48ed-9fc0-caf17d1fe3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [258568  42936 185366 237211  43149 190298   1827 192464 119497 195618]\n",
      "Top AMGM values: [1.0029745 1.0029751 1.0029768 1.0029768 1.0029768 1.0029769 1.0029773\n",
      " 1.0029789 1.0029818 1.0029832]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7839531c-9945-47be-833e-80db75be7a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1534495-440f-4159-875a-98514c8949f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a1526a-f7b5-4710-80d4-b07ab600594b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa6fa48-0487-4aa3-8b43-3c9657fc04c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe28551-3cb0-4140-95da-93d129b27393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6091262-5372-40e5-a6d7-d479e2b85d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4b3d3a-635c-4763-8577-566e385a906b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61ce28ed-7121-4a6b-a1b6-5568d2928186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4149abb1-7335-4e35-b629-30ae30c88881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbb62f60-d011-45c7-875c-7ebb741f234c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c0c4a3a-d328-4aed-ab05-b53d22042000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1111580a-628c-48ce-a630-eff97a39c84a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "  0%|                                                                           | 0/20 [00:06<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000269003D91C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "  0%|                                                                           | 0/20 [00:08<?, ?trial/s, best loss=?]WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000026900CEBD80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "100%|███████████████████████████████████████████████| 20/20 [07:30<00:00, 22.54s/trial, best loss: -0.6752631578947368]\n",
      "Best parameters:  {'ae_activity_reg': 1.7577538901751265e-07, 'ae_batch_size': 17.0, 'ae_dropout_rate': 0.23638913845296405, 'ae_learning_rate': 0.0008400982542766581, 'autoencoder_units': 74.0, 'encoding_dim': 20.0, 'fnn_batch_size': 37.0, 'fnn_dropout_rate': 0.4556162618056063, 'fnn_learning_rate': 0.0031621793581322255, 'fnn_units': 116.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f042186d-12cd-4060-8ae0-296f20ed2ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd55f54-fff2-4deb-9377-d908200330bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a855d829-e2ec-40f4-8e90-0bd6b987cc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Final Model - Accuracy: 0.5857894736842104\n",
      "Final Model - F1 Score: 0.5454545454545455\n",
      "Final Model - Sensitivity: 0.5354545454545454\n",
      "Final Model - Specificity: 0.65\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd815a-6093-4c57-b465-28aec27b698e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c801249-ee93-4668-8605-e9c59a68c55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "890e812d-90ad-4a97-a5c5-e7ee73c864e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2da66292-4d96-496d-84cb-1f0ad7def947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56a75571-898c-4fec-85d9-7cba2c54d37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5cba03-4f8d-44ab-a105-40b74c5d1178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedColorectalCancerData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f4b92e-cd9b-495e-a03e-77233896804e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_17932\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6db631f-83d3-4bdd-9ae7-8651b30f5640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccfc3b4-9e8e-4e10-95db-b9f753d849dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff389f4-e4a2-457c-b9ed-415d477465f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1580d3-488e-4113-aaac-da75866b5bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3dc17b7-08c9-4730-a422-8dc5f7ecae75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac81729-2f51-48be-92d9-5002e5cd0c7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - loss: 1.2502 - val_loss: 1.2402\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 1.2422 - val_loss: 1.2454\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 1.1462 - val_loss: 1.2418\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9945 - val_loss: 1.2343\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9888 - val_loss: 1.2253\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9859 - val_loss: 1.2174\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9830 - val_loss: 1.2110\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9795 - val_loss: 1.2052\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9759 - val_loss: 1.2000\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9730 - val_loss: 1.1960\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9701 - val_loss: 1.1931\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9675 - val_loss: 1.1907\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9652 - val_loss: 1.1889\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9631 - val_loss: 1.1876\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9612 - val_loss: 1.1871\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9595 - val_loss: 1.1871\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9580 - val_loss: 1.1876\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9567 - val_loss: 1.1883\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9555 - val_loss: 1.1893\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9544 - val_loss: 1.1904\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9535 - val_loss: 1.1918\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9526 - val_loss: 1.1933\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9518 - val_loss: 1.1948\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9512 - val_loss: 1.1964\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9505 - val_loss: 1.1980\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9500 - val_loss: 1.1995\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9495 - val_loss: 1.2011\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9490 - val_loss: 1.2026\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9487 - val_loss: 1.2041\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9483 - val_loss: 1.2056\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9479 - val_loss: 1.2070\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9477 - val_loss: 1.2083\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9474 - val_loss: 1.2096\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9471 - val_loss: 1.2108\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9469 - val_loss: 1.2119\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9467 - val_loss: 1.2130\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9465 - val_loss: 1.2140\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9464 - val_loss: 1.2150\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9462 - val_loss: 1.2159\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9460 - val_loss: 1.2168\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9459 - val_loss: 1.2176\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9458 - val_loss: 1.2183\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9457 - val_loss: 1.2190\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9456 - val_loss: 1.2197\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9454 - val_loss: 1.2203\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9454 - val_loss: 1.2209\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9453 - val_loss: 1.2215\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9452 - val_loss: 1.2220\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9451 - val_loss: 1.2225\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9450 - val_loss: 1.2230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2785db81e90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder, encoder = create_feature_autoencoder(input_dim, encoding_dim)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65e520a2-8474-4e5b-bd71-817cba66e1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step\n",
      "Shape of encoded features: (225, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = encoder.predict(X_scaled)\n",
    "print(f\"Shape of encoded features: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a623d6-b43d-409e-ae05-893a765a93b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after L1-based Feature Selection: (225, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.342e-02, tolerance: 5.504e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "target_features = 200  # Target number of features\n",
    "X_final, selected_indices_l1 = apply_l1_feature_selection(X_encoded, y, alpha=0.005, target_features=target_features)\n",
    "print(f\"Shape after L1-based Feature Selection: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a636d3c2-a6ce-4148-8e5c-98d60241efb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d327dc6-f6ad-467d-8b4b-758ffdf233a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9a0ce0f1-64ac-4548-8b5a-f8f9ac2ef8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e04de0e4-173c-47bc-899a-8ec385177381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4cadd998-1a71-4ef5-8470-393bf25b21e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4625eb2e-2ca8-431c-b49b-dd3a6f005a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1900 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_630 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1901 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_631 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1902 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1903 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1904 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1900 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_630 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1901 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_631 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1902 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m5,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1903 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m20,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1904 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m201\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "493b6215-f3d7-4394-b994-fe8456a7de50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.4865 - loss: 0.7893 - val_accuracy: 0.5652 - val_loss: 0.6867 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5190 - loss: 0.7347 - val_accuracy: 0.4783 - val_loss: 0.6860 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5110 - loss: 0.6980 - val_accuracy: 0.5652 - val_loss: 0.6506 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6219 - loss: 0.6627 - val_accuracy: 0.5652 - val_loss: 0.6395 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5927 - loss: 0.6808 - val_accuracy: 0.8261 - val_loss: 0.6327 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6527 - loss: 0.6332 - val_accuracy: 0.8261 - val_loss: 0.6208 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6910 - loss: 0.6033 - val_accuracy: 0.6087 - val_loss: 0.6040 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5920 - loss: 0.6547 - val_accuracy: 0.6957 - val_loss: 0.5885 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6548 - loss: 0.6260 - val_accuracy: 0.7391 - val_loss: 0.5667 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6659 - loss: 0.5884 - val_accuracy: 0.7391 - val_loss: 0.5492 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7081 - loss: 0.5155 - val_accuracy: 0.7826 - val_loss: 0.5299 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7157 - loss: 0.5390 - val_accuracy: 0.8261 - val_loss: 0.4964 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: 0.6126 - val_accuracy: 0.8261 - val_loss: 0.4960 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7109 - loss: 0.6045 - val_accuracy: 0.7826 - val_loss: 0.4817 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7501 - loss: 0.4748 - val_accuracy: 0.7826 - val_loss: 0.4634 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7384 - loss: 0.5228 - val_accuracy: 0.7826 - val_loss: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7460 - loss: 0.5172 - val_accuracy: 0.7826 - val_loss: 0.4124 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.4136 - val_accuracy: 0.8261 - val_loss: 0.3841 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7395 - loss: 0.4784 - val_accuracy: 0.8261 - val_loss: 0.3731 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7880 - loss: 0.4375 - val_accuracy: 0.8696 - val_loss: 0.3507 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8510 - loss: 0.3858 - val_accuracy: 0.8696 - val_loss: 0.3487 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8248 - loss: 0.4460 - val_accuracy: 0.9130 - val_loss: 0.3541 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7715 - loss: 0.4219 - val_accuracy: 0.9130 - val_loss: 0.3497 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8543 - loss: 0.2947 - val_accuracy: 0.7826 - val_loss: 0.3491 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8848 - loss: 0.2724 - val_accuracy: 0.7826 - val_loss: 0.3628 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8569 - loss: 0.3758 - val_accuracy: 0.8261 - val_loss: 0.2925 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8282 - loss: 0.3174 - val_accuracy: 0.8696 - val_loss: 0.3060 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8623 - loss: 0.3671 - val_accuracy: 0.8261 - val_loss: 0.2968 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8790 - loss: 0.3040 - val_accuracy: 0.8696 - val_loss: 0.2865 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8518 - loss: 0.3022 - val_accuracy: 0.9130 - val_loss: 0.2862 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9337 - loss: 0.1840 - val_accuracy: 0.9130 - val_loss: 0.2830 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9187 - loss: 0.2275 - val_accuracy: 0.8696 - val_loss: 0.2825 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9073 - loss: 0.2693 - val_accuracy: 0.8696 - val_loss: 0.2975 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8777 - loss: 0.2478 - val_accuracy: 0.9130 - val_loss: 0.2899 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9057 - loss: 0.2332 - val_accuracy: 0.9130 - val_loss: 0.2389 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9331 - loss: 0.1807 - val_accuracy: 0.9130 - val_loss: 0.2329 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8832 - loss: 0.2510 - val_accuracy: 0.8696 - val_loss: 0.2705 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.2558 - val_accuracy: 0.8696 - val_loss: 0.2775 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2362 - val_accuracy: 0.9130 - val_loss: 0.2059 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8814 - loss: 0.2729 - val_accuracy: 0.9130 - val_loss: 0.1885 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9195 - loss: 0.1665 - val_accuracy: 0.8696 - val_loss: 0.2232 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8737 - loss: 0.2996 - val_accuracy: 0.8696 - val_loss: 0.2555 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9107 - loss: 0.1865 - val_accuracy: 0.8261 - val_loss: 0.2636 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1434 - val_accuracy: 0.8261 - val_loss: 0.2347 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8890 - loss: 0.2981 - val_accuracy: 0.8261 - val_loss: 0.2370 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.1629 - val_accuracy: 0.8261 - val_loss: 0.2335 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9389 - loss: 0.1567 - val_accuracy: 0.8261 - val_loss: 0.2895 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.2441 - val_accuracy: 0.8261 - val_loss: 0.2845 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9087 - loss: 0.1792 - val_accuracy: 0.8261 - val_loss: 0.2996 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9130 - loss: 0.2048 - val_accuracy: 0.8261 - val_loss: 0.3155 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f63df77-b18c-4d57-9191-0cd5cc4643aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b2f05b0a-579b-4851-8505-1f3c6881d17f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2e37b5f4-78ee-4291-a4a2-4dfce95291bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.8888888888888888\n",
      "Specificity: 0.9375\n",
      "Sensitivity: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7887a-9362-4c12-88ed-1868dde959fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e8036-2b06-4284-a114-61b97de002c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33950000-89b2-463f-94b7-bbd8145fd3a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7b16e0ef-d7d8-4392-86c6-2fa0a245ec3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "60ca365c-f6ec-4f19-ae6d-3ef6c86fcf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f5e6d5b3-7150-4497-ac39-b97a3e578844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "244e38b3-c5f1-4318-8629-e7f10c290aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4bcab3b0-3430-4cdd-ac39-e53d3549cf30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9377777777777778, F1 Score: 0.9292929292929293, Sensitivity: 0.9583333333333334, Specificity: 0.9224806201550387\n",
      "Accuracy: 0.7644444444444445, F1 Score: 0.6293706293706294, Sensitivity: 0.46875, Specificity: 0.9844961240310077      \n",
      "Accuracy: 0.7288888888888889, F1 Score: 0.5343511450381679, Sensitivity: 0.3645833333333333, Specificity: 1.0          \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.64, F1 Score: 0.2702702702702703, Sensitivity: 0.15625, Specificity: 1.0                                   \n",
      "Accuracy: 0.9155555555555556, F1 Score: 0.8961748633879781, Sensitivity: 0.8541666666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9278350515463918, Sensitivity: 0.9375, Specificity: 0.937984496124031        \n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.93, Sensitivity: 0.96875, Specificity: 0.9147286821705426                    \n",
      "Accuracy: 0.9333333333333333, F1 Score: 0.9230769230769231, Sensitivity: 0.9375, Specificity: 0.9302325581395349       \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9484536082474226, Sensitivity: 0.9583333333333334, Specificity: 0.9534883720930233\n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.8311111111111111, F1 Score: 0.7682926829268293, Sensitivity: 0.65625, Specificity: 0.9612403100775194      \n",
      "Accuracy: 0.9466666666666667, F1 Score: 0.9381443298969072, Sensitivity: 0.9479166666666666, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.9422222222222222, F1 Score: 0.9346733668341709, Sensitivity: 0.96875, Specificity: 0.9224806201550387      \n",
      "Accuracy: 0.9288888888888889, F1 Score: 0.9191919191919192, Sensitivity: 0.9479166666666666, Specificity: 0.9147286821705426\n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.9511111111111111, F1 Score: 0.9430051813471503, Sensitivity: 0.9479166666666666, Specificity: 0.9534883720930233\n",
      "Accuracy: 0.76, F1 Score: 0.6086956521739131, Sensitivity: 0.4375, Specificity: 1.0                                    \n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9270833333333334, Sensitivity: 0.9270833333333334, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.8711111111111111, F1 Score: 0.8342857142857143, Sensitivity: 0.7604166666666666, Specificity: 0.9534883720930233\n",
      "100%|███████████████████████████████████████████████| 20/20 [07:14<00:00, 21.71s/trial, best loss: -0.9484536082474226]\n",
      "Best parameters found:  {'batch_size': 48.0, 'dropout_rate': 0.6551201949996381, 'epochs': 200.0, 'learning_rate': 0.000753710320272019, 'neurons1': 128.0, 'neurons2': 80.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c83ac28e-a8c2-4c96-8dd4-ce6c6e212929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9555555555555556\n",
      "Best F1 Score: 0.9484536082474226\n",
      "Best Specificity: 0.9534883720930233\n",
      "Best Sensitivity: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "df378319-20a0-4336-9abd-ae57813864db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_101\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_101\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2405 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_832 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2406 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_833 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2407 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2408 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2409 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_2405 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m12,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_832 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2406 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │          \u001b[38;5;34m10,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_833 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2407 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m10,368\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2408 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m12,900\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2409 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,617</span> (182.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,617\u001b[0m (182.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,617</span> (182.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,617\u001b[0m (182.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a57f6326-b82a-4d02-9702-7028b11b303c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 128\n",
      "Neurons in second layer: 80\n",
      "Dropout rate: 0.6551201949996381\n",
      "Learning rate: 0.000753710320272019\n",
      "Number of epochs: 200\n",
      "Batch size: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549aedc4-1da4-4145-88b3-8c6efa91ac82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f2922ce-024f-4740-9620-de13223b5c39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "168f6e9b-c0fd-47be-9764-6d3e94c99b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b49c7443-588d-44f3-918b-e07271ac7074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c5610fb5-be75-4dca-9dde-7450b66e8b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 64)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.7),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "99267302-a85b-41d4-b948-0d35d84a167b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a3556744-e9d2-413e-939f-c19c836ffeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.7388888888888889, F1 Score: 0.6499582289055973, Sensitivity: 0.633140756302521, Specificity: 0.8492524916943521\n",
      "Iteration Results - Accuracy: 0.6388888888888888, F1 Score: 0.543998513563731, Sensitivity: 0.5388655462184874, Specificity: 0.7625622923588039\n",
      "Iteration Results - Accuracy: 0.6944444444444443, F1 Score: 0.6346320346320345, Sensitivity: 0.6447829131652661, Specificity: 0.7551910299003323\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.7342825361512793, Sensitivity: 0.841999299719888, Specificity: 0.725359911406423\n",
      "Iteration Results - Accuracy: 0.7333333333333334, F1 Score: 0.6806557639890972, Sensitivity: 0.7057948179271708, Specificity: 0.7798657253599114\n",
      "Iteration Results - Accuracy: 0.6777777777777777, F1 Score: 0.6371338524286244, Sensitivity: 0.6745448179271708, Specificity: 0.6814091915836102\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.3874840845429081, Sensitivity: 0.48161764705882354, Specificity: 0.6785368217054263\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.43297558922558926, Sensitivity: 0.5535714285714285, Specificity: 0.6424418604651163\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.5054798182304197, Sensitivity: 0.5026260504201681, Specificity: 0.7286475636766334\n",
      "Iteration Results - Accuracy: 0.638888888888889, F1 Score: 0.5414353461077765, Sensitivity: 0.5269607843137255, Specificity: 0.7566791251384274\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.6844401461422738, Sensitivity: 0.7462359943977591, Specificity: 0.7345999446290143\n",
      "Iteration Results - Accuracy: 0.6388888888888888, F1 Score: 0.5361811391223156, Sensitivity: 0.539390756302521, Specificity: 0.779485049833887\n",
      "Iteration Results - Accuracy: 0.6555555555555556, F1 Score: 0.5899415204678363, Sensitivity: 0.604341736694678, Specificity: 0.7271594684385382\n",
      "Iteration Results - Accuracy: 0.7000000000000001, F1 Score: 0.6456741326306544, Sensitivity: 0.6735819327731093, Specificity: 0.7634966777408638\n",
      "Iteration Results - Accuracy: 0.5666666666666668, F1 Score: 0.5519728116710875, Sensitivity: 0.6815476190476191, Specificity: 0.5605966223698782\n",
      "Iteration Results - Accuracy: 0.7388888888888889, F1 Score: 0.6762626262626262, Sensitivity: 0.6899509803921569, Specificity: 0.8206672203765226\n",
      "Iteration Results - Accuracy: 0.6833333333333332, F1 Score: 0.5944404752454288, Sensitivity: 0.5624124649859944, Specificity: 0.7900401439645627\n",
      "Iteration Results - Accuracy: 0.5777777777777778, F1 Score: 0.4823688094874536, Sensitivity: 0.5997023809523809, Specificity: 0.6630329457364341\n",
      "Iteration Results - Accuracy: 0.5944444444444444, F1 Score: 0.5561881757533932, Sensitivity: 0.6607142857142857, Specificity: 0.6368009413067552\n",
      "Iteration Results - Accuracy: 0.6055555555555556, F1 Score: 0.5267724867724868, Sensitivity: 0.5599614845938375, Specificity: 0.6961517165005536\n",
      "100%|███████████████████████████████████████████████| 20/20 [27:53<00:00, 83.66s/trial, best loss: -0.7342825361512793]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bad32715-f08e-481e-b506-0db2ce934e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 192, 'dropout_rate': 0.10789176927584963, 'learning_rate': 0.0005431554477143651, 'epochs': 30, 'batch_size': 64, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "beb9feb0-db34-42a7-a2f9-50a700aedfc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7777777777777778\n",
      "F1 Score: 0.6875\n",
      "Sensitivity: 0.5789473684210527\n",
      "Specificity: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a13ffe-7106-4df6-9db4-c3de401bbb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e3cb33-e44d-43b9-b70d-c81ade5f9113",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GRU with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53f0e7a0-6ab3-45ec-9d56-a9933c17ee0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a0650d7-f2ff-4835-9d00-7eafc30a5c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3258ddae-cf08-4132-800c-b8b27d73b05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0abea934-4487-4c52-8cb5-012c40b8c995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 128, 64)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3450ac81-1bec-4140-aed1-702c3e41ef50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4a5b402-92f9-4789-8192-9995347a4c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6539624183006536, Sensitivity: 0.7574548907882241, Specificity: 0.5292929292929293\n",
      "Iteration Results - Accuracy: 0.6000000000000001, F1 Score: 0.6280188114659466, Sensitivity: 0.7535612535612536, Specificity: 0.4666666666666666\n",
      "Iteration Results - Accuracy: 0.5944444444444444, F1 Score: 0.6061506776877904, Sensitivity: 0.687369420702754, Specificity: 0.5202020202020202\n",
      "Iteration Results - Accuracy: 0.6, F1 Score: 0.6220538720538721, Sensitivity: 0.7301044634377968, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6537308482273846, Sensitivity: 0.7034188034188035, Specificity: 0.6191919191919192\n",
      "Iteration Results - Accuracy: 0.6055555555555556, F1 Score: 0.625510058673011, Sensitivity: 0.7407407407407408, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.5666666666666668, F1 Score: 0.5544767443732751, Sensitivity: 0.5978157644824311, Specificity: 0.5380867498514558\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.6282689912826899, Sensitivity: 0.6980056980056979, Specificity: 0.565359477124183\n",
      "Iteration Results - Accuracy: 0.6166666666666667, F1 Score: 0.6266655370103645, Sensitivity: 0.7074074074074074, Specificity: 0.5441473559120619\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6460707502374169, Sensitivity: 0.7716049382716049, Specificity: 0.5014260249554368\n",
      "Iteration Results - Accuracy: 0.65, F1 Score: 0.6512495555973817, Sensitivity: 0.7444444444444445, Specificity: 0.569399881164587\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6387453550195711, Sensitivity: 0.6461538461538461, Specificity: 0.6747474747474748\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.5921589919350277, Sensitivity: 0.6207027540360873, Specificity: 0.6370766488413547\n",
      "Iteration Results - Accuracy: 0.6833333333333332, F1 Score: 0.6981993514251578, Sensitivity: 0.7946818613485281, Specificity: 0.5909090909090908\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6339541280993272, Sensitivity: 0.7065527065527065, Specificity: 0.5865715983363042\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6894660894660894, Sensitivity: 0.8548907882241217, Specificity: 0.4671420083184789\n",
      "Iteration Results - Accuracy: 0.6277777777777779, F1 Score: 0.6491240026734867, Sensitivity: 0.7757834757834757, Specificity: 0.49393939393939396\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.6408712038849025, Sensitivity: 0.7586894586894587, Specificity: 0.4888888888888889\n",
      "Iteration Results - Accuracy: 0.688888888888889, F1 Score: 0.6907272890323738, Sensitivity: 0.7549857549857549, Specificity: 0.6333333333333333\n",
      "Iteration Results - Accuracy: 0.6499999999999999, F1 Score: 0.6458143132481232, Sensitivity: 0.7000949667616334, Specificity: 0.6101010101010101\n",
      "100%|████████████████████████████████████████████| 20/20 [2:21:14<00:00, 423.72s/trial, best loss: -0.6981993514251578]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a833d91-e41e-4e4b-8656-2be4a67c6bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 64, 'dropout_rate': 0.3224123746707528, 'epochs': 30, 'learning_rate': 0.0001354902537099134, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)  \n",
    "print(\"Best Parameters:\", best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65278dd4-b5c4-417a-8c66-6882994903ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b47c42ee-b1f8-49e6-8310-d06af77066dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2fd4b-7d47-40db-bdff-33c2ec5ae1f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f460f-38e4-4df0-9906-27dbc326cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce962fdc-0063-4139-9576-1e1df44bdfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
