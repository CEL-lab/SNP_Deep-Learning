{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362b524e-58cf-4768-98f3-b471cd781993",
   "metadata": {},
   "source": [
    "## Data / Package Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c7d571-357a-44f9-a34c-7bc37b87e38f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Affy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, GRU, Layer, Add, GlobalAveragePooling1D, Conv1D, ReLU\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "import scipy.stats as stats\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from accelerate import DataLoaderConfiguration\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from boruta import BorutaPy\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346a9c8-1f9f-4b83-8cae-25367ffa2b91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AMGM and Cosine Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e829d5-f03b-4ab2-9f61-b6717c0fbc3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_amgm(X):\n",
    "    \"\"\"\n",
    "    Calculate AMGM for each feature (row) in the dataset X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): The input data array with shape (n_features, n_samples)\n",
    "    \n",
    "    Returns:\n",
    "    amgm_values (numpy array): The AMGM values for each feature (row)\n",
    "    \"\"\"\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    exp_X = np.exp(X)\n",
    "    amgm_values = (np.mean(exp_X, axis=1)) / (np.exp(np.mean(X, axis=1)))\n",
    "    \n",
    "    return amgm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfd2859-f20b-47af-bfa7-60c5407e6749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_redundant_features(X, relevant_indices, threshold=0.9):\n",
    "    relevant_features = X[relevant_indices, :]\n",
    "    cos_sim_matrix = cosine_similarity(relevant_features)\n",
    "    \n",
    "    to_keep = []\n",
    "    to_drop = set()\n",
    "    for i in range(cos_sim_matrix.shape[0]):\n",
    "        if i not in to_drop:\n",
    "            to_keep.append(relevant_indices[i])\n",
    "            for j in range(i + 1, cos_sim_matrix.shape[0]):\n",
    "                if cos_sim_matrix[i, j] > threshold:\n",
    "                    to_drop.add(relevant_indices[j])\n",
    "    return to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555bbaf-dfe2-4b4f-b1a9-83314c80706c",
   "metadata": {},
   "source": [
    "## Autoencoder Feature Selection with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d8147b-3f65-47c3-82a3-14417216c195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_feature_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)  # Encoder part\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)  # Decoder part\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7aad969-a7e6-4948-8b47-7ab1316d419d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_l1_feature_selection(X, y, alpha=0.01, target_features=100):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "    model = SelectFromModel(lasso, prefit=True, max_features=target_features)\n",
    "    X_reduced = model.transform(X)\n",
    "    selected_indices = model.get_support(indices=True)\n",
    "    return X_reduced, selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a26820-e32b-43f5-ba95-be123d06c31c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initial Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1435bc6a-a745-40ed-b73a-bb4fa0d56c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ca7d9d-21c8-4084-806e-af502aa3d57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c8261a-9b63-43cf-9549-da7e4099067d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda60a3e-0218-45a1-9c2a-90c382db4d69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_36732\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992f63ce-8e84-45e3-a005-7c73319a4da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c37aca-e160-4a61-b8a6-93b253f6402b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2611e12-d0b6-475f-b3ed-bdfe69c1e6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8768c7d7-7ec8-44d4-a4fd-0ce196245ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [459916 418589 273342 737619 340049 530632 555527 109587 310058 650485]\n",
      "Top AMGM values: [1.00982801 1.00983343 1.00983343 1.00983442 1.00983559 1.00983791\n",
      " 1.0098399  1.00984224 1.00984512 1.00984512]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46f89be7-38a8-45a7-ad0c-4fe9458983bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64cdc52a-3bba-4b95-9f30-1fd4ac619ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e90e0e6c-815d-4885-9e5f-8ad4ca222569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd0e2c08-a601-48c7-9524-2bbf101d1209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19d7182e-eb5a-4766-a9ab-17df933425d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a943dc0b-0d5d-41f4-b3ef-79f8ea479ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f39b2b01-08f6-4608-95b4-31592119cf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b21e3f14-e8ca-487e-a5bc-a39562a2516c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 25)                1275      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 50)                1300      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12826 (50.10 KB)\n",
      "Trainable params: 12826 (50.10 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aef79af3-5b88-4738-bce5-ca7a121491ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 32ms/step - loss: 0.7257 - accuracy: 0.5478 - val_loss: 0.7032 - val_accuracy: 0.4348 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7348 - accuracy: 0.5223 - val_loss: 0.6905 - val_accuracy: 0.4348 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7185 - accuracy: 0.5159 - val_loss: 0.6684 - val_accuracy: 0.6087 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6771 - accuracy: 0.5987 - val_loss: 0.6632 - val_accuracy: 0.5652 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6866 - accuracy: 0.5669 - val_loss: 0.6596 - val_accuracy: 0.6522 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7088 - accuracy: 0.4713 - val_loss: 0.6594 - val_accuracy: 0.8261 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6586 - accuracy: 0.6433 - val_loss: 0.6468 - val_accuracy: 0.7391 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6685 - accuracy: 0.6051 - val_loss: 0.6349 - val_accuracy: 0.6957 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6536 - accuracy: 0.6051 - val_loss: 0.6207 - val_accuracy: 0.6522 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 0.6561 - val_loss: 0.6024 - val_accuracy: 0.7391 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6080 - accuracy: 0.7006 - val_loss: 0.5807 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5819 - accuracy: 0.7006 - val_loss: 0.5508 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5978 - accuracy: 0.6879 - val_loss: 0.5194 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5743 - accuracy: 0.6688 - val_loss: 0.4868 - val_accuracy: 0.8261 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5421 - accuracy: 0.7325 - val_loss: 0.4548 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4995 - accuracy: 0.7707 - val_loss: 0.4273 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.7707 - val_loss: 0.3910 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4498 - accuracy: 0.7834 - val_loss: 0.3648 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.8408 - val_loss: 0.3424 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.8025 - val_loss: 0.3278 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.8662 - val_loss: 0.3132 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3117 - accuracy: 0.8790 - val_loss: 0.3009 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3527 - accuracy: 0.8408 - val_loss: 0.2896 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3088 - accuracy: 0.8662 - val_loss: 0.2880 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3089 - accuracy: 0.8790 - val_loss: 0.2817 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2767 - accuracy: 0.9236 - val_loss: 0.2740 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2658 - accuracy: 0.8854 - val_loss: 0.2724 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2809 - accuracy: 0.8790 - val_loss: 0.2645 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2111 - accuracy: 0.9363 - val_loss: 0.2570 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2311 - accuracy: 0.9299 - val_loss: 0.2514 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2488 - accuracy: 0.8917 - val_loss: 0.2479 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2828 - accuracy: 0.8535 - val_loss: 0.2464 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2202 - accuracy: 0.9363 - val_loss: 0.2372 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2268 - accuracy: 0.9045 - val_loss: 0.2251 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1947 - accuracy: 0.9299 - val_loss: 0.2171 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2186 - accuracy: 0.8981 - val_loss: 0.2116 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2525 - accuracy: 0.9045 - val_loss: 0.2058 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1297 - accuracy: 0.9682 - val_loss: 0.2013 - val_accuracy: 0.9130 - lr: 0.0011\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1630 - accuracy: 0.9490 - val_loss: 0.1981 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1030 - accuracy: 0.9745 - val_loss: 0.1958 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2336 - accuracy: 0.9172 - val_loss: 0.1903 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1363 - accuracy: 0.9554 - val_loss: 0.1880 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1600 - accuracy: 0.9363 - val_loss: 0.1885 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0948 - accuracy: 0.9745 - val_loss: 0.1918 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1541 - accuracy: 0.9554 - val_loss: 0.1991 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.9618 - val_loss: 0.1994 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.9682 - val_loss: 0.1886 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1742 - accuracy: 0.9299 - val_loss: 0.1854 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1631 - accuracy: 0.9363 - val_loss: 0.1904 - val_accuracy: 0.9565 - lr: 0.0011\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1333 - accuracy: 0.9427 - val_loss: 0.1866 - val_accuracy: 0.9565 - lr: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33305bb3-1de2-4ae1-8a0d-ba965f141dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9777777777777777\n",
      "F1 Score: 0.9600000000000001\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6030c1f-d0c6-4352-831c-05028ad00e95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcda0be1-8113-4829-a545-7e3869593461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "F1 Score: 0.9600000000000001\n",
      "Specificity: 1.0\n",
      "Sensitivity: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4b29d-86a2-4082-a8a6-0c1ab26b28c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aa9c7c5-4188-4350-b06b-68f8381f57a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73698fe8-3b4f-4f4c-96f4-ee03b7a5c5ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_11868\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4e0a9b-2c6a-4bd1-a21c-c1372a7cc69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f279b29-5fae-4c0c-9211-a18293c78841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76c1489-8fd2-48de-a5ba-9f279a319ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62bd4125-787e-4779-86e9-58e5061cf3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [459916 418589 273342 737619 340049 530632 555527 109587 310058 650485]\n",
      "Top AMGM values: [1.00982801 1.00983343 1.00983343 1.00983442 1.00983559 1.00983791\n",
      " 1.0098399  1.00984224 1.00984512 1.00984512]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5310c936-8af3-4dec-9710-bc27ee48d01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "838831ed-5038-47b9-b6aa-10df93d4fead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3852d99-1430-4bbc-8090-e21d67d2471b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687e0e6c-f350-4f0b-b68d-84f705a4df3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d9473b-c6dd-485f-8de7-f54704b12477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1161b1ba-dc4e-44d0-b6d6-fd2310bf9e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc96a759-c14f-4de1-b488-ac7335b478db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_selected.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_selected, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc369a0e-56f2-4b87-98d4-e7b934d3e9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/20 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001DB456A3CE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.9288888888888889, F1 Score: 0.9120879120879121, Sensitivity: 0.8645833333333334, Specificity: 0.9767441860465116\n",
      "  5%|                                             | 1/20 [00:14<04:41, 14.84s/trial, best loss: -0.9120879120879121]WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001DB44E85440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9292929292929293, Sensitivity: 0.9583333333333334, Specificity: 0.9224806201550387\n",
      "Accuracy: 0.9466666666666667, F1 Score: 0.9387755102040817, Sensitivity: 0.9583333333333334, Specificity: 0.937984496124031\n",
      "Accuracy: 0.9422222222222222, F1 Score: 0.9326424870466321, Sensitivity: 0.9375, Specificity: 0.9457364341085271       \n",
      "Accuracy: 0.9511111111111111, F1 Score: 0.9435897435897436, Sensitivity: 0.9583333333333334, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9247311827956989, Sensitivity: 0.8958333333333334, Specificity: 0.9689922480620154\n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9270833333333334, Sensitivity: 0.9270833333333334, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.6222222222222222, F1 Score: 0.205607476635514, Sensitivity: 0.11458333333333333, Specificity: 1.0          \n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9285714285714286, Sensitivity: 0.9479166666666666, Specificity: 0.9302325581395349\n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9306930693069307, Sensitivity: 0.9791666666666666, Specificity: 0.9069767441860465\n",
      "Accuracy: 0.9644444444444444, F1 Score: 0.9587628865979382, Sensitivity: 0.96875, Specificity: 0.9612403100775194      \n",
      "Accuracy: 0.9422222222222222, F1 Score: 0.934010152284264, Sensitivity: 0.9583333333333334, Specificity: 0.9302325581395349\n",
      "Accuracy: 0.88, F1 Score: 0.8457142857142858, Sensitivity: 0.7708333333333334, Specificity: 0.9612403100775194         \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9484536082474226, Sensitivity: 0.9583333333333334, Specificity: 0.9534883720930233\n",
      "Accuracy: 0.9466666666666667, F1 Score: 0.9393939393939394, Sensitivity: 0.96875, Specificity: 0.9302325581395349      \n",
      "Accuracy: 0.9466666666666667, F1 Score: 0.9375, Sensitivity: 0.9375, Specificity: 0.9534883720930233                   \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.8622222222222222, F1 Score: 0.8187134502923976, Sensitivity: 0.7291666666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.9422222222222222, F1 Score: 0.9333333333333333, Sensitivity: 0.9479166666666666, Specificity: 0.937984496124031\n",
      "Accuracy: 0.5733333333333334, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                                        \n",
      "100%|| 20/20 [07:31<00:00, 22.58s/trial, best loss: -0.9587628865979382]\n",
      "Best parameters found:  {'batch_size': 128.0, 'dropout_rate': 0.685419694987923, 'epochs': 100.0, 'learning_rate': 0.03884197914857913, 'neurons1': 32.0, 'neurons2': 64.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89f5bd80-5264-4ec2-8496-97d0281405a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9644444444444444\n",
      "Best F1 Score: 0.9587628865979382\n",
      "Best Specificity: 0.9612403100775194\n",
      "Best Sensitivity: 0.96875\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2712035d-5a92-49b0-bb92-9a9c4ab33308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_100\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_100\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " dense_500 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,232</span> \n",
       "\n",
       " dropout_200 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_501 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> \n",
       "\n",
       " dropout_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> \n",
       "\n",
       " dense_503 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">3,300</span> \n",
       "\n",
       " dense_504 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_500 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                             \u001b[38;5;34m3,232\u001b[0m \n",
       "\n",
       " dropout_200 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_501 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             \u001b[38;5;34m2,112\u001b[0m \n",
       "\n",
       " dropout_201 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_502 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                             \u001b[38;5;34m2,080\u001b[0m \n",
       "\n",
       " dense_503 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                            \u001b[38;5;34m3,300\u001b[0m \n",
       "\n",
       " dense_504 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                \u001b[38;5;34m101\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,825</span> (42.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,825\u001b[0m (42.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,825</span> (42.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,825\u001b[0m (42.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58c3de40-8f2f-4682-bed1-ddaad7999903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 32\n",
      "Neurons in second layer: 64\n",
      "Dropout rate: 0.685419694987923\n",
      "Learning rate: 0.03884197914857913\n",
      "Number of epochs: 100\n",
      "Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2b124-e354-488b-9644-18b41f162454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b4acc3-585e-4ee6-b81a-181b2c4ede21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae1bec1f-b154-403e-a9c3-0b500bdc9e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "697e4b5c-d601-41f7-a2f2-8a3d6d37a4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_11868\\795450887.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "661d99c3-10b3-4ba3-a56a-8995b2999df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d5bc8ac3-bd7a-42d9-8bf5-a41966c7b424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1a68641-177e-412f-b218-e8be27b480d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c36b1479-baba-43c4-a1de-f7f6f2292b49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [459916 418589 273342 737619 340049 530632 555527 109587 310058 650485]\n",
      "Top AMGM values: [1.00982801 1.00983343 1.00983343 1.00983442 1.00983559 1.00983791\n",
      " 1.0098399  1.00984224 1.00984512 1.00984512]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5b68ec2-f202-489a-b587-9b0ccf60ca8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5823643-01ca-45ca-abe7-fc89475457e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "37397bd3-1fe2-4b5e-8dba-d2981d85e104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1071bfd2-8a33-4a0e-8906-c582028227d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed5c5c62-79a5-43b8-a7d2-f9fba8987fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 128, 32)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69006e00-8ff7-4570-a4bc-b764756c0dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ca49a36a-52a5-4e62-99ad-b7737e181a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.8892645180677635, Sensitivity: 0.8506652661064426, Specificity: 0.9636627906976744\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.8774243987866278, Sensitivity: 0.8402485994397759, Specificity: 0.9532461240310077\n",
      "Iteration Results - Accuracy: 0.9055555555555556, F1 Score: 0.8850408850408851, Sensitivity: 0.8298319327731093, Specificity: 0.9714147286821705\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.8709870336415554, Sensitivity: 0.8191526610644257, Specificity: 0.9636627906976744\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9013888888888889, Sensitivity: 0.8863795518207284, Specificity: 0.9241071428571429\n",
      "Iteration Results - Accuracy: 0.8388888888888889, F1 Score: 0.7981900452488687, Sensitivity: 0.81468837535014, Specificity: 0.8591154485049834\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.8982547850472379, Sensitivity: 0.8375350140056023, Specificity: 0.9791666666666666\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.8749152082485416, Sensitivity: 0.9000350140056023, Specificity: 0.9103336101882613\n",
      "Iteration Results - Accuracy: 0.9277777777777777, F1 Score: 0.9157456922162804, Sensitivity: 0.8911064425770308, Specificity: 0.9609980620155039\n",
      "Iteration Results - Accuracy: 0.8944444444444445, F1 Score: 0.8685154777108801, Sensitivity: 0.8387605042016807, Specificity: 0.9454941860465116\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.8927899686520376, Sensitivity: 0.8506652661064426, Specificity: 0.9609980620155039\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.8786825074857529, Sensitivity: 0.8506652661064426, Specificity: 0.9428294573643411\n",
      "Iteration Results - Accuracy: 0.888888888888889, F1 Score: 0.865546218487395, Sensitivity: 0.8298319327731093, Specificity: 0.9428294573643411\n",
      "Iteration Results - Accuracy: 0.8944444444444445, F1 Score: 0.8723830598069949, Sensitivity: 0.8402485994397759, Specificity: 0.9413413621262459\n",
      "Iteration Results - Accuracy: 0.9055555555555556, F1 Score: 0.8863370547581074, Sensitivity: 0.8402485994397759, Specificity: 0.9609980620155039\n",
      "Iteration Results - Accuracy: 0.9166666666666666, F1 Score: 0.8974324293861725, Sensitivity: 0.8896183473389355, Specificity: 0.9440060908084164\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.8904139433551198, Sensitivity: 0.8610819327731093, Specificity: 0.9517580287929125\n",
      "Iteration Results - Accuracy: 0.8388888888888889, F1 Score: 0.813696562135456, Sensitivity: 0.8375350140056023, Specificity: 0.8552740863787376\n",
      "Iteration Results - Accuracy: 0.7611111111111111, F1 Score: 0.5037986704653371, Sensitivity: 0.4479166666666667, Specificity: 0.9330357142857143\n",
      "Iteration Results - Accuracy: 0.9166666666666666, F1 Score: 0.898177174039243, Sensitivity: 0.8506652661064426, Specificity: 0.9714147286821705\n",
      "100%|| 20/20 [26:48<00:00, 80.44s/trial, best loss: -0.9157456922162804]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b1bc955d-aea4-41eb-adc3-36a3d2c0fdae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 64, 'dropout_rate': 0.23421937922257197, 'learning_rate': 0.0020603366872177595, 'epochs': 30, 'batch_size': 16, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dae7a270-4adb-49a3-9fd7-989d6af48985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.9142857142857143\n",
      "Sensitivity: 0.8421052631578947\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1fdcc-a140-4929-9820-721c37cd8647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98253ca7-7d76-438c-b7dd-2daec85981b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GRU with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a168d442-edad-4a9a-9581-dc56d13a40c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a4d33ac4-90ae-4397-b539-2c352b291154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6cfc2d87-ed27-4fb1-be3e-9ab859a2685b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_11868\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1443f452-b7eb-4fa9-9796-9cde97c8ac58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f7f87ea-63d2-4a53-b208-31380799625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f81e483d-6cd4-43e6-a13c-e937ee3e9b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "374ff74c-afcc-4315-8c7a-04a3bdc62bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5265cef0-ae34-4f25-b8cb-d69ac7f906c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "65cb06c5-0c00-4e04-9e28-db275077fd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ff6981f9-8a8d-48b8-880b-f424ba5171fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "619c1bd2-d8c0-40c8-9f5c-8bba010b9fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 32, 64, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.4),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "247393ae-704a-401d-95b6-659cf5e1f68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a249b175-5cc9-47cd-a714-3103f43d70ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.8611111111111112, F1 Score: 0.8387878787878787, Sensitivity: 0.7835707502374168, Specificity: 0.9284610814022578\n",
      "Iteration Results - Accuracy: 0.8222222222222223, F1 Score: 0.7848383500557414, Sensitivity: 0.7105413105413105, Specificity: 0.9190730837789661\n",
      "Iteration Results - Accuracy: 0.8666666666666667, F1 Score: 0.8514588859416445, Sensitivity: 0.8314339981006648, Specificity: 0.8971479500891265\n",
      "Iteration Results - Accuracy: 0.8888888888888888, F1 Score: 0.8742844532715436, Sensitivity: 0.8433048433048432, Specificity: 0.9281639928698753\n",
      "Iteration Results - Accuracy: 0.8999999999999999, F1 Score: 0.8891562481433386, Sensitivity: 0.868945868945869, Specificity: 0.9281639928698753\n",
      "Iteration Results - Accuracy: 0.7722222222222223, F1 Score: 0.7442680776014109, Sensitivity: 0.7428300094966761, Specificity: 0.7932857991681521\n",
      "Iteration Results - Accuracy: 0.8777777777777778, F1 Score: 0.8644964577167967, Sensitivity: 0.8433048433048432, Specificity: 0.9056446821152703\n",
      "Iteration Results - Accuracy: 0.8722222222222222, F1 Score: 0.8624075913053072, Sensitivity: 0.868945868945869, Specificity: 0.8779560308972073\n",
      "Iteration Results - Accuracy: 0.8555555555555555, F1 Score: 0.8380952380952381, Sensitivity: 0.8156695156695157, Specificity: 0.8840166369578135\n",
      "Iteration Results - Accuracy: 0.7722222222222223, F1 Score: 0.7648651020256633, Sensitivity: 0.8082621082621083, Specificity: 0.7437908496732026\n",
      "Iteration Results - Accuracy: 0.7722222222222223, F1 Score: 0.7442680776014109, Sensitivity: 0.7428300094966761, Specificity: 0.7932857991681521\n",
      "Iteration Results - Accuracy: 0.888888888888889, F1 Score: 0.8740618858265918, Sensitivity: 0.8339031339031339, Specificity: 0.9382650029708853\n",
      "Iteration Results - Accuracy: 0.8777777777777778, F1 Score: 0.862010582010582, Sensitivity: 0.8321937321937322, Specificity: 0.9180629827688652\n",
      "Iteration Results - Accuracy: 0.6277777777777778, F1 Score: 0.36190476190476195, Sensitivity: 0.362962962962963, Specificity: 0.8242424242424242\n",
      "Iteration Results - Accuracy: 0.8888888888888888, F1 Score: 0.8761098378745437, Sensitivity: 0.856125356125356, Specificity: 0.9190730837789661\n",
      "Iteration Results - Accuracy: 0.7333333333333334, F1 Score: 0.6242376703598392, Sensitivity: 0.5698005698005698, Specificity: 0.8628045157456922\n",
      "Iteration Results - Accuracy: 0.8833333333333333, F1 Score: 0.8664039408866994, Sensitivity: 0.818613485280152, Specificity: 0.9369578134284017\n",
      "Iteration Results - Accuracy: 0.8833333333333333, F1 Score: 0.8677822762033288, Sensitivity: 0.8314339981006648, Specificity: 0.9284610814022578\n",
      "Iteration Results - Accuracy: 0.8833333333333333, F1 Score: 0.8687942571931121, Sensitivity: 0.8433048433048432, Specificity: 0.9183600713012477\n",
      "Iteration Results - Accuracy: 0.8444444444444444, F1 Score: 0.8433228996068779, Sensitivity: 0.9022792022792023, Specificity: 0.7910873440285204\n",
      "100%|| 20/20 [1:08:21<00:00, 205.08s/trial, best loss: -0.8891562481433386]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bda36308-47d7-4d06-82ff-0447d70d7b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 48, 'dropout_rate': 0.27966291936271315, 'epochs': 20, 'learning_rate': 0.009892223354706116, 'units': 32}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ff996c96-8e43-4ae2-9dc8-9925e866301a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "24efc4cb-db7b-4bc0-9afd-53baa2d407e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "11aa2678-d0b4-4965-a93c-c75ec3d55ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000001DD412012D0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 418, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dd79b44410>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b262a864-333a-498d-a803-6c07a706383d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.88\n",
      "Sensitivity: 0.8461538461538461\n",
      "Specificity: 0.96875\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06800a32-61b6-4931-b62c-afec61a67b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fba88723-fd58-45e2-bccf-912857d24ca3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f50f16c6-ec0c-4ab1-a1aa-6243941f8eb8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_11868\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5af415b9-8d51-4ab8-ada9-459cc1f76fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf5fa872-4a3e-4f16-a46d-a333a5d096ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ed4c4a8-5ed7-4d3e-add3-86d0b02e7752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ce80449-a407-4f6a-ae99-70b4eb62e45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9d606ee-7321-407e-8ab9-968d4f432ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1346e11-714c-4281-861c-00f4bc26f582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18d1349b-7b88-44af-9783-c1d94be3477f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape(X_selected.shape[0], X_selected.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "13755777-2320-4be4-8471-8d36c78ec767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d1c075cf-f755-4089-b268-2e67d769b7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "72f9bdce-e9b9-456b-8acf-ab9df8f35f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f1c187d9-be4a-4e79-a494-d664f34ef006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "98b62231-d543-4b15-808d-5c4fd771a5ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7666666666666666, F1 Score: 0.6596491228070175, Sensitivity: 0.5015194681861348, Specificity: 0.9901960784313726\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7944444444444444, F1 Score: 0.6928169480304535, Sensitivity: 0.5452041785375119, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8055555555555555, F1 Score: 0.7276203328834908, Sensitivity: 0.6044634377967711, Specificity: 0.9797979797979798\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9111111111111111, F1 Score: 0.9017470139342617, Sensitivity: 0.879582146248813, Specificity: 0.936660724896019\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8888888888888888, F1 Score: 0.8688301454258901, Sensitivity: 0.821747388414055, Specificity: 0.9506833036244801\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8944444444444444, F1 Score: 0.8739167620626587, Sensitivity: 0.7956315289648623, Specificity: 0.9790849673202615\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8500000000000001, F1 Score: 0.8079303675048356, Sensitivity: 0.6885090218423552, Specificity: 0.9901960784313726\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8777777777777779, F1 Score: 0.8497212931995541, Sensitivity: 0.7621082621082621, Specificity: 0.9800950683303625\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777777, F1 Score: 0.6824054498473103, Sensitivity: 0.5197530864197532, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9166666666666666, F1 Score: 0.9030036256927013, Sensitivity: 0.8442545109211776, Specificity: 0.9803921568627452\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777777, F1 Score: 0.664823194234959, Sensitivity: 0.5096866096866096, Specificity: 1.0\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9, F1 Score: 0.8789260385005067, Sensitivity: 0.8045584045584045, Specificity: 0.9800950683303625\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8444444444444444, F1 Score: 0.7913677666188427, Sensitivity: 0.6805318138651472, Specificity: 0.9901960784313726\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8777777777777778, F1 Score: 0.8496743378202344, Sensitivity: 0.7511870845204177, Specificity: 0.9901960784313726\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.9055555555555556, F1 Score: 0.8907309941520468, Sensitivity: 0.8319088319088319, Specificity: 0.9679738562091503\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8055555555555555, F1 Score: 0.7322386679000924, Sensitivity: 0.594681861348528, Specificity: 0.9901960784313726\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8944444444444444, F1 Score: 0.8825764476252441, Sensitivity: 0.856125356125356, Specificity: 0.9268568033273916\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8555555555555555, F1 Score: 0.8616695804195804, Sensitivity: 0.9410256410256411, Specificity: 0.7814022578728461\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8999999999999999, F1 Score: 0.8800515796260476, Sensitivity: 0.8057929724596392, Specificity: 0.9800950683303625\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.8888888888888888, F1 Score: 0.8736772486772487, Sensitivity: 0.8321937321937322, Specificity: 0.93767082590612\n",
      "100%|| 20/20 [05:50<00:00, 17.53s/trial, best loss: -0.9030036256927013]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "669686a6-a160-4a0c-b8af-2ad569680ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 32, 'dropout_rate': 0.2658645244404154, 'epochs': 50, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.0039056432020402646}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c92018e9-49b8-4893-8cd0-50ec83bc7df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2b502591-d415-4db2-87bd-43e4c8a30f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dda7cb5390>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5d592f2b-2da3-48f0-9e8b-65b2315d4348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5b22e6b1-85fe-42c9-9b72-0b38dfd4b24d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9777777777777777\n",
      "F1 Score: 0.96\n",
      "Sensitivity: 0.9230769230769231\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34071e-cb97-4c84-a9cd-1e953381fa67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24a8b311-546f-4a4f-b04c-ad9365cf9000",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96ea81d3-b363-4d7f-ab80-6ae3ae1f0256",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_33032\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a62579bb-3b46-48ad-b118-2184972697b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2842bc31-b5cb-4ebe-be50-ee6d248b20d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a29e9773-9d6b-4620-baaa-3f6e42a7cb5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f312c77d-a691-4056-8c5b-d5940b9a1dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c35a1419-6aa0-4b22-a024-6ca5a9707ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac67fbaa-fba7-4c65-aaea-e1d4b3027892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49f0ac82-f2a3-414e-9d15-4aead5fb4356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cd66bbe-433b-49e1-94ec-f31c162a13bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecf5569f-6fd7-4aad-8afe-7add7d7920fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ab79cc2-dbb8-43e9-8ab4-04cd6e21bbec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99a60c98-97ae-4f25-9944-955d75ab4615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8735db28-2bc8-4656-adde-c47494cf1911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11438ce9-6cb1-47e2-80aa-f3f7a14eb0ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3980549886155438, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0001176773605317018, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.5159001350402832, Filters: 128, Blocks: 10, Kernel Size: 4, Dropout: 0.3980549886155438, LR: 0.0001176773605317018, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.48487451410894156, 'epochs': 30, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.007015621834685462, 'num_blocks': 6}\n",
      "Iteration - Loss: 68.81507873535156, Filters: 64, Blocks: 6, Kernel Size: 4, Dropout: 0.48487451410894156, LR: 0.007015621834685462, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.2717027872146768, 'epochs': 40, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.007186455782248792, 'num_blocks': 10}\n",
      "Iteration - Loss: 124419.0, Filters: 128, Blocks: 10, Kernel Size: 3, Dropout: 0.2717027872146768, LR: 0.007186455782248792, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.20439935311637122, 'epochs': 30, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.00041651322193142216, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.5704503059387207, Filters: 96, Blocks: 6, Kernel Size: 3, Dropout: 0.20439935311637122, LR: 0.00041651322193142216, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3843120564878674, 'epochs': 40, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0024135841949019282, 'num_blocks': 8}\n",
      "Iteration - Loss: 63.66143798828125, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.3843120564878674, LR: 0.0024135841949019282, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3844105227054702, 'epochs': 20, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.0035113748865880823, 'num_blocks': 8}\n",
      "Iteration - Loss: 9.512887001037598, Filters: 64, Blocks: 8, Kernel Size: 5, Dropout: 0.3844105227054702, LR: 0.0035113748865880823, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.34168551327238605, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0002548315889809493, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5221168398857117, Filters: 64, Blocks: 8, Kernel Size: 4, Dropout: 0.34168551327238605, LR: 0.0002548315889809493, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.3867906224082569, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.009125196790130137, 'num_blocks': 10}\n",
      "Iteration - Loss: 0.8759521245956421, Filters: 96, Blocks: 10, Kernel Size: 3, Dropout: 0.3867906224082569, LR: 0.009125196790130137, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.33190955164763336, 'epochs': 20, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.00045850567767451004, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.4370105564594269, Filters: 32, Blocks: 8, Kernel Size: 4, Dropout: 0.33190955164763336, LR: 0.00045850567767451004, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.2842581130736044, 'epochs': 30, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.0015507911175217477, 'num_blocks': 10}\n",
      "Iteration - Loss: 2.630856513977051, Filters: 128, Blocks: 10, Kernel Size: 3, Dropout: 0.2842581130736044, LR: 0.0015507911175217477, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.20046030387481673, 'epochs': 50, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0012668950860414852, 'num_blocks': 8}\n",
      "Iteration - Loss: 2.68200945854187, Filters: 128, Blocks: 8, Kernel Size: 4, Dropout: 0.20046030387481673, LR: 0.0012668950860414852, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.23645519291170747, 'epochs': 50, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0004950459865201355, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.5861899852752686, Filters: 128, Blocks: 4, Kernel Size: 4, Dropout: 0.23645519291170747, LR: 0.0004950459865201355, Batch Size: 32, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.4052725772550979, 'epochs': 50, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.0016713138045519136, 'num_blocks': 8}\n",
      "Iteration - Loss: 2.698580741882324, Filters: 64, Blocks: 8, Kernel Size: 5, Dropout: 0.4052725772550979, LR: 0.0016713138045519136, Batch Size: 64, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.432915859978057, 'epochs': 40, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.00010049232336779202, 'num_blocks': 8}\n",
      "Iteration - Loss: 0.5369765758514404, Filters: 128, Blocks: 8, Kernel Size: 3, Dropout: 0.432915859978057, LR: 0.00010049232336779202, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.41815706576787304, 'epochs': 20, 'filters': 32, 'kernel_size': 3, 'learning_rate': 0.00018356813458771053, 'num_blocks': 6}\n",
      "Iteration - Loss: 0.4983605146408081, Filters: 32, Blocks: 6, Kernel Size: 3, Dropout: 0.41815706576787304, LR: 0.00018356813458771053, Batch Size: 64, Epochs: 20\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.49706878484728845, 'epochs': 40, 'filters': 64, 'kernel_size': 3, 'learning_rate': 0.001363087694289134, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.4724205732345581, Filters: 64, Blocks: 4, Kernel Size: 3, Dropout: 0.49706878484728845, LR: 0.001363087694289134, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.2357791332753371, 'epochs': 50, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0019109248761221616, 'num_blocks': 10}\n",
      "Iteration - Loss: 2.5186564922332764, Filters: 96, Blocks: 10, Kernel Size: 3, Dropout: 0.2357791332753371, LR: 0.0019109248761221616, Batch Size: 48, Epochs: 50\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.3187852105337471, 'epochs': 30, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.0014071839150855722, 'num_blocks': 8}\n",
      "Iteration - Loss: 1.5590057373046875, Filters: 128, Blocks: 8, Kernel Size: 3, Dropout: 0.3187852105337471, LR: 0.0014071839150855722, Batch Size: 64, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.31392463355309996, 'epochs': 30, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0002568014275552699, 'num_blocks': 4}\n",
      "Iteration - Loss: 0.49952417612075806, Filters: 96, Blocks: 4, Kernel Size: 4, Dropout: 0.31392463355309996, LR: 0.0002568014275552699, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.2946313886038331, 'epochs': 30, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.003654556885827544, 'num_blocks': 6}\n",
      "Iteration - Loss: 35.68112564086914, Filters: 96, Blocks: 6, Kernel Size: 4, Dropout: 0.2946313886038331, LR: 0.003654556885827544, Batch Size: 32, Epochs: 30\n",
      "100%|| 20/20 [03:36<00:00, 10.82s/trial, best loss: 0.4370105564594269]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "755f26ce-5d31-4cab-9eab-7665327bcaef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 48, 'dropout_rate': 0.33190955164763336, 'epochs': 20, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.00045850567767451004, 'num_blocks': 8}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a997e89-0ad3-4a81-ad00-ad16ced71401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "717e860a-cf93-45bf-afc2-3258b1595cd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 143ms/step - accuracy: 0.4833 - loss: 1.5220 - val_accuracy: 0.3333 - val_loss: 0.8322\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6180 - loss: 0.8143 - val_accuracy: 0.3333 - val_loss: 0.8701\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7425 - loss: 0.4666 - val_accuracy: 0.3333 - val_loss: 0.8193\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8930 - loss: 0.3102 - val_accuracy: 0.5556 - val_loss: 0.7209\n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8711 - loss: 0.3041 - val_accuracy: 0.7222 - val_loss: 0.6235\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8773 - loss: 0.3349 - val_accuracy: 0.8889 - val_loss: 0.5489\n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8822 - loss: 0.2824 - val_accuracy: 0.8889 - val_loss: 0.4894\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9099 - loss: 0.2451 - val_accuracy: 0.9444 - val_loss: 0.4508\n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9098 - loss: 0.2472 - val_accuracy: 0.9444 - val_loss: 0.4317\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8900 - loss: 0.2358 - val_accuracy: 0.9444 - val_loss: 0.4298\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8924 - loss: 0.2399 - val_accuracy: 0.7778 - val_loss: 0.4391\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8841 - loss: 0.2424 - val_accuracy: 0.7222 - val_loss: 0.4562\n",
      "Epoch 13/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9100 - loss: 0.2170 - val_accuracy: 0.7222 - val_loss: 0.4719\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7718b8ee-445b-4aa2-8e5d-d327a3359cac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ad5837a-e95f-4fc9-8661-a36e9375112f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.8695652173913043\n",
      "Sensitivity: 0.7692307692307693\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93982f-fada-4eed-887e-c1bab7af4d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e098983c-54b6-49f9-a6d5-5d554d232e6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "600c6d4c-53f6-4e97-abd9-371e9497cf5e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_33032\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c65b3770-835f-4211-990c-a9652001b26f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aef7f344-e9d6-49a7-86e3-b5fc02b40606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01ad4ff1-d3d6-4203-ba0c-ce86b2e1da6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ae3e504-6ce8-4286-aed5-a913ed375a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a44e37e-8450-45b3-9967-673fd0cf34aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6182d1d-19bc-44f9-86dc-f3c9f4c29f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a0a4499-de75-4fa4-ae1a-3dcc01dcec16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_selected.reshape((X_selected.shape[0], X_selected.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20b290ab-2881-40ef-94e6-1c18e8c9463e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1b258ea-ac1f-4d50-9ce8-0a57bc5deb72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da2a5768-fe80-4494-8535-454c0efae58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "888b32bc-74ae-4e7b-b85e-d3f499e6da75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65188614-8f10-4aad-808f-44cd2bf02e3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 0.37399160861968994, Params: {'batch_size': 48, 'dropout_rate': 0.18017612999444907, 'epochs': 80, 'learning_rate': 0.0007425035235943857, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.41896700859069824, Params: {'batch_size': 80, 'dropout_rate': 0.21204374065699502, 'epochs': 140, 'learning_rate': 0.003660219911958971, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.15412847697734833, Params: {'batch_size': 48, 'dropout_rate': 0.12153783201760492, 'epochs': 90, 'learning_rate': 0.000461078143663016, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.6269364953041077, Params: {'batch_size': 128, 'dropout_rate': 0.46803668757237316, 'epochs': 50, 'learning_rate': 3.692984065917628e-05, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.31880784034729004, Params: {'batch_size': 48, 'dropout_rate': 0.3846741632858198, 'epochs': 60, 'learning_rate': 0.00027629495803198725, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.5683258771896362, Params: {'batch_size': 32, 'dropout_rate': 0.37375863610810567, 'epochs': 80, 'learning_rate': 8.239026526093029e-05, 'num_layers': 2, 'units': 64}\n",
      "Iteration - Loss: 0.5524654388427734, Params: {'batch_size': 64, 'dropout_rate': 0.14530327826420805, 'epochs': 100, 'learning_rate': 1.0963875266898625e-05, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.3280903100967407, Params: {'batch_size': 32, 'dropout_rate': 0.4429884021156201, 'epochs': 130, 'learning_rate': 0.0037009557627115624, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 0.2522137463092804, Params: {'batch_size': 32, 'dropout_rate': 0.18546631565818883, 'epochs': 60, 'learning_rate': 0.00036114505881693906, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.6311109066009521, Params: {'batch_size': 112, 'dropout_rate': 0.4387645685086836, 'epochs': 150, 'learning_rate': 1.7237285476763422e-05, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.3358106315135956, Params: {'batch_size': 96, 'dropout_rate': 0.1332498374601582, 'epochs': 90, 'learning_rate': 0.008747957666620504, 'num_layers': 4, 'units': 224}\n",
      "Iteration - Loss: 0.3559838533401489, Params: {'batch_size': 96, 'dropout_rate': 0.19041951402415008, 'epochs': 120, 'learning_rate': 0.00011514003715849777, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.32537275552749634, Params: {'batch_size': 48, 'dropout_rate': 0.28192475123475275, 'epochs': 60, 'learning_rate': 0.0006989870547005645, 'num_layers': 5, 'units': 64}\n",
      "Iteration - Loss: 0.63897305727005, Params: {'batch_size': 32, 'dropout_rate': 0.4721842669391264, 'epochs': 130, 'learning_rate': 1.9834960406917758e-05, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.4320327639579773, Params: {'batch_size': 96, 'dropout_rate': 0.13970285096695198, 'epochs': 60, 'learning_rate': 0.003320525962879404, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.3631517291069031, Params: {'batch_size': 80, 'dropout_rate': 0.44769163052534533, 'epochs': 80, 'learning_rate': 0.0009688780494637423, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.27967000007629395, Params: {'batch_size': 112, 'dropout_rate': 0.4163820428090349, 'epochs': 140, 'learning_rate': 0.00022977367166116127, 'num_layers': 3, 'units': 160}\n",
      "Iteration - Loss: 0.6430143713951111, Params: {'batch_size': 112, 'dropout_rate': 0.2183033350089915, 'epochs': 90, 'learning_rate': 5.006972858263414e-05, 'num_layers': 6, 'units': 64}\n",
      "Iteration - Loss: 0.5850183963775635, Params: {'batch_size': 96, 'dropout_rate': 0.34206949959212585, 'epochs': 90, 'learning_rate': 2.4605960222354756e-05, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.3244011104106903, Params: {'batch_size': 48, 'dropout_rate': 0.1745996892226538, 'epochs': 60, 'learning_rate': 0.0029002679735924716, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.10413222759962082, Params: {'batch_size': 16, 'dropout_rate': 0.2538006916785532, 'epochs': 110, 'learning_rate': 0.0013309981692679437, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.1443314552307129, Params: {'batch_size': 16, 'dropout_rate': 0.2692407831876309, 'epochs': 110, 'learning_rate': 0.0014736302061406502, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.2424928843975067, Params: {'batch_size': 16, 'dropout_rate': 0.2707880348011178, 'epochs': 110, 'learning_rate': 0.0019529720740533174, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.2656268775463104, Params: {'batch_size': 16, 'dropout_rate': 0.24964259562549834, 'epochs': 110, 'learning_rate': 0.008673086056791688, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.27791351079940796, Params: {'batch_size': 16, 'dropout_rate': 0.32010327771847447, 'epochs': 110, 'learning_rate': 0.0014979455066316527, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.3868357241153717, Params: {'batch_size': 16, 'dropout_rate': 0.2434731544167766, 'epochs': 120, 'learning_rate': 0.0013713324486228267, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.4072067439556122, Params: {'batch_size': 64, 'dropout_rate': 0.3156145048350406, 'epochs': 100, 'learning_rate': 0.006062311134271062, 'num_layers': 6, 'units': 128}\n",
      "Iteration - Loss: 0.3975415825843811, Params: {'batch_size': 32, 'dropout_rate': 0.34362537000790294, 'epochs': 120, 'learning_rate': 0.00017100861694700184, 'num_layers': 2, 'units': 160}\n",
      "Iteration - Loss: 0.3554416596889496, Params: {'batch_size': 16, 'dropout_rate': 0.2826664253426394, 'epochs': 130, 'learning_rate': 0.0006524919003124892, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.3312944173812866, Params: {'batch_size': 64, 'dropout_rate': 0.2389628911535851, 'epochs': 110, 'learning_rate': 0.0021073314396327265, 'num_layers': 3, 'units': 128}\n",
      "100%|| 30/30 [01:45<00:00,  3.53s/trial, best loss: 0.10413222759962082]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d41308f-e07e-443d-ada5-5f110fc24a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2538006916785532, 'epochs': 110, 'learning_rate': 0.0013309981692679437, 'num_layers': 2, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06ab43bd-1892-42f4-9b08-53f9c50e9283",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8220 - loss: 0.4930 - val_accuracy: 0.8889 - val_loss: 0.3800\n",
      "Epoch 2/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2330 - val_accuracy: 0.9444 - val_loss: 0.3406\n",
      "Epoch 3/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1607 - val_accuracy: 0.9444 - val_loss: 0.3681\n",
      "Epoch 4/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0894 - val_accuracy: 0.9444 - val_loss: 0.3576\n",
      "Epoch 5/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0730 - val_accuracy: 0.9444 - val_loss: 0.2865\n",
      "Epoch 6/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0571 - val_accuracy: 0.9444 - val_loss: 0.2645\n",
      "Epoch 7/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0379 - val_accuracy: 0.8889 - val_loss: 0.2880\n",
      "Epoch 8/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0350 - val_accuracy: 0.8889 - val_loss: 0.3100\n",
      "Epoch 9/110\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.8889 - val_loss: 0.3085\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c35fcdbc-6845-4904-a86c-c78d0f32809c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BD99DD6FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BD99DD6FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9777777777777777\n",
      "F1 Score: 0.9629629629629629\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.96875\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae9ddf-2c4c-4095-9afd-9deba68c8432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7991f66-79a2-4974-9bec-560aa8c6b0da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7606643-843f-496f-abcb-6b0ddb4d927b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_22324\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b384cc9f-3ac8-4fa4-8aeb-4a94e369b804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values\n",
    "features_df = features_df.apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a486593-fa89-4d41-981c-0091694141d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(features_df.values)\n",
    "num_features = 10000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bf19599-b62a-4d8e-a118-875dc2b6966d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(features_df.values, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f15b842-8c1f-4cf3-ade5-856808228ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = features_df.iloc[selected_indices, :].T\n",
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88343ce4-865d-4208-91f4-81d70e8a5907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4efecc9c-2798-43af-9561-a7a2f086c287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b2a0dfa-7824-4534-9ac7-66a82474b3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c21ba8eb-c9a2-437d-bdd9-c8b5ec7fb751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:30:32,826] A new study created in memory with name: no-name-a843a549-ef87-4d7b-9ba2-8f1f8b9b4a04\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de0509a5-9dbb-451a-bb5c-410659f30daa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 02:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.678291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.671713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.664239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:33:24,767] Trial 0 finished with value: 0.6642386317253113 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.9228344816660464e-05, 'max_length': 174}. Best is trial 0 with value: 0.6642386317253113.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 03:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.675857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.667638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.657009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:37:02,798] Trial 1 finished with value: 0.6570088267326355 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 2.3242484375658725e-05, 'max_length': 218}. Best is trial 1 with value: 0.6570088267326355.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 03:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.664055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.651582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679200</td>\n",
       "      <td>0.625574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:41:09,277] Trial 2 finished with value: 0.6255738735198975 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 3.4214898356394043e-05, 'max_length': 244}. Best is trial 2 with value: 0.6255738735198975.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 01:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>0.718731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.677569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:43:16,574] Trial 3 finished with value: 0.6775685548782349 and parameters: {'num_train_epochs': 2, 'batch_size': 16, 'learning_rate': 1.891575476153777e-05, 'max_length': 182}. Best is trial 2 with value: 0.6255738735198975.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 02:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.700175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.676326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.632369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-12 12:46:27,232] Trial 4 finished with value: 0.6323688626289368 and parameters: {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 2.3839167137016707e-05, 'max_length': 188}. Best is trial 2 with value: 0.6255738735198975.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99f43414-2736-48ea-a25c-7fba573e6b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 3, 'batch_size': 16, 'learning_rate': 3.4214898356394043e-05, 'max_length': 244}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb2fe71d-9c03-448e-8174-edafb88bc409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47bdc7a7-996f-4a58-9c10-9b872edc44b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26a66ba3-224d-4247-8c02-c352c175f50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5262ca18-af36-4375-b3ff-87302cfc9b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "106f1743-055c-46b8-804d-17ab8bd73c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a69af07d-6251-4a4d-8692-2c43bab41ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 17:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.757100</td>\n",
       "      <td>0.605353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.710800</td>\n",
       "      <td>0.639214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.620413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=0.7132268084420098, metrics={'train_runtime': 1090.1102, 'train_samples_per_second': 0.495, 'train_steps_per_second': 0.033, 'total_flos': 142079969894400.0, 'train_loss': 0.7132268084420098, 'epoch': 3.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a99777b-052e-41d3-b745-ffe6046d1c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7333333333333333\n",
      "F1 Score: 0.25\n",
      "Sensitivity: 0.15384615384615385\n",
      "Specificity: 0.96875\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fee474-0134-416f-b8e7-e92b624ee747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "113d51cf-b263-405b-9cc4-cb4ee9a4239d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638282f6-4fb7-410d-93f1-5f420703bb31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_16228\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eef800f-21d2-40c3-9cc3-9213caf3c43b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :] \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values  \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3751242e-2ffa-4b3d-ad3a-d9e2b3e00116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "186e3491-a9ed-4325-b83d-07fb268f6892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 25000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "013d99a5-c8b2-4226-916d-186a2732c708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:2500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25d65bd4-2068-46e3-b5db-b78a9337b42c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d75259d3-9a21-4c8f-8363-24ac3e8f6eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_selected)\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b99ae62a-5807-452e-be9a-6cbef810abd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e372484-7266-46fa-ac06-c5c531638a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6669477d-4709-4816-9981-e31707502b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 08:34:29,262] A new study created in memory with name: no-name-b50f0f04-4393-4b0c-9aee-1298738a08f0\n",
      "[I 2024-06-13 08:34:33,522] Trial 0 finished with value: 0.0006556596490554512 and parameters: {'num_units': 64, 'learning_rate': 0.00044388207153177913, 'dropout_rate': 0.11700041965897287, 'activity_regularizer': 2.336138723070626e-07, 'batch_size': 35}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:34:37,808] Trial 1 finished with value: 0.0012135799042880535 and parameters: {'num_units': 136, 'learning_rate': 0.0009441060118585653, 'dropout_rate': 0.2509450365530612, 'activity_regularizer': 8.994791895440329e-06, 'batch_size': 51}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:34:41,789] Trial 2 finished with value: 0.0008103905711323023 and parameters: {'num_units': 192, 'learning_rate': 6.139003110672853e-05, 'dropout_rate': 0.10963539554549137, 'activity_regularizer': 5.192731780847544e-07, 'batch_size': 20}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:34:45,870] Trial 3 finished with value: 0.001444741035811603 and parameters: {'num_units': 185, 'learning_rate': 0.0003771252966664942, 'dropout_rate': 0.01471128783616089, 'activity_regularizer': 2.2434036093890432e-05, 'batch_size': 31}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:34:49,930] Trial 4 finished with value: 0.0036209686659276485 and parameters: {'num_units': 183, 'learning_rate': 1.1495689741611544e-05, 'dropout_rate': 0.044753974508654294, 'activity_regularizer': 2.5207683389788623e-07, 'batch_size': 46}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:34:54,418] Trial 5 finished with value: 0.0007078929338604212 and parameters: {'num_units': 118, 'learning_rate': 0.000897810696867337, 'dropout_rate': 0.05832708944033059, 'activity_regularizer': 7.446197726881857e-07, 'batch_size': 35}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:34:55,267] Trial 6 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:34:56,208] Trial 7 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:34:57,127] Trial 8 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:34:58,052] Trial 9 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:02,233] Trial 10 finished with value: 0.0008783609373494983 and parameters: {'num_units': 68, 'learning_rate': 0.0003389128068619117, 'dropout_rate': 0.18543729973135506, 'activity_regularizer': 2.3484090602226075e-06, 'batch_size': 26}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:35:03,130] Trial 11 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:04,052] Trial 12 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:05,168] Trial 13 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:06,283] Trial 14 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:07,182] Trial 15 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:08,284] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:11,385] Trial 17 pruned. Trial was pruned at epoch 32.\n",
      "[I 2024-06-13 08:35:15,690] Trial 18 finished with value: 0.0006601862842217088 and parameters: {'num_units': 79, 'learning_rate': 0.0006064086197210336, 'dropout_rate': 0.005513804683634799, 'activity_regularizer': 1.1582202744508901e-07, 'batch_size': 43}. Best is trial 0 with value: 0.0006556596490554512.\n",
      "[I 2024-06-13 08:35:16,565] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:17,698] Trial 20 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:18,581] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:19,519] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:23,862] Trial 23 finished with value: 0.0005799116916023195 and parameters: {'num_units': 113, 'learning_rate': 0.0009990251345722958, 'dropout_rate': 0.05329256557231495, 'activity_regularizer': 3.383231632991909e-07, 'batch_size': 31}. Best is trial 23 with value: 0.0005799116916023195.\n",
      "[I 2024-06-13 08:35:24,641] Trial 24 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:29,908] Trial 25 finished with value: 0.0007288891356438398 and parameters: {'num_units': 76, 'learning_rate': 0.00022483363345288161, 'dropout_rate': 0.0063271701704083055, 'activity_regularizer': 1.0282656328187567e-07, 'batch_size': 24}. Best is trial 23 with value: 0.0005799116916023195.\n",
      "[I 2024-06-13 08:35:30,774] Trial 26 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:35,017] Trial 27 finished with value: 0.0006902868044562638 and parameters: {'num_units': 90, 'learning_rate': 0.0004798833880672404, 'dropout_rate': 0.04904108560827501, 'activity_regularizer': 1.9436420460821e-07, 'batch_size': 32}. Best is trial 23 with value: 0.0005799116916023195.\n",
      "[I 2024-06-13 08:35:35,907] Trial 28 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:40,256] Trial 29 finished with value: 0.0004989323788322508 and parameters: {'num_units': 145, 'learning_rate': 0.0009879709840204275, 'dropout_rate': 0.24994807044911907, 'activity_regularizer': 5.542497170817539e-06, 'batch_size': 16}. Best is trial 29 with value: 0.0004989323788322508.\n",
      "[I 2024-06-13 08:35:41,977] Trial 30 pruned. Trial was pruned at epoch 15.\n",
      "[I 2024-06-13 08:35:42,827] Trial 31 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:44,592] Trial 32 pruned. Trial was pruned at epoch 11.\n",
      "[I 2024-06-13 08:35:46,355] Trial 33 pruned. Trial was pruned at epoch 9.\n",
      "[I 2024-06-13 08:35:47,180] Trial 34 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:48,167] Trial 35 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:49,126] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:50,228] Trial 37 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:54,737] Trial 38 finished with value: 0.0005135787068866193 and parameters: {'num_units': 211, 'learning_rate': 0.0008001946974418238, 'dropout_rate': 0.09813153622239489, 'activity_regularizer': 6.786591389152257e-07, 'batch_size': 28}. Best is trial 29 with value: 0.0004989323788322508.\n",
      "[I 2024-06-13 08:35:55,685] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-13 08:35:59,959] Trial 40 finished with value: 0.000470922386739403 and parameters: {'num_units': 222, 'learning_rate': 0.0008131784800367935, 'dropout_rate': 0.10315677079792779, 'activity_regularizer': 2.0464699306749694e-06, 'batch_size': 20}. Best is trial 40 with value: 0.000470922386739403.\n",
      "[I 2024-06-13 08:36:03,912] Trial 41 finished with value: 0.00043762673158198595 and parameters: {'num_units': 214, 'learning_rate': 0.0008044772363795157, 'dropout_rate': 0.09407158613563486, 'activity_regularizer': 1.864444396878514e-06, 'batch_size': 16}. Best is trial 41 with value: 0.00043762673158198595.\n",
      "[I 2024-06-13 08:36:07,681] Trial 42 finished with value: 0.00047223817091435194 and parameters: {'num_units': 208, 'learning_rate': 0.0008075732868481403, 'dropout_rate': 0.09893481192317234, 'activity_regularizer': 2.1727970099064695e-06, 'batch_size': 17}. Best is trial 41 with value: 0.00043762673158198595.\n",
      "[I 2024-06-13 08:36:11,501] Trial 43 finished with value: 0.0003772198688238859 and parameters: {'num_units': 221, 'learning_rate': 0.0007929613235907673, 'dropout_rate': 0.09715903055372935, 'activity_regularizer': 2.16158137657423e-06, 'batch_size': 16}. Best is trial 43 with value: 0.0003772198688238859.\n",
      "[I 2024-06-13 08:36:13,700] Trial 44 pruned. Trial was pruned at epoch 18.\n",
      "[I 2024-06-13 08:36:15,237] Trial 45 pruned. Trial was pruned at epoch 8.\n",
      "[I 2024-06-13 08:36:16,754] Trial 46 pruned. Trial was pruned at epoch 8.\n",
      "[I 2024-06-13 08:36:18,077] Trial 47 pruned. Trial was pruned at epoch 3.\n",
      "[I 2024-06-13 08:36:20,363] Trial 48 pruned. Trial was pruned at epoch 18.\n",
      "[I 2024-06-13 08:36:21,428] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de16e0cc-6e59-4e4a-a30c-4fa01de591b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 221, 'learning_rate': 0.0007929613235907673, 'dropout_rate': 0.09715903055372935, 'activity_regularizer': 2.16158137657423e-06, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98c20931-8e3a-4c82-85d7-bf962d99c763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28dc2e35-96ea-455d-a679-95d0c9972197",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - val_loss: 9.5362e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - val_loss: 9.4659e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - val_loss: 9.1007e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2010d4c0dd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94b7f956-1bcb-416d-b0a2-ddb82f3df874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.0021\n",
      "Validation Loss:  0.002161786425858736\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed062d41-2c4f-4038-86ed-6a485b57e722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed77022d-156f-433a-9814-5b2a79f80137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d242255a-61e2-48ce-8fd1-8c5cb01d7f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3589e921-2416-4329-9961-a60b73dd1a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6888888888888889\n",
      "F1 Score: 0.125\n",
      "Sensitivity: 0.07692307692307693\n",
      "Specificity: 0.9375\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4c096-8d11-4249-84db-e4a1566acff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b179dded-c00d-4557-8618-a956e506bf5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5b6266d4-1ec5-4054-b046-83dbb1853cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_16228\\795450887.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "Input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  # Change for different files\n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d26c1dd-3f1d-4202-a22f-a6143eff6dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]  \n",
    "case_control_info = df.iloc[-1, :]  \n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values \n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e3e2ce13-d434-4e49-9651-36a8abc86540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "740618de-1fc7-4c14-b4bf-a137bf46ee17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc6073b1-b938-4860-b9ef-eb25b9fbaac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9004ebb0-0894-44ef-8840-e410d2fd2512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [459916 340049 418589 273342 737619 530632 555527 109587 714143 460763]\n",
      "Top AMGM values: [1.009828  1.0098338 1.0098346 1.0098348 1.0098356 1.0098383 1.0098398\n",
      " 1.0098432 1.0098473 1.0098473]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a0dd893c-617d-4313-8ed0-1d2d7dd723d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7c4f266f-4b4f-4b82-8e3b-f7baee856119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T\n",
    "X_selected = X_selected.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a3650cbe-9df0-4168-9af0-54dce956cadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9fabba9e-c7a2-4edd-8f09-1bef873e8278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "88020620-d937-4bb4-9158-7aef5e90a3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b17e5d78-845c-434c-b9a2-89db42a6314b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "70aedf20-f044-48fc-98b6-c204462e2947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1bb6e6db-da9a-403d-b667-4d163e623497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "24c5db8e-e6c5-42d9-a52e-07eca835d79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ab5ced51-dbd9-4da1-b089-2217b9919bca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 816ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8444444444444444, F1 Score: 0.8377967711301045, Sensitivity: 0.8771130104463438, Specificity: 0.8131907308377896\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8722222222222222, F1 Score: 0.8571428571428571, Sensitivity: 0.8321937321937322, Specificity: 0.9076648841354724\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 763ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 832ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 789ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8055555555555557, F1 Score: 0.777955213915805, Sensitivity: 0.7448243114909782, Specificity: 0.8566250742721331\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.85, F1 Score: 0.8432916187684669, Sensitivity: 0.8684710351377017, Specificity: 0.8352346999405823\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 762ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 851ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7777777777777778, F1 Score: 0.6728908572226545, Sensitivity: 0.6193732193732194, Specificity: 0.903921568627451\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 913ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 898ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 803ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8277777777777778, F1 Score: 0.7860998650472334, Sensitivity: 0.7189933523266857, Specificity: 0.9157456922162804\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 932ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 917ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8666666666666667, F1 Score: 0.8627869361465531, Sensitivity: 0.8899335232668566, Specificity: 0.8402852049910874\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7722222222222223, F1 Score: 0.6940791232290832, Sensitivity: 0.5938271604938271, Specificity: 0.9154486036838979\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 767ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8777777777777779, F1 Score: 0.8604761904761905, Sensitivity: 0.8087369420702754, Specificity: 0.9372549019607842\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5777777777777778, F1 Score: 0.19103641456582632, Sensitivity: 0.1264957264957265, Specificity: 0.9666666666666667\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6277777777777778, F1 Score: 0.24806201550387597, Sensitivity: 0.19753086419753085, Specificity: 1.0\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 837ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 800ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7277777777777779, F1 Score: 0.560344827586207, Sensitivity: 0.5110161443494777, Specificity: 0.9052287581699346\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8277777777777778, F1 Score: 0.808473053436277, Sensitivity: 0.7823361823361824, Specificity: 0.8657159833630422\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 786ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.8555555555555555, F1 Score: 0.8230000366893616, Sensitivity: 0.7573599240265908, Specificity: 0.9372549019607842\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 974ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 937ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.0, Sensitivity: 0.0, Specificity: 1.0                    \n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.2222222222222222, Sensitivity: 0.3333333333333333, Specificity: 0.6666666666666666\n",
      "100%|| 20/20 [1:04:18<00:00, 192.94s/trial, best loss: -0.8627869361465531]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "00050f20-5d0c-47e3-9c0e-398cf4344ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'ae_activity_reg': 0.0006429546477326348, 'ae_batch_size': 58.0, 'ae_dropout_rate': 0.2925406250019609, 'ae_learning_rate': 0.0009621957746082583, 'autoencoder_units': 410.0, 'encoding_dim': 65.0, 'lstm_batch_size': 52.0, 'lstm_dropout_rate': 0.35677318375859857, 'lstm_learning_rate': 0.001083250751743305, 'lstm_units': 435.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bf7585a7-664f-4c45-98f7-f0ef6036df44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6fd60fc5-8dea-4c19-9e2f-5462abe7d27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5ff81520-924e-415c-bc34-8cf86f78f933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2fd46bdc-0410-434e-ac1a-0538d42f2bce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 1.7122 - val_loss: 1.3640\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3553 - val_loss: 1.2697\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2469 - val_loss: 1.2470\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2463 - val_loss: 1.2378\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2438 - val_loss: 1.2297\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2304 - val_loss: 1.2206\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2084 - val_loss: 1.2093\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2270 - val_loss: 1.1907\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2162 - val_loss: 1.1540\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1671 - val_loss: 1.0954\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1152 - val_loss: 1.0355\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1125 - val_loss: 1.0008\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0892 - val_loss: 0.9859\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1069 - val_loss: 0.9781\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0804 - val_loss: 0.9720\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0881 - val_loss: 0.9639\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1226 - val_loss: 0.9558\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0562 - val_loss: 0.9496\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0385 - val_loss: 0.9465\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0371 - val_loss: 0.9453\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0280 - val_loss: 0.9444\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9951 - val_loss: 0.9422\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0107 - val_loss: 0.9405\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0260 - val_loss: 0.9392\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0481 - val_loss: 0.9372\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0271 - val_loss: 0.9349\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0053 - val_loss: 0.9328\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0002 - val_loss: 0.9315\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0154 - val_loss: 0.9304\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0213 - val_loss: 0.9292\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0049 - val_loss: 0.9287\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0247 - val_loss: 0.9287\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0191 - val_loss: 0.9283\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0054 - val_loss: 0.9273\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0494 - val_loss: 0.9266\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0422 - val_loss: 0.9256\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0022 - val_loss: 0.9250\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0099 - val_loss: 0.9245\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0257 - val_loss: 0.9241\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0261 - val_loss: 0.9235\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0237 - val_loss: 0.9225\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9828 - val_loss: 0.9219\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0538 - val_loss: 0.9218\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9743 - val_loss: 0.9217\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0126 - val_loss: 0.9208\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0028 - val_loss: 0.9194\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9970 - val_loss: 0.9191\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9890 - val_loss: 0.9186\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9708 - val_loss: 0.9187\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9948 - val_loss: 0.9182\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.4481 - loss: 0.6881 - val_accuracy: 0.9333 - val_loss: 0.4463\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.7677 - loss: 1.0026 - val_accuracy: 0.7111 - val_loss: 0.4727\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.5739 - loss: 0.6070 - val_accuracy: 0.7111 - val_loss: 0.6794\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.7476 - loss: 0.6856 - val_accuracy: 0.3333 - val_loss: 0.6934\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.5439 - loss: 0.6877 - val_accuracy: 0.6444 - val_loss: 0.6878\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.7149 - loss: 0.6806 - val_accuracy: 0.9111 - val_loss: 0.6039\n"
     ]
    }
   ],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5aaa201f-6abe-4a71-849c-15dadbf828f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761ms/step\n",
      "Accuracy: 0.9111111111111111\n",
      "F1 Score: 0.8181818181818182\n",
      "Sensitivity: 0.6923076923076923\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa166e-e450-4869-bb89-bb5d6f6fb9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2afe6055-7f87-42f5-bbc8-22a612244e77",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9efea1b6-f8c7-49a4-8b04-0ea927af7286",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_19016\\1784159331.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv'  \n",
    "df = pd.read_csv(input_file_path, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb647c8f-87ae-4d0a-9103-d84bdc97aa13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df = df.iloc[:-1, :]\n",
    "case_control_info = df.iloc[-1, :]\n",
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values.astype(np.float32)\n",
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5bf830a-4b69-4955-bf87-3711f39a908b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amgm_values = calculate_amgm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880ffb32-2231-416c-a7bb-6f808e068dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 1000  # Number of features to select based on AMGM\n",
    "top_amgm_indices = np.argsort(amgm_values)[-num_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81312db1-0753-4b17-9fbf-1a8d1a66190c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top AMGM feature indices: [459916 340049 418589 273342 737619 530632 555527 109587 714143 460763]\n",
      "Top AMGM values: [1.009828  1.0098338 1.0098346 1.0098348 1.0098356 1.0098383 1.0098398\n",
      " 1.0098432 1.0098473 1.0098473]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top AMGM feature indices:\", top_amgm_indices[:10])  # Print the first 10 indices\n",
    "print(\"Top AMGM values:\", amgm_values[top_amgm_indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36252fb-dea3-4459-91f2-46afe3f3e9d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_indices = filter_redundant_features(X, top_amgm_indices, threshold=0.9)\n",
    "selected_indices = selected_indices[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17635f13-a67e-4924-8b0c-5fbd2ceb1581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X[selected_indices, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9ab984-af94-469c-8afe-90cbf67a335f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_selected = scaler.fit_transform(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35dcf65-fe0b-4910-b4e5-6fca01e78f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d682bcf5-1dd0-4737-be26-e707dd986aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "670464ee-e4af-47ee-a5d2-47ed55683883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ea6046e-c147-4fd6-9df3-b78560a03db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f0756eb-2e95-4e84-b96c-763fbea6200e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0171cf8-859b-44b3-bf45-03e67c5cbf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af9f6f8e-d4b6-4312-b031-e00e3c807b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c13bf86-0de9-44f8-b424-d53b71e1d8d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "100%|| 20/20 [08:29<00:00, 25.49s/trial, best loss: -0.9333333333333333]\n",
      "Best parameters:  {'ae_activity_reg': 3.3125569101435986e-07, 'ae_batch_size': 22.0, 'ae_dropout_rate': 0.1623512673341741, 'ae_learning_rate': 0.003834674127770905, 'autoencoder_units': 146.0, 'encoding_dim': 84.0, 'fnn_batch_size': 30.0, 'fnn_dropout_rate': 0.26515948628846636, 'fnn_learning_rate': 0.0005101527116195893, 'fnn_units': 419.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "801a72ee-a3c9-4fbf-a53f-1e33c4497c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "508f15d2-ada4-481b-877d-5dfb0ee63ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7df3d5e4-8c6d-4b8c-8b41-1a37f93ff96d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Final Model - Accuracy: 0.9277777777777778\n",
      "Final Model - F1 Score: 0.916048951048951\n",
      "Final Model - Sensitivity: 0.9000840336134454\n",
      "Final Model - Specificity: 0.9488351560719981\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc9d50-afa9-4ad0-9a65-52eae974662f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e828970-29b2-4402-bdec-5984ba3a89ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1385963-dc75-4b03-b555-870a15e06b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim // 2, input_shape=(input_dim,), activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 4, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer\n",
    "    model.add(Dense(input_dim // 2, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d9f9af1-1360-4646-bc2d-51a1b1848291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cyclical_learning_rate(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.006\n",
    "    step_size = 2000\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f71588d-077e-4812-a8dd-617295477318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file_path = 'C:/Research_Summer/FinalizedThyroidData.csv' #Change for different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d555b2-ab18-4283-9179-7f59c43bb23e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colte\\AppData\\Local\\Temp\\ipykernel_17932\\562430524.py:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file_path, header=0, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_file_path, header=0, index_col=0)\n",
    "features_df = df.iloc[:-1, :]  # SNP genotype data\n",
    "case_control_info = df.iloc[-1, :]  # Case/Control row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6914e9-d383-40cd-8a60-3ead3521e5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = features_df.apply(pd.to_numeric, errors='coerce').fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d9edbe-b7dc-4adf-94d7-1158bcc50727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ee4f4f-de8d-4a63-a284-16db2d75c79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38246726-46ee-4930-b048-a524d56b387e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1ff43f-113f-4d29-a7c9-b7fb63191890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae976b36-03b3-49da-8958-30ca542fc9d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - loss: 1.2502 - val_loss: 1.2402\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 1.2422 - val_loss: 1.2454\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 1.1462 - val_loss: 1.2418\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9945 - val_loss: 1.2343\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9888 - val_loss: 1.2253\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9859 - val_loss: 1.2174\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9830 - val_loss: 1.2110\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9795 - val_loss: 1.2052\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9759 - val_loss: 1.2000\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9730 - val_loss: 1.1960\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9701 - val_loss: 1.1931\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9675 - val_loss: 1.1907\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9652 - val_loss: 1.1889\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9631 - val_loss: 1.1876\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9612 - val_loss: 1.1871\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9595 - val_loss: 1.1871\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9580 - val_loss: 1.1876\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9567 - val_loss: 1.1883\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9555 - val_loss: 1.1893\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9544 - val_loss: 1.1904\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9535 - val_loss: 1.1918\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9526 - val_loss: 1.1933\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9518 - val_loss: 1.1948\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9512 - val_loss: 1.1964\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9505 - val_loss: 1.1980\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9500 - val_loss: 1.1995\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9495 - val_loss: 1.2011\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9490 - val_loss: 1.2026\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9487 - val_loss: 1.2041\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9483 - val_loss: 1.2056\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9479 - val_loss: 1.2070\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9477 - val_loss: 1.2083\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9474 - val_loss: 1.2096\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9471 - val_loss: 1.2108\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9469 - val_loss: 1.2119\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9467 - val_loss: 1.2130\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9465 - val_loss: 1.2140\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9464 - val_loss: 1.2150\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9462 - val_loss: 1.2159\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9460 - val_loss: 1.2168\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9459 - val_loss: 1.2176\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9458 - val_loss: 1.2183\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9457 - val_loss: 1.2190\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9456 - val_loss: 1.2197\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9454 - val_loss: 1.2203\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9454 - val_loss: 1.2209\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9453 - val_loss: 1.2215\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9452 - val_loss: 1.2220\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - loss: 0.9451 - val_loss: 1.2225\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 0.9450 - val_loss: 1.2230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2785db81e90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder, encoder = create_feature_autoencoder(input_dim, encoding_dim)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acaeb5d8-5916-444d-a713-18dd97876cba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 273ms/step\n",
      "Shape of encoded features: (225, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = encoder.predict(X_scaled)\n",
    "print(f\"Shape of encoded features: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536fb739-ebca-4d51-b38f-74ed077bd29f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after L1-based Feature Selection: (225, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.342e-02, tolerance: 5.504e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "target_features = 200  # Target number of features\n",
    "X_final, selected_indices_l1 = apply_l1_feature_selection(X_encoded, y, alpha=0.005, target_features=target_features)\n",
    "print(f\"Shape after L1-based Feature Selection: {X_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02002b4-6619-4681-8313-1068bd918bca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9025d0-d0cd-4060-8992-590af2ca422a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "be19d5e8-6f31-461c-849b-7bc482016756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fcee3611-2fa8-4b8d-a436-6e1ce24ea4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e2e69004-0b6e-48e7-87c6-3d0a7483e9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = create_deep_autoencoder(input_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2a932da1-14bc-4460-b2fa-5d32cdc7849e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " dense_1900 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> \n",
       "\n",
       " dropout_630 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1901 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> \n",
       "\n",
       " dropout_631 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1902 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> \n",
       "\n",
       " dense_1903 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> \n",
       "\n",
       " dense_1904 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_1900 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                           \u001b[38;5;34m20,100\u001b[0m \n",
       "\n",
       " dropout_630 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1901 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                             \u001b[38;5;34m5,050\u001b[0m \n",
       "\n",
       " dropout_631 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1902 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                            \u001b[38;5;34m5,100\u001b[0m \n",
       "\n",
       " dense_1903 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                           \u001b[38;5;34m20,200\u001b[0m \n",
       "\n",
       " dense_1904 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                \u001b[38;5;34m201\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,651</span> (197.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,651\u001b[0m (197.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6889555d-51ba-4935-a061-cf16db56bc0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.4865 - loss: 0.7893 - val_accuracy: 0.5652 - val_loss: 0.6867 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5190 - loss: 0.7347 - val_accuracy: 0.4783 - val_loss: 0.6860 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5110 - loss: 0.6980 - val_accuracy: 0.5652 - val_loss: 0.6506 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6219 - loss: 0.6627 - val_accuracy: 0.5652 - val_loss: 0.6395 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5927 - loss: 0.6808 - val_accuracy: 0.8261 - val_loss: 0.6327 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6527 - loss: 0.6332 - val_accuracy: 0.8261 - val_loss: 0.6208 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6910 - loss: 0.6033 - val_accuracy: 0.6087 - val_loss: 0.6040 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5920 - loss: 0.6547 - val_accuracy: 0.6957 - val_loss: 0.5885 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6548 - loss: 0.6260 - val_accuracy: 0.7391 - val_loss: 0.5667 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6659 - loss: 0.5884 - val_accuracy: 0.7391 - val_loss: 0.5492 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7081 - loss: 0.5155 - val_accuracy: 0.7826 - val_loss: 0.5299 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7157 - loss: 0.5390 - val_accuracy: 0.8261 - val_loss: 0.4964 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: 0.6126 - val_accuracy: 0.8261 - val_loss: 0.4960 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7109 - loss: 0.6045 - val_accuracy: 0.7826 - val_loss: 0.4817 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7501 - loss: 0.4748 - val_accuracy: 0.7826 - val_loss: 0.4634 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7384 - loss: 0.5228 - val_accuracy: 0.7826 - val_loss: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7460 - loss: 0.5172 - val_accuracy: 0.7826 - val_loss: 0.4124 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.4136 - val_accuracy: 0.8261 - val_loss: 0.3841 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7395 - loss: 0.4784 - val_accuracy: 0.8261 - val_loss: 0.3731 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7880 - loss: 0.4375 - val_accuracy: 0.8696 - val_loss: 0.3507 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8510 - loss: 0.3858 - val_accuracy: 0.8696 - val_loss: 0.3487 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8248 - loss: 0.4460 - val_accuracy: 0.9130 - val_loss: 0.3541 - learning_rate: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7715 - loss: 0.4219 - val_accuracy: 0.9130 - val_loss: 0.3497 - learning_rate: 0.0011\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8543 - loss: 0.2947 - val_accuracy: 0.7826 - val_loss: 0.3491 - learning_rate: 0.0011\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8848 - loss: 0.2724 - val_accuracy: 0.7826 - val_loss: 0.3628 - learning_rate: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8569 - loss: 0.3758 - val_accuracy: 0.8261 - val_loss: 0.2925 - learning_rate: 0.0011\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8282 - loss: 0.3174 - val_accuracy: 0.8696 - val_loss: 0.3060 - learning_rate: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8623 - loss: 0.3671 - val_accuracy: 0.8261 - val_loss: 0.2968 - learning_rate: 0.0011\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8790 - loss: 0.3040 - val_accuracy: 0.8696 - val_loss: 0.2865 - learning_rate: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8518 - loss: 0.3022 - val_accuracy: 0.9130 - val_loss: 0.2862 - learning_rate: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9337 - loss: 0.1840 - val_accuracy: 0.9130 - val_loss: 0.2830 - learning_rate: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9187 - loss: 0.2275 - val_accuracy: 0.8696 - val_loss: 0.2825 - learning_rate: 0.0011\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9073 - loss: 0.2693 - val_accuracy: 0.8696 - val_loss: 0.2975 - learning_rate: 0.0011\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8777 - loss: 0.2478 - val_accuracy: 0.9130 - val_loss: 0.2899 - learning_rate: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9057 - loss: 0.2332 - val_accuracy: 0.9130 - val_loss: 0.2389 - learning_rate: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9331 - loss: 0.1807 - val_accuracy: 0.9130 - val_loss: 0.2329 - learning_rate: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8832 - loss: 0.2510 - val_accuracy: 0.8696 - val_loss: 0.2705 - learning_rate: 0.0011\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.2558 - val_accuracy: 0.8696 - val_loss: 0.2775 - learning_rate: 0.0011\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2362 - val_accuracy: 0.9130 - val_loss: 0.2059 - learning_rate: 0.0011\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8814 - loss: 0.2729 - val_accuracy: 0.9130 - val_loss: 0.1885 - learning_rate: 0.0011\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9195 - loss: 0.1665 - val_accuracy: 0.8696 - val_loss: 0.2232 - learning_rate: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8737 - loss: 0.2996 - val_accuracy: 0.8696 - val_loss: 0.2555 - learning_rate: 0.0011\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9107 - loss: 0.1865 - val_accuracy: 0.8261 - val_loss: 0.2636 - learning_rate: 0.0011\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1434 - val_accuracy: 0.8261 - val_loss: 0.2347 - learning_rate: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8890 - loss: 0.2981 - val_accuracy: 0.8261 - val_loss: 0.2370 - learning_rate: 0.0011\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.1629 - val_accuracy: 0.8261 - val_loss: 0.2335 - learning_rate: 0.0011\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9389 - loss: 0.1567 - val_accuracy: 0.8261 - val_loss: 0.2895 - learning_rate: 0.0011\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.2441 - val_accuracy: 0.8261 - val_loss: 0.2845 - learning_rate: 0.0011\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9087 - loss: 0.1792 - val_accuracy: 0.8261 - val_loss: 0.2996 - learning_rate: 0.0011\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9130 - loss: 0.2048 - val_accuracy: 0.8261 - val_loss: 0.3155 - learning_rate: 0.0011\n"
     ]
    }
   ],
   "source": [
    "clr = LearningRateScheduler(cyclical_learning_rate)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "616cdefc-e6c1-45e5-b8ef-fa524842597e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "66c6f12b-8c1f-4853-81d2-0319cc6734f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Control', 'Case'], yticklabels=['Control', 'Case'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ddce48e6-7500-473b-8546-166e02a7bbac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.8888888888888888\n",
      "Specificity: 0.9375\n",
      "Sensitivity: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49065334-c1a1-483f-a6a9-b9b64eba5be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ace289-cdd4-4d0a-b9ba-c3bea615c635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e69cb81-54a2-4b33-b73a-39c8a34c6b61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Deep Autoencoder with Optimized Hyperparameters (Bayesian Optimization) - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10cf7955-1b2a-40a5-903c-04ca6f5a0f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, neurons1=64, neurons2=32, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(neurons1, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons1, activation='linear'))\n",
    "    model.add(Dense(input_dim, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Final classification layer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0b5b5f2-9724-43b0-a3b4-532bf7c3df5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "113083f7-9d56-4fdc-bd6b-c7ba9d22bb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'neurons1': scope.int(hp.quniform('neurons1', 32, 256, 32)),\n",
    "    'neurons2': scope.int(hp.quniform('neurons2', 16, 128, 16)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.7),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 200, 50)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5457fa22-a01e-4499-a67b-94bf199d138c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model = KerasClassifier(\n",
    "        model=create_deep_autoencoder,\n",
    "        input_dim=X_final.shape[1],\n",
    "        neurons1=params['neurons1'],\n",
    "        neurons2=params['neurons2'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y_pred = cross_val_predict(model, X_final, y, cv=kfold, method='predict')\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}, F1 Score: {f1}, Sensitivity: {sensitivity}, Specificity: {specificity}\")\n",
    "\n",
    "    # Return the negative F1 score as Hyperopt minimizes the objective function\n",
    "    return {'loss': -f1, 'status': STATUS_OK, 'accuracy': accuracy, 'f1': f1, 'sensitivity': sensitivity, 'specificity': specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0fa158e2-4915-45ef-8c98-b7202cea6f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9377777777777778, F1 Score: 0.9292929292929293, Sensitivity: 0.9583333333333334, Specificity: 0.9224806201550387\n",
      "Accuracy: 0.7644444444444445, F1 Score: 0.6293706293706294, Sensitivity: 0.46875, Specificity: 0.9844961240310077      \n",
      "Accuracy: 0.7288888888888889, F1 Score: 0.5343511450381679, Sensitivity: 0.3645833333333333, Specificity: 1.0          \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.64, F1 Score: 0.2702702702702703, Sensitivity: 0.15625, Specificity: 1.0                                   \n",
      "Accuracy: 0.9155555555555556, F1 Score: 0.8961748633879781, Sensitivity: 0.8541666666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9278350515463918, Sensitivity: 0.9375, Specificity: 0.937984496124031        \n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.93, Sensitivity: 0.96875, Specificity: 0.9147286821705426                    \n",
      "Accuracy: 0.9333333333333333, F1 Score: 0.9230769230769231, Sensitivity: 0.9375, Specificity: 0.9302325581395349       \n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9484536082474226, Sensitivity: 0.9583333333333334, Specificity: 0.9534883720930233\n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.8311111111111111, F1 Score: 0.7682926829268293, Sensitivity: 0.65625, Specificity: 0.9612403100775194      \n",
      "Accuracy: 0.9466666666666667, F1 Score: 0.9381443298969072, Sensitivity: 0.9479166666666666, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.9422222222222222, F1 Score: 0.9346733668341709, Sensitivity: 0.96875, Specificity: 0.9224806201550387      \n",
      "Accuracy: 0.9288888888888889, F1 Score: 0.9191919191919192, Sensitivity: 0.9479166666666666, Specificity: 0.9147286821705426\n",
      "Accuracy: 0.9555555555555556, F1 Score: 0.9479166666666666, Sensitivity: 0.9479166666666666, Specificity: 0.9612403100775194\n",
      "Accuracy: 0.9511111111111111, F1 Score: 0.9430051813471503, Sensitivity: 0.9479166666666666, Specificity: 0.9534883720930233\n",
      "Accuracy: 0.76, F1 Score: 0.6086956521739131, Sensitivity: 0.4375, Specificity: 1.0                                    \n",
      "Accuracy: 0.9377777777777778, F1 Score: 0.9270833333333334, Sensitivity: 0.9270833333333334, Specificity: 0.9457364341085271\n",
      "Accuracy: 0.8711111111111111, F1 Score: 0.8342857142857143, Sensitivity: 0.7604166666666666, Specificity: 0.9534883720930233\n",
      "100%|| 20/20 [07:14<00:00, 21.71s/trial, best loss: -0.9484536082474226]\n",
      "Best parameters found:  {'batch_size': 48.0, 'dropout_rate': 0.6551201949996381, 'epochs': 200.0, 'learning_rate': 0.000753710320272019, 'neurons1': 128.0, 'neurons2': 80.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of evaluations to perform\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7f4b8ab3-d282-4bc8-b25f-87de31955fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9555555555555556\n",
      "Best F1 Score: 0.9484536082474226\n",
      "Best Specificity: 0.9534883720930233\n",
      "Best Sensitivity: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "best_trial = min(trials.results, key=lambda x: x['loss'])\n",
    "print(f\"Best Accuracy: {best_trial['accuracy']}\")\n",
    "print(f\"Best F1 Score: {-best_trial['loss']}\")\n",
    "print(f\"Best Specificity: {best_trial['specificity']}\")\n",
    "print(f\"Best Sensitivity: {best_trial['sensitivity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0faaa6de-7f36-4dfd-aa43-b93248293a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_101\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_101\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
       "\n",
       " dense_2405 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> \n",
       "\n",
       " dropout_832 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_2406 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">10,320</span> \n",
       "\n",
       " dropout_833 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_2407 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> \n",
       "\n",
       " dense_2408 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> \n",
       "\n",
       " dense_2409 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " dense_2405 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m12,928\u001b[0m \n",
       "\n",
       " dropout_832 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_2406 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                            \u001b[38;5;34m10,320\u001b[0m \n",
       "\n",
       " dropout_833 (\u001b[38;5;33mDropout\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_2407 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m10,368\u001b[0m \n",
       "\n",
       " dense_2408 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                           \u001b[38;5;34m12,900\u001b[0m \n",
       "\n",
       " dense_2409 (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                \u001b[38;5;34m101\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,617</span> (182.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,617\u001b[0m (182.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,617</span> (182.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,617\u001b[0m (182.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = {\n",
    "    'neurons1': int(best['neurons1']),\n",
    "    'neurons2': int(best['neurons2']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size'])\n",
    "}\n",
    "\n",
    "best_model = create_deep_autoencoder(\n",
    "    input_dim=X_selected.shape[1],\n",
    "    neurons1=best_params['neurons1'],\n",
    "    neurons2=best_params['neurons2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f7f13d80-c012-4e92-8b55-5de6f03c0928",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "Neurons in first layer: 128\n",
      "Neurons in second layer: 80\n",
      "Dropout rate: 0.6551201949996381\n",
      "Learning rate: 0.000753710320272019\n",
      "Number of epochs: 200\n",
      "Batch size: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Neurons in first layer: {int(best['neurons1'])}\")\n",
    "print(f\"Neurons in second layer: {int(best['neurons2'])}\")\n",
    "print(f\"Dropout rate: {best['dropout_rate']}\")\n",
    "print(f\"Learning rate: {best['learning_rate']}\")\n",
    "print(f\"Number of epochs: {int(best['epochs'])}\")\n",
    "print(f\"Batch size: {int(best['batch_size'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1483e6-a1cf-46c7-a7df-83e5e3d20564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca3593d3-f4df-4916-a174-8007c4b974c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bidirectional LSTM with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66f27a9c-c508-44fc-b0ac-35dcb98c12c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, units=64, bidirectional=False, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if bidirectional:\n",
    "        model.add(Bidirectional(LSTM(units, return_sequences=False)))\n",
    "    else:\n",
    "        model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31d02994-a311-42c1-830b-67626090473f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f162902a-206e-4cd2-9ef5-a94e71f88735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 16, 64, 16)),  # Reduced range for faster evaluation\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),  # Reduced range\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),  # Adjusted range\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),  # Reduced number of epochs\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),  # Reduced range\n",
    "    'bidirectional': hp.choice('bidirectional', [True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3af4fd8-c99e-4ca2-9834-2f51ca22b95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)  \n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = KerasClassifier(\n",
    "            model=create_rnn_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            bidirectional=params['bidirectional'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)  # True Positive Rate / Recall\n",
    "        specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2f3a533-5d6b-4a2d-95c6-533cc42f83a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.7722222222222221, F1 Score: 0.7155597186909913, Sensitivity: 0.7125350140056023, Specificity: 0.8691514396456257\n",
      "Iteration Results - Accuracy: 0.7277777777777777, F1 Score: 0.6933686417301114, Sensitivity: 0.7723214285714285, Specificity: 0.7559869878183831\n",
      "Iteration Results - Accuracy: 0.7611111111111111, F1 Score: 0.7203065134099617, Sensitivity: 0.7661064425770308, Specificity: 0.7974114064230343\n",
      "Iteration Results - Accuracy: 0.5833333333333334, F1 Score: 0.6000369198312236, Sensitivity: 0.8125, Specificity: 0.4802394795127353\n",
      "Iteration Results - Accuracy: 0.7833333333333333, F1 Score: 0.7261751608114794, Sensitivity: 0.7214635854341737, Specificity: 0.8795681063122923\n",
      "Iteration Results - Accuracy: 0.6277777777777778, F1 Score: 0.5513833992094862, Sensitivity: 0.5857843137254902, Specificity: 0.7324197120708749\n",
      "Iteration Results - Accuracy: 0.5666666666666668, F1 Score: 0.3232122117139539, Sensitivity: 0.36204481792717086, Specificity: 0.811046511627907\n",
      "Iteration Results - Accuracy: 0.7722222222222221, F1 Score: 0.7370978032996082, Sensitivity: 0.7837009803921569, Specificity: 0.7902823920265781\n",
      "Iteration Results - Accuracy: 0.611111111111111, F1 Score: 0.5500178253119429, Sensitivity: 0.603641456582633, Specificity: 0.6652131782945737\n",
      "Iteration Results - Accuracy: 0.7444444444444445, F1 Score: 0.69223181786505, Sensitivity: 0.7063200280112044, Specificity: 0.8167566445182725\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.636231884057971, Sensitivity: 0.6554621848739496, Specificity: 0.7840185492801771\n",
      "Iteration Results - Accuracy: 0.6388888888888888, F1 Score: 0.5649204596573018, Sensitivity: 0.601890756302521, Specificity: 0.7151854928017718\n",
      "Iteration Results - Accuracy: 0.5499999999999999, F1 Score: 0.4311373873873874, Sensitivity: 0.5431547619047619, Specificity: 0.6707156699889257\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.5322909950569525, Sensitivity: 0.5753676470588235, Specificity: 0.7115863787375415\n",
      "Iteration Results - Accuracy: 0.7555555555555555, F1 Score: 0.7268637023354004, Sensitivity: 0.7916666666666666, Specificity: 0.7940545404208196\n",
      "Iteration Results - Accuracy: 0.6888888888888888, F1 Score: 0.6476157804459691, Sensitivity: 0.6882002801120448, Specificity: 0.7386835548172757\n",
      "Iteration Results - Accuracy: 0.6888888888888888, F1 Score: 0.6658960347484938, Sensitivity: 0.759891456582633, Specificity: 0.6693660022148394\n",
      "Iteration Results - Accuracy: 0.7388888888888889, F1 Score: 0.6788682986349425, Sensitivity: 0.6911764705882352, Specificity: 0.8045404208194906\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6247349673927979, Sensitivity: 0.71875, Specificity: 0.7043881506090809\n",
      "Iteration Results - Accuracy: 0.6, F1 Score: 0.6315520713463751, Sensitivity: 0.8541666666666666, Specificity: 0.46833471760797335\n",
      "100%|| 20/20 [2:40:18<00:00, 480.94s/trial, best loss: -0.7370978032996082]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1db91348-2f31-4796-a7f9-7f72cb48e832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'units': 32, 'dropout_rate': 0.13141058659328136, 'learning_rate': 0.0012914716978016608, 'epochs': 40, 'batch_size': 48, 'bidirectional': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'units': int(best['units']),\n",
    "    'dropout_rate': best['dropout_rate'],\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'epochs': int(best['epochs']),\n",
    "    'batch_size': int(best['batch_size']),\n",
    "    'bidirectional': best['bidirectional']\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Build and summarize the best model\n",
    "best_model = create_rnn_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    bidirectional=best_params['bidirectional'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5233d4b6-a4dc-4125-b16e-ae94cfc12017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7555555555555555\n",
      "F1 Score: 0.7441860465116279\n",
      "Sensitivity: 0.8421052631578947\n",
      "Specificity: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81e117-b43c-4bbc-97da-ce7afd3fc01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ec390a-e157-47cb-ae7d-232329a57d16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GRU with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b113768b-b538-4b74-9d31-8943a7446e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a472e1e3-2a02-4812-9117-58d5e0c9e4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(GRU(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fdee8be-824b-410c-9813-0b220acaf92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c94bcc6-ecd4-4420-ade5-806556c96bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units': scope.int(hp.quniform('units', 64, 128, 64)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 30, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4486c88f-4129-47bd-9cd1-1bc6c1f91c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            model=create_gru_model,\n",
    "            input_shape=(X_final.shape[1], 1),\n",
    "            units=params['units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        \n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "    \n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "    \n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70af85d1-e501-492b-a020-94d598ada449",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6539624183006536, Sensitivity: 0.7574548907882241, Specificity: 0.5292929292929293\n",
      "Iteration Results - Accuracy: 0.6000000000000001, F1 Score: 0.6280188114659466, Sensitivity: 0.7535612535612536, Specificity: 0.4666666666666666\n",
      "Iteration Results - Accuracy: 0.5944444444444444, F1 Score: 0.6061506776877904, Sensitivity: 0.687369420702754, Specificity: 0.5202020202020202\n",
      "Iteration Results - Accuracy: 0.6, F1 Score: 0.6220538720538721, Sensitivity: 0.7301044634377968, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6537308482273846, Sensitivity: 0.7034188034188035, Specificity: 0.6191919191919192\n",
      "Iteration Results - Accuracy: 0.6055555555555556, F1 Score: 0.625510058673011, Sensitivity: 0.7407407407407408, Specificity: 0.4875816993464052\n",
      "Iteration Results - Accuracy: 0.5666666666666668, F1 Score: 0.5544767443732751, Sensitivity: 0.5978157644824311, Specificity: 0.5380867498514558\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.6282689912826899, Sensitivity: 0.6980056980056979, Specificity: 0.565359477124183\n",
      "Iteration Results - Accuracy: 0.6166666666666667, F1 Score: 0.6266655370103645, Sensitivity: 0.7074074074074074, Specificity: 0.5441473559120619\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6460707502374169, Sensitivity: 0.7716049382716049, Specificity: 0.5014260249554368\n",
      "Iteration Results - Accuracy: 0.65, F1 Score: 0.6512495555973817, Sensitivity: 0.7444444444444445, Specificity: 0.569399881164587\n",
      "Iteration Results - Accuracy: 0.6611111111111111, F1 Score: 0.6387453550195711, Sensitivity: 0.6461538461538461, Specificity: 0.6747474747474748\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.5921589919350277, Sensitivity: 0.6207027540360873, Specificity: 0.6370766488413547\n",
      "Iteration Results - Accuracy: 0.6833333333333332, F1 Score: 0.6981993514251578, Sensitivity: 0.7946818613485281, Specificity: 0.5909090909090908\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.6339541280993272, Sensitivity: 0.7065527065527065, Specificity: 0.5865715983363042\n",
      "Iteration Results - Accuracy: 0.6444444444444444, F1 Score: 0.6894660894660894, Sensitivity: 0.8548907882241217, Specificity: 0.4671420083184789\n",
      "Iteration Results - Accuracy: 0.6277777777777779, F1 Score: 0.6491240026734867, Sensitivity: 0.7757834757834757, Specificity: 0.49393939393939396\n",
      "Iteration Results - Accuracy: 0.6111111111111112, F1 Score: 0.6408712038849025, Sensitivity: 0.7586894586894587, Specificity: 0.4888888888888889\n",
      "Iteration Results - Accuracy: 0.688888888888889, F1 Score: 0.6907272890323738, Sensitivity: 0.7549857549857549, Specificity: 0.6333333333333333\n",
      "Iteration Results - Accuracy: 0.6499999999999999, F1 Score: 0.6458143132481232, Sensitivity: 0.7000949667616334, Specificity: 0.6101010101010101\n",
      "100%|| 20/20 [2:21:14<00:00, 423.72s/trial, best loss: -0.6981993514251578]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca186178-efce-43cf-bf95-4c4cc94231a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 64, 'dropout_rate': 0.3224123746707528, 'epochs': 30, 'learning_rate': 0.0001354902537099134, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)  \n",
    "print(\"Best Parameters:\", best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7eaa69c3-85b6-42b7-8735-7e6119b9d8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_gru_model(\n",
    "    input_shape=(X_final.shape[1], 1),\n",
    "    units=best_params['units'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d3220f8-65b5-44b8-b436-27f819d4dc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2abd3874-ddc3-4a91-b641-8ad395310c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28d61975990>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6b7c669-c3ac-4c65-be74-748e27743f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.7555555555555555\n",
      "F1 Score: 0.6666666666666666\n",
      "Sensitivity: 0.5789473684210527\n",
      "Specificity: 0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870a966-0d37-48e8-8043-0f9c0e769f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63a9bfb5-c5d3-4740-9b50-ee770d46cf92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CNN with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dbc0a73-cb29-4ac1-9b68-748c666fb0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape(X_final.shape[0], X_final.shape[1], 1)  # Add a channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "110f7a16-e8a8-45eb-9910-086b1b248966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15c09a9a-12b9-4d40-8b98-cfbb20601b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, filters=64, kernel_size=3, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv1D(filters=filters * 2, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b07fd2cc-1c01-40d1-b0d1-9250563f381e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 2, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 30, 50, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9dfb7ee-2199-45e3-b548-79174b1c8953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create a K-Fold cross-validator\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Placeholder for cross-validation results\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        # Create the model with given hyperparameters\n",
    "        model = create_cnn_model(\n",
    "            input_shape=(X_selected.shape[1], 1),\n",
    "            filters=params['filters'],\n",
    "            kernel_size=params['kernel_size'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], verbose=0, callbacks=[early_stopping])\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Convert predictions to binary using a threshold of 0.5\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics for this fold\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Append metrics\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0641d319-fadc-46e2-94df-d178df9f187d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7611111111111111, F1 Score: 0.7545292405895053, Sensitivity: 0.7894586894586895, Specificity: 0.7449197860962568\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.7622494289160956, Sensitivity: 0.9382716049382717, Specificity: 0.5338086749851456\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7999999999999999, F1 Score: 0.8061778891967571, Sensitivity: 0.8982905982905983, Specificity: 0.730718954248366\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6333333333333333, F1 Score: 0.3605769230769231, Sensitivity: 0.3950617283950617, Specificity: 0.7999999999999999\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.5777777777777778, F1 Score: 0.4608096468561585, Sensitivity: 0.5925925925925926, Specificity: 0.6060606060606061\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222223, F1 Score: 0.5678893178893178, Sensitivity: 0.6405508072174738, Specificity: 0.7758169934640522\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.7294549343864413, Sensitivity: 0.9765432098765432, Specificity: 0.4045157456922162\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7666666666666666, F1 Score: 0.7815146094215862, Sensitivity: 0.8623931623931624, Specificity: 0.6797979797979797\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.7183908045977011, Sensitivity: 0.8114909781576448, Specificity: 0.6101604278074867\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.7666555666555667, Sensitivity: 0.9876543209876543, Specificity: 0.49221628045157456\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6944444444444445, F1 Score: 0.7507043088752523, Sensitivity: 1.0, Specificity: 0.43351158645276294\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7722222222222221, F1 Score: 0.8038437597261127, Sensitivity: 0.9748338081671415, Specificity: 0.6092691622103387\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7222222222222222, F1 Score: 0.7728937728937728, Sensitivity: 0.9743589743589745, Specificity: 0.4987522281639929\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6222222222222222, F1 Score: 0.48883374689826303, Sensitivity: 0.6410256410256411, Specificity: 0.6399286987522281\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6055555555555556, F1 Score: 0.7055868916334033, Sensitivity: 1.0, Specificity: 0.2787878787878788\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.764005632426685, Sensitivity: 0.9888888888888889, Specificity: 0.4843137254901961\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6666666666666666, F1 Score: 0.7267628205128206, Sensitivity: 0.9615384615384616, Specificity: 0.41051693404634576\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6722222222222222, F1 Score: 0.737743006164059, Sensitivity: 1.0, Specificity: 0.3954248366013072\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.6944444444444445, F1 Score: 0.7514023928556388, Sensitivity: 0.9888888888888889, Specificity: 0.45068330362448\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\n",
      "Iteration Results - Accuracy: 0.7000000000000001, F1 Score: 0.7134081196581196, Sensitivity: 0.8316239316239317, Specificity: 0.6079025549613785\n",
      "100%|| 20/20 [03:30<00:00, 10.54s/trial, best loss: -0.8061778891967571]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Number of trials, adjust based on your needs\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ad196a8-8b50-4a16-91a8-882e330b7f04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 64, 'dropout_rate': 0.3752746992054573, 'epochs': 40, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0025512099307836845}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6654ee35-2cd3-48d9-bdd0-cee866defeb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = create_cnn_model(\n",
    "    input_shape=(X_selected.shape[1], 1),\n",
    "    filters=best_params['filters'],\n",
    "    kernel_size=best_params['kernel_size'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d4bc908e-7e39-43cf-90ed-a63e0d875974",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28d6fa94d10>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_val, y_train_val, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d103c33-8c16-4bdc-a586-fa7757d38cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_pred_binary = (y_test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6da0946c-ff40-4c99-b138-e61b4b13d71a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.8222222222222222\n",
      "F1 Score: 0.7647058823529411\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.75\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred_binary)\n",
    "test_f1 = f1_score(y_test, y_test_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_binary).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d93d60-3b31-4e99-8a0c-2d27505c4fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9f5ae9d-2d31-4dab-88ab-70be8dbde197",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ResNet - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "899f26b6-2305-4e7c-8126-a99a959fe56a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8435ed57-ae0d-4bbe-9172-b438dc9ef527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3b6ddf0-d9c3-41d4-9f9f-db446845082c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=stride)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', strides=1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv1D(filters, kernel_size, padding='same', strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "        \n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2baa34aa-d2fc-4030-8c6c-e1805818fb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, filters=64, num_blocks=6, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, padding='same', strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    for _ in range(num_blocks):\n",
    "        x = residual_block(x, filters, kernel_size=kernel_size)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbac432b-840f-4f53-9d8d-62412a5c82d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'filters': scope.int(hp.quniform('filters', 32, 128, 32)),\n",
    "    'num_blocks': scope.int(hp.quniform('num_blocks', 4, 10, 2)),\n",
    "    'kernel_size': scope.int(hp.quniform('kernel_size', 3, 5, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-2)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 64, 16)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 20, 50, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f89848f-6e4f-4695-93d1-fbbab09f8dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(f\"Trying params: {params}\")\n",
    "    filters = params['filters']\n",
    "    num_blocks = params['num_blocks']\n",
    "    kernel_size = params['kernel_size']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    # Create the ResNet model\n",
    "    model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                filters=filters,\n",
    "                                num_blocks=num_blocks,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dropout_rate=dropout_rate,\n",
    "                                learning_rate=learning_rate)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Filters: {filters}, Blocks: {num_blocks}, Kernel Size: {kernel_size}, Dropout: {dropout_rate}, LR: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73f49a82-f2ca-4aae-a563-bccde4cd8ac8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.4387996642991684, 'epochs': 20, 'filters': 128, 'kernel_size': 3, 'learning_rate': 0.0006375038015807285, 'num_blocks': 4}\n",
      "Iteration - Loss: 12.32732105255127, Filters: 128, Blocks: 4, Kernel Size: 3, Dropout: 0.4387996642991684, LR: 0.0006375038015807285, Batch Size: 64, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.2971975569764382, 'epochs': 50, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.009248241736063393, 'num_blocks': 8}\n",
      "Iteration - Loss: 45.96067428588867, Filters: 32, Blocks: 8, Kernel Size: 4, Dropout: 0.2971975569764382, LR: 0.009248241736063393, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.26820920159400913, 'epochs': 30, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.0009345905647160417, 'num_blocks': 8}\n",
      "Iteration - Loss: 10.972443580627441, Filters: 32, Blocks: 8, Kernel Size: 4, Dropout: 0.26820920159400913, LR: 0.0009345905647160417, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.4721250599575162, 'epochs': 20, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.004899610014201033, 'num_blocks': 6}\n",
      "Iteration - Loss: 1592.8236083984375, Filters: 96, Blocks: 6, Kernel Size: 5, Dropout: 0.4721250599575162, LR: 0.004899610014201033, Batch Size: 48, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.30538010777298846, 'epochs': 30, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.007396668209583953, 'num_blocks': 6}\n",
      "Iteration - Loss: 2080.73779296875, Filters: 96, Blocks: 6, Kernel Size: 3, Dropout: 0.30538010777298846, LR: 0.007396668209583953, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3770734577540463, 'epochs': 30, 'filters': 128, 'kernel_size': 4, 'learning_rate': 0.0005696161837089599, 'num_blocks': 6}\n",
      "Iteration - Loss: 15.110872268676758, Filters: 128, Blocks: 6, Kernel Size: 4, Dropout: 0.3770734577540463, LR: 0.0005696161837089599, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.3604904280351954, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.0011830244455375556, 'num_blocks': 4}\n",
      "Iteration - Loss: 16.273723602294922, Filters: 64, Blocks: 4, Kernel Size: 4, Dropout: 0.3604904280351954, LR: 0.0011830244455375556, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.29176504490788097, 'epochs': 40, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.00039353789867171995, 'num_blocks': 8}\n",
      "Iteration - Loss: 8.235269546508789, Filters: 64, Blocks: 8, Kernel Size: 4, Dropout: 0.29176504490788097, LR: 0.00039353789867171995, Batch Size: 64, Epochs: 40\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.315211071000154, 'epochs': 30, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.005269213393304437, 'num_blocks': 8}\n",
      "Iteration - Loss: 19183.466796875, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.315211071000154, LR: 0.005269213393304437, Batch Size: 48, Epochs: 30\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.34121142510787644, 'epochs': 50, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.004936565817097217, 'num_blocks': 8}\n",
      "Iteration - Loss: 89.52030181884766, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.34121142510787644, LR: 0.004936565817097217, Batch Size: 64, Epochs: 50\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.26915145817376457, 'epochs': 20, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.001954153335998307, 'num_blocks': 4}\n",
      "Iteration - Loss: 27.358186721801758, Filters: 96, Blocks: 4, Kernel Size: 5, Dropout: 0.26915145817376457, LR: 0.001954153335998307, Batch Size: 32, Epochs: 20\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.48873733437511074, 'epochs': 40, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.0026751793719144304, 'num_blocks': 6}\n",
      "Iteration - Loss: 563.2926635742188, Filters: 96, Blocks: 6, Kernel Size: 5, Dropout: 0.48873733437511074, LR: 0.0026751793719144304, Batch Size: 32, Epochs: 40\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3444678739513979, 'epochs': 30, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00024905823624566835, 'num_blocks': 6}\n",
      "Iteration - Loss: 1.136749029159546, Filters: 64, Blocks: 6, Kernel Size: 5, Dropout: 0.3444678739513979, LR: 0.00024905823624566835, Batch Size: 16, Epochs: 30\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.3383682029926538, 'epochs': 40, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.0003490765600674144, 'num_blocks': 8}\n",
      "Iteration - Loss: 5.34743070602417, Filters: 64, Blocks: 8, Kernel Size: 5, Dropout: 0.3383682029926538, LR: 0.0003490765600674144, Batch Size: 16, Epochs: 40\n",
      "Trying params: {'batch_size': 64, 'dropout_rate': 0.4259059028441898, 'epochs': 50, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0001652924602912878, 'num_blocks': 6}\n",
      "Iteration - Loss: 2.900691032409668, Filters: 96, Blocks: 6, Kernel Size: 3, Dropout: 0.4259059028441898, LR: 0.0001652924602912878, Batch Size: 64, Epochs: 50\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.272978204279806, 'epochs': 20, 'filters': 96, 'kernel_size': 4, 'learning_rate': 0.0012207389379790272, 'num_blocks': 8}\n",
      "Iteration - Loss: 128.60421752929688, Filters: 96, Blocks: 8, Kernel Size: 4, Dropout: 0.272978204279806, LR: 0.0012207389379790272, Batch Size: 16, Epochs: 20\n",
      "Trying params: {'batch_size': 16, 'dropout_rate': 0.48922925307002574, 'epochs': 50, 'filters': 64, 'kernel_size': 4, 'learning_rate': 0.006908355054524663, 'num_blocks': 8}\n",
      "Iteration - Loss: 32.23158264160156, Filters: 64, Blocks: 8, Kernel Size: 4, Dropout: 0.48922925307002574, LR: 0.006908355054524663, Batch Size: 16, Epochs: 50\n",
      "Trying params: {'batch_size': 48, 'dropout_rate': 0.29095132705442894, 'epochs': 40, 'filters': 32, 'kernel_size': 4, 'learning_rate': 0.002132890345509543, 'num_blocks': 8}\n",
      "Iteration - Loss: 25.517807006835938, Filters: 32, Blocks: 8, Kernel Size: 4, Dropout: 0.29095132705442894, LR: 0.002132890345509543, Batch Size: 48, Epochs: 40\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.36977570742567, 'epochs': 30, 'filters': 96, 'kernel_size': 5, 'learning_rate': 0.003981829576968271, 'num_blocks': 6}\n",
      "Iteration - Loss: 214.39468383789062, Filters: 96, Blocks: 6, Kernel Size: 5, Dropout: 0.36977570742567, LR: 0.003981829576968271, Batch Size: 32, Epochs: 30\n",
      "Trying params: {'batch_size': 32, 'dropout_rate': 0.31271814957503774, 'epochs': 40, 'filters': 96, 'kernel_size': 3, 'learning_rate': 0.0033697431747458408, 'num_blocks': 6}\n",
      "Iteration - Loss: 313.93548583984375, Filters: 96, Blocks: 6, Kernel Size: 3, Dropout: 0.31271814957503774, LR: 0.0033697431747458408, Batch Size: 32, Epochs: 40\n",
      "100%|| 20/20 [09:02<00:00, 27.14s/trial, best loss: 1.136749029159546]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,  # Adjust the number of evaluations\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd59c843-0df5-441b-83ab-030be5ccaa3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'batch_size': 16, 'dropout_rate': 0.3444678739513979, 'epochs': 30, 'filters': 64, 'kernel_size': 5, 'learning_rate': 0.00024905823624566835, 'num_blocks': 6}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "419428c7-2ee7-4f91-897f-2b05d2097929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "best_model = create_resnet_model(input_shape=(X_train.shape[1], 1),\n",
    "                                 filters=best_params['filters'],\n",
    "                                 num_blocks=best_params['num_blocks'],\n",
    "                                 kernel_size=best_params['kernel_size'],\n",
    "                                 dropout_rate=best_params['dropout_rate'],\n",
    "                                 learning_rate=best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3da7281d-a53a-424b-989d-0970abd77322",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 365ms/step - accuracy: 0.6753 - loss: 0.7143 - val_accuracy: 0.5556 - val_loss: 7.4960\n",
      "Epoch 2/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350ms/step - accuracy: 0.7579 - loss: 0.5574 - val_accuracy: 0.5556 - val_loss: 6.0373\n",
      "Epoch 3/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369ms/step - accuracy: 0.7265 - loss: 0.5564 - val_accuracy: 0.5556 - val_loss: 4.7844\n",
      "Epoch 4/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357ms/step - accuracy: 0.6747 - loss: 0.6324 - val_accuracy: 0.5556 - val_loss: 3.8622\n",
      "Epoch 5/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.8340 - loss: 0.3741 - val_accuracy: 0.5556 - val_loss: 4.4730\n",
      "Epoch 6/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.8428 - loss: 0.3212 - val_accuracy: 0.5556 - val_loss: 3.0305\n",
      "Epoch 7/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 292ms/step - accuracy: 0.8837 - loss: 0.2891 - val_accuracy: 0.5556 - val_loss: 5.7840\n",
      "Epoch 8/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 278ms/step - accuracy: 0.8597 - loss: 0.3260 - val_accuracy: 0.5556 - val_loss: 4.6163\n",
      "Epoch 9/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step - accuracy: 0.8917 - loss: 0.2624 - val_accuracy: 0.5556 - val_loss: 2.3202\n",
      "Epoch 10/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 393ms/step - accuracy: 0.9353 - loss: 0.1822 - val_accuracy: 0.5556 - val_loss: 3.9709\n",
      "Epoch 11/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 548ms/step - accuracy: 0.8642 - loss: 0.3955 - val_accuracy: 0.5556 - val_loss: 1.9841\n",
      "Epoch 12/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 461ms/step - accuracy: 0.8792 - loss: 0.3408 - val_accuracy: 0.5556 - val_loss: 3.7924\n",
      "Epoch 13/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 340ms/step - accuracy: 0.9492 - loss: 0.1499 - val_accuracy: 0.5556 - val_loss: 6.2457\n",
      "Epoch 14/30\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.9582 - loss: 0.1179 - val_accuracy: 0.6667 - val_loss: 3.3479\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c17dfe3-1af4-4eed-9dea-c66f975ed05a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1637a419-6f6c-4169-9b74-750fd56d86d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.6666666666666666\n",
      "F1 Score: 0.6341463414634146\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.53125\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f054c-9430-40e2-a1ca-542b985a06b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee0a270f-cbef-4d51-a180-145025275104",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FNN with Bayesian Optimization - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "591f7dd8-d0d3-488e-b7c1-91cbd2a1c94b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_selected = X_final.reshape((X_final.shape[0], X_final.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c1fa452-b7a7-4dc2-9530-a85638230d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "373f765c-da3c-47d0-8d54-45103556049e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, num_layers=2, units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f21b88e3-163f-4d01-bc82-8f6ef57ebba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_layers': scope.int(hp.quniform('num_layers', 2, 6, 1)),\n",
    "    'units': scope.int(hp.quniform('units', 64, 256, 32)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 50, 150, 10)),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 16, 128, 16))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29a21134-a1d3-4f6a-ac70-9af957eab532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Create the FNN model with given hyperparameters\n",
    "    model = create_fnn_model(input_dim=X_train.shape[1], \n",
    "                             num_layers=params['num_layers'], \n",
    "                             units=params['units'], \n",
    "                             dropout_rate=params['dropout_rate'], \n",
    "                             learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], \n",
    "                        validation_split=0.1, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    \n",
    "    print(f\"Iteration - Loss: {val_loss}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b9046d9-44ae-4c79-bb2b-b7a98a2749f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - Loss: 1.1368592977523804, Params: {'batch_size': 16, 'dropout_rate': 0.11840606988352037, 'epochs': 120, 'learning_rate': 2.3374439939091925e-05, 'num_layers': 4, 'units': 96}\n",
      "Iteration - Loss: 3.4277029037475586, Params: {'batch_size': 128, 'dropout_rate': 0.42656188598245925, 'epochs': 110, 'learning_rate': 0.006720911465107453, 'num_layers': 3, 'units': 96}\n",
      "Iteration - Loss: 2.9794020652770996, Params: {'batch_size': 80, 'dropout_rate': 0.4247482055620856, 'epochs': 140, 'learning_rate': 0.002320933944916599, 'num_layers': 2, 'units': 192}\n",
      "Iteration - Loss: 1.8896592855453491, Params: {'batch_size': 48, 'dropout_rate': 0.20839159372599383, 'epochs': 140, 'learning_rate': 1.5368596781058096e-05, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 0.18487416207790375, Params: {'batch_size': 64, 'dropout_rate': 0.21231874443718857, 'epochs': 100, 'learning_rate': 0.005086038563545574, 'num_layers': 2, 'units': 224}\n",
      "Iteration - Loss: 6.2055182456970215, Params: {'batch_size': 64, 'dropout_rate': 0.1713525370146256, 'epochs': 120, 'learning_rate': 2.076782047783858e-05, 'num_layers': 3, 'units': 64}\n",
      "Iteration - Loss: 3.115023136138916, Params: {'batch_size': 32, 'dropout_rate': 0.41353048611680243, 'epochs': 90, 'learning_rate': 0.00038717788468978, 'num_layers': 5, 'units': 96}\n",
      "Iteration - Loss: 1.1051955223083496, Params: {'batch_size': 64, 'dropout_rate': 0.30455581821951827, 'epochs': 120, 'learning_rate': 0.005169689145339174, 'num_layers': 3, 'units': 128}\n",
      "Iteration - Loss: 3.453941583633423, Params: {'batch_size': 48, 'dropout_rate': 0.18474958439122294, 'epochs': 110, 'learning_rate': 1.2820205829941877e-05, 'num_layers': 3, 'units': 192}\n",
      "Iteration - Loss: 0.5412724614143372, Params: {'batch_size': 32, 'dropout_rate': 0.20848050426131698, 'epochs': 70, 'learning_rate': 0.0029525174688750204, 'num_layers': 4, 'units': 64}\n",
      "Iteration - Loss: 8.535918235778809, Params: {'batch_size': 48, 'dropout_rate': 0.3318870182684191, 'epochs': 70, 'learning_rate': 3.3220524102203026e-05, 'num_layers': 4, 'units': 128}\n",
      "Iteration - Loss: 0.10141384601593018, Params: {'batch_size': 16, 'dropout_rate': 0.2361957116824922, 'epochs': 90, 'learning_rate': 0.004618281805173749, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 0.7070558071136475, Params: {'batch_size': 112, 'dropout_rate': 0.3629160861882772, 'epochs': 110, 'learning_rate': 0.0041321128208856375, 'num_layers': 5, 'units': 192}\n",
      "Iteration - Loss: 0.8646509051322937, Params: {'batch_size': 80, 'dropout_rate': 0.45834907237349065, 'epochs': 70, 'learning_rate': 0.001224461630793537, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 0.4730212390422821, Params: {'batch_size': 96, 'dropout_rate': 0.2906764831656481, 'epochs': 130, 'learning_rate': 0.0012501784072903122, 'num_layers': 5, 'units': 160}\n",
      "Iteration - Loss: 1.5488531589508057, Params: {'batch_size': 32, 'dropout_rate': 0.4951821608361432, 'epochs': 70, 'learning_rate': 0.00010238920631824107, 'num_layers': 5, 'units': 128}\n",
      "Iteration - Loss: 0.46179091930389404, Params: {'batch_size': 80, 'dropout_rate': 0.38279264883208397, 'epochs': 110, 'learning_rate': 0.003198088964253609, 'num_layers': 5, 'units': 224}\n",
      "Iteration - Loss: 2.272710084915161, Params: {'batch_size': 96, 'dropout_rate': 0.4506581013808405, 'epochs': 50, 'learning_rate': 0.006577559018361673, 'num_layers': 2, 'units': 96}\n",
      "Iteration - Loss: 0.10725364089012146, Params: {'batch_size': 48, 'dropout_rate': 0.4136406036811332, 'epochs': 130, 'learning_rate': 0.004462787317451899, 'num_layers': 3, 'units': 256}\n",
      "Iteration - Loss: 0.9189168214797974, Params: {'batch_size': 48, 'dropout_rate': 0.2544034502869734, 'epochs': 60, 'learning_rate': 0.008966076441072566, 'num_layers': 2, 'units': 128}\n",
      "Iteration - Loss: 1.096431016921997, Params: {'batch_size': 16, 'dropout_rate': 0.11595192980323904, 'epochs': 90, 'learning_rate': 0.0005899757908380971, 'num_layers': 6, 'units': 256}\n",
      "Iteration - Loss: 0.7757365703582764, Params: {'batch_size': 16, 'dropout_rate': 0.2760748691381997, 'epochs': 150, 'learning_rate': 0.00020395272605569959, 'num_layers': 3, 'units': 256}\n",
      "Iteration - Loss: 0.3252820670604706, Params: {'batch_size': 32, 'dropout_rate': 0.49701154788154306, 'epochs': 90, 'learning_rate': 0.0014633724396364287, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 2.0409560203552246, Params: {'batch_size': 16, 'dropout_rate': 0.3372184180056451, 'epochs': 150, 'learning_rate': 0.0007318869666745012, 'num_layers': 3, 'units': 224}\n",
      "Iteration - Loss: 0.32642465829849243, Params: {'batch_size': 32, 'dropout_rate': 0.2449350250169479, 'epochs': 80, 'learning_rate': 0.009627324722573353, 'num_layers': 4, 'units': 256}\n",
      "Iteration - Loss: 0.8650047779083252, Params: {'batch_size': 48, 'dropout_rate': 0.15920036169871876, 'epochs': 100, 'learning_rate': 0.00015147247543764294, 'num_layers': 6, 'units': 224}\n",
      "Iteration - Loss: 5.575531005859375, Params: {'batch_size': 16, 'dropout_rate': 0.3262408263642538, 'epochs': 130, 'learning_rate': 6.910068568395466e-05, 'num_layers': 3, 'units': 256}\n",
      "Iteration - Loss: 1.822287917137146, Params: {'batch_size': 64, 'dropout_rate': 0.37563091903449514, 'epochs': 80, 'learning_rate': 0.001983790057205485, 'num_layers': 4, 'units': 160}\n",
      "Iteration - Loss: 0.4097125232219696, Params: {'batch_size': 16, 'dropout_rate': 0.13849645220301193, 'epochs': 130, 'learning_rate': 0.0007116357727221459, 'num_layers': 4, 'units': 192}\n",
      "Iteration - Loss: 0.17268666625022888, Params: {'batch_size': 32, 'dropout_rate': 0.2520662811005152, 'epochs': 140, 'learning_rate': 0.009895692882517479, 'num_layers': 3, 'units': 256}\n",
      "100%|| 30/30 [02:37<00:00,  5.26s/trial, best loss: 0.10141384601593018]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,  # Number of evaluations (trials)\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed6893a7-4fc3-4d8e-92d3-d918f5ed6e91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 16, 'dropout_rate': 0.2361957116824922, 'epochs': 90, 'learning_rate': 0.004618281805173749, 'num_layers': 4, 'units': 256}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4cfd2162-59e2-4e58-8bed-7c81fc1bb4da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5427 - loss: 35.5334 - val_accuracy: 0.6667 - val_loss: 13.1652\n",
      "Epoch 2/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6692 - loss: 10.1335 - val_accuracy: 0.8333 - val_loss: 1.2204\n",
      "Epoch 3/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7518 - loss: 2.3172 - val_accuracy: 0.9444 - val_loss: 0.7523\n",
      "Epoch 4/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8951 - loss: 1.1870 - val_accuracy: 0.9444 - val_loss: 0.9986\n",
      "Epoch 5/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9056 - loss: 0.5037 - val_accuracy: 0.8889 - val_loss: 0.8536\n",
      "Epoch 6/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9602 - loss: 0.3913 - val_accuracy: 1.0000 - val_loss: 0.1017\n",
      "Epoch 7/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9555 - loss: 0.3503 - val_accuracy: 0.9444 - val_loss: 0.1904\n",
      "Epoch 8/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9820 - loss: 0.1848 - val_accuracy: 1.0000 - val_loss: 0.0432\n",
      "Epoch 9/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9875 - loss: 0.1667 - val_accuracy: 1.0000 - val_loss: 0.0208\n",
      "Epoch 10/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9930 - loss: 0.0828 - val_accuracy: 0.8889 - val_loss: 0.3893\n",
      "Epoch 11/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9802 - loss: 0.0262 - val_accuracy: 0.9444 - val_loss: 0.3742\n",
      "Epoch 12/90\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9915 - loss: 0.8693 - val_accuracy: 0.8889 - val_loss: 0.5718\n"
     ]
    }
   ],
   "source": [
    "best_model = create_fnn_model(input_dim=X_train.shape[1],\n",
    "                              num_layers=best_params['num_layers'],\n",
    "                              units=best_params['units'],\n",
    "                              dropout_rate=best_params['dropout_rate'],\n",
    "                              learning_rate=best_params['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], \n",
    "                         validation_split=0.1, callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a625bb08-b886-4774-a35f-49f5a02dcbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "\n",
      "Test Performance:\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score: 0.896551724137931\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.90625\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "test_sensitivity = tp / (tp + fn)\n",
    "test_specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\nTest Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"F1 Score: {test_f1}\")\n",
    "print(f\"Sensitivity: {test_sensitivity}\")\n",
    "print(f\"Specificity: {test_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e888179-7987-4d6b-b0b9-7d9d34ec0f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b4cbf1-eec4-42a5-8244-ee859ebeb894",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## BERT Transformer - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8231d0d1-8c80-41e7-9835-474cabe136a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences = [' '.join(map(str, row)) for row in X_final]\n",
    "labels = case_control_info.map({'Control': 0, 'Case': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "649edc68-1e80-4d24-aea0-156020c64b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SNPDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0199fddd-ef8d-489e-9755-032ac47773b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 3)  # Reduced number of epochs for faster trials\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])  # Higher batch sizes might not fit in memory\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    max_length = trial.suggest_int('max_length', 128, 256)  # Reduced sequence length\n",
    "\n",
    "    # Load DistilBERT tokenizer and model\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Split the data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "    val_dataset = SNPDataset(val_encodings, val_labels)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1  # Keep only the last checkpoint\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
    "\n",
    "    # Return the evaluation metric to be minimized\n",
    "    return eval_result['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "280cf110-f5f5-42cb-ab14-edc22e3f3de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 08:19:58,629] A new study created in memory with name: no-name-209b2bba-2051-4ec3-80c1-4de4da969260\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b64de11-e7a4-4a6c-b326-d2b89be16c0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>0.700531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>0.672147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 08:22:05,877] Trial 0 finished with value: 0.6721472144126892 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.1133062491366179e-05, 'max_length': 162}. Best is trial 0 with value: 0.6721472144126892.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.686616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.647721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 08:23:30,074] Trial 1 finished with value: 0.6477210521697998 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 4.626177938272114e-05, 'max_length': 135}. Best is trial 1 with value: 0.6477210521697998.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 02:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>0.678381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 08:25:47,907] Trial 2 finished with value: 0.6783807873725891 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 1.0797310290888597e-05, 'max_length': 216}. Best is trial 1 with value: 0.6477210521697998.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 01:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.678445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.656361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 08:27:52,427] Trial 3 finished with value: 0.6563611626625061 and parameters: {'num_train_epochs': 3, 'batch_size': 32, 'learning_rate': 1.214855483250016e-05, 'max_length': 128}. Best is trial 1 with value: 0.6477210521697998.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 02:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.661197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 08:30:21,264] Trial 4 finished with value: 0.6611966490745544 and parameters: {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 2.870543412238035e-05, 'max_length': 229}. Best is trial 1 with value: 0.6477210521697998.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65476efd-81cf-45bb-b01f-6f6f1c14e91c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_train_epochs': 2, 'batch_size': 32, 'learning_rate': 4.626177938272114e-05, 'max_length': 135}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "79ba44a1-c227-45d3-9061-ad717f47faa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1e00746e-3aee-4a45-98e8-e0a19a4cd6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c51cf7cc-e04d-4882-b299-749249358043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "train_dataset = SNPDataset(train_encodings, train_labels)\n",
    "val_dataset = SNPDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f74301a7-f129-4667-9a7f-a4a02298c4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=best_params['num_train_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a25f3f1f-ba3f-468e-8fa8-bbfa11179a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "38dcb183-708d-4ae9-8d8c-3c9848fc4ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 10:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.666281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>0.643506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=0.6278658111890157, metrics={'train_runtime': 690.6826, 'train_samples_per_second': 0.521, 'train_steps_per_second': 0.017, 'total_flos': 94719979929600.0, 'train_loss': 0.6278658111890157, 'epoch': 2.0})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2df6023b-d156-4912-90bf-c22475dbd4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5555555555555556\n",
      "F1 Score: 0.5652173913043478\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.375\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds)\n",
    "conf_matrix = confusion_matrix(val_labels, preds)\n",
    "\n",
    "# Compute specificity and sensitivity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d427824-ffdf-4ad6-9f56-cff16d188ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8502af7b-6595-4830-af8e-bdf0737e4607",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sparse Autoencoder - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e30a0a88-719f-46af-8d34-aad4f0bb5d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val= train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4addd75c-a383-43be-889b-50eb0810b927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sparse_autoencoder(input_dim, num_units, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Dense(num_units, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer))(input_layer)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "    decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbb4cdfc-c133-4795-8bce-517b4579cd8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_units = trial.suggest_int('num_units', 64, 256)  # Reduced upper bound\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)  # Lower upper bound\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.3)  # Reduced upper bound\n",
    "    activity_regularizer = trial.suggest_float('activity_regularizer', 1e-7, 1e-4, log=True)  # Reduced range\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)  # Reduced upper bound\n",
    "\n",
    "    # Create the model\n",
    "    model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=num_units, dropout_rate=dropout_rate, activity_regularizer=activity_regularizer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    # Set early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, X_train, epochs=50, batch_size=batch_size, validation_data=(X_val, X_val), callbacks=[early_stopping, TFKerasPruningCallback(trial, 'val_loss')], verbose=0)\n",
    "\n",
    "    # Return the best validation loss\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0349d0cf-b1e6-4f4e-82ae-35200900308b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-18 09:13:50,780] A new study created in memory with name: no-name-ae50c266-74ee-4a2e-99c6-142589d7e403\n",
      "[I 2024-06-18 09:14:00,573] Trial 0 finished with value: 5033.30126953125 and parameters: {'num_units': 208, 'learning_rate': 4.896915661944763e-05, 'dropout_rate': 0.011310552708354071, 'activity_regularizer': 1.536045821488744e-05, 'batch_size': 46}. Best is trial 0 with value: 5033.30126953125.\n",
      "[I 2024-06-18 09:14:12,698] Trial 1 finished with value: 5036.72607421875 and parameters: {'num_units': 219, 'learning_rate': 4.9079591360599705e-05, 'dropout_rate': 0.0309312187234686, 'activity_regularizer': 7.85508526848169e-05, 'batch_size': 37}. Best is trial 0 with value: 5033.30126953125.\n",
      "[I 2024-06-18 09:14:22,369] Trial 2 finished with value: 5023.765625 and parameters: {'num_units': 198, 'learning_rate': 7.743009306861386e-05, 'dropout_rate': 0.14949171157774166, 'activity_regularizer': 2.9232239694999035e-07, 'batch_size': 62}. Best is trial 2 with value: 5023.765625.\n",
      "[I 2024-06-18 09:14:35,181] Trial 3 finished with value: 5015.04736328125 and parameters: {'num_units': 145, 'learning_rate': 0.0009775908215640015, 'dropout_rate': 0.09559215664550774, 'activity_regularizer': 9.042841753504424e-06, 'batch_size': 32}. Best is trial 3 with value: 5015.04736328125.\n",
      "[I 2024-06-18 09:14:49,439] Trial 4 finished with value: 5042.341796875 and parameters: {'num_units': 239, 'learning_rate': 2.155325849071633e-05, 'dropout_rate': 0.19341683349034403, 'activity_regularizer': 5.1234848104720856e-05, 'batch_size': 29}. Best is trial 3 with value: 5015.04736328125.\n",
      "[I 2024-06-18 09:14:50,251] Trial 5 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-18 09:14:51,792] Trial 6 pruned. Trial was pruned at epoch 7.\n",
      "[I 2024-06-18 09:14:52,246] Trial 7 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:14:54,532] Trial 8 pruned. Trial was pruned at epoch 10.\n",
      "[I 2024-06-18 09:14:56,890] Trial 9 pruned. Trial was pruned at epoch 14.\n",
      "[I 2024-06-18 09:15:08,166] Trial 10 finished with value: 5014.2978515625 and parameters: {'num_units': 68, 'learning_rate': 0.0008886852358252423, 'dropout_rate': 0.28769366573068833, 'activity_regularizer': 4.685205163925786e-06, 'batch_size': 17}. Best is trial 10 with value: 5014.2978515625.\n",
      "[I 2024-06-18 09:15:19,953] Trial 11 finished with value: 5014.44873046875 and parameters: {'num_units': 66, 'learning_rate': 0.0008298031026523347, 'dropout_rate': 0.09285872909857737, 'activity_regularizer': 3.877449690875519e-06, 'batch_size': 16}. Best is trial 10 with value: 5014.2978515625.\n",
      "[I 2024-06-18 09:15:30,087] Trial 12 finished with value: 5014.623046875 and parameters: {'num_units': 70, 'learning_rate': 0.0009359553283287964, 'dropout_rate': 0.2814285460327579, 'activity_regularizer': 2.4948887059810175e-06, 'batch_size': 16}. Best is trial 10 with value: 5014.2978515625.\n",
      "[I 2024-06-18 09:15:32,211] Trial 13 pruned. Trial was pruned at epoch 3.\n",
      "[I 2024-06-18 09:15:32,857] Trial 14 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:15:45,564] Trial 15 finished with value: 5014.18994140625 and parameters: {'num_units': 88, 'learning_rate': 0.00041179544925319135, 'dropout_rate': 0.14551668795952089, 'activity_regularizer': 1.4667306888799002e-06, 'batch_size': 22}. Best is trial 15 with value: 5014.18994140625.\n",
      "[I 2024-06-18 09:15:46,019] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:15:46,402] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:15:46,744] Trial 18 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:15:47,292] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:15:52,626] Trial 20 pruned. Trial was pruned at epoch 19.\n",
      "[I 2024-06-18 09:15:53,241] Trial 21 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:15:53,758] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:01,381] Trial 23 pruned. Trial was pruned at epoch 19.\n",
      "[I 2024-06-18 09:16:01,742] Trial 24 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:02,191] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:02,467] Trial 26 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:11,659] Trial 27 finished with value: 5015.06298828125 and parameters: {'num_units': 116, 'learning_rate': 0.0007354393433225038, 'dropout_rate': 0.17595719037573956, 'activity_regularizer': 1.612776503601923e-06, 'batch_size': 20}. Best is trial 15 with value: 5014.18994140625.\n",
      "[I 2024-06-18 09:16:12,156] Trial 28 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:12,512] Trial 29 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:12,929] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:18,437] Trial 31 pruned. Trial was pruned at epoch 14.\n",
      "[I 2024-06-18 09:16:26,829] Trial 32 finished with value: 5014.6513671875 and parameters: {'num_units': 75, 'learning_rate': 0.000804483105110752, 'dropout_rate': 0.2671412780750871, 'activity_regularizer': 3.3619491879474823e-06, 'batch_size': 19}. Best is trial 15 with value: 5014.18994140625.\n",
      "[I 2024-06-18 09:16:27,304] Trial 33 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:27,695] Trial 34 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:33,226] Trial 35 pruned. Trial was pruned at epoch 16.\n",
      "[I 2024-06-18 09:16:33,633] Trial 36 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:33,983] Trial 37 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:34,442] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:40,691] Trial 39 finished with value: 5014.4013671875 and parameters: {'num_units': 176, 'learning_rate': 0.000700654949437268, 'dropout_rate': 0.2797466723285883, 'activity_regularizer': 3.1028311077283863e-07, 'batch_size': 22}. Best is trial 15 with value: 5014.18994140625.\n",
      "[I 2024-06-18 09:16:41,105] Trial 40 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:47,809] Trial 41 finished with value: 5014.0185546875 and parameters: {'num_units': 194, 'learning_rate': 0.000812869310836898, 'dropout_rate': 0.27778329357127274, 'activity_regularizer': 3.850144733992973e-07, 'batch_size': 22}. Best is trial 41 with value: 5014.0185546875.\n",
      "[I 2024-06-18 09:16:52,342] Trial 42 finished with value: 5014.36376953125 and parameters: {'num_units': 187, 'learning_rate': 0.00068017570263487, 'dropout_rate': 0.22447371465114585, 'activity_regularizer': 1.2533051960561853e-07, 'batch_size': 23}. Best is trial 41 with value: 5014.0185546875.\n",
      "[I 2024-06-18 09:16:56,994] Trial 43 pruned. Trial was pruned at epoch 16.\n",
      "[I 2024-06-18 09:16:57,385] Trial 44 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:58,389] Trial 45 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-06-18 09:16:58,722] Trial 46 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:59,091] Trial 47 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:59,570] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-06-18 09:16:59,916] Trial 49 pruned. Trial was pruned at epoch 0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a0cecb9a-6aa6-4bd7-ac97-7fced1f73cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'num_units': 194, 'learning_rate': 0.000812869310836898, 'dropout_rate': 0.27778329357127274, 'activity_regularizer': 3.850144733992973e-07, 'batch_size': 22}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8b4195eb-a4d2-40b5-afe5-671a26f25e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2c29311d-dd3f-4a59-ac04-425e5f4f5bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5649.4556 - val_loss: 5040.9805\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5897.5483 - val_loss: 5032.5493\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5470.1553 - val_loss: 5027.1211\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5770.1787 - val_loss: 5023.3081\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5759.4683 - val_loss: 5020.7314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28d968c9250>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_sparse_autoencoder(input_dim=X_train.shape[1], num_units=best_params['num_units'], dropout_rate=best_params['dropout_rate'], activity_regularizer=best_params['activity_regularizer'])\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss=MeanSquaredError())\n",
    "best_model.fit(X_train, X_train, epochs=50, batch_size=best_params['batch_size'], validation_data=(X_val, X_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "986cbe90-f6a9-4f55-9664-aa2959450e91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5156.1064 \n",
      "Validation Loss:  5040.9921875\n"
     ]
    }
   ],
   "source": [
    "val_loss = best_model.evaluate(X_val, X_val)\n",
    "print(\"Validation Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ae7e8986-0aae-4dbf-aeb5-8b7bbdb1ae4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "reconstructions = best_model.predict(X_val)\n",
    "reconstruction_errors = np.mean(np.square(X_val - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f3eed7c7-f584-4fec-95d3-83a5e183f851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "44c5a998-866b-49c3-971f-cbc07118c78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1dbf8acb-5657-4e07-8002-e0be0ee4c37c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7777777777777778\n",
      "F1 Score: 0.375\n",
      "Sensitivity: 0.23076923076923078\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba784e78-5acc-46c8-9623-6fcc7defec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb3cfc4-ac7c-418b-9963-203e46d9716f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & LSTM Model - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8a1bef7c-5dc9-42bc-ab74-c9e79cfc1fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final = X_final.astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8ccf30ba-f4ed-45d5-aa40-f1ad32809097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "24b2c8a9-4e88-417f-ba36-a423d48fd302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_deep_autoencoder(input_dim, encoding_dim, hidden_layers, dropout_rate, activity_regularizer):\n",
    "    input_layer = Input(shape=(input_dim,), dtype='float32')\n",
    "    x = input_layer\n",
    "    for units in hidden_layers:\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    encoder = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(activity_regularizer), dtype='float32')(x)\n",
    "    encoder = Dropout(dropout_rate)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    x = encoder\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = Dense(units, activation='relu', dtype='float32')(x)\n",
    "    decoder = Dense(input_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoder)\n",
    "    encoder_model = Model(input_layer, encoder)\n",
    "    return autoencoder, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d5524cdb-0ff0-41ae-952d-1cf116f1c32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bilstm_model(input_shape, lstm_units, dropout_rate, output_dim):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), dtype='float32')\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dtype='float32'))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, dtype='float32'))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_dim, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9db91760-d236-4ce4-857e-c1fc88d470b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_stacked_model(X_train, X_val, autoencoder_params, lstm_params):\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    # Autoencoder part\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=autoencoder_params['batch_size'], validation_data=(X_val, X_val), verbose=0)\n",
    "\n",
    "    # Encoder output\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "    \n",
    "    # Prepare for LSTM\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # BiLSTM part\n",
    "    lstm_model = create_bilstm_model(input_shape=X_encoded_train.shape, lstm_units=lstm_params['lstm_units'], dropout_rate=lstm_params['dropout_rate'], output_dim=1)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return autoencoder, lstm_model, X_encoded_train, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "faf0c4b4-4481-4cad-90e0-4e5d014dafef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_val, y_train_val):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': int(params['encoding_dim']),\n",
    "            'hidden_layers': [int(params['autoencoder_units'])],\n",
    "            'dropout_rate': params['ae_dropout_rate'],\n",
    "            'activity_regularizer': params['ae_activity_reg'],\n",
    "            'learning_rate': params['ae_learning_rate'],\n",
    "            'batch_size': int(params['ae_batch_size'])\n",
    "        }\n",
    "        \n",
    "        lstm_params = {\n",
    "            'lstm_units': int(params['lstm_units']),\n",
    "            'dropout_rate': params['lstm_dropout_rate'],\n",
    "            'learning_rate': params['lstm_learning_rate'],\n",
    "            'batch_size': int(params['lstm_batch_size'])\n",
    "        }\n",
    "\n",
    "        autoencoder, lstm_model, X_encoded_train, X_encoded_val = create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        lstm_model.fit(X_encoded_train, y_train, epochs=50, batch_size=lstm_params['batch_size'], validation_data=(X_encoded_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "        \n",
    "        y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Iteration Results - Accuracy: {avg_accuracy}, F1 Score: {avg_f1}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK, 'accuracy': avg_accuracy, 'f1': avg_f1, 'sensitivity': avg_sensitivity, 'specificity': avg_specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2ed21fc3-4106-461a-8f92-832814d62013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'lstm_units': hp.quniform('lstm_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'lstm_dropout_rate': hp.uniform('lstm_dropout_rate', 0.1, 0.5),\n",
    "    'lstm_learning_rate': hp.loguniform('lstm_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'lstm_batch_size': hp.quniform('lstm_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0b4f30c0-77cb-4ba3-bd4a-5630d5d46f0d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.65, F1 Score: 0.715999686587922, Sensitivity: 0.9615384615384616, Specificity: 0.3824123588829471\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6722222222222222, F1 Score: 0.7007959429958373, Sensitivity: 0.8494776828110161, Specificity: 0.5115270350564468\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.5388888888888889, F1 Score: 0.2222222222222222, Sensitivity: 0.3333333333333333, Specificity: 0.6666666666666666\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                               \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6888888888888888, F1 Score: 0.733033033033033, Sensitivity: 0.9222222222222222, Specificity: 0.5045157456922164\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6833333333333335, F1 Score: 0.7137897258347637, Sensitivity: 0.8440645773979107, Specificity: 0.5448009506833036\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6277777777777778, F1 Score: 0.5118708452041786, Sensitivity: 0.6794871794871794, Specificity: 0.5575757575757575\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step                                                  \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.7111111111111111, F1 Score: 0.7550123067364446, Sensitivity: 0.9506172839506174, Specificity: 0.5035056446821152\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                 \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6944444444444445, F1 Score: 0.7289490718871918, Sensitivity: 0.8908831908831908, Specificity: 0.5277480689245395\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                 \n",
      "\n",
      "Iteration Results - Accuracy: 0.7055555555555556, F1 Score: 0.7167251461988303, Sensitivity: 0.8149097815764482, Specificity: 0.6019607843137255\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step                                                  \n",
      "\n",
      "Iteration Results - Accuracy: 0.6944444444444443, F1 Score: 0.6989235914829471, Sensitivity: 0.7721747388414055, Specificity: 0.6330362448009507\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284ms/step                                              \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step                                               \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step                                              \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step                                              \n",
      "\n",
      "Iteration Results - Accuracy: 0.6722222222222222, F1 Score: 0.657563025210084, Sensitivity: 0.6841405508072175, Specificity: 0.6551990493166964\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step                                                  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step                                                  \n",
      "\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      " 55%|                   | 11/20 [2:07:22<1:44:13, 694.80s/trial, best loss: -0.7550123067364446]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m----> 2\u001b[0m best \u001b[38;5;241m=\u001b[39m fmin(fn\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[0;32m      3\u001b[0m             space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[0;32m      4\u001b[0m             algo\u001b[38;5;241m=\u001b[39mtpe\u001b[38;5;241m.\u001b[39msuggest,\n\u001b[0;32m      5\u001b[0m             max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m      6\u001b[0m             trials\u001b[38;5;241m=\u001b[39mtrials)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trials\u001b[38;5;241m.\u001b[39mfmin(\n\u001b[0;32m    541\u001b[0m         fn,\n\u001b[0;32m    542\u001b[0m         space,\n\u001b[0;32m    543\u001b[0m         algo\u001b[38;5;241m=\u001b[39malgo,\n\u001b[0;32m    544\u001b[0m         max_evals\u001b[38;5;241m=\u001b[39mmax_evals,\n\u001b[0;32m    545\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    546\u001b[0m         loss_threshold\u001b[38;5;241m=\u001b[39mloss_threshold,\n\u001b[0;32m    547\u001b[0m         max_queue_len\u001b[38;5;241m=\u001b[39mmax_queue_len,\n\u001b[0;32m    548\u001b[0m         rstate\u001b[38;5;241m=\u001b[39mrstate,\n\u001b[0;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[38;5;241m=\u001b[39mpass_expr_memo_ctrl,\n\u001b[0;32m    550\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    551\u001b[0m         catch_eval_exceptions\u001b[38;5;241m=\u001b[39mcatch_eval_exceptions,\n\u001b[0;32m    552\u001b[0m         return_argmin\u001b[38;5;241m=\u001b[39mreturn_argmin,\n\u001b[0;32m    553\u001b[0m         show_progressbar\u001b[38;5;241m=\u001b[39mshow_progressbar,\n\u001b[0;32m    554\u001b[0m         early_stop_fn\u001b[38;5;241m=\u001b[39mearly_stop_fn,\n\u001b[0;32m    555\u001b[0m         trials_save_file\u001b[38;5;241m=\u001b[39mtrials_save_file,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fmin(\n\u001b[0;32m    672\u001b[0m     fn,\n\u001b[0;32m    673\u001b[0m     space,\n\u001b[0;32m    674\u001b[0m     algo\u001b[38;5;241m=\u001b[39malgo,\n\u001b[0;32m    675\u001b[0m     max_evals\u001b[38;5;241m=\u001b[39mmax_evals,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    677\u001b[0m     loss_threshold\u001b[38;5;241m=\u001b[39mloss_threshold,\n\u001b[0;32m    678\u001b[0m     trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    679\u001b[0m     rstate\u001b[38;5;241m=\u001b[39mrstate,\n\u001b[0;32m    680\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    681\u001b[0m     max_queue_len\u001b[38;5;241m=\u001b[39mmax_queue_len,\n\u001b[0;32m    682\u001b[0m     allow_trials_fmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# -- prevent recursion\u001b[39;00m\n\u001b[0;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[38;5;241m=\u001b[39mpass_expr_memo_ctrl,\n\u001b[0;32m    684\u001b[0m     catch_eval_exceptions\u001b[38;5;241m=\u001b[39mcatch_eval_exceptions,\n\u001b[0;32m    685\u001b[0m     return_argmin\u001b[38;5;241m=\u001b[39mreturn_argmin,\n\u001b[0;32m    686\u001b[0m     show_progressbar\u001b[38;5;241m=\u001b[39mshow_progressbar,\n\u001b[0;32m    687\u001b[0m     early_stop_fn\u001b[38;5;241m=\u001b[39mearly_stop_fn,\n\u001b[0;32m    688\u001b[0m     trials_save_file\u001b[38;5;241m=\u001b[39mtrials_save_file,\n\u001b[0;32m    689\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[38;5;241m.\u001b[39mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_evals \u001b[38;5;241m-\u001b[39m n_done, block_until_done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[152], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     29\u001b[0m autoencoder, lstm_model, X_encoded_train, X_encoded_val \u001b[38;5;241m=\u001b[39m create_stacked_model(X_train, X_val, autoencoder_params, lstm_params)\n\u001b[0;32m     31\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 33\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39mfit(X_encoded_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mlstm_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], validation_data\u001b[38;5;241m=\u001b[39m(X_encoded_val, y_val), callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     35\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mpredict(X_encoded_val)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     36\u001b[0m y_val_pred_binary \u001b[38;5;241m=\u001b[39m (y_val_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:339\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    330\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    331\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    338\u001b[0m     )\n\u001b[1;32m--> 339\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    340\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    341\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    342\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m    343\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m    344\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    345\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    346\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    347\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    349\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    351\u001b[0m }\n\u001b[0;32m    352\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:425\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    424\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 425\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m    426\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    427\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:810\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_functions_eagerly:\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# Only count the statistics the first time, before initialization took\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:161\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single test step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 161\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    162\u001b[0m     one_step_on_data, args\u001b[38;5;241m=\u001b[39m(data,)\n\u001b[0;32m    163\u001b[0m )\n\u001b[0;32m    164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    165\u001b[0m     outputs,\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    167\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended\u001b[38;5;241m.\u001b[39mcall_for_each_replica(fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:150\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_test_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    149\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single test step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_step(data)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:78\u001b[0m, in \u001b[0;36mTensorFlowTrainer.test_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     76\u001b[0m x, y, sample_weight \u001b[38;5;241m=\u001b[39m data_adapter_utils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_has_training_arg:\n\u001b[1;32m---> 78\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[0;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[0;32m     45\u001b[0m         call_fn,\n\u001b[0;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     47\u001b[0m     )\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:202\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[1;32m--> 202\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_through_graph(\n\u001b[0;32m    203\u001b[0m     inputs, operation_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m op: operation_fn(op, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m    204\u001b[0m )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py:155\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[1;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[0;32m    153\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:592\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    590\u001b[0m ):\n\u001b[0;32m    591\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[1;32m--> 592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m operation(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[0;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[0;32m     45\u001b[0m         call_fn,\n\u001b[0;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     47\u001b[0m     )\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:221\u001b[0m, in \u001b[0;36mBidirectional.call\u001b[1;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[0;32m    216\u001b[0m     forward_state, backward_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_layer(\n\u001b[0;32m    219\u001b[0m     forward_inputs, initial_state\u001b[38;5;241m=\u001b[39mforward_state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    220\u001b[0m )\n\u001b[1;32m--> 221\u001b[0m y_rev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward_layer(\n\u001b[0;32m    222\u001b[0m     backward_inputs, initial_state\u001b[38;5;241m=\u001b[39mbackward_state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    223\u001b[0m )\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_state:\n\u001b[0;32m    226\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(y[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m y_rev[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[0;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[0;32m     45\u001b[0m         call_fn,\n\u001b[0;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     47\u001b[0m     )\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:560\u001b[0m, in \u001b[0;36mLSTM.call\u001b[1;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequences, initial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcall(\n\u001b[0;32m    561\u001b[0m         sequences, mask\u001b[38;5;241m=\u001b[39mmask, training\u001b[38;5;241m=\u001b[39mtraining, initial_state\u001b[38;5;241m=\u001b[39minitial_state\n\u001b[0;32m    562\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:406\u001b[0m, in \u001b[0;36mRNN.call\u001b[1;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# Prepopulate the dropout state so that the inner_loop is stateless\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# this is particularly important for JAX backend.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_config_dropout_masks(\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell, sequences[:, \u001b[38;5;241m0\u001b[39m, :], initial_state\n\u001b[0;32m    404\u001b[0m )\n\u001b[1;32m--> 406\u001b[0m last_output, outputs, states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_loop(\n\u001b[0;32m    407\u001b[0m     sequences\u001b[38;5;241m=\u001b[39msequences,\n\u001b[0;32m    408\u001b[0m     initial_state\u001b[38;5;241m=\u001b[39minitial_state,\n\u001b[0;32m    409\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    410\u001b[0m     training\u001b[38;5;241m=\u001b[39mtraining,\n\u001b[0;32m    411\u001b[0m )\n\u001b[0;32m    412\u001b[0m last_output \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(last_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m    413\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:555\u001b[0m, in \u001b[0;36mLSTM.inner_loop\u001b[1;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cudnn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cudnn=True was specified, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut cuDNN is not supported for this layer configuration \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith this backend. Pass use_cudnn=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to fallback \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a non-cuDNN implementation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m     )\n\u001b[1;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minner_loop(\n\u001b[0;32m    556\u001b[0m     sequences, initial_state, mask\u001b[38;5;241m=\u001b[39mmask, training\u001b[38;5;241m=\u001b[39mtraining\n\u001b[0;32m    557\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:346\u001b[0m, in \u001b[0;36mRNN.inner_loop\u001b[1;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mis_nested(initial_state):\n\u001b[0;32m    344\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m [initial_state]\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mrnn(\n\u001b[0;32m    347\u001b[0m     step,\n\u001b[0;32m    348\u001b[0m     sequences,\n\u001b[0;32m    349\u001b[0m     initial_state,\n\u001b[0;32m    350\u001b[0m     go_backwards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgo_backwards,\n\u001b[0;32m    351\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    352\u001b[0m     unroll\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munroll,\n\u001b[0;32m    353\u001b[0m     input_length\u001b[38;5;241m=\u001b[39msequences\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    354\u001b[0m     zero_output_for_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_output_for_mask,\n\u001b[0;32m    355\u001b[0m     return_all_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_sequences,\n\u001b[0;32m    356\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py:428\u001b[0m, in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[0;32m    423\u001b[0m         new_states \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m    424\u001b[0m             initial_states, flat_new_state\n\u001b[0;32m    425\u001b[0m         )\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, output_ta_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(new_states)\n\u001b[1;32m--> 428\u001b[0m     final_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mwhile_loop(\n\u001b[0;32m    429\u001b[0m         body\u001b[38;5;241m=\u001b[39m_step,\n\u001b[0;32m    430\u001b[0m         loop_vars\u001b[38;5;241m=\u001b[39m(time, output_ta) \u001b[38;5;241m+\u001b[39m states,\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mwhile_loop_kwargs,\n\u001b[0;32m    432\u001b[0m     )\n\u001b[0;32m    433\u001b[0m     new_states \u001b[38;5;241m=\u001b[39m final_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    435\u001b[0m output_ta \u001b[38;5;241m=\u001b[39m final_outputs[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:660\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    653\u001b[0m         _log_deprecation(\n\u001b[0;32m    654\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    655\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m    659\u001b[0m             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date), instructions)\n\u001b[1;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py:241\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_arg_values(\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m                   maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m                   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python for-\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m \n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m while_loop(\n\u001b[0;32m    242\u001b[0m       cond\u001b[38;5;241m=\u001b[39mcond,\n\u001b[0;32m    243\u001b[0m       body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    244\u001b[0m       loop_vars\u001b[38;5;241m=\u001b[39mloop_vars,\n\u001b[0;32m    245\u001b[0m       shape_invariants\u001b[38;5;241m=\u001b[39mshape_invariants,\n\u001b[0;32m    246\u001b[0m       parallel_iterations\u001b[38;5;241m=\u001b[39mparallel_iterations,\n\u001b[0;32m    247\u001b[0m       back_prop\u001b[38;5;241m=\u001b[39mback_prop,\n\u001b[0;32m    248\u001b[0m       swap_memory\u001b[38;5;241m=\u001b[39mswap_memory,\n\u001b[0;32m    249\u001b[0m       name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    250\u001b[0m       maximum_iterations\u001b[38;5;241m=\u001b[39mmaximum_iterations,\n\u001b[0;32m    251\u001b[0m       return_same_structure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py:488\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m    485\u001b[0m loop_var_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(type_spec\u001b[38;5;241m.\u001b[39mtype_spec_from_value,\n\u001b[0;32m    486\u001b[0m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cond(\u001b[38;5;241m*\u001b[39mloop_vars):\n\u001b[1;32m--> 488\u001b[0m   loop_vars \u001b[38;5;241m=\u001b[39m body(\u001b[38;5;241m*\u001b[39mloop_vars)\n\u001b[0;32m    489\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    490\u001b[0m     packed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\while_loop.py:479\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m    476\u001b[0m     loop_vars \u001b[38;5;241m=\u001b[39m (counter, loop_vars)\n\u001b[0;32m    477\u001b[0m     cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m    478\u001b[0m         math_ops\u001b[38;5;241m.\u001b[39mlogical_and(i \u001b[38;5;241m<\u001b[39m maximum_iterations, orig_cond(\u001b[38;5;241m*\u001b[39mlv)))\n\u001b[1;32m--> 479\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, orig_body(\u001b[38;5;241m*\u001b[39mlv))\n\u001b[0;32m    480\u001b[0m   try_to_pack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executing_eagerly:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py:411\u001b[0m, in \u001b[0;36mrnn.<locals>._step\u001b[1;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[0;32m    409\u001b[0m current_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ta\u001b[38;5;241m.\u001b[39mread(time) \u001b[38;5;28;01mfor\u001b[39;00m ta \u001b[38;5;129;01min\u001b[39;00m input_ta)\n\u001b[0;32m    410\u001b[0m current_input \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpack_sequence_as(inputs, current_input)\n\u001b[1;32m--> 411\u001b[0m output, new_states \u001b[38;5;241m=\u001b[39m step_function(\n\u001b[0;32m    412\u001b[0m     current_input, \u001b[38;5;28mtuple\u001b[39m(states) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(constants)\n\u001b[0;32m    413\u001b[0m )\n\u001b[0;32m    414\u001b[0m flat_new_state \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(new_states)\n\u001b[0;32m    416\u001b[0m flat_output \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(output)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:338\u001b[0m, in \u001b[0;36mRNN.inner_loop.<locals>.step\u001b[1;34m(inputs, states)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(inputs, states):\n\u001b[1;32m--> 338\u001b[0m     output, new_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell(inputs, states, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcell_kwargs)\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mis_nested(new_states):\n\u001b[0;32m    340\u001b[0m         new_states \u001b[38;5;241m=\u001b[39m [new_states]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[0;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[0;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[0;32m     45\u001b[0m         call_fn,\n\u001b[0;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     47\u001b[0m     )\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:264\u001b[0m, in \u001b[0;36mLSTMCell.call\u001b[1;34m(self, inputs, states, training)\u001b[0m\n\u001b[0;32m    262\u001b[0m     c, o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_carry_and_output(x, h_tm1, c_tm1)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m     z \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmatmul(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel)\n\u001b[0;32m    266\u001b[0m     z \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmatmul(h_tm1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_kernel)\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\numpy.py:3440\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m   3438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[0;32m   3439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Matmul()\u001b[38;5;241m.\u001b[39msymbolic_call(x1, x2)\n\u001b[1;32m-> 3440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mmatmul(x1, x2)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:375\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m    373\u001b[0m     output_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    374\u001b[0m x1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(x1, compute_dtype)\n\u001b[1;32m--> 375\u001b[0m x2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(x2, compute_dtype)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_combined_batch_dimensions\u001b[39m(a, b, output_shape, fn_3d):\n\u001b[0;32m    378\u001b[0m     a_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(a, tf\u001b[38;5;241m.\u001b[39mSparseTensor)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1010\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m   1004\u001b[0m   x \u001b[38;5;241m=\u001b[39m indexed_slices\u001b[38;5;241m.\u001b[39mIndexedSlices(values_cast, x\u001b[38;5;241m.\u001b[39mindices, x\u001b[38;5;241m.\u001b[39mdense_shape)\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1006\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[1;32m-> 1010\u001b[0m   x \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1011\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_complex \u001b[38;5;129;01mand\u001b[39;00m base_type\u001b[38;5;241m.\u001b[39mis_floating:\n\u001b[0;32m   1012\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1013\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1014\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.  This will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscard the imaginary part and may not be what you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintended.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1017\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[1;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m    714\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[0;32m    715\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    207\u001b[0m overload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__tf_tensor__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m overload(dtype, name)  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[0;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:65\u001b[0m, in \u001b[0;36mVariable.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_tensor_v2(\n\u001b[0;32m    162\u001b[0m       value, dtype\u001b[38;5;241m=\u001b[39mdtype, dtype_hint\u001b[38;5;241m=\u001b[39mdtype_hint, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m    163\u001b[0m   )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m    172\u001b[0m     value, dtype, name, preferred_dtype\u001b[38;5;241m=\u001b[39mdtype_hint\n\u001b[0;32m    173\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m conversion_func(value, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname, as_ref\u001b[38;5;241m=\u001b[39mas_ref)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2331\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m var\u001b[38;5;241m.\u001b[39m_dense_var_to_tensor(dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname, as_ref\u001b[38;5;241m=\u001b[39mas_ref)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1577\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1575\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1577\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:629\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_value\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28;01mNone\u001b[39;00m, ignore_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 629\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_variable_op()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:813\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    811\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 813\u001b[0m   result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    816\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    817\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    818\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    819\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    820\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    821\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:803\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    802\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 803\u001b[0m result \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mread_variable_op(\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[0;32m    805\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:535\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m    536\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, resource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype)\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2eed7-3323-4e8e-9896-d7b320e000c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386c055-69d9-4d8f-8466-4d854364a8ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'encoding_dim': best['encoding_dim'],\n",
    "    'autoencoder_units': best['autoencoder_units'],\n",
    "    'lstm_units': best['lstm_units'],\n",
    "    'ae_dropout_rate': best['ae_dropout_rate'],\n",
    "    'ae_activity_reg': best['ae_activity_reg'],\n",
    "    'ae_learning_rate': best['ae_learning_rate'],\n",
    "    'ae_batch_size': best['ae_batch_size'],\n",
    "    'lstm_dropout_rate': best['lstm_dropout_rate'],\n",
    "    'lstm_learning_rate': best['lstm_learning_rate'],\n",
    "    'lstm_batch_size': best['lstm_batch_size']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa091308-3fad-496d-9434-acf75b187f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce6090-15ac-46f5-87db-50d9fd083f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_val, y_val, best_params):\n",
    "    # Extracting autoencoder parameters from the best params\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(best_params['encoding_dim']),\n",
    "        'hidden_layers': [int(best_params['autoencoder_units'])],\n",
    "        'dropout_rate': best_params['ae_dropout_rate'],\n",
    "        'activity_regularizer': best_params['ae_activity_reg'],\n",
    "        'learning_rate': best_params['ae_learning_rate'],\n",
    "        'batch_size': int(best_params['ae_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Extracting BiLSTM parameters from the best params\n",
    "    lstm_params = {\n",
    "        'lstm_units': int(best_params['lstm_units']),\n",
    "        'dropout_rate': best_params['lstm_dropout_rate'],\n",
    "        'learning_rate': best_params['lstm_learning_rate'],\n",
    "        'batch_size': int(best_params['lstm_batch_size'])\n",
    "    }\n",
    "\n",
    "    # Create the stacked model\n",
    "    autoencoder, encoder = create_deep_autoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        encoding_dim=autoencoder_params['encoding_dim'],\n",
    "        hidden_layers=autoencoder_params['hidden_layers'],\n",
    "        dropout_rate=autoencoder_params['dropout_rate'],\n",
    "        activity_regularizer=autoencoder_params['activity_regularizer']\n",
    "    )\n",
    "\n",
    "    # Compile and train the autoencoder\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=autoencoder_params['learning_rate']), loss='mse')\n",
    "    autoencoder.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=50,\n",
    "        batch_size=autoencoder_params['batch_size'],\n",
    "        validation_data=(X_val, X_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Encode the training and validation data\n",
    "    X_encoded_train = encoder.predict(X_train).astype('float32')\n",
    "    X_encoded_val = encoder.predict(X_val).astype('float32')\n",
    "\n",
    "    # Reshape the encoded data for LSTM input\n",
    "    X_encoded_train = np.expand_dims(X_encoded_train, axis=-1)\n",
    "    X_encoded_val = np.expand_dims(X_encoded_val, axis=-1)\n",
    "\n",
    "    # Create and compile the BiLSTM model\n",
    "    lstm_model = create_bilstm_model(\n",
    "        input_shape=X_encoded_train.shape,\n",
    "        lstm_units=lstm_params['lstm_units'],\n",
    "        dropout_rate=lstm_params['dropout_rate'],\n",
    "        output_dim=1  # Assuming binary classification\n",
    "    )\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lstm_params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the BiLSTM model\n",
    "    lstm_model.fit(\n",
    "        X_encoded_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=lstm_params['batch_size'],\n",
    "        validation_data=(X_encoded_val, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return lstm_model, X_encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e32b13-5664-4be9-bbdf-b42de01a9eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_model, X_encoded_val = train_final_model(X_train_val, y_train_val, X_test, y_test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d3d14-e02b-40a1-a4fe-9507fb91de5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_val_pred = lstm_model.predict(X_encoded_val).flatten()\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_val_pred_binary)\n",
    "f1 = f1_score(y_test, y_val_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_val_pred_binary).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e7fb7-b76d-4bbc-8f4a-7d41d0ac7890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bb75407-8d5a-472b-a5f0-0ab33d230263",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stacked Autoencoder & FNN Model - L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2ce6fba8-f46a-4300-b20b-02d83066789d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e8f74848-170b-419c-95e9-6ec0703f98cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_val = X_train_val.astype(np.float32)\n",
    "y_train_val = y_train_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "52e6d73c-478b-45b9-b257-a5f2c937d469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_float32(data):\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "34d3c773-a91d-4dcc-8f5f-47a711048b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, autoencoder_params):\n",
    "        self.autoencoder_params = autoencoder_params\n",
    "        self.encoder = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = ensure_float32(X)\n",
    "        autoencoder, encoder = create_deep_autoencoder(\n",
    "            input_dim=X.shape[1],\n",
    "            encoding_dim=int(self.autoencoder_params['encoding_dim']),\n",
    "            hidden_layers=[int(self.autoencoder_params['autoencoder_units'])],\n",
    "            dropout_rate=self.autoencoder_params['ae_dropout_rate'],\n",
    "            activity_regularizer=self.autoencoder_params['ae_activity_reg']\n",
    "        )\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=self.autoencoder_params['ae_learning_rate']), loss='mse')\n",
    "        autoencoder.fit(X, X, epochs=50, batch_size=int(self.autoencoder_params['ae_batch_size']), verbose=0)\n",
    "        self.encoder = encoder\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = ensure_float32(X)\n",
    "        return self.encoder.predict(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9d987ee3-dc58-46bf-8557-7b50123ba570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fnn_model(input_dim, fnn_units, dropout_rate, learning_rate):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    x = Dense(fnn_units, activation='relu')(input_layer)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "001be284-ce34-4723-a7df-b0fe42438d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    autoencoder_params = {\n",
    "        'encoding_dim': int(params['encoding_dim']),\n",
    "        'autoencoder_units': int(params['autoencoder_units']),\n",
    "        'ae_dropout_rate': params['ae_dropout_rate'],\n",
    "        'ae_activity_reg': params['ae_activity_reg'],\n",
    "        'ae_learning_rate': params['ae_learning_rate'],\n",
    "        'ae_batch_size': int(params['ae_batch_size'])\n",
    "    }\n",
    "    \n",
    "    fnn_params = {\n",
    "        'fnn_units': int(params['fnn_units']),\n",
    "        'fnn_dropout_rate': params['fnn_dropout_rate'],\n",
    "        'fnn_learning_rate': params['fnn_learning_rate'],\n",
    "        'fnn_batch_size': int(params['fnn_batch_size'])\n",
    "    }\n",
    "\n",
    "    autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "    fnn_classifier = KerasClassifier(\n",
    "        model=create_fnn_model,\n",
    "        input_dim=int(autoencoder_params['encoding_dim']),\n",
    "        fnn_units=fnn_params['fnn_units'],\n",
    "        dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "        learning_rate=fnn_params['fnn_learning_rate'],\n",
    "        epochs=50,\n",
    "        batch_size=fnn_params['fnn_batch_size'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('autoencoder', autoencoder_transformer),\n",
    "        ('fnn', fnn_classifier)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = cross_val_score(pipeline, X_train_val, y_train_val, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return {'loss': -np.mean(results), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "43b2c44d-8527-4510-9081-3082af18cf17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'encoding_dim': hp.quniform('encoding_dim', 10, 100, 1),\n",
    "    'autoencoder_units': hp.quniform('autoencoder_units', 50, 500, 1),\n",
    "    'ae_dropout_rate': hp.uniform('ae_dropout_rate', 0.1, 0.5),\n",
    "    'ae_activity_reg': hp.loguniform('ae_activity_reg', np.log(1e-7), np.log(1e-2)),\n",
    "    'ae_learning_rate': hp.loguniform('ae_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'ae_batch_size': hp.quniform('ae_batch_size', 16, 64, 1),\n",
    "    'fnn_units': hp.quniform('fnn_units', 50, 500, 1),\n",
    "    'fnn_dropout_rate': hp.uniform('fnn_dropout_rate', 0.1, 0.5),\n",
    "    'fnn_learning_rate': hp.loguniform('fnn_learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "    'fnn_batch_size': hp.quniform('fnn_batch_size', 16, 64, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa98836b-fad2-4098-97f8-fbb646b4e0d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step                                                \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step                                                 \n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step                                                \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step                                                 \n",
      "\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step                                                \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step                                                 \n",
      "\n",
      "100%|| 20/20 [08:29<00:00, 25.49s/trial, best loss: -0.9333333333333333]\n",
      "Best parameters:  {'ae_activity_reg': 3.3125569101435986e-07, 'ae_batch_size': 22.0, 'ae_dropout_rate': 0.1623512673341741, 'ae_learning_rate': 0.003834674127770905, 'autoencoder_units': 146.0, 'encoding_dim': 84.0, 'fnn_batch_size': 30.0, 'fnn_dropout_rate': 0.26515948628846636, 'fnn_learning_rate': 0.0005101527116195893, 'fnn_units': 419.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "print(\"Best parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d10a8087-6026-438c-847b-ea4667c97823",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {k: (int(v) if 'batch_size' in k or 'units' in k or 'encoding_dim' in k else float(v)) for k, v in best_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5848cf3b-6a6c-4447-a78e-4b58f1cced32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_final_model(X, y, best_params):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    fold_sensitivities = []\n",
    "    fold_specificities = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        autoencoder_params = {\n",
    "            'encoding_dim': best_params['encoding_dim'],\n",
    "            'autoencoder_units': best_params['autoencoder_units'],\n",
    "            'ae_dropout_rate': best_params['ae_dropout_rate'],\n",
    "            'ae_activity_reg': best_params['ae_activity_reg'],\n",
    "            'ae_learning_rate': best_params['ae_learning_rate'],\n",
    "            'ae_batch_size': best_params['ae_batch_size']\n",
    "        }\n",
    "        \n",
    "        fnn_params = {\n",
    "            'fnn_units': best_params['fnn_units'],\n",
    "            'fnn_dropout_rate': best_params['fnn_dropout_rate'],\n",
    "            'fnn_learning_rate': best_params['fnn_learning_rate'],\n",
    "            'fnn_batch_size': best_params['fnn_batch_size']\n",
    "        }\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        autoencoder_transformer = AutoencoderTransformer(autoencoder_params=autoencoder_params)\n",
    "        autoencoder_transformer.fit(X_train)\n",
    "        \n",
    "        # Encode the training and validation data\n",
    "        X_encoded_train = autoencoder_transformer.transform(X_train)\n",
    "        X_encoded_val = autoencoder_transformer.transform(X_val)\n",
    "\n",
    "        # Train the FNN on encoded data\n",
    "        fnn_model = create_fnn_model(\n",
    "            input_dim=X_encoded_train.shape[1],\n",
    "            fnn_units=fnn_params['fnn_units'],\n",
    "            dropout_rate=fnn_params['fnn_dropout_rate'],\n",
    "            learning_rate=fnn_params['fnn_learning_rate']\n",
    "        )\n",
    "        \n",
    "        fnn_model.fit(\n",
    "            X_encoded_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=fnn_params['fnn_batch_size'],\n",
    "            validation_data=(X_encoded_val, y_val),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Predict on validation data\n",
    "        y_val_pred = fnn_model.predict(X_encoded_val).flatten()\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "        f1 = f1_score(y_val, y_val_pred_binary)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_val_pred_binary).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "        fold_sensitivities.append(sensitivity)\n",
    "        fold_specificities.append(specificity)\n",
    "    \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    avg_sensitivity = np.mean(fold_sensitivities)\n",
    "    avg_specificity = np.mean(fold_specificities)\n",
    "\n",
    "    print(f\"Final Model - Accuracy: {avg_accuracy}\")\n",
    "    print(f\"Final Model - F1 Score: {avg_f1}\")\n",
    "    print(f\"Final Model - Sensitivity: {avg_sensitivity}\")\n",
    "    print(f\"Final Model - Specificity: {avg_specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f709040-371a-4028-be99-06b2035c3ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Final Model - Accuracy: 0.9277777777777778\n",
      "Final Model - F1 Score: 0.916048951048951\n",
      "Final Model - Sensitivity: 0.9000840336134454\n",
      "Final Model - Specificity: 0.9488351560719981\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_final_model(X_train_val, y_train_val, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92e958-55e8-4296-b146-1b403dad371e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
